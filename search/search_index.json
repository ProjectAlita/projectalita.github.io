{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ELITEA Documentation ELITEA is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations. Our Values: Democratize AI Access for all organizational levels with accessible, user-friendly AI technology. Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments. Foster Collaboration by providing environments where people can share their assets within projects and organization. Scale with Your Needs with a platform that scales from small teams to enterprise levels.","title":"Welcome to ELITEA Documentation"},{"location":"#welcome-to-elitea-documentation","text":"ELITEA is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations.","title":"Welcome to ELITEA Documentation"},{"location":"#our-values","text":"Democratize AI Access for all organizational levels with accessible, user-friendly AI technology. Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments. Foster Collaboration by providing environments where people can share their assets within projects and organization. Scale with Your Needs with a platform that scales from small teams to enterprise levels.","title":"Our Values:"},{"location":"faqs/","text":"Frequently Asked Questions Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with ELITEA, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of ELITEA. What You'll Find Here In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what ELITEA can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use ELITEA for optimal results. How to Use This Section Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section. Why an FAQ Section? We believe in empowering our users with knowledge. An informed user can better leverage ELITEA's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly. Let's Dive In! Ready to explore? Great! Your next step towards mastering ELITEA begins here. Navigate through the questions, uncover new insights, and elevate your ELITEA experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f FAQs How Can I Integrate Confluence as a Source Type in ELITEA? Answer Integrating Confluence with ELITEA allows you to seamlessly connect and utilize your Confluence data within ELITEA. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for ELITEA to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps ELITEA connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data ELITEA accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup . Example Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : [your token] Username : [your username] Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Frequently Asked Questions"},{"location":"faqs/#frequently-asked-questions","text":"Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with ELITEA, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of ELITEA.","title":"Frequently Asked Questions"},{"location":"faqs/#what-youll-find-here","text":"In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what ELITEA can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use ELITEA for optimal results.","title":"What You'll Find Here"},{"location":"faqs/#how-to-use-this-section","text":"Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section.","title":"How to Use This Section"},{"location":"faqs/#why-an-faq-section","text":"We believe in empowering our users with knowledge. An informed user can better leverage ELITEA's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly.","title":"Why an FAQ Section?"},{"location":"faqs/#lets-dive-in","text":"Ready to explore? Great! Your next step towards mastering ELITEA begins here. Navigate through the questions, uncover new insights, and elevate your ELITEA experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f","title":"Let's Dive In!"},{"location":"faqs/#faqs","text":"","title":"FAQs"},{"location":"faqs/#how-can-i-integrate-confluence-as-a-source-type-in-elitea","text":"","title":"How Can I Integrate Confluence as a Source Type in ELITEA?"},{"location":"faqs/#answer","text":"Integrating Confluence with ELITEA allows you to seamlessly connect and utilize your Confluence data within ELITEA. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for ELITEA to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps ELITEA connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data ELITEA accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup .","title":"Answer"},{"location":"faqs/#example","text":"Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : [your token] Username : [your username] Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Example"},{"location":"admin-guide/chat/","text":"Conversations ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models. Creating a Conversation Click the + Conversation button located at the top right corner or + icon next to CONVERSATIONS . Provide the Name . By default, it is set to \"New Conversation\". After creating Conversation add partiicpants to the conversation by clicking the PARTICIPANTS + button. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list. Private and Public Conversations Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private. Participants Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project or public ones which can be added to the conversation to execute them and get responses. Datasources : Already created datasources within the project or public ones which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project or public ones which can be added to the conversation to execute them and get responses. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants. How to Add a Participant To add a participant to a conversation: Click the Add participants button if you just created a conversation or + icon next to PARTICIPANTS . A pop-up window appears. Type the letters of the name or description of the available participant in the Search field. You can also filter and select required participant by type or tags. As soon as you see the participant that you need from the proposed list, click the Chat Now button on the participant card. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section. Note : You can also add several participants at once (by clicking in the cards) and then click the Add Participants button. How to Use a Participant Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"Select from the list or mention participant you wish to engage with.\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again. How to Configure/Modify Participants You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. If the agent has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. Actions for Conversation The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Note : Not applicable now. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Chat"},{"location":"admin-guide/chat/#conversations","text":"ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models.","title":"Conversations"},{"location":"admin-guide/chat/#creating-a-conversation","text":"Click the + Conversation button located at the top right corner or + icon next to CONVERSATIONS . Provide the Name . By default, it is set to \"New Conversation\". After creating Conversation add partiicpants to the conversation by clicking the PARTICIPANTS + button. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list.","title":"Creating a Conversation"},{"location":"admin-guide/chat/#private-and-public-conversations","text":"Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private.","title":"Private and Public Conversations"},{"location":"admin-guide/chat/#participants","text":"Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project or public ones which can be added to the conversation to execute them and get responses. Datasources : Already created datasources within the project or public ones which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project or public ones which can be added to the conversation to execute them and get responses. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants.","title":"Participants"},{"location":"admin-guide/chat/#how-to-add-a-participant","text":"To add a participant to a conversation: Click the Add participants button if you just created a conversation or + icon next to PARTICIPANTS . A pop-up window appears. Type the letters of the name or description of the available participant in the Search field. You can also filter and select required participant by type or tags. As soon as you see the participant that you need from the proposed list, click the Chat Now button on the participant card. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section. Note : You can also add several participants at once (by clicking in the cards) and then click the Add Participants button.","title":"How to Add a Participant"},{"location":"admin-guide/chat/#how-to-use-a-participant","text":"Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"Select from the list or mention participant you wish to engage with.\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again.","title":"How to Use a Participant"},{"location":"admin-guide/chat/#how-to-configuremodify-participants","text":"You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. If the agent has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon.","title":"How to Configure/Modify Participants"},{"location":"admin-guide/chat/#actions-for-conversation","text":"The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Note : Not applicable now. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Actions for Conversation"},{"location":"admin-guide/collections/","text":"Collections Private project - Collections menu The Collections menu within Private project serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've crafted. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections The Collection serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. How to Create a Collection Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection. Exploring Collections Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection How to Modify a Collection To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published. How to Filter Prompts within a Collection Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes. How to Publish a Collection To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain already published prompts before publication. How to Delete a Collection To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections. How to Export a Collection Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization. Collections Menu The Collections menu is a curated space of grouped prompts shared and published within the community. Layout of the Collections Menu Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community. Engaging with Collections Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage: Liking Collections Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: To like a collection, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the collection. Other Actions for Collections Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Collections"},{"location":"admin-guide/collections/#collections","text":"","title":"Collections"},{"location":"admin-guide/collections/#private-project-collections-menu","text":"The Collections menu within Private project serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've crafted. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections The Collection serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"Private project - Collections menu"},{"location":"admin-guide/collections/#how-to-create-a-collection","text":"Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection.","title":"How to Create a Collection"},{"location":"admin-guide/collections/#exploring-collections","text":"Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection","title":"Exploring Collections"},{"location":"admin-guide/collections/#how-to-modify-a-collection","text":"To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published.","title":"How to Modify a Collection"},{"location":"admin-guide/collections/#how-to-filter-prompts-within-a-collection","text":"Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes.","title":"How to Filter Prompts within a Collection"},{"location":"admin-guide/collections/#how-to-publish-a-collection","text":"To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain already published prompts before publication.","title":"How to Publish a Collection"},{"location":"admin-guide/collections/#how-to-delete-a-collection","text":"To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections.","title":"How to Delete a Collection"},{"location":"admin-guide/collections/#how-to-export-a-collection","text":"Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization.","title":"How to Export a Collection"},{"location":"admin-guide/collections/#collections-menu","text":"The Collections menu is a curated space of grouped prompts shared and published within the community.","title":"Collections Menu"},{"location":"admin-guide/collections/#layout-of-the-collections-menu","text":"Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community.","title":"Layout of the Collections Menu"},{"location":"admin-guide/collections/#engaging-with-collections","text":"Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage:","title":"Engaging with Collections"},{"location":"admin-guide/collections/#liking-collections","text":"Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: To like a collection, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the collection.","title":"Liking Collections"},{"location":"admin-guide/collections/#other-actions-for-collections","text":"Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Other Actions for Collections"},{"location":"admin-guide/datasources/","text":"Datasources Private project - Datasources menu Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information. Creating a Datasource To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation. Exploring Datasources Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage. Connecting a Dataset to the Datasource The initial step involves linking your dataset to the desired datasource: Press the + icon to start adding a new dataset. Enter a name for your dataset. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded. Source type - File ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported file types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Table This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning. Source type - GIT For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Confluence For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. The Secret and Password options are available. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. The Secret and Password options are available. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance. Source type - QTest Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - Utilize a confidential key configured in the Secrets feature within ELITEA HUB for enhanced security during API requests. This secret can be selected from the secrets you have set up previously. Password - an option for API access, that verifies authorized requesters through a password. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. DQL for QTest - this setting allows you to query and filter data before indexing it. Utilize DQL (Data Query Language) to define specific criteria that refine the data fetched from QTest, ensuring that only relevant data is processed and indexed. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\"). TRANSFORMERS Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing. SUMMARIZATION Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization model - select from available LLMs based on your document\u2019s complexity. Document summarization - enables summarization of the entire document. Chunk summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis. CONTEXT Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions. WELCOME MESSAGE The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the datasource. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this datasource for asking questions about FT Armenia\" \"Don't forget to double-check the generated responses\" CONVERSATION STARTERS The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the datasource. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the datasource. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the datasource. Examples of Conversation Starters : \"How to create a prompt?\" \"I am on bench, and want to know what activities can be done\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the datasource more efficient and standardized. Working with Your Dataset After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do: Chat The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation. To use the Chat and query info : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an Chat model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Search The Search feature allows you to quickly locate specific information within your indexed dataset. How to Conduct a Search : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Deduplicate The Deduplication is a handy feature for identifying duplicate information. How to Run Deduplication : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : More items will be excluded , as they will not be considered similar enough. This can be useful if you want to ensure that only highly unique content remains. Lower values : More items will be retained , as they will be considered similar enough. This can be useful if you want to keep more variations of the content. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Click the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Show differences : An option allowing to quickly show/hide differences. Download result : Allows you to save the deduplication results directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Public project - Datasources menu The Datasources menu within Public project showcases a collection of published and shared datasources within the community. Layout of the Datasources Menu The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community. Engaging with Published Datasources Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation: Liking Published Datasources Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource. Other Actions for Published Datasources Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Datasources"},{"location":"admin-guide/datasources/#datasources","text":"","title":"Datasources"},{"location":"admin-guide/datasources/#private-project-datasources-menu","text":"Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information.","title":"Private project - Datasources menu"},{"location":"admin-guide/datasources/#creating-a-datasource","text":"To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation.","title":"Creating a Datasource"},{"location":"admin-guide/datasources/#exploring-datasources","text":"Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage.","title":"Exploring Datasources"},{"location":"admin-guide/datasources/#connecting-a-dataset-to-the-datasource","text":"The initial step involves linking your dataset to the desired datasource: Press the + icon to start adding a new dataset. Enter a name for your dataset. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded.","title":"Connecting a Dataset to the Datasource"},{"location":"admin-guide/datasources/#source-type-file","text":"ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported file types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - File"},{"location":"admin-guide/datasources/#source-type-table","text":"This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning.","title":"Source type - Table"},{"location":"admin-guide/datasources/#source-type-git","text":"For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - GIT"},{"location":"admin-guide/datasources/#source-type-confluence","text":"For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. The Secret and Password options are available. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. The Secret and Password options are available. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance.","title":"Source type - Confluence"},{"location":"admin-guide/datasources/#source-type-qtest","text":"Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - Utilize a confidential key configured in the Secrets feature within ELITEA HUB for enhanced security during API requests. This secret can be selected from the secrets you have set up previously. Password - an option for API access, that verifies authorized requesters through a password. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. DQL for QTest - this setting allows you to query and filter data before indexing it. Utilize DQL (Data Query Language) to define specific criteria that refine the data fetched from QTest, ensuring that only relevant data is processed and indexed. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\").","title":"Source type - QTest"},{"location":"admin-guide/datasources/#transformers","text":"Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing.","title":"TRANSFORMERS"},{"location":"admin-guide/datasources/#summarization","text":"Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization model - select from available LLMs based on your document\u2019s complexity. Document summarization - enables summarization of the entire document. Chunk summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis.","title":"SUMMARIZATION"},{"location":"admin-guide/datasources/#context","text":"Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions.","title":"CONTEXT"},{"location":"admin-guide/datasources/#welcome-message","text":"The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the datasource. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this datasource for asking questions about FT Armenia\" \"Don't forget to double-check the generated responses\"","title":"WELCOME MESSAGE"},{"location":"admin-guide/datasources/#conversation-starters","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the datasource. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the datasource. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the datasource. Examples of Conversation Starters : \"How to create a prompt?\" \"I am on bench, and want to know what activities can be done\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the datasource more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"admin-guide/datasources/#working-with-your-dataset","text":"After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do:","title":"Working with Your Dataset"},{"location":"admin-guide/datasources/#chat","text":"The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation. To use the Chat and query info : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an Chat model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Chat"},{"location":"admin-guide/datasources/#search","text":"The Search feature allows you to quickly locate specific information within your indexed dataset. How to Conduct a Search : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Search"},{"location":"admin-guide/datasources/#deduplicate","text":"The Deduplication is a handy feature for identifying duplicate information. How to Run Deduplication : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : More items will be excluded , as they will not be considered similar enough. This can be useful if you want to ensure that only highly unique content remains. Lower values : More items will be retained , as they will be considered similar enough. This can be useful if you want to keep more variations of the content. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Click the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Show differences : An option allowing to quickly show/hide differences. Download result : Allows you to save the deduplication results directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Deduplicate"},{"location":"admin-guide/datasources/#public-project-datasources-menu","text":"The Datasources menu within Public project showcases a collection of published and shared datasources within the community.","title":"Public project - Datasources menu"},{"location":"admin-guide/datasources/#layout-of-the-datasources-menu","text":"The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community.","title":"Layout of the Datasources Menu"},{"location":"admin-guide/datasources/#engaging-with-published-datasources","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation:","title":"Engaging with Published Datasources"},{"location":"admin-guide/datasources/#liking-published-datasources","text":"Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource.","title":"Liking Published Datasources"},{"location":"admin-guide/datasources/#other-actions-for-published-datasources","text":"Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Other Actions for Published Datasources"},{"location":"admin-guide/intro/","text":"Introduction Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with Generative AI. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts, datasources and agents like never before. Key Features: Prompt Management : Effortlessly create, modify, and manage prompts. Keep track of different versions to ensure you always have access to your best work. Datasources : Play a pivotal role in enhancing the functionalities of ELITEA by integrating user-specific or project-specific data. This not only broadens the LLM's context but also enriches it with tailored information, making your interactions more relevant and insightful. Agents : Customize and create virtual assistants within ELITEA to handle specific tasks or sets of tasks. These agents integrate prompts, datasources, and external toolkits into a cohesive mechanism, enabling actions such as online searches or creating Jira tickets based on decisions made by LLMs. Chat : Combine all ELITEA features in one place with ELITEA Chat, an ultimate feature that allows for dynamic interaction and optimal results. Engage in conversations that utilize natural language to interact with human users and seamlessly integrate feedback from various participants like language models, datasources, and agents. Extensions : Transform your coding workflow with Alita Code and Alita Code Chat the ultimate AI-powered IDE extensions. Integrated seamlessly with VS Code and IntelliJ, these extensions offers intelligent suggestions, automates routine tasks, and provides unmatched adaptability to elevate your coding experience. Collection Integration : Organize your prompts, datasources and agents into Collections for better workflow management or to concentrate on specific themes or projects. Execution with Precision : Tailor the execution of prompts using various models and parameters to meet your specific needs, ensuring a customized experience. Advanced Creation Tools : Craft complex prompts, datasources and agents with precision using tools like variables, system prompts, Assistant Messages, and advanced tools. Powerful Search : Employ a robust search functionality to easily locate prompts, datasources and agents by tags, names, or descriptions. Community Engagement : Engage with the community by creating, modifying, and publishing prompts, datasources and agents. Enhance collaboration through sharing and liking content. ELITEA is designed to be a versatile and powerful tool, enhancing how you interact with AI technologies and manage data-driven projects. Whether you're coding, creating content, or managing complex data sets, ELITEA provides the tools you need to succeed. Let's embark on this journey to unlock the full potential of your ideas. Our user guide will walk you through every feature, ensuring you maximize your ELITEA experience. Accessing ELITEA To access and navigate through ELITEA, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://nexus.elitea.ai into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA. ELITEA - Main Interface The ELITEA's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating new items (conversation, prompt, datasource, agent and collection, importing entities), Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Chat, Prompts, Datasources, Agents, Collections and Artifacts. Search : A Search box available to find prompts, datasources, agents and collections by their names and descriptions. Note : The Search functionality operates within the selected menu and is not universal across the entire application. View Switcher : A tool for quickly switching between Card list and Table views. Quick button : A button that allows for the rapid creation of a new conversation, prompt, datasource, agent or collection. The default of this button ( +Conversation , +Prompt , +Datasource , +Agent or +Collection ) changes based on the selected menu. Notifications : Notification's bell allowing user to get notified about various events such as prompt publishing status within the ELITEA. Project Switcher : A tool for quickly switching among projects. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure various project and profile specific settings. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts, datasources and agents with the community. General Navigation and Management Across the Application This section provides an overview of the common functionalities and actions available across various menus and pages within the application. The aim is to ensure a consistent and efficient user experience by maintaining uniformity in navigation and management features across both Private and Public projects. Private Project Navigation : In a Private project, you have exclusive access to your personalized content across the following menus: Chat menu: Access all your private and public conversations, allowing for seamless communication and collaboration. Prompts menu: View and manage all the prompts you have created, enabling easy modification and reuse. Datasources menu: Contains all the datasources you have developed. Agents menu: Access all your created agents, each designed to perform specific tasks or sets of tasks. Collections menu: Manage your collections of prompts, datasources, and agents, organized for specific projects or themes. Artifacts menu: Utilize the Artifacts toolkit to create Buckets in ELITEA for saving, updating (appending), reading, and deleting files. Artifacts serve as a temporary file storage solution, enhancing your project's data management capabilities. Public Project Navigation : In a Public project, you can engage with the community and explore content created by other users through the following sections: Prompts menu: Navigate through the Latest prompts, explore prompts you've liked (My Likes), and discover Trending prompts within the community. Datasources menu: Access the Latest datasources, view datasources you've liked (My Likes), and explore Trending datasources shared by the community. Agents menu: Discover the Latest agents, check out agents you've liked (My Likes), and find Trending agents that are popular in the community. Collections menu: Explore the Latest collections, view collections you've liked (My Likes), and discover Trending collections that are gaining attention. While the context may vary depending on the specific page you're viewing, the core principles of action and functionality remain consistent. This unified approach ensures that whether you are navigating a private or public project, the experience is intuitive and user-friendly, facilitating effective management and exploration of content within the application. Common Viewing Options Card list view : Offers a compact, card-format snapshot of items like prompts, datasources, agents and collections, making it easy to visually scan through published materials. Table view : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis. Search and Filtering Functionality Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes. Sorting Options (Detailed View Only) Name & Description : Alphabetically organize published items by their names, providing an effortless method to find specific titles. Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. Likes : Order the items by the number of likes they have received. This functionality is applicable only for menus within Public project. Authors : Sort the items by the author's name. This functionality is applicable only for menus within Public project. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment. Discover - Menus ELITEA application consists of the following main menus: Chat Prompts Datasources Agents Collections Artifacts Navigation : To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu.","title":"Get Started"},{"location":"admin-guide/intro/#introduction","text":"Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with Generative AI. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts, datasources and agents like never before. Key Features: Prompt Management : Effortlessly create, modify, and manage prompts. Keep track of different versions to ensure you always have access to your best work. Datasources : Play a pivotal role in enhancing the functionalities of ELITEA by integrating user-specific or project-specific data. This not only broadens the LLM's context but also enriches it with tailored information, making your interactions more relevant and insightful. Agents : Customize and create virtual assistants within ELITEA to handle specific tasks or sets of tasks. These agents integrate prompts, datasources, and external toolkits into a cohesive mechanism, enabling actions such as online searches or creating Jira tickets based on decisions made by LLMs. Chat : Combine all ELITEA features in one place with ELITEA Chat, an ultimate feature that allows for dynamic interaction and optimal results. Engage in conversations that utilize natural language to interact with human users and seamlessly integrate feedback from various participants like language models, datasources, and agents. Extensions : Transform your coding workflow with Alita Code and Alita Code Chat the ultimate AI-powered IDE extensions. Integrated seamlessly with VS Code and IntelliJ, these extensions offers intelligent suggestions, automates routine tasks, and provides unmatched adaptability to elevate your coding experience. Collection Integration : Organize your prompts, datasources and agents into Collections for better workflow management or to concentrate on specific themes or projects. Execution with Precision : Tailor the execution of prompts using various models and parameters to meet your specific needs, ensuring a customized experience. Advanced Creation Tools : Craft complex prompts, datasources and agents with precision using tools like variables, system prompts, Assistant Messages, and advanced tools. Powerful Search : Employ a robust search functionality to easily locate prompts, datasources and agents by tags, names, or descriptions. Community Engagement : Engage with the community by creating, modifying, and publishing prompts, datasources and agents. Enhance collaboration through sharing and liking content. ELITEA is designed to be a versatile and powerful tool, enhancing how you interact with AI technologies and manage data-driven projects. Whether you're coding, creating content, or managing complex data sets, ELITEA provides the tools you need to succeed. Let's embark on this journey to unlock the full potential of your ideas. Our user guide will walk you through every feature, ensuring you maximize your ELITEA experience.","title":"Introduction"},{"location":"admin-guide/intro/#accessing-elitea","text":"To access and navigate through ELITEA, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://nexus.elitea.ai into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA.","title":"Accessing ELITEA"},{"location":"admin-guide/intro/#elitea-main-interface","text":"The ELITEA's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating new items (conversation, prompt, datasource, agent and collection, importing entities), Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Chat, Prompts, Datasources, Agents, Collections and Artifacts. Search : A Search box available to find prompts, datasources, agents and collections by their names and descriptions. Note : The Search functionality operates within the selected menu and is not universal across the entire application. View Switcher : A tool for quickly switching between Card list and Table views. Quick button : A button that allows for the rapid creation of a new conversation, prompt, datasource, agent or collection. The default of this button ( +Conversation , +Prompt , +Datasource , +Agent or +Collection ) changes based on the selected menu. Notifications : Notification's bell allowing user to get notified about various events such as prompt publishing status within the ELITEA. Project Switcher : A tool for quickly switching among projects. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure various project and profile specific settings. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts, datasources and agents with the community.","title":"ELITEA - Main Interface"},{"location":"admin-guide/intro/#general-navigation-and-management-across-the-application","text":"This section provides an overview of the common functionalities and actions available across various menus and pages within the application. The aim is to ensure a consistent and efficient user experience by maintaining uniformity in navigation and management features across both Private and Public projects. Private Project Navigation : In a Private project, you have exclusive access to your personalized content across the following menus: Chat menu: Access all your private and public conversations, allowing for seamless communication and collaboration. Prompts menu: View and manage all the prompts you have created, enabling easy modification and reuse. Datasources menu: Contains all the datasources you have developed. Agents menu: Access all your created agents, each designed to perform specific tasks or sets of tasks. Collections menu: Manage your collections of prompts, datasources, and agents, organized for specific projects or themes. Artifacts menu: Utilize the Artifacts toolkit to create Buckets in ELITEA for saving, updating (appending), reading, and deleting files. Artifacts serve as a temporary file storage solution, enhancing your project's data management capabilities. Public Project Navigation : In a Public project, you can engage with the community and explore content created by other users through the following sections: Prompts menu: Navigate through the Latest prompts, explore prompts you've liked (My Likes), and discover Trending prompts within the community. Datasources menu: Access the Latest datasources, view datasources you've liked (My Likes), and explore Trending datasources shared by the community. Agents menu: Discover the Latest agents, check out agents you've liked (My Likes), and find Trending agents that are popular in the community. Collections menu: Explore the Latest collections, view collections you've liked (My Likes), and discover Trending collections that are gaining attention. While the context may vary depending on the specific page you're viewing, the core principles of action and functionality remain consistent. This unified approach ensures that whether you are navigating a private or public project, the experience is intuitive and user-friendly, facilitating effective management and exploration of content within the application.","title":"General Navigation and Management Across the Application"},{"location":"admin-guide/intro/#common-viewing-options","text":"Card list view : Offers a compact, card-format snapshot of items like prompts, datasources, agents and collections, making it easy to visually scan through published materials. Table view : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis.","title":"Common Viewing Options"},{"location":"admin-guide/intro/#search-and-filtering-functionality","text":"Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes.","title":"Search and Filtering Functionality"},{"location":"admin-guide/intro/#sorting-options-detailed-view-only","text":"Name & Description : Alphabetically organize published items by their names, providing an effortless method to find specific titles. Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. Likes : Order the items by the number of likes they have received. This functionality is applicable only for menus within Public project. Authors : Sort the items by the author's name. This functionality is applicable only for menus within Public project. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment.","title":"Sorting Options (Detailed View Only)"},{"location":"admin-guide/intro/#discover-menus","text":"ELITEA application consists of the following main menus: Chat Prompts Datasources Agents Collections Artifacts Navigation : To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu.","title":"Discover - Menus"},{"location":"admin-guide/settings/","text":"Settings The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. The Settings consists of several tabs and settings each dedicated to specific functionalities: Profile : Customize your user profile within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Code Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Projects : Manage users within project. This tab is only available for the user within admin permissions within the project. Theme : Switch between Dark and Light theme for the whole application. Log out : Securely log out from the ELITEA. Navigation : To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section. Profile In the Profile , you\u2019re presented with options to personalize your account within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported. Monitoring The Monitoring feature in ELITEA is designed to provide a comprehensive overview of the application's usage and performance. This feature is essential for administrators and users who want to gain insights into various aspects of the application, from user engagement to the effectiveness of configured artifacts like prompts, datasources, and agents. By leveraging the detailed charts and statistics available within the Monitoring feature, you can make informed decisions to optimize the performance and user experience of your ELITEA application. This section will guide you through the various components of the Monitoring feature, including configuration options, key metrics, adoption and usage statistics, sentiment analysis, accuracy metrics, prompt topics, and topics summary. Each of these components offers valuable insights that can help you understand how the application is being used and how it can be improved. Configuration Options At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Projects : A dropdown lits allowing you to select the project. Note : For your Private project, you can only see your private project data. If you have an admin role in another projects, you can select other projects to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. Aggregation : A dropdown list providing options to view aggregated data over different time periods. You can choose from Hour , Day , Week , Two Weeks , Three Weeks , and Month to tailor the data aggregation to your specific needs. Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations. Key Metrics Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the ELITEA application. Tokens In : The number of tokens consumed by the ELITEA application. Tokens Out : The number of tokens generated by the ELITEA application. Engagement : The percentage of active users out of all users who logged into ELITEA for the selected period, indicating the level of interaction with the application. Acceptance rate : The percentage of interactions during the selected period where users accepted the generated output by copying, downloading, or saving it, reflecting user satisfaction and utility of the results. Prompts : The total number of prompts created. Agents : The total number of agents created. Conversations : The total number of conversations created. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period. Adoption and Usage Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy. Acceptance Rate The Acceptance Rate section provides a comprehensive view of user interactions with the ELITEA application, focusing on how often users accept the generated outputs. This section includes visualizations that help you understand user satisfaction and the effectiveness of the system's responses. Acceptance Rate Chart The Acceptance Rate Chart displays the number of accepted and not accepted interactions for the selected period and filter options. This chart helps you assess how frequently users find the generated outputs useful enough to accept by copying, downloading, or saving them. Accepted Interactions : This metric shows the count of interactions where user(s) have accepted the generated output, indicating satisfaction and utility. Not Accepted Interactions : This metric reflects the number of interactions where user(s) did not accept the output, suggesting areas for potential improvement in response quality. By analyzing the Acceptance Rate Chart, you can gain insights into user satisfaction levels and identify opportunities to enhance the effectiveness of the ELITEA application, ultimately improving the overall user experience. Sentiments The Sentiments section provides a visual representation of the emotional tone of both user inputs and the outputs generated by LLMs. Understanding sentiment is crucial for tailoring responses to better meet user needs and improve overall interaction quality. Sentiment Analysis Overview Sentiment analysis categorizes text into three primary emotional states: Positive : Indicates a favorable or happy emotional tone. Negative : Indicates an unfavorable or unhappy emotional tone. Neutral : Indicates a neutral or indifferent emotional tone. ELITEA performs sentiment analysis on user inputs to gauge the user's emotional state. This capability is particularly important for providing high-quality customer service, as the LLM can adjust its response tone and content based on the user's emotions. Visual Representation The Sentiments section includes two pie charts that offer a clear visual representation of sentiment distribution: Human Input : This pie chart shows the sentiment distribution of user inputs. It helps you understand how users are feeling when they interact with the LLMs. LLM Output : This pie chart displays the sentiment distribution of LLM's outputs. It helps you ensure that the responses generated by the LLM are appropriate and aligned with user emotions. Practical Applications Understanding sentiment can significantly enhance the user experience in several ways: Customer Service : By analyzing the sentiment of user inputs, LLMs can adjust its responses to be more empathetic and supportive, thereby improving customer satisfaction. User Engagement : Monitoring sentiment trends over time can help you identify patterns in user behavior and adjust your strategies accordingly. Content Moderation : Sentiment analysis can be used to flag potentially harmful or inappropriate content, ensuring a safer and more positive interaction environment. Accuracy The Accuracy section provides detailed insights into the performance and reliability of the ELITEA application. This section includes various metrics and visualizations that help you understand how well the system is responding to user inputs and how effective your configured artifacts (prompts, datasources, agents, conversations) are. Relevance The Relevance metric is divided into two key lines: Input vs Context : This line measures the relevance of the user's input (question or query) against the context of the artifact (prompt, datasource, agent or conversation). In the ELITEA, \"context\" refers to the configured instructions for the artifact. A higher relevance score indicates that the user's input closely matches the context, making it easier for the LLM to provide accurate responses. Output vs Input : This line measures the relevance of the generated output by the LLM against the user's input. A higher relevance score here indicates that the output is closely aligned with the user's query, ensuring that the response is appropriate and useful. Note : The maximum value for relevance is 6. The higher the score, the better the relevance, indicating a more accurate and contextually appropriate interaction. Reliability The Reliability Score answers the question of whether there is enough context to respond accurately to the user's questions or queries. This metric helps you gauge the confidence level of the LLM's responses. Note : The maximum reliability score is 10. A higher score indicates that there is sufficient context to provide a correct and reliable response to the user's query. Instruction Quality vs Usage The Instruction Quality vs Usage is a 2x2 matrix that helps you evaluate the effectiveness and utilization of your artifacts (prompts, agents, datasources or conversations): Low Quality, Low Usage : Artifacts in this box have low quality scores and are rarely used. These artifacts may need to be re-evaluated or improved. High Quality, Low Usage : Artifacts in this box have high quality scores but are not frequently used. Efforts should be made to promote these high-quality artifacts to increase their usage. High Quality, High Usage : Artifacts in this box have high quality scores and are frequently used. These are your most effective artifacts and should be maintained. Low Quality, High Usage : Artifacts in this box have low quality scores but are frequently used. These artifacts should be improved in quality or their usage should be reduced in favor of higher-quality alternatives. Matrix legend : Quality Score : The maximum quality score is 4. A higher score indicates better quality. Calls : This metric shows how many times an artifact has been used. Depending on the context (matrix box), a higher number of calls can be either positive or negative. By analyzing these metrics, you can make informed decisions to improve the accuracy and reliability of your Alita AI application, ensuring a better user experience. Prompt Topics The Prompt Topics section provides an automatic classification of the available artifacts (prompts, datasources, and agents) within the Alita AI application. This section helps you understand the distribution and focus areas of your artifacts, enabling you to identify trends and gaps in your content. Chart Components The Prompt Topics section displays a clustered column chart that categorizes your artifacts by topic. This visual representation allows you to quickly see how many prompts, datasources, or agents are associated with each topic. The clustered column chart includes the following components: Items : Indicates the number of artifacts associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of your artifacts. Practical Applications Understanding the distribution of your artifacts across different topics can provide several benefits: Content Gaps : Identify topics with fewer artifacts, indicating potential areas where additional content may be needed. Content Focus : Recognize topics with a high number of artifacts, helping you understand the primary focus areas of your users. Resource Allocation : Allocate resources more effectively by focusing on topics that require more attention or improvement. By leveraging the insights provided by the Prompt Topics section, you can ensure that your application covers a comprehensive range of topics, enhancing the overall user experience and effectiveness of the application. Topics Summary The Topics Summary section provides an automatic classification of user inputs, categorizing the topics that users have queried or questioned about. This section helps you understand user interests and the most frequently discussed topics within ELITEA. Chart Components The Topics Summary section displays a clustered column chart that categorizes user inputs by topic. This visual representation allows you to quickly see how many times users have queried information for each topic within a selected timeframe. The clustered column chart includes the following components: Items : Indicates the number of user queries associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of user queries. Practical Applications Understanding the distribution of user queries across different topics can provide several benefits: User Interests : Identify the topics that users are most interested in, allowing you to tailor your content and responses to better meet their needs. Content Gaps : Recognize topics with fewer user queries, indicating potential areas where additional content or promotion may be needed. Trend Analysis : Monitor how user interests evolve over time, helping you stay ahead of emerging trends and adjust your strategies accordingly. By leveraging the insights provided by the Topics Summary section, you can ensure that ELITEA is aligned with user interests, enhancing the overall user experience and effectiveness of the application. The Monitoring feature in ELITEA offers a robust set of tools and metrics to help you understand the performance and usage of your application. By utilizing the various charts and statistics available, you can gain valuable insights into user engagement, sentiment, accuracy, and the distribution of topics within your project. These insights are crucial for making data-driven decisions that can enhance the overall user experience and effectiveness of your ELITEA application. Whether you are looking to improve customer's experience through sentiment analysis, optimize the relevance and reliability of LLM responses, or identify content gaps and user interests, the Monitoring feature provides the necessary data to guide your efforts. By regularly reviewing and analyzing these metrics, you can ensure that your project remains aligned with user needs and continues to perform at its best. By leveraging the comprehensive monitoring capabilities of ELITEA, you can create a more responsive, efficient, and user-friendly application, ultimately leading to higher user satisfaction and better overall performance. Configuration The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Code Chat. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential. To create a token: Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings and the Download Jetbrains Settings icons will appear next to the created token. This allows you to download the configuration files to integrate and configure the ELITEA project with Alita Code extensions on VSCode and IntelliJ respectively. For more information about how to setup it, please refer to the Alita Code Documentation . Deployments The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations. Creating a New Deployment for EPAM AI Dial To set up a new deployment for EPAM AI Dial within your system, follow these detailed steps: Obtain API Key : Important : Before proceeding, you must obtain a separate API Key from the EPAM DIAL team. This key is essential for authenticating and enabling communication with the AI Dial services. API Key Retrieval : Once you have received the API Key and any additional required information via email, return to this page to input these details. Initiate Deployment Creation : Click the + icon to start creating a new deployment. Select Deployment Type : From the list of available deployment types, select AI Dial . Configure Deployment Details : In the configuration window, fill in the following information: Name : Enter a descriptive name for the deployment. This name will be displayed alongside LLM models configured with this deployment. API Base : For EPAM AI Dial, use https://ai-proxy.lab.epam.com as the API Base. Secret API Key : Paste the API Key that you received from the AI Dial team. API Version : Enter the API version information provided by the AI Dial team. Add Models to Deployment : Click the + icon to add one or more models associated with this deployment. For each model, provide the model's name, maximum input tokens, and capabilities. Important : Ensure that you enter the correct model name as used in EPAM AI DIAL. For detailed information on model specifications and configurations, refer to the EPAM AI Dial documentation . Click Save to complete the creation of the deployment. By following these steps, you can successfully create and configure a new deployment for EPAM AI Dial, enabling you to leverage advanced capabilities within your projects. Integrations The Integrations menu in ELITEA is designed to enhance the platform's functionality and flexibility by allowing users to connect with essential external tools such as Jira, Confluence, Testrail, and GitHub. These integrations enable seamless data flow and collaboration across different platforms, enhancing productivity and efficiency. Once configured, these integrations can be selected as configurations in the Agent's tool setup for each corresponding tool, allowing for streamlined operations within ELITEA. You can create integrations in both Private workspaces and Team projects, providing versatility in managing your connections. Confluence Integration Setup To set up a Confluence integration, follow these step-by-step instructions: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Confluence : From the available options, select Confluence . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"Conf_Integration\". URL : Enter the Confluence URL for your organization, e.g., https://kb.epam.com/ . Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your Confluence integration is now configured and ready to use. GitHub Integration Setup For GitHub integration, choose from the following authentication options: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Confluence : From the available options, select GitHub . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"GitHub_Integration\". Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Anonymous : Select this option, if no anuthentication is required. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your GitHub integration is now configured and ready to use. Jira Integration Setup To set up a Jira integration, follow these step-by-step instructions: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Jira : From the available options, select Jira . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"Jira_Integration\". URL : Enter the Jira URL for your organization, e.g., https://jiraeu.epam.com/ . Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your Jira integration is now configured and ready to use. TestRail Integration Setup To set up a Testrail integration, provide the following details: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Jira : From the available options, select TestRail . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"TestRail_Integration\". URL : Enter the TestRail URL for your organization, e.g., https://testrail.epam.com/ . Email : Enter the email used for authentication. Authentication Options : Choose your preferred method for secure connection: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your TestRail integration is now configured and ready to use. By setting up these integrations, you can streamline workflows and enhance collaboration across different platforms, making ELITEA a more powerful tool for your projects. Projects The Projects menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Note : It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Groups The Groups feature in ELITEA is designed to facilitate efficient management and monitoring of multiple projects by admins or managers. This feature allows you to consolidate several projects under a single group, making it easier to oversee and coordinate activities across these projects. If you are an admin of two or more projects, you can leverage the Groups feature to organize and monitor your projects collectively: Create a New Group : Click the Pencil icon to initiate the creation of a new group. You will be prompted to name the group and select the projects you wish to include. Add Projects to Existing Group : If you already have established groups, you can add additional projects to these groups. This grouping functionality not only simplifies the administrative workload but also enhances the visibility and control over multiple projects, enabling more effective management and monitoring. Teammates The Teammates feature in ELITEA is specifically crafted to streamline the process of collaborating within projects by allowing you to invite new users (teammates) and assign them appropriate roles. These roles include system, admin, editor, and viewer, each providing different levels of access and control within the project. Note : Only users with an admin role are empowered to invite new members. This ensures that the invitation and role assignment process is managed by users with appropriate authority and understanding of the project\u2019s needs. Inviting New Teammates : Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Teammates , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Teammates : The Teammates table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name. Secrets The Secrets feature in ELITEA serves as a secure vault designed to store and manage sensitive information such as passwords, tokens, API keys, and other authentication details. This centralized system allows you to configure secrets once and utilize them across various components, such as Agent's toolkits within ELITEA. Creating a Secret : To add a new secret to the vault, follow these steps: Click the + icon to initiate the creation of a new secret. Enter a descriptive name for the secret to help you identify its use. In the Value field, input the token, password, API key, or any other authentication details. Once configured, this secret can now be selected and used within various components of ELITEA. Managing Secrets : The management of secrets is straightforward and secure, facilitated by the Secrets table which displays all your configured secrets: View Secret : Click the Eye icon to reveal the value of a configured secret. This allows you to quickly check the details without modifying them. Copy Secret : Easily copy the secret value to your clipboard (by clicking the hidden value) for use in configurations or integrations. Hide Secret : Hide the secret from the interface to maintain security when not actively managing the secret. Modify Secret : Update the value of the secret if the existing credentials change or need to be corrected. Delete Secret : Remove a secret permanently from the vault if it is no longer needed or if security concerns necessitate its deletion. This feature enhances the security and efficiency of managing sensitive information within ELITEA, ensuring that authentication details are handled in a secure, centralized manner.","title":"Settings"},{"location":"admin-guide/settings/#settings","text":"The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. The Settings consists of several tabs and settings each dedicated to specific functionalities: Profile : Customize your user profile within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Code Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Projects : Manage users within project. This tab is only available for the user within admin permissions within the project. Theme : Switch between Dark and Light theme for the whole application. Log out : Securely log out from the ELITEA. Navigation : To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section.","title":"Settings"},{"location":"admin-guide/settings/#profile","text":"In the Profile , you\u2019re presented with options to personalize your account within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported.","title":"Profile"},{"location":"admin-guide/settings/#monitoring","text":"The Monitoring feature in ELITEA is designed to provide a comprehensive overview of the application's usage and performance. This feature is essential for administrators and users who want to gain insights into various aspects of the application, from user engagement to the effectiveness of configured artifacts like prompts, datasources, and agents. By leveraging the detailed charts and statistics available within the Monitoring feature, you can make informed decisions to optimize the performance and user experience of your ELITEA application. This section will guide you through the various components of the Monitoring feature, including configuration options, key metrics, adoption and usage statistics, sentiment analysis, accuracy metrics, prompt topics, and topics summary. Each of these components offers valuable insights that can help you understand how the application is being used and how it can be improved.","title":"Monitoring"},{"location":"admin-guide/settings/#configuration-options","text":"At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Projects : A dropdown lits allowing you to select the project. Note : For your Private project, you can only see your private project data. If you have an admin role in another projects, you can select other projects to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. Aggregation : A dropdown list providing options to view aggregated data over different time periods. You can choose from Hour , Day , Week , Two Weeks , Three Weeks , and Month to tailor the data aggregation to your specific needs. Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations.","title":"Configuration Options"},{"location":"admin-guide/settings/#key-metrics","text":"Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the ELITEA application. Tokens In : The number of tokens consumed by the ELITEA application. Tokens Out : The number of tokens generated by the ELITEA application. Engagement : The percentage of active users out of all users who logged into ELITEA for the selected period, indicating the level of interaction with the application. Acceptance rate : The percentage of interactions during the selected period where users accepted the generated output by copying, downloading, or saving it, reflecting user satisfaction and utility of the results. Prompts : The total number of prompts created. Agents : The total number of agents created. Conversations : The total number of conversations created. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period.","title":"Key Metrics"},{"location":"admin-guide/settings/#adoption-and-usage","text":"Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy.","title":"Adoption and Usage"},{"location":"admin-guide/settings/#acceptance-rate","text":"The Acceptance Rate section provides a comprehensive view of user interactions with the ELITEA application, focusing on how often users accept the generated outputs. This section includes visualizations that help you understand user satisfaction and the effectiveness of the system's responses. Acceptance Rate Chart The Acceptance Rate Chart displays the number of accepted and not accepted interactions for the selected period and filter options. This chart helps you assess how frequently users find the generated outputs useful enough to accept by copying, downloading, or saving them. Accepted Interactions : This metric shows the count of interactions where user(s) have accepted the generated output, indicating satisfaction and utility. Not Accepted Interactions : This metric reflects the number of interactions where user(s) did not accept the output, suggesting areas for potential improvement in response quality. By analyzing the Acceptance Rate Chart, you can gain insights into user satisfaction levels and identify opportunities to enhance the effectiveness of the ELITEA application, ultimately improving the overall user experience.","title":"Acceptance Rate"},{"location":"admin-guide/settings/#sentiments","text":"The Sentiments section provides a visual representation of the emotional tone of both user inputs and the outputs generated by LLMs. Understanding sentiment is crucial for tailoring responses to better meet user needs and improve overall interaction quality.","title":"Sentiments"},{"location":"admin-guide/settings/#sentiment-analysis-overview","text":"Sentiment analysis categorizes text into three primary emotional states: Positive : Indicates a favorable or happy emotional tone. Negative : Indicates an unfavorable or unhappy emotional tone. Neutral : Indicates a neutral or indifferent emotional tone. ELITEA performs sentiment analysis on user inputs to gauge the user's emotional state. This capability is particularly important for providing high-quality customer service, as the LLM can adjust its response tone and content based on the user's emotions.","title":"Sentiment Analysis Overview"},{"location":"admin-guide/settings/#visual-representation","text":"The Sentiments section includes two pie charts that offer a clear visual representation of sentiment distribution: Human Input : This pie chart shows the sentiment distribution of user inputs. It helps you understand how users are feeling when they interact with the LLMs. LLM Output : This pie chart displays the sentiment distribution of LLM's outputs. It helps you ensure that the responses generated by the LLM are appropriate and aligned with user emotions.","title":"Visual Representation"},{"location":"admin-guide/settings/#practical-applications","text":"Understanding sentiment can significantly enhance the user experience in several ways: Customer Service : By analyzing the sentiment of user inputs, LLMs can adjust its responses to be more empathetic and supportive, thereby improving customer satisfaction. User Engagement : Monitoring sentiment trends over time can help you identify patterns in user behavior and adjust your strategies accordingly. Content Moderation : Sentiment analysis can be used to flag potentially harmful or inappropriate content, ensuring a safer and more positive interaction environment.","title":"Practical Applications"},{"location":"admin-guide/settings/#accuracy","text":"The Accuracy section provides detailed insights into the performance and reliability of the ELITEA application. This section includes various metrics and visualizations that help you understand how well the system is responding to user inputs and how effective your configured artifacts (prompts, datasources, agents, conversations) are.","title":"Accuracy"},{"location":"admin-guide/settings/#relevance","text":"The Relevance metric is divided into two key lines: Input vs Context : This line measures the relevance of the user's input (question or query) against the context of the artifact (prompt, datasource, agent or conversation). In the ELITEA, \"context\" refers to the configured instructions for the artifact. A higher relevance score indicates that the user's input closely matches the context, making it easier for the LLM to provide accurate responses. Output vs Input : This line measures the relevance of the generated output by the LLM against the user's input. A higher relevance score here indicates that the output is closely aligned with the user's query, ensuring that the response is appropriate and useful. Note : The maximum value for relevance is 6. The higher the score, the better the relevance, indicating a more accurate and contextually appropriate interaction.","title":"Relevance"},{"location":"admin-guide/settings/#reliability","text":"The Reliability Score answers the question of whether there is enough context to respond accurately to the user's questions or queries. This metric helps you gauge the confidence level of the LLM's responses. Note : The maximum reliability score is 10. A higher score indicates that there is sufficient context to provide a correct and reliable response to the user's query.","title":"Reliability"},{"location":"admin-guide/settings/#instruction-quality-vs-usage","text":"The Instruction Quality vs Usage is a 2x2 matrix that helps you evaluate the effectiveness and utilization of your artifacts (prompts, agents, datasources or conversations): Low Quality, Low Usage : Artifacts in this box have low quality scores and are rarely used. These artifacts may need to be re-evaluated or improved. High Quality, Low Usage : Artifacts in this box have high quality scores but are not frequently used. Efforts should be made to promote these high-quality artifacts to increase their usage. High Quality, High Usage : Artifacts in this box have high quality scores and are frequently used. These are your most effective artifacts and should be maintained. Low Quality, High Usage : Artifacts in this box have low quality scores but are frequently used. These artifacts should be improved in quality or their usage should be reduced in favor of higher-quality alternatives. Matrix legend : Quality Score : The maximum quality score is 4. A higher score indicates better quality. Calls : This metric shows how many times an artifact has been used. Depending on the context (matrix box), a higher number of calls can be either positive or negative. By analyzing these metrics, you can make informed decisions to improve the accuracy and reliability of your Alita AI application, ensuring a better user experience.","title":"Instruction Quality vs Usage"},{"location":"admin-guide/settings/#prompt-topics","text":"The Prompt Topics section provides an automatic classification of the available artifacts (prompts, datasources, and agents) within the Alita AI application. This section helps you understand the distribution and focus areas of your artifacts, enabling you to identify trends and gaps in your content.","title":"Prompt Topics"},{"location":"admin-guide/settings/#chart-components","text":"The Prompt Topics section displays a clustered column chart that categorizes your artifacts by topic. This visual representation allows you to quickly see how many prompts, datasources, or agents are associated with each topic. The clustered column chart includes the following components: Items : Indicates the number of artifacts associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of your artifacts.","title":"Chart Components"},{"location":"admin-guide/settings/#practical-applications_1","text":"Understanding the distribution of your artifacts across different topics can provide several benefits: Content Gaps : Identify topics with fewer artifacts, indicating potential areas where additional content may be needed. Content Focus : Recognize topics with a high number of artifacts, helping you understand the primary focus areas of your users. Resource Allocation : Allocate resources more effectively by focusing on topics that require more attention or improvement. By leveraging the insights provided by the Prompt Topics section, you can ensure that your application covers a comprehensive range of topics, enhancing the overall user experience and effectiveness of the application.","title":"Practical Applications"},{"location":"admin-guide/settings/#topics-summary","text":"The Topics Summary section provides an automatic classification of user inputs, categorizing the topics that users have queried or questioned about. This section helps you understand user interests and the most frequently discussed topics within ELITEA.","title":"Topics Summary"},{"location":"admin-guide/settings/#chart-components_1","text":"The Topics Summary section displays a clustered column chart that categorizes user inputs by topic. This visual representation allows you to quickly see how many times users have queried information for each topic within a selected timeframe. The clustered column chart includes the following components: Items : Indicates the number of user queries associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of user queries.","title":"Chart Components"},{"location":"admin-guide/settings/#practical-applications_2","text":"Understanding the distribution of user queries across different topics can provide several benefits: User Interests : Identify the topics that users are most interested in, allowing you to tailor your content and responses to better meet their needs. Content Gaps : Recognize topics with fewer user queries, indicating potential areas where additional content or promotion may be needed. Trend Analysis : Monitor how user interests evolve over time, helping you stay ahead of emerging trends and adjust your strategies accordingly. By leveraging the insights provided by the Topics Summary section, you can ensure that ELITEA is aligned with user interests, enhancing the overall user experience and effectiveness of the application. The Monitoring feature in ELITEA offers a robust set of tools and metrics to help you understand the performance and usage of your application. By utilizing the various charts and statistics available, you can gain valuable insights into user engagement, sentiment, accuracy, and the distribution of topics within your project. These insights are crucial for making data-driven decisions that can enhance the overall user experience and effectiveness of your ELITEA application. Whether you are looking to improve customer's experience through sentiment analysis, optimize the relevance and reliability of LLM responses, or identify content gaps and user interests, the Monitoring feature provides the necessary data to guide your efforts. By regularly reviewing and analyzing these metrics, you can ensure that your project remains aligned with user needs and continues to perform at its best. By leveraging the comprehensive monitoring capabilities of ELITEA, you can create a more responsive, efficient, and user-friendly application, ultimately leading to higher user satisfaction and better overall performance.","title":"Practical Applications"},{"location":"admin-guide/settings/#configuration","text":"The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Code Chat. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential. To create a token: Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings and the Download Jetbrains Settings icons will appear next to the created token. This allows you to download the configuration files to integrate and configure the ELITEA project with Alita Code extensions on VSCode and IntelliJ respectively. For more information about how to setup it, please refer to the Alita Code Documentation .","title":"Configuration"},{"location":"admin-guide/settings/#deployments","text":"The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations.","title":"Deployments"},{"location":"admin-guide/settings/#creating-a-new-deployment-for-epam-ai-dial","text":"To set up a new deployment for EPAM AI Dial within your system, follow these detailed steps: Obtain API Key : Important : Before proceeding, you must obtain a separate API Key from the EPAM DIAL team. This key is essential for authenticating and enabling communication with the AI Dial services. API Key Retrieval : Once you have received the API Key and any additional required information via email, return to this page to input these details. Initiate Deployment Creation : Click the + icon to start creating a new deployment. Select Deployment Type : From the list of available deployment types, select AI Dial . Configure Deployment Details : In the configuration window, fill in the following information: Name : Enter a descriptive name for the deployment. This name will be displayed alongside LLM models configured with this deployment. API Base : For EPAM AI Dial, use https://ai-proxy.lab.epam.com as the API Base. Secret API Key : Paste the API Key that you received from the AI Dial team. API Version : Enter the API version information provided by the AI Dial team. Add Models to Deployment : Click the + icon to add one or more models associated with this deployment. For each model, provide the model's name, maximum input tokens, and capabilities. Important : Ensure that you enter the correct model name as used in EPAM AI DIAL. For detailed information on model specifications and configurations, refer to the EPAM AI Dial documentation . Click Save to complete the creation of the deployment. By following these steps, you can successfully create and configure a new deployment for EPAM AI Dial, enabling you to leverage advanced capabilities within your projects.","title":"Creating a New Deployment for EPAM AI Dial"},{"location":"admin-guide/settings/#integrations","text":"The Integrations menu in ELITEA is designed to enhance the platform's functionality and flexibility by allowing users to connect with essential external tools such as Jira, Confluence, Testrail, and GitHub. These integrations enable seamless data flow and collaboration across different platforms, enhancing productivity and efficiency. Once configured, these integrations can be selected as configurations in the Agent's tool setup for each corresponding tool, allowing for streamlined operations within ELITEA. You can create integrations in both Private workspaces and Team projects, providing versatility in managing your connections.","title":"Integrations"},{"location":"admin-guide/settings/#confluence-integration-setup","text":"To set up a Confluence integration, follow these step-by-step instructions: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Confluence : From the available options, select Confluence . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"Conf_Integration\". URL : Enter the Confluence URL for your organization, e.g., https://kb.epam.com/ . Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your Confluence integration is now configured and ready to use.","title":"Confluence Integration Setup"},{"location":"admin-guide/settings/#github-integration-setup","text":"For GitHub integration, choose from the following authentication options: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Confluence : From the available options, select GitHub . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"GitHub_Integration\". Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Anonymous : Select this option, if no anuthentication is required. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your GitHub integration is now configured and ready to use.","title":"GitHub Integration Setup"},{"location":"admin-guide/settings/#jira-integration-setup","text":"To set up a Jira integration, follow these step-by-step instructions: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Jira : From the available options, select Jira . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"Jira_Integration\". URL : Enter the Jira URL for your organization, e.g., https://jiraeu.epam.com/ . Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your Jira integration is now configured and ready to use.","title":"Jira Integration Setup"},{"location":"admin-guide/settings/#testrail-integration-setup","text":"To set up a Testrail integration, provide the following details: Initiate New Integration : Click the + icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create. Select Jira : From the available options, select TestRail . This will open a new pop-up window where you can enter the necessary details for the integration. Enter Integration Details : Name : Provide a descriptive name for the integration, such as \"TestRail_Integration\". URL : Enter the TestRail URL for your organization, e.g., https://testrail.epam.com/ . Email : Enter the email used for authentication. Authentication Options : Choose your preferred method for secure connection: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Set as Default : Check the checkbox to set this integration as the default. Save the Integration : Click the Save button to finalize the integration setup. Your TestRail integration is now configured and ready to use. By setting up these integrations, you can streamline workflows and enhance collaboration across different platforms, making ELITEA a more powerful tool for your projects.","title":"TestRail Integration Setup"},{"location":"admin-guide/settings/#projects","text":"The Projects menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Note : It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project.","title":"Projects"},{"location":"admin-guide/settings/#groups","text":"The Groups feature in ELITEA is designed to facilitate efficient management and monitoring of multiple projects by admins or managers. This feature allows you to consolidate several projects under a single group, making it easier to oversee and coordinate activities across these projects. If you are an admin of two or more projects, you can leverage the Groups feature to organize and monitor your projects collectively: Create a New Group : Click the Pencil icon to initiate the creation of a new group. You will be prompted to name the group and select the projects you wish to include. Add Projects to Existing Group : If you already have established groups, you can add additional projects to these groups. This grouping functionality not only simplifies the administrative workload but also enhances the visibility and control over multiple projects, enabling more effective management and monitoring.","title":"Groups"},{"location":"admin-guide/settings/#teammates","text":"The Teammates feature in ELITEA is specifically crafted to streamline the process of collaborating within projects by allowing you to invite new users (teammates) and assign them appropriate roles. These roles include system, admin, editor, and viewer, each providing different levels of access and control within the project. Note : Only users with an admin role are empowered to invite new members. This ensures that the invitation and role assignment process is managed by users with appropriate authority and understanding of the project\u2019s needs. Inviting New Teammates : Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Teammates , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Teammates : The Teammates table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.","title":"Teammates"},{"location":"admin-guide/settings/#secrets","text":"The Secrets feature in ELITEA serves as a secure vault designed to store and manage sensitive information such as passwords, tokens, API keys, and other authentication details. This centralized system allows you to configure secrets once and utilize them across various components, such as Agent's toolkits within ELITEA. Creating a Secret : To add a new secret to the vault, follow these steps: Click the + icon to initiate the creation of a new secret. Enter a descriptive name for the secret to help you identify its use. In the Value field, input the token, password, API key, or any other authentication details. Once configured, this secret can now be selected and used within various components of ELITEA. Managing Secrets : The management of secrets is straightforward and secure, facilitated by the Secrets table which displays all your configured secrets: View Secret : Click the Eye icon to reveal the value of a configured secret. This allows you to quickly check the details without modifying them. Copy Secret : Easily copy the secret value to your clipboard (by clicking the hidden value) for use in configurations or integrations. Hide Secret : Hide the secret from the interface to maintain security when not actively managing the secret. Modify Secret : Update the value of the secret if the existing credentials change or need to be corrected. Delete Secret : Remove a secret permanently from the vault if it is no longer needed or if security concerns necessitate its deletion. This feature enhances the security and efficiency of managing sensitive information within ELITEA, ensuring that authentication details are handled in a secure, centralized manner.","title":"Secrets"},{"location":"admin-guide/agents/agents-examples/","text":"Agents Examples and Materials Agents - Helpful Materials To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents. Video Tutorials Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation Agent Frameworks General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. ReAct Agent Type For the ReAct agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes. Practical Examples Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Agents Examples and Materials"},{"location":"admin-guide/agents/agents-examples/#agents-examples-and-materials","text":"","title":"Agents Examples and Materials"},{"location":"admin-guide/agents/agents-examples/#agents-helpful-materials","text":"To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents.","title":"Agents - Helpful Materials"},{"location":"admin-guide/agents/agents-examples/#video-tutorials","text":"Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation","title":"Video Tutorials"},{"location":"admin-guide/agents/agents-examples/#agent-frameworks","text":"General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. ReAct Agent Type For the ReAct agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes.","title":"Agent Frameworks"},{"location":"admin-guide/agents/agents-examples/#practical-examples","text":"Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Practical Examples"},{"location":"admin-guide/agents/agents/","text":"Agents Private project - Agents menu ELITEA Agents are a cornerstone feature within the ELITEA platform, designed to significantly enhance and expand the capabilities of AI technologies. By leveraging the advanced natural language processing capabilities of GPT models, ELITEA Agents serve as virtual assistants or \"agents\" that automate tasks and streamline workflows, providing users with a more efficient and effective way to interact with AI models. What are ELITEA Agents? ELITEA Agents are customizable virtual assistants or bots that you can create within the ELITEA interface. Each agent is tailored to handle specific tasks or sets of tasks, based on the instructions and capabilities you define. These agents integrate various components such as prompts, datasources, and external toolkits, allowing them to make informed decisions and perform actions like searching on Google, creating Jira tickets, interacting with your code in GitHub. The flexibility of ELITEA Agents enables them to work with a wide range of external toolkits, making them versatile tools for automating complex workflows. Purpose of ELITEA Agents The primary purpose of ELITEA Agents is to provide a structured and efficient way to interact with AI models for diverse use cases. Unlike open-ended conversations, agents are designed to achieve specific goals, tasks, or workflows. This is particularly beneficial in scenarios that involve repetitive or intricate tasks requiring multiple steps or the aggregation and processing of information from various sources. By automating these processes, ELITEA Agents help reduce manual effort and increase productivity. How do Agents work? Creating an Agent involves defining a set of instructions, toolkits, or goals that the agent is meant to accomplish. These instructions can range from simple to complex, incorporating steps, conditions, and actions that guide the agent's behavior. Once configured, the agent utilizes the natural language processing capabilities of the selected GPT model to interpret and execute the provided instructions. This allows the agent to autonomously perform tasks, make decisions, and adapt to changing conditions without requiring constant human intervention. Key Features of ELITEA Agents Autonomy : ELITEA Agents operate independently, making decisions and taking actions based on predefined goals and instructions. Proactivity : Agents can proactively determine the next steps needed to achieve their objectives, even in the absence of explicit instructions. Integration : By combining prompts, datasources, and external toolkits, agents can seamlessly integrate decision-making processes with actionable tasks. Customization : Users can tailor agents to meet specific needs, defining the scope and complexity of tasks they are designed to handle. Scalability : ELITEA Agents can be scaled to manage a wide array of tasks across different domains, enhancing their utility and effectiveness. By understanding and utilizing ELITEA Agents, users can unlock the full potential of AI-driven automation, transforming how tasks are managed and executed within the ELITEA platform. This not only improves efficiency but also empowers users to focus on more strategic and creative aspects of their work. Integration with External Toolkits, Services, and APIs ELITEA Agents are designed to be highly versatile, capable of integrating with a wide array of external toolkits, services, and APIs. This capability allows agents to extend their functionality beyond the core ELITEA platform, enabling them to perform complex and specialized tasks across various domains. By leveraging these integrations, Agents can act as powerful virtual assistants, automating and streamlining workflows to enhance productivity and efficiency. Internal Toolkits : - Agents, Datasources, Prompts, and Artifacts : These are the foundational components within ELITEA that agents can utilize to perform tasks, manage data, and execute workflows. By integrating these internal toolkits, agents can seamlessly coordinate actions and decisions within the ELITEA environment. Management Tools : - Jira, Confluence, Bitbucket, Rally : Agents can integrate with these project management and collaboration tools to manage tasks, track issues, and facilitate team collaboration. This integration allows agents to automate project updates, issue tracking, and documentation management, ensuring that teams remain aligned and informed. Test Management Tools - XRAY Cloud, TestRail, Zephyr Scale, QTest : By connecting with test management platforms, agents can assist in managing test cases, executing tests, and generating reports. This integration streamlines the software testing lifecycle, improving accuracy and efficiency in quality assurance processes. Coding Tools : - GitHub, GitLab, GitLab Org, Sonar : Integration with version control and code quality tools enables agents to manage code repositories, facilitate pull requests, and conduct code reviews. This helps streamline the development process, ensuring code integrity and facilitating collaboration among developers. EPAM Tools : - Report Portal, TEST IO : Agents can leverage EPAM-specific tools to enhance reporting and testing capabilities. This integration allows for automated data collection and analysis, providing insights that drive informed decision-making. Azure Tools : - ADO wiki, ADO plans, ADO boards : By integrating with Azure DevOps tools, agents can manage documentation, project plans, and work items. This ensures that development and operations teams can collaborate effectively, maintaining alignment with project goals and timelines. Other Tools : - SQL, Browser, Google Places, Open API, Custom : ELITEA Agents can interact with databases, search web, access location data, and connect with custom APIs. These integrations enable agents to perform data retrieval, automate web-based workflows, and access external data sources, reducing manual effort and enhancing data-driven decision-making. Setting Up Integrations To set up these integrations, users may need to perform additional configuration and authentication steps. This includes providing API keys, access tokens, or configuring webhooks and communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, allowing ELITEA Agents to function effectively within your existing technological ecosystem. By harnessing the power of these integrations, ELITEA Agents can automate a wide range of tasks, from project management and software testing to code management and data processing. This not only enhances the capabilities of the ELITEA platform but also empowers users to achieve greater efficiency and productivity in their workflows. Note : For more information, please check Alita Tools and Alita SDK git repos. Creating an Agent To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type . Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter and Welcome Message . Click Save . Your newly created agent will subsequently appear on the Agents page for your project. How to Create Instructions The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Instructions Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit). How to Select an Agent Type Selecting the right Agent type in ELITEA is essential for optimizing the performance and effectiveness of your AI-driven tasks. Each Agent type is designed to leverage specific capabilities and frameworks, catering to different use cases and operational needs. Below is a detailed overview of the available Agent types and their ideal applications: ReAct Description : The ReAct Agent type is designed for straightforward, linear tasks that require minimal context. Users can specify the desired actions and add necessary toolkits using fields such as Actor, Goals, Instructions, and Constraints to clearly define the agent's behavior. Best For : Simple tasks with clear, direct instructions where the agent's actions are well-defined and do not require extensive context or interaction history. XMLChat Description : Similar to ReAct, but utilizes XML for tool integration instead of JSON. This makes XMLChat more suitable for models like LLama and Anthropic, which may benefit from XML's structured format. Best For : Scenarios where XML is preferred for tool integration, particularly with LLama and Anthropic models. OpenAI Description : OpenAI Agents are built on the LangChain backend and are specifically designed for integrations with Azure OpenAI Service. These agents excel in generating human-like text and handling a wide range of conversational tasks. Best For : Tasks requiring high-quality natural language understanding and generation, such as customer support, content creation, and complex query resolution. Pipeline Description : Similar to OpenAI, Pipeline Agents are also based on the LangChain backend and work exclusively with Azure OpenAI Service integrations. They are designed to handle complex workflows and data processing tasks. Instructions must be written in YAML format. Best For : Scenarios that require structured workflows and data processing capabilities, leveraging the power of Azure OpenAI Service. Each Agent type in ELITEA is crafted to maximize the strengths of its underlying models and frameworks. Selecting the appropriate Agent type based on your specific task requirements and desired outcomes will ensure optimal performance and efficiency. For more detailed guidance on selecting the right Agent type and crafting effective instructions, please refer to the Agent Frameworks document. How to select and configure Toolkits Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under TOOLS section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit already created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available: Agent toolkit The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration. Datasource toolkit The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration. Prompt toolkit The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt. Browser toolkit The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration. Confluence toolkit The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Create page : Enable this to allow the agent to create a new page in Confluence. Create pages : Enable this to allow the agent to create multiple pages in Confluence. Get page tree : Enable this to retrieve the hierarchical structure of pages in Confluence. Delete page : Enable this to allow the agent to delete a page. Update page by id : Enable this to allow the agent to update existing page by page id. Update page by title : Enable this to allow the agent to update page by title. Update labels : Enable this to allow the agent to update page labels. Update pages : Enable this to allow the agent to update multiple pages in Confluence. Site search : Enable this to search pages in Confluence. Search by title : Enable this to allow the agent to search existing page by page id. Read page by id : Enable this to allow the agent to read and show the content of the existing page by page id. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration. Jira toolkit The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. List comments : To allow showing available comments of the Jira issue. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Get specific field info : To allow getting info from the specific Jira field. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration. GitHub toolkit The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration. Gitlab toolkit Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Token : Provide the configured token for authentication. You have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration. Bitbucket toolkit The Bitbucket toolkit integrates into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from Bitbucket, facilitating better version control and development process integration. To configure Bitbucket toolkit : Click the + icon under Tools section. Select the Bitbucket tool from the dropdown list. The New Bitbucket tool configuration section is opened. Name : Assign a distinctive name to your Bitbucket toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Url : Enter the URL to your Bitbucket repository. Username : Input the Username associated with your Bitbucket account to complete the authentication process. Repository : Enter the name of the Bitbucket repository you wish to integrate (e.g. ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Password : Select this option if you are using your Bitbucket account password for authentication you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Bitbucket repository: Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Click the arrow icon next to the New Bitbucket tool to complete the setup and move back to the main menu of Agent configuration. Testrail toolkit The Testrail toolkit enables a direct integration with Testrauk, allowing users to manage test cases directly from the ELITEA platform. To configure TestTrail toolkit : Click the + icon under Tools section. Select the TestRail tool from the dropdown list. The New Testrail tool configuration section is opened. Name : Provide a unique name to identify your Testrail toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Testrail. Email : Enter the email used for authentication. Password : Enter the password for authentication. Tools - the following tools are avaialble for selection: Get case : To enable selecting test case. Get cases : To enable selecting test cases. Add case : To enable adding new case into Testrail. Click the arrow icon next to the New testrail tool to complete the setup and move back to the main menu of Agent configuration. Open API toolkit The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration. Custom toolkit The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration. Artifact toolkit The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration. WELCOME MESSAGE The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this agent for generating manual test cases\" \"Don't forget to double-check the generated test cases\" CONVERSATION STARTERS The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized. How to Execute Agent To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Managing Agent Versions: Save, Create Versions, and Manage To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them. How to Save an Agent: To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent. How to Create New Versions: For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements. Agents Menu The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents. Layout of the Agents Menu The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community. Engaging with Published Agents Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation: Liking Published Agents Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent. Other Actions for Published Agents Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use.","title":"Agents"},{"location":"admin-guide/agents/agents/#agents","text":"","title":"Agents"},{"location":"admin-guide/agents/agents/#private-project-agents-menu","text":"ELITEA Agents are a cornerstone feature within the ELITEA platform, designed to significantly enhance and expand the capabilities of AI technologies. By leveraging the advanced natural language processing capabilities of GPT models, ELITEA Agents serve as virtual assistants or \"agents\" that automate tasks and streamline workflows, providing users with a more efficient and effective way to interact with AI models.","title":"Private project - Agents menu"},{"location":"admin-guide/agents/agents/#what-are-elitea-agents","text":"ELITEA Agents are customizable virtual assistants or bots that you can create within the ELITEA interface. Each agent is tailored to handle specific tasks or sets of tasks, based on the instructions and capabilities you define. These agents integrate various components such as prompts, datasources, and external toolkits, allowing them to make informed decisions and perform actions like searching on Google, creating Jira tickets, interacting with your code in GitHub. The flexibility of ELITEA Agents enables them to work with a wide range of external toolkits, making them versatile tools for automating complex workflows.","title":"What are ELITEA Agents?"},{"location":"admin-guide/agents/agents/#purpose-of-elitea-agents","text":"The primary purpose of ELITEA Agents is to provide a structured and efficient way to interact with AI models for diverse use cases. Unlike open-ended conversations, agents are designed to achieve specific goals, tasks, or workflows. This is particularly beneficial in scenarios that involve repetitive or intricate tasks requiring multiple steps or the aggregation and processing of information from various sources. By automating these processes, ELITEA Agents help reduce manual effort and increase productivity.","title":"Purpose of ELITEA Agents"},{"location":"admin-guide/agents/agents/#how-do-agents-work","text":"Creating an Agent involves defining a set of instructions, toolkits, or goals that the agent is meant to accomplish. These instructions can range from simple to complex, incorporating steps, conditions, and actions that guide the agent's behavior. Once configured, the agent utilizes the natural language processing capabilities of the selected GPT model to interpret and execute the provided instructions. This allows the agent to autonomously perform tasks, make decisions, and adapt to changing conditions without requiring constant human intervention.","title":"How do Agents work?"},{"location":"admin-guide/agents/agents/#key-features-of-elitea-agents","text":"Autonomy : ELITEA Agents operate independently, making decisions and taking actions based on predefined goals and instructions. Proactivity : Agents can proactively determine the next steps needed to achieve their objectives, even in the absence of explicit instructions. Integration : By combining prompts, datasources, and external toolkits, agents can seamlessly integrate decision-making processes with actionable tasks. Customization : Users can tailor agents to meet specific needs, defining the scope and complexity of tasks they are designed to handle. Scalability : ELITEA Agents can be scaled to manage a wide array of tasks across different domains, enhancing their utility and effectiveness. By understanding and utilizing ELITEA Agents, users can unlock the full potential of AI-driven automation, transforming how tasks are managed and executed within the ELITEA platform. This not only improves efficiency but also empowers users to focus on more strategic and creative aspects of their work.","title":"Key Features of ELITEA Agents"},{"location":"admin-guide/agents/agents/#integration-with-external-toolkits-services-and-apis","text":"ELITEA Agents are designed to be highly versatile, capable of integrating with a wide array of external toolkits, services, and APIs. This capability allows agents to extend their functionality beyond the core ELITEA platform, enabling them to perform complex and specialized tasks across various domains. By leveraging these integrations, Agents can act as powerful virtual assistants, automating and streamlining workflows to enhance productivity and efficiency. Internal Toolkits : - Agents, Datasources, Prompts, and Artifacts : These are the foundational components within ELITEA that agents can utilize to perform tasks, manage data, and execute workflows. By integrating these internal toolkits, agents can seamlessly coordinate actions and decisions within the ELITEA environment. Management Tools : - Jira, Confluence, Bitbucket, Rally : Agents can integrate with these project management and collaboration tools to manage tasks, track issues, and facilitate team collaboration. This integration allows agents to automate project updates, issue tracking, and documentation management, ensuring that teams remain aligned and informed. Test Management Tools - XRAY Cloud, TestRail, Zephyr Scale, QTest : By connecting with test management platforms, agents can assist in managing test cases, executing tests, and generating reports. This integration streamlines the software testing lifecycle, improving accuracy and efficiency in quality assurance processes. Coding Tools : - GitHub, GitLab, GitLab Org, Sonar : Integration with version control and code quality tools enables agents to manage code repositories, facilitate pull requests, and conduct code reviews. This helps streamline the development process, ensuring code integrity and facilitating collaboration among developers. EPAM Tools : - Report Portal, TEST IO : Agents can leverage EPAM-specific tools to enhance reporting and testing capabilities. This integration allows for automated data collection and analysis, providing insights that drive informed decision-making. Azure Tools : - ADO wiki, ADO plans, ADO boards : By integrating with Azure DevOps tools, agents can manage documentation, project plans, and work items. This ensures that development and operations teams can collaborate effectively, maintaining alignment with project goals and timelines. Other Tools : - SQL, Browser, Google Places, Open API, Custom : ELITEA Agents can interact with databases, search web, access location data, and connect with custom APIs. These integrations enable agents to perform data retrieval, automate web-based workflows, and access external data sources, reducing manual effort and enhancing data-driven decision-making.","title":"Integration with External Toolkits, Services, and APIs"},{"location":"admin-guide/agents/agents/#setting-up-integrations","text":"To set up these integrations, users may need to perform additional configuration and authentication steps. This includes providing API keys, access tokens, or configuring webhooks and communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, allowing ELITEA Agents to function effectively within your existing technological ecosystem. By harnessing the power of these integrations, ELITEA Agents can automate a wide range of tasks, from project management and software testing to code management and data processing. This not only enhances the capabilities of the ELITEA platform but also empowers users to achieve greater efficiency and productivity in their workflows. Note : For more information, please check Alita Tools and Alita SDK git repos.","title":"Setting Up Integrations"},{"location":"admin-guide/agents/agents/#creating-an-agent","text":"To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type . Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter and Welcome Message . Click Save . Your newly created agent will subsequently appear on the Agents page for your project.","title":"Creating an Agent"},{"location":"admin-guide/agents/agents/#how-to-create-instructions","text":"The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests.","title":"How to Create Instructions"},{"location":"admin-guide/agents/agents/#how-to-input-instructions","text":"Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit).","title":"How to Input Instructions"},{"location":"admin-guide/agents/agents/#how-to-select-an-agent-type","text":"Selecting the right Agent type in ELITEA is essential for optimizing the performance and effectiveness of your AI-driven tasks. Each Agent type is designed to leverage specific capabilities and frameworks, catering to different use cases and operational needs. Below is a detailed overview of the available Agent types and their ideal applications:","title":"How to Select an Agent Type"},{"location":"admin-guide/agents/agents/#react","text":"Description : The ReAct Agent type is designed for straightforward, linear tasks that require minimal context. Users can specify the desired actions and add necessary toolkits using fields such as Actor, Goals, Instructions, and Constraints to clearly define the agent's behavior. Best For : Simple tasks with clear, direct instructions where the agent's actions are well-defined and do not require extensive context or interaction history.","title":"ReAct"},{"location":"admin-guide/agents/agents/#xmlchat","text":"Description : Similar to ReAct, but utilizes XML for tool integration instead of JSON. This makes XMLChat more suitable for models like LLama and Anthropic, which may benefit from XML's structured format. Best For : Scenarios where XML is preferred for tool integration, particularly with LLama and Anthropic models.","title":"XMLChat"},{"location":"admin-guide/agents/agents/#openai","text":"Description : OpenAI Agents are built on the LangChain backend and are specifically designed for integrations with Azure OpenAI Service. These agents excel in generating human-like text and handling a wide range of conversational tasks. Best For : Tasks requiring high-quality natural language understanding and generation, such as customer support, content creation, and complex query resolution.","title":"OpenAI"},{"location":"admin-guide/agents/agents/#pipeline","text":"Description : Similar to OpenAI, Pipeline Agents are also based on the LangChain backend and work exclusively with Azure OpenAI Service integrations. They are designed to handle complex workflows and data processing tasks. Instructions must be written in YAML format. Best For : Scenarios that require structured workflows and data processing capabilities, leveraging the power of Azure OpenAI Service. Each Agent type in ELITEA is crafted to maximize the strengths of its underlying models and frameworks. Selecting the appropriate Agent type based on your specific task requirements and desired outcomes will ensure optimal performance and efficiency. For more detailed guidance on selecting the right Agent type and crafting effective instructions, please refer to the Agent Frameworks document.","title":"Pipeline"},{"location":"admin-guide/agents/agents/#how-to-select-and-configure-toolkits","text":"Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under TOOLS section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit already created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available:","title":"How to select and configure Toolkits"},{"location":"admin-guide/agents/agents/#agent-toolkit","text":"The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration.","title":"Agent toolkit"},{"location":"admin-guide/agents/agents/#datasource-toolkit","text":"The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration.","title":"Datasource toolkit"},{"location":"admin-guide/agents/agents/#prompt-toolkit","text":"The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt.","title":"Prompt toolkit"},{"location":"admin-guide/agents/agents/#browser-toolkit","text":"The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration.","title":"Browser toolkit"},{"location":"admin-guide/agents/agents/#confluence-toolkit","text":"The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Create page : Enable this to allow the agent to create a new page in Confluence. Create pages : Enable this to allow the agent to create multiple pages in Confluence. Get page tree : Enable this to retrieve the hierarchical structure of pages in Confluence. Delete page : Enable this to allow the agent to delete a page. Update page by id : Enable this to allow the agent to update existing page by page id. Update page by title : Enable this to allow the agent to update page by title. Update labels : Enable this to allow the agent to update page labels. Update pages : Enable this to allow the agent to update multiple pages in Confluence. Site search : Enable this to search pages in Confluence. Search by title : Enable this to allow the agent to search existing page by page id. Read page by id : Enable this to allow the agent to read and show the content of the existing page by page id. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration.","title":"Confluence toolkit"},{"location":"admin-guide/agents/agents/#jira-toolkit","text":"The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. List comments : To allow showing available comments of the Jira issue. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Get specific field info : To allow getting info from the specific Jira field. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration.","title":"Jira toolkit"},{"location":"admin-guide/agents/agents/#github-toolkit","text":"The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration.","title":"GitHub toolkit"},{"location":"admin-guide/agents/agents/#gitlab-toolkit","text":"Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Token : Provide the configured token for authentication. You have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration.","title":"Gitlab toolkit"},{"location":"admin-guide/agents/agents/#bitbucket-toolkit","text":"The Bitbucket toolkit integrates into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from Bitbucket, facilitating better version control and development process integration. To configure Bitbucket toolkit : Click the + icon under Tools section. Select the Bitbucket tool from the dropdown list. The New Bitbucket tool configuration section is opened. Name : Assign a distinctive name to your Bitbucket toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Url : Enter the URL to your Bitbucket repository. Username : Input the Username associated with your Bitbucket account to complete the authentication process. Repository : Enter the name of the Bitbucket repository you wish to integrate (e.g. ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Password : Select this option if you are using your Bitbucket account password for authentication you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Bitbucket repository: Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Click the arrow icon next to the New Bitbucket tool to complete the setup and move back to the main menu of Agent configuration.","title":"Bitbucket toolkit"},{"location":"admin-guide/agents/agents/#testrail-toolkit","text":"The Testrail toolkit enables a direct integration with Testrauk, allowing users to manage test cases directly from the ELITEA platform. To configure TestTrail toolkit : Click the + icon under Tools section. Select the TestRail tool from the dropdown list. The New Testrail tool configuration section is opened. Name : Provide a unique name to identify your Testrail toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Testrail. Email : Enter the email used for authentication. Password : Enter the password for authentication. Tools - the following tools are avaialble for selection: Get case : To enable selecting test case. Get cases : To enable selecting test cases. Add case : To enable adding new case into Testrail. Click the arrow icon next to the New testrail tool to complete the setup and move back to the main menu of Agent configuration.","title":"Testrail toolkit"},{"location":"admin-guide/agents/agents/#open-api-toolkit","text":"The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration.","title":"Open API toolkit"},{"location":"admin-guide/agents/agents/#custom-toolkit","text":"The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration.","title":"Custom toolkit"},{"location":"admin-guide/agents/agents/#artifact-toolkit","text":"The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration.","title":"Artifact toolkit"},{"location":"admin-guide/agents/agents/#welcome-message","text":"The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this agent for generating manual test cases\" \"Don't forget to double-check the generated test cases\"","title":"WELCOME MESSAGE"},{"location":"admin-guide/agents/agents/#conversation-starters","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"admin-guide/agents/agents/#how-to-execute-agent","text":"To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"How to Execute Agent"},{"location":"admin-guide/agents/agents/#managing-agent-versions-save-create-versions-and-manage","text":"To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them.","title":"Managing Agent Versions: Save, Create Versions, and Manage"},{"location":"admin-guide/agents/agents/#how-to-save-an-agent","text":"To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent.","title":"How to Save an Agent:"},{"location":"admin-guide/agents/agents/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"admin-guide/agents/agents/#agents-menu","text":"The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents.","title":"Agents Menu"},{"location":"admin-guide/agents/agents/#layout-of-the-agents-menu","text":"The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community.","title":"Layout of the Agents Menu"},{"location":"admin-guide/agents/agents/#engaging-with-published-agents","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation:","title":"Engaging with Published Agents"},{"location":"admin-guide/agents/agents/#liking-published-agents","text":"Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent.","title":"Liking Published Agents"},{"location":"admin-guide/agents/agents/#other-actions-for-published-agents","text":"Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use.","title":"Other Actions for Published Agents"},{"location":"admin-guide/extensions/alita-chat/","text":"Alita Code Chat Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB. Pre-requisite Alita Code Chat operates in conjunction with Alita Code for both VS Code and IntelliJ. To utilize Alita Code Chat, you must first install Alita Code from their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace. Important : Ensure that Alita Code is not only installed but also properly configured with ELITEA HUB to function correctly. For detailed installation and configuration instructions, please refer to the Alita Code documentation . This step is crucial for enabling the full capabilities of Alita Code Chat within your development environment. Features list: Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned. Alita Code Chat for VS code Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code. Installation Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code. Alita Code Chat Usage With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and agents to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Prompts To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Datasources To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the prompt that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the AlitaCodeChat. Start conversation in the form of a question, statement, or command that simulates human-like interaction . AlitaCodeChat for IntelliJ AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode. Installation Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Alita Chat for IntelliJ offers two distinct modes to cater to different user preferences and integration styles. Each mode is designed to provide a seamless user experience while aligning with specific design philosophies: Native Mode : This mode is tailored to blend seamlessly with the IntelliJ environment. It adheres to the native design and style guidelines of IntelliJ, ensuring that the interface feels familiar and integrated for users who prefer consistency with their development environment. React Mode : Designed to echo the aesthetics and usability of ELITEA, this mode brings the distinctive look and feel of ELITEA's design language into IntelliJ. It's ideal for users who enjoy the ELITEA interface and wish to have a similar user experience within the IntelliJ platform. Both modes are crafted to provide a robust and intuitive chat interface, allowing users to choose according to their design preference and familiarity. Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem. AlitaCodeChat Usage Prompts To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Datasources To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the agent that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction . Additional Interaction Features Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Alita Code Chat"},{"location":"admin-guide/extensions/alita-chat/#alita-code-chat","text":"Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB.","title":"Alita Code Chat"},{"location":"admin-guide/extensions/alita-chat/#pre-requisite","text":"Alita Code Chat operates in conjunction with Alita Code for both VS Code and IntelliJ. To utilize Alita Code Chat, you must first install Alita Code from their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace. Important : Ensure that Alita Code is not only installed but also properly configured with ELITEA HUB to function correctly. For detailed installation and configuration instructions, please refer to the Alita Code documentation . This step is crucial for enabling the full capabilities of Alita Code Chat within your development environment.","title":"Pre-requisite"},{"location":"admin-guide/extensions/alita-chat/#features-list","text":"Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned.","title":"Features list:"},{"location":"admin-guide/extensions/alita-chat/#alita-code-chat-for-vs-code","text":"Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code.","title":"Alita Code Chat for VS code"},{"location":"admin-guide/extensions/alita-chat/#installation","text":"Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code.","title":"Installation"},{"location":"admin-guide/extensions/alita-chat/#alita-code-chat-usage","text":"With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and agents to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Alita Code Chat Usage"},{"location":"admin-guide/extensions/alita-chat/#prompts","text":"To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.","title":"Prompts"},{"location":"admin-guide/extensions/alita-chat/#datasources","text":"To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"admin-guide/extensions/alita-chat/#agents","text":"To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the prompt that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"admin-guide/extensions/alita-chat/#chat","text":"Open the AlitaCodeChat. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"admin-guide/extensions/alita-chat/#alitacodechat-for-intellij","text":"AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode.","title":"AlitaCodeChat for IntelliJ"},{"location":"admin-guide/extensions/alita-chat/#installation_1","text":"Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Alita Chat for IntelliJ offers two distinct modes to cater to different user preferences and integration styles. Each mode is designed to provide a seamless user experience while aligning with specific design philosophies: Native Mode : This mode is tailored to blend seamlessly with the IntelliJ environment. It adheres to the native design and style guidelines of IntelliJ, ensuring that the interface feels familiar and integrated for users who prefer consistency with their development environment. React Mode : Designed to echo the aesthetics and usability of ELITEA, this mode brings the distinctive look and feel of ELITEA's design language into IntelliJ. It's ideal for users who enjoy the ELITEA interface and wish to have a similar user experience within the IntelliJ platform. Both modes are crafted to provide a robust and intuitive chat interface, allowing users to choose according to their design preference and familiarity. Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem.","title":"Installation"},{"location":"admin-guide/extensions/alita-chat/#alitacodechat-usage","text":"","title":"AlitaCodeChat Usage"},{"location":"admin-guide/extensions/alita-chat/#prompts_1","text":"To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.","title":"Prompts"},{"location":"admin-guide/extensions/alita-chat/#datasources_1","text":"To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"admin-guide/extensions/alita-chat/#agents_1","text":"To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the agent that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"admin-guide/extensions/alita-chat/#chat_1","text":"Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"admin-guide/extensions/alita-chat/#additional-interaction-features","text":"Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Additional Interaction Features"},{"location":"admin-guide/extensions/alita-code/","text":"Alita Code Get Started with Alita Code Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code and InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience. Why Choose Alita Code? Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts. Key Features Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts and datasources powered by ELITEA Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation Alita Code for VS Code Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with Alita Code is straightforward and involves a few simple steps: Open VS Code and navigate to the Extensions section. In the Marketplace, search for Alita Code and click Install . Configuration on ELITEA HUB To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings icon will appear next to the created token. Click this icon to download the settings.json file, which contains all necessary configuration information for integration with VS Code. Note : The settings.json file includes essential information such as Project ID, ELITEA HUB's URL, LLM model, Integration UID, and the generated token. Important : Alternatively, you can manually copy and paste all required parameters into the Alita Code extension's settings in VS Code. Configuration on VS Code Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in VS Code. Navigate to the .vscode folder and open the settings.json file. If this folder does not exist, create it and add a settings.json file. Open the settings.json file downloaded from ELITEA HUB. Copy all information from this file into the .vscode/settings.json file in your project. Note : Be careful not to overwrite other configurations. If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Alita Code \u2192 Extension Settings \u2192 Workspace tab. Go to Extensions \u2192 Alita Code \u2192 Extension Settings . Open the Workspace tab and verify that all parameters are correctly populated from the settings.json file. Note : Manual adjustments can be made if necessary. Types of Settings in Alita Code Alita Code offers two types of settings to cater to different needs: User Settings : These are global settings that apply to all sessions across any workspace, providing a consistent environment across your projects. Workspace Settings : These are specific to a particular workspace, allowing for tailored configurations such as different project IDs or models, which is essential for managing separate environments or specific tasks. The following settings are available in both tabs (which can either be prepopulated or manually configured): Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alitacode: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting VS Code may be necessary for changes to take effect. Configuring Alita Code To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. Alita Code Usage Getting Started with Extension Commands Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together. Synchronize External Prompts Sync prompts and datasources created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita: Sync External Prompts from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB. Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Extend Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions. Predict (Execute) Prompt To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your Alita Code: Default View Mode settings . This could be appended, replaced, split, or prepended based on your configuration. Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB . AlitaCode for IntelliJ Idea AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with Alita Code is straightforward and involves a few simple steps: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install . Configuration on ELITEA HUB To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download Jetbrains Settings icon will appear next to the created token. Click this icon to download the alita.xml file, which contains all necessary configuration information (except generated token) for integration with IntelliJ. Configuration on IntelliJ Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in IntelliJ. Navigate to the .idea folder and open the alita.xml file. If this folder does not exist, create it and add a alita.xml file. Open the alita.xml file downloaded from ELITEA HUB. Copy all information from this file into the .idea/alita.xml file in your project. Note : If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Settings \u2192 Tools \u2192 Alita tab. Go to Settings \u2192 Tools \u2192 Alita . Open it and verify that all parameters are correctly populated from the alita.xml file. Copy and paste generated token to the LLM Auth Token field. Check and apply configuration: Click the Reload icon next to the Integration Name dropdown list. Select the ai_dial as integration and click OK button. To complete the setup click the OK button. Settings in Alita Code Alita Code includes the following settings: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita option. LLM Auth Token : Provide your Bearer token for the LLM service provider. Provide Settings Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration Name : To use Epam AI Dial models, select ai_dial option. Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Check the Use custom model checkbox. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. Advanced Settings : Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response Timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting IntelliJ may be necessary for changes to take effect. Configuration To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. AlitaCode Usage Getting Started with Extension Commands Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Synchronize External Prompts Sync prompts and datasources created in the ELITEA HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB. Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. Alita Code will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Edit Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes. Predict (Execute) Prompt To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Alita Code"},{"location":"admin-guide/extensions/alita-code/#alita-code","text":"","title":"Alita Code"},{"location":"admin-guide/extensions/alita-code/#get-started-with-alita-code","text":"Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code and InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience.","title":"Get Started with Alita Code"},{"location":"admin-guide/extensions/alita-code/#why-choose-alita-code","text":"Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts.","title":"Why Choose Alita Code?"},{"location":"admin-guide/extensions/alita-code/#key-features","text":"Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts and datasources powered by ELITEA Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation","title":"Key Features"},{"location":"admin-guide/extensions/alita-code/#alita-code-for-vs-code","text":"Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend.","title":"Alita Code for VS Code"},{"location":"admin-guide/extensions/alita-code/#installation","text":"Getting started with Alita Code is straightforward and involves a few simple steps: Open VS Code and navigate to the Extensions section. In the Marketplace, search for Alita Code and click Install .","title":"Installation"},{"location":"admin-guide/extensions/alita-code/#configuration-on-elitea-hub","text":"To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings icon will appear next to the created token. Click this icon to download the settings.json file, which contains all necessary configuration information for integration with VS Code. Note : The settings.json file includes essential information such as Project ID, ELITEA HUB's URL, LLM model, Integration UID, and the generated token. Important : Alternatively, you can manually copy and paste all required parameters into the Alita Code extension's settings in VS Code.","title":"Configuration on ELITEA HUB"},{"location":"admin-guide/extensions/alita-code/#configuration-on-vs-code","text":"Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in VS Code. Navigate to the .vscode folder and open the settings.json file. If this folder does not exist, create it and add a settings.json file. Open the settings.json file downloaded from ELITEA HUB. Copy all information from this file into the .vscode/settings.json file in your project. Note : Be careful not to overwrite other configurations. If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Alita Code \u2192 Extension Settings \u2192 Workspace tab. Go to Extensions \u2192 Alita Code \u2192 Extension Settings . Open the Workspace tab and verify that all parameters are correctly populated from the settings.json file. Note : Manual adjustments can be made if necessary.","title":"Configuration on VS Code"},{"location":"admin-guide/extensions/alita-code/#types-of-settings-in-alita-code","text":"Alita Code offers two types of settings to cater to different needs: User Settings : These are global settings that apply to all sessions across any workspace, providing a consistent environment across your projects. Workspace Settings : These are specific to a particular workspace, allowing for tailored configurations such as different project IDs or models, which is essential for managing separate environments or specific tasks. The following settings are available in both tabs (which can either be prepopulated or manually configured): Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alitacode: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting VS Code may be necessary for changes to take effect.","title":"Types of Settings in Alita Code"},{"location":"admin-guide/extensions/alita-code/#configuring-alita-code","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuring Alita Code"},{"location":"admin-guide/extensions/alita-code/#alita-code-usage","text":"","title":"Alita Code Usage"},{"location":"admin-guide/extensions/alita-code/#getting-started-with-extension-commands","text":"Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together.","title":"Getting Started with Extension Commands"},{"location":"admin-guide/extensions/alita-code/#synchronize-external-prompts","text":"Sync prompts and datasources created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita: Sync External Prompts from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB.","title":"Synchronize External Prompts"},{"location":"admin-guide/extensions/alita-code/#create-a-prompt","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"admin-guide/extensions/alita-code/#extend-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions.","title":"Extend Prompt Context"},{"location":"admin-guide/extensions/alita-code/#predict-execute-prompt","text":"To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your Alita Code: Default View Mode settings . This could be appended, replaced, split, or prepended based on your configuration. Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"admin-guide/extensions/alita-code/#alitacode-for-intellij-idea","text":"AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend.","title":"AlitaCode for IntelliJ Idea"},{"location":"admin-guide/extensions/alita-code/#installation_1","text":"Getting started with Alita Code is straightforward and involves a few simple steps: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install .","title":"Installation"},{"location":"admin-guide/extensions/alita-code/#configuration-on-elitea-hub_1","text":"To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download Jetbrains Settings icon will appear next to the created token. Click this icon to download the alita.xml file, which contains all necessary configuration information (except generated token) for integration with IntelliJ.","title":"Configuration on ELITEA HUB"},{"location":"admin-guide/extensions/alita-code/#configuration-on-intellij","text":"Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in IntelliJ. Navigate to the .idea folder and open the alita.xml file. If this folder does not exist, create it and add a alita.xml file. Open the alita.xml file downloaded from ELITEA HUB. Copy all information from this file into the .idea/alita.xml file in your project. Note : If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Settings \u2192 Tools \u2192 Alita tab. Go to Settings \u2192 Tools \u2192 Alita . Open it and verify that all parameters are correctly populated from the alita.xml file. Copy and paste generated token to the LLM Auth Token field. Check and apply configuration: Click the Reload icon next to the Integration Name dropdown list. Select the ai_dial as integration and click OK button. To complete the setup click the OK button.","title":"Configuration on IntelliJ"},{"location":"admin-guide/extensions/alita-code/#settings-in-alita-code","text":"Alita Code includes the following settings: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita option. LLM Auth Token : Provide your Bearer token for the LLM service provider. Provide Settings Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration Name : To use Epam AI Dial models, select ai_dial option. Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Check the Use custom model checkbox. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. Advanced Settings : Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response Timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting IntelliJ may be necessary for changes to take effect.","title":"Settings in Alita Code"},{"location":"admin-guide/extensions/alita-code/#configuration","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuration"},{"location":"admin-guide/extensions/alita-code/#alitacode-usage","text":"","title":"AlitaCode Usage"},{"location":"admin-guide/extensions/alita-code/#getting-started-with-extension-commands_1","text":"Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend.","title":"Getting Started with Extension Commands"},{"location":"admin-guide/extensions/alita-code/#synchronize-external-prompts_1","text":"Sync prompts and datasources created in the ELITEA HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB.","title":"Synchronize External Prompts"},{"location":"admin-guide/extensions/alita-code/#create-a-prompt_1","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. Alita Code will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"admin-guide/extensions/alita-code/#edit-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes.","title":"Edit Prompt Context"},{"location":"admin-guide/extensions/alita-code/#predict-execute-prompt_1","text":"To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"admin-guide/prompts/prompts-examples/","text":"Prompts Examples and Materials Prompts - Helpful Materials To assist you in maximizing the capabilities of Prompts within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Prompts. Prompting Frameworks To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing: CREATE Framework The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. **Character**: Act as a senior software tester with expertise in regression testing. **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. **Examples**: Include scenarios like: **Preconditions**: CRM software has been updated to the latest version. **Steps to reproduce**: User logs in and accesses the customer data module. **Expected results**: User should see updated customer data without any data loss. **Adjustment**: Focus on critical modules like customer data management and transaction processing. **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality. Elavis Saravia Framework This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. **Instruction**: Generate test cases for user interface consistency across different devices. **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. **Input Data**: User accesses the application from different devices. **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type. CRISPE Framework The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. **Capacity and Role**: Serve as an automated testing tool expert. **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. **Personality**: Maintain a technical and precise tone throughout the test scripts. **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.","title":"Prompts Examples and Materials"},{"location":"admin-guide/prompts/prompts-examples/#prompts-examples-and-materials","text":"","title":"Prompts Examples and Materials"},{"location":"admin-guide/prompts/prompts-examples/#prompts-helpful-materials","text":"To assist you in maximizing the capabilities of Prompts within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Prompts.","title":"Prompts - Helpful Materials"},{"location":"admin-guide/prompts/prompts-examples/#prompting-frameworks","text":"To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing:","title":"Prompting Frameworks"},{"location":"admin-guide/prompts/prompts-examples/#create-framework","text":"The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. **Character**: Act as a senior software tester with expertise in regression testing. **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. **Examples**: Include scenarios like: **Preconditions**: CRM software has been updated to the latest version. **Steps to reproduce**: User logs in and accesses the customer data module. **Expected results**: User should see updated customer data without any data loss. **Adjustment**: Focus on critical modules like customer data management and transaction processing. **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality.","title":"CREATE Framework"},{"location":"admin-guide/prompts/prompts-examples/#elavis-saravia-framework","text":"This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. **Instruction**: Generate test cases for user interface consistency across different devices. **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. **Input Data**: User accesses the application from different devices. **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type.","title":"Elavis Saravia Framework"},{"location":"admin-guide/prompts/prompts-examples/#crispe-framework","text":"The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. **Capacity and Role**: Serve as an automated testing tool expert. **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. **Personality**: Maintain a technical and precise tone throughout the test scripts. **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.","title":"CRISPE Framework"},{"location":"admin-guide/prompts/prompts/","text":"Prompts Private project - Prompts menu The Prompts menu within Private project serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted. How to Create a New Prompt In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button located on the top right of the Prompts menu. This action will navigate you to the Configuration tab, where you can define and set up your new prompt. Within the Configuration tab, you will need to fill in the mandatory fields: Name , Description , and Context . Name : Provide a clear and concise name for your prompt to easily identify it later. Description : Add a brief explanation of the prompt's purpose or intended use. Context : Enter the foundational information or instructions that will guide the AI model's responses. This is a crucial step in defining the scope and behavior of your prompt. After filling in the required information, click the Save button to create your prompt. Note : The Name and Description fields are non-editable after the prompt is saved. Ensure you have entered the correct information before saving. While creating your prompt in the Configuration tab, you can also configure other settings like Tags , Welcome Message , Conversation Starters , and Messages to further customize your prompt's behavior and interaction flow. After creating a prompt and saving it, the prompt's interface will be organized into three distinct tabs, each serving a specific purpose in managing and utilizing your prompt: Run tab : This is your primary interface for executing the prompt. Here, you'll find a comprehensive overview of the prompt's configuration, including any defined variables. If variables are configured, you can input or modify their values before execution. Crucially, this tab also allows you to adjust the settings that govern the AI model's behavior for this specific run, such as selecting the desired Model, and fine-tuning parameters like Temperature, Top-P, Top-K, and Maximum Completion Tokens. Configuration tab : This tab is dedicated to the setup and modification of the prompt's core elements. Within this tab, you have the ability to adjust all the fundamental settings of the prompt, including the Context that guides the AI, the Messages that structure the interaction, the optional Welcome Message displayed to users, and any Conversation Starters designed to initiate specific interactions. Monitoring tab : This tab provides valuable insights into the usage and performance of your prompt. Here, you can access monitoring data related to the prompt's executions, allowing you to track its activity, understand its usage patterns, and potentially identify areas for optimization or refinement. For more information about Monitoring, refer to the Monitoring . Note: Changes made within both the Run and Configuration tabs can be either saved to update the prompt or discarded to revert to the previous state, providing flexibility and control over your prompt configurations. Tags In ELITEA, Tags are a powerful organizational tool that allows you to categorize and manage your collection of prompts, datasources, and agents effectively. Think of them as labels that help you quickly identify and group related items. By assigning relevant tags to each prompt, you create an intuitive labeling system that significantly simplifies access and retrieval. This is particularly beneficial when you have a large number of prompts covering various topics or use cases. You can later filter your prompts by these tags, making it easy to find the precise prompt you need without sifting through an extensive list. Adding Tags to Your Prompt: Locate the Tags input box within the Configuration tab. Begin typing a tag name . As you type, you may see suggestions for pre-existing tags. You can either select one of these suggestions or continue typing to create a new tag. To finalize a tag, click the Enter key. This will add the tag to your prompt. Click the Save button to save the prompt with the selected tags. Note : You have the flexibility to assign one or more tags to each prompt, allowing for a multi-dimensional labeling system. This means a single prompt can be associated with multiple categories, enhancing its discoverability. CONTEXT The Context field in ELITEA is a fundamental component where you provide the essential background information, instructions, and guidelines that direct the LLM in generating accurate and relevant responses. This section acts as the foundational knowledge base for the model, enabling it to understand and effectively process your specific requests. A well-defined context is crucial for achieving the desired output from the AI. How to Effectively Input Context: Identify Key Information : Before you start typing, carefully consider the essential details or instructions the model needs to understand your request effectively. This might include the topic, specific terminology, relevant background information, the desired format of the output, or the specific task you want the model to perform. Enter the Details Clearly and Concisely : Input the identified information directly into the Context field. Ensure your language is clear, concise, and unambiguous. Avoid unnecessary jargon or overly complex sentences. The more direct and focused your context, the better the model can understand and respond appropriately. Leveraging Variables for Dynamic Content : For situations where you need to introduce dynamic elements into your prompts, you can incorporate variables directly within the Context . Variables are denoted by double curly braces, for example, {{variable_name}} . Once you define a variable in the Context , it will automatically appear in the Variables section, where you can assign a specific value to it. This allows you to create reusable prompts that can be easily adapted for different scenarios by simply changing the variable values. Note : For comprehensive guidance on crafting effective instructions for your prompts, please refer to the Prompting Frameworks document. This resource provides valuable strategies and examples to help you optimize your prompts for better results. Editability and Version Control You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate. MESSAGES The MESSAGES section is a powerful feature that allows you to meticulously structure the flow of interaction within a prompt by defining specific roles and content for different participants in the conversation. This section is crucial for creating more complex and nuanced interactions with the LLM model. The MESSAGES utilizes three distinct message types: System Message : This message sets the overall context, instructions, and guidelines for the Gen AI's behavior. It's like providing the AI with its role and responsibilities for the interaction. This message is not visible to the end-user but is fundamental in shaping the AI's responses. Assistant Message : This represents the Gen AI's responses or contributions within the conversation. You can pre-define Assistant Messages to guide the interaction or provide examples of the desired output format. User Message : This simulates the input or queries from the user interacting with the Gen AI. You can use User Messages to set up specific scenarios or provide examples of how a user might interact with the prompt. These message types work in concert to create a structured and meaningful dialogue. The System Message establishes the framework, the User Message initiates and guides the conversation flow, and the Assistant Message provides the content of the interaction, all contributing to a coherent and purposeful exchange. Understanding the Message Types: System Message : Think of this as the \"director's notes\" for the AI. It defines the AI's persona, the task at hand, and any specific rules or constraints it should follow. System Message: \"You are a helpful AI assistant specialized in providing concise summaries of scientific articles. Focus on extracting the main findings and conclusions.\" Assistant Message : This allows you to pre-program the AI's responses or provide examples of how it should respond to certain user inputs. User Message: \"What is the main finding of this article?\" Assistant Message: \"The main finding of the article is that...\" User Message : This allows you to simulate user input and guide the conversation flow. User Message: \"Summarize the methodology section.\" Managing Messages: To enhance the interactivity of a prompt, you can add multiple messages of any type by clicking the + icon, selecting the desired message type from the dropdown, and providing the relevant content. You also have the flexibility to manage the order and content of your messages: Delete : Remove a message by clicking the delete icon. Copy : Duplicate a message by clicking the copy icon. Reorder : Change the order of messages by dragging and dropping the message boxes. This allows you to precisely control the flow of the conversation. WELCOME MESSAGE The Welcome Message feature allows you to provide an initial message or instruction that is displayed to the user when they interact with the prompt, datasource, or agent. While currently sent to the LLM along with other instructions, it primarily serves as a way to communicate specific guidance or information to the user before they begin interacting with the prompt. Adding a Welcome Message: Locate the Welcome Message input field within the Configuration tab. Type the desired welcome message text into the input field. This could be instructions, reminders, or any other information you want the user to see. Click the Save button to save the configuration. This will make the configured welcome message visible to the user in the Chat section. How the Welcome Message is Used: When a user navigates to the Chat section of the prompt, the configured Welcome Message will be displayed at the top of the chat interface. This provides an immediate notification or instruction, setting the stage for their interaction with the prompt. Examples of Effective Welcome Messages: \"Use this prompt for generating comprehensive test cases based on the provided requirements.\" \"Remember to carefully review the generated output before implementing it.\" \"This prompt is designed to assist with summarizing technical documentation. Please provide the document content below.\" CONVERSATION STARTERS The Conversation Starter feature empowers you to configure and add predefined text options that users can click to initiate a conversation or trigger a specific action when executing a prompt. This is particularly useful for guiding users and providing them with quick access to common or recommended interactions, ensuring a consistent and efficient starting point for their engagement with the prompt. Setting Up Conversation Starters: Navigate to the Conversation Starter section within the Configuration tab. Click the + icon. This will open a text input field where you can type the text you want to use as a conversation starter. Enter the desired text for the conversation starter. This should be a clear and actionable phrase or question. Click the Save button to save the configuration. The configured conversation starter will now be available for users. Using Conversation Starters to Initiate Interactions: When a user goes to the Chat section of the prompt, they will see a list of the saved conversation starters. Clicking on a desired starter will automatically populate the chat input field with that text and execute the prompt, streamlining the process of initiating specific tasks or queries. Examples of Effective Conversation Starters: \"Generate test cases for the following user story: [Paste User Story Here]\" \"Summarize the key findings from this research paper.\" \"Translate this document into Spanish.\" \"Explain the concept of [Technical Term].\" By providing these pre-defined options, you make it easier for users to understand the capabilities of the prompt and quickly initiate relevant interactions. By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the prompt more efficient and standardized. VARIABLES The Variables within prompts introduce a powerful layer of dynamic customization, allowing you to create flexible and reusable prompts that can be easily adapted to specific needs or contexts without requiring modifications to the core prompt structure. This feature significantly enhances the versatility and efficiency of your prompts. Understanding Variables: Variables are placeholders within your prompt's Context or Messages that are denoted by double curly brackets, for example, {{user_story}} . These placeholders represent information that might change depending on the specific use case. How Variables Work: Define Variables in Context or Messages : Begin by identifying the elements within your Context or Messages that you want to make dynamic. Replace these static values with variable placeholders using the {{variable_name}} syntax. Choose descriptive names for your variables to easily understand their purpose. Automatic Population in the Variables Section : Once you define a variable in the Context or Messages , it will automatically appear in the VARIABLES section located below. Assign Values to Variables : In the VARIABLES section, you can assign specific values to each defined variable. This is where you provide the actual data that will replace the placeholder when the prompt is executed. This process empowers you to create prompts that can be easily adapted by simply changing the values of the variables, eliminating the need to rewrite the entire prompt for different scenarios. Note : You have the flexibility to define one or more variables within each prompt. Variables can be defined in both the Context and Messages sections, providing flexibility in how you structure your dynamic prompts. ADVANCED SETTINGS For users who require more granular control over the AI model's behavior, ELITEA provides Advanced Settings . These settings allow you to fine-tune the parameters that influence the generation of responses. To access these settings, click the Gear icon on the Configurations tab or SETTINGS section under the Run tab. The following advanced settings are available: Model : This dropdown menu allows you to select the specific Large Language Model (LLM) that will be used to process your prompt. Different models have varying capabilities and performance characteristics. Common options include: gpt-4o : A highly capable and advanced model known for its nuanced understanding and high-quality output. gpt-35-turbo : A more cost-effective and faster model that still provides excellent performance for a wide range of tasks. The choice of model can significantly impact the quality, speed, and cost of your prompt executions. Temperature : This parameter controls the randomness and creativity of the AI's responses. It is a value between 0 and 1 . A lower temperature (closer to 0) results in more predictable and focused responses. The AI will tend to choose the most likely next words, making the output more deterministic and consistent. This is suitable for tasks requiring factual accuracy and precision. A higher temperature (closer to 1 or above) introduces more randomness, leading to more creative and unexpected outputs. The AI will consider less probable words, potentially generating more diverse and novel responses. This is useful for brainstorming, creative writing, or when exploring different possibilities. Top P (0-1) : Also known as nucleus sampling, Top P offers another way to control the randomness of the output. It works by considering the smallest set of most probable tokens whose cumulative probability exceeds the value of P. A lower Top P value (e.g., 0.1) means the AI will only consider a very small, highly probable set of tokens, leading to more focused and deterministic responses. A higher Top P value (e.g., 0.9) allows the AI to consider a broader range of tokens, including less probable ones, resulting in more varied and potentially creative outputs. Top P provides a more dynamic way to control randomness compared to Temperature , as the number of tokens considered can vary depending on the context. Top K : This parameter limits the AI's token selection to the K most likely tokens at each step of the generation process. A lower Top K value (e.g., 10) restricts the AI to choosing from only the top 10 most probable tokens, leading to more focused and predictable responses. A higher Top K value (e.g., 100) allows the AI to choose from a wider range of likely tokens, potentially increasing the diversity and surprise in the output. Top K is useful for controlling the vocabulary and ensuring the AI stays within a certain range of likely words. Maximum Completion Tokens : This setting defines the maximum length of the AI's generated response, measured in tokens. Tokens can be roughly thought of as parts of words. Setting a lower value for Maximum Completion Tokens will result in shorter, more concise responses. This is useful when you need brief answers or summaries. Setting a higher value allows the AI to generate longer, more detailed responses. Be mindful that longer responses may consume more processing resources. By carefully adjusting these Advanced Settings , you can tailor the AI's behavior to suit the specific requirements of your prompt and achieve the desired output characteristics. Experimenting with these parameters can significantly enhance the effectiveness and versatility of your interactions with ELITEA. How to Execute Prompt Once your prompt is configured, ELITEA offers two primary methods to execute it and obtain the desired output: Chat : This method is designed for interactive, conversational exchanges with the AI model. It's ideal for scenarios where you want to engage in a dialogue, ask follow-up questions, or refine the output through iterative interactions. Completion : This method is more direct, providing a single output based on the prompt's configuration. It's suitable for tasks where you need a straightforward answer, generation, or completion without the need for back-and-forth conversation. Executing a Prompt Using the Chat Option: Navigate to the Run Tab : After configuring your prompt, access the Run tab. This tab provides the interface for executing your prompt and adjusting runtime settings. Review Prompt Configuration : In the Run tab, you'll see a summary of your prompt's setup. Ensure the Context , Messages , and any defined Variables are as intended. If variables are present, provide or adjust their values as needed. Select the AI Model : Choose the desired AI model from the Model dropdown list. The available models (e.g., gpt-4-0125-preview , gpt-35-turbo ) will influence the quality and nature of the generated responses. Adjust Basic Settings : You can quickly adjust the Temperature parameter to influence the creativity and predictability of the AI's responses. A lower temperature results in more focused and deterministic outputs, while a higher temperature encourages more creative and varied responses. Access Advanced Settings (Optional) : For more fine-grained control over the AI's output, check the Advanced Settings . Here, you can adjust parameters like Top P , Top K , and Maximum Completion Tokens . Refer to the Advanced Settings section for detailed information on these parameters. Initiate Interaction : In the chat input box, type your question, statement, or command to initiate the conversation with the AI. This input serves as the starting point for the interaction. Send Your Message : Click the Send icon (often represented by a paper airplane or similar symbol) to submit your input to the AI model. ELITEA will process your request based on the prompt's configuration and the selected settings. The AI's response will then appear in the chat interface. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Executing a Prompt Using the Completion Option: Navigate to the Run Tab : After configuring your prompt, access the Run tab. This tab serves as the central hub for executing your prompts and managing related settings. Review Prompt Configuration : In the Run tab, carefully review the prompt's setup, including the Context , Messages , and any defined Variables . Ensure everything is configured correctly for your desired outcome. If variables are present, provide or adjust their values as necessary. Select the AI Model : Choose the appropriate AI model from the Model dropdown list. The available models (e.g., gpt-4-0125-preview , gpt-35-turbo ) offer different capabilities and performance characteristics, so select the one that best suits your needs. Adjust Basic Settings : You can quickly adjust the Temperature parameter to control the level of creativity and predictability in the AI's output. A lower temperature leads to more focused and deterministic results, while a higher temperature encourages more varied and creative responses. Access Advanced Settings (Optional) : For more fine-grained control over the AI's output, check the Advanced Settings . Here, you can adjust parameters like Top P , Top K , and Maximum Completion Tokens . Refer to the Advanced Settings section for detailed information on these parameters. Select the Completion Option : Ensure that the Completion option is selected as the execution method. This is typically a radio button or a tab within the Run tab interface. Initiate Execution : Once you have reviewed the configuration and selected the Completion option, click the Run button. ELITEA will then process your prompt based on the defined settings and generate a single, complete output. The result will be displayed in the output area. Managing Prompt Versions: Save, Create Versions, and Manage To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them. How to Save a Prompt: To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt. How to Create New Versions: For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements. How to Publish a Prompt To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button. Moderator Review Process Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data. Possible Outcomes of the Review After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Tracking the Status of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. Prompt Actions ELITEA provides a set of convenient actions you can perform on your prompts to manage, share, and organize them effectively. These actions are easily accessible through dedicated icons associated with each prompt. Copy link to clipboard : Clicking the Copy icon will copy a direct link to the current prompt to your clipboard. This allows you to easily share the prompt with colleagues or reference it in other documents. Add to collection : The Bookmark icon allows you to add the current prompt to one of your existing collections. This helps you organize your prompts into logical groups based on topic, project, or any other criteria you find useful. Export prompt : Clicking the Export icon will initiate the process of exporting your prompt. The prompt will be saved as a JSON file to your local device. This file contains all the prompt's configurations, including context, messages, variables, and settings, making it easy to back up or share your prompt outside of ELITEA. Fork prompt : Clicking the Fork icon will initiate the process of creating a copy of the prompt within a different project. This is a useful feature for transferring prompts between projects without needing to export and import them. When you fork a prompt, a complete copy of its configuration is created in the target project, allowing you to modify it independently. Delete Prompt : Clicking the Thrash icon will delete the prompt. Be cautious when using this action, as deleted prompts cannot be recovered. How to Import a Prompt To use the prompts created in other projects, environments, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document. Public project - Prompts menu The Prompts menu within Public project showcases a collection of published and shared prompts within the community. Layout of the Prompts Menu The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community. Engaging with Published Prompts Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation: Liking Published Prompts Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt. Other Actions for Published Prompts Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt.s Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Prompts"},{"location":"admin-guide/prompts/prompts/#prompts","text":"","title":"Prompts"},{"location":"admin-guide/prompts/prompts/#private-project-prompts-menu","text":"The Prompts menu within Private project serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted.","title":"Private project - Prompts menu"},{"location":"admin-guide/prompts/prompts/#how-to-create-a-new-prompt","text":"In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button located on the top right of the Prompts menu. This action will navigate you to the Configuration tab, where you can define and set up your new prompt. Within the Configuration tab, you will need to fill in the mandatory fields: Name , Description , and Context . Name : Provide a clear and concise name for your prompt to easily identify it later. Description : Add a brief explanation of the prompt's purpose or intended use. Context : Enter the foundational information or instructions that will guide the AI model's responses. This is a crucial step in defining the scope and behavior of your prompt. After filling in the required information, click the Save button to create your prompt. Note : The Name and Description fields are non-editable after the prompt is saved. Ensure you have entered the correct information before saving. While creating your prompt in the Configuration tab, you can also configure other settings like Tags , Welcome Message , Conversation Starters , and Messages to further customize your prompt's behavior and interaction flow. After creating a prompt and saving it, the prompt's interface will be organized into three distinct tabs, each serving a specific purpose in managing and utilizing your prompt: Run tab : This is your primary interface for executing the prompt. Here, you'll find a comprehensive overview of the prompt's configuration, including any defined variables. If variables are configured, you can input or modify their values before execution. Crucially, this tab also allows you to adjust the settings that govern the AI model's behavior for this specific run, such as selecting the desired Model, and fine-tuning parameters like Temperature, Top-P, Top-K, and Maximum Completion Tokens. Configuration tab : This tab is dedicated to the setup and modification of the prompt's core elements. Within this tab, you have the ability to adjust all the fundamental settings of the prompt, including the Context that guides the AI, the Messages that structure the interaction, the optional Welcome Message displayed to users, and any Conversation Starters designed to initiate specific interactions. Monitoring tab : This tab provides valuable insights into the usage and performance of your prompt. Here, you can access monitoring data related to the prompt's executions, allowing you to track its activity, understand its usage patterns, and potentially identify areas for optimization or refinement. For more information about Monitoring, refer to the Monitoring . Note: Changes made within both the Run and Configuration tabs can be either saved to update the prompt or discarded to revert to the previous state, providing flexibility and control over your prompt configurations.","title":"How to Create a New Prompt"},{"location":"admin-guide/prompts/prompts/#tags","text":"In ELITEA, Tags are a powerful organizational tool that allows you to categorize and manage your collection of prompts, datasources, and agents effectively. Think of them as labels that help you quickly identify and group related items. By assigning relevant tags to each prompt, you create an intuitive labeling system that significantly simplifies access and retrieval. This is particularly beneficial when you have a large number of prompts covering various topics or use cases. You can later filter your prompts by these tags, making it easy to find the precise prompt you need without sifting through an extensive list. Adding Tags to Your Prompt: Locate the Tags input box within the Configuration tab. Begin typing a tag name . As you type, you may see suggestions for pre-existing tags. You can either select one of these suggestions or continue typing to create a new tag. To finalize a tag, click the Enter key. This will add the tag to your prompt. Click the Save button to save the prompt with the selected tags. Note : You have the flexibility to assign one or more tags to each prompt, allowing for a multi-dimensional labeling system. This means a single prompt can be associated with multiple categories, enhancing its discoverability.","title":"Tags"},{"location":"admin-guide/prompts/prompts/#context","text":"The Context field in ELITEA is a fundamental component where you provide the essential background information, instructions, and guidelines that direct the LLM in generating accurate and relevant responses. This section acts as the foundational knowledge base for the model, enabling it to understand and effectively process your specific requests. A well-defined context is crucial for achieving the desired output from the AI. How to Effectively Input Context: Identify Key Information : Before you start typing, carefully consider the essential details or instructions the model needs to understand your request effectively. This might include the topic, specific terminology, relevant background information, the desired format of the output, or the specific task you want the model to perform. Enter the Details Clearly and Concisely : Input the identified information directly into the Context field. Ensure your language is clear, concise, and unambiguous. Avoid unnecessary jargon or overly complex sentences. The more direct and focused your context, the better the model can understand and respond appropriately. Leveraging Variables for Dynamic Content : For situations where you need to introduce dynamic elements into your prompts, you can incorporate variables directly within the Context . Variables are denoted by double curly braces, for example, {{variable_name}} . Once you define a variable in the Context , it will automatically appear in the Variables section, where you can assign a specific value to it. This allows you to create reusable prompts that can be easily adapted for different scenarios by simply changing the variable values. Note : For comprehensive guidance on crafting effective instructions for your prompts, please refer to the Prompting Frameworks document. This resource provides valuable strategies and examples to help you optimize your prompts for better results.","title":"CONTEXT"},{"location":"admin-guide/prompts/prompts/#editability-and-version-control","text":"You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate.","title":"Editability and Version Control"},{"location":"admin-guide/prompts/prompts/#messages","text":"The MESSAGES section is a powerful feature that allows you to meticulously structure the flow of interaction within a prompt by defining specific roles and content for different participants in the conversation. This section is crucial for creating more complex and nuanced interactions with the LLM model. The MESSAGES utilizes three distinct message types: System Message : This message sets the overall context, instructions, and guidelines for the Gen AI's behavior. It's like providing the AI with its role and responsibilities for the interaction. This message is not visible to the end-user but is fundamental in shaping the AI's responses. Assistant Message : This represents the Gen AI's responses or contributions within the conversation. You can pre-define Assistant Messages to guide the interaction or provide examples of the desired output format. User Message : This simulates the input or queries from the user interacting with the Gen AI. You can use User Messages to set up specific scenarios or provide examples of how a user might interact with the prompt. These message types work in concert to create a structured and meaningful dialogue. The System Message establishes the framework, the User Message initiates and guides the conversation flow, and the Assistant Message provides the content of the interaction, all contributing to a coherent and purposeful exchange. Understanding the Message Types: System Message : Think of this as the \"director's notes\" for the AI. It defines the AI's persona, the task at hand, and any specific rules or constraints it should follow. System Message: \"You are a helpful AI assistant specialized in providing concise summaries of scientific articles. Focus on extracting the main findings and conclusions.\" Assistant Message : This allows you to pre-program the AI's responses or provide examples of how it should respond to certain user inputs. User Message: \"What is the main finding of this article?\" Assistant Message: \"The main finding of the article is that...\" User Message : This allows you to simulate user input and guide the conversation flow. User Message: \"Summarize the methodology section.\" Managing Messages: To enhance the interactivity of a prompt, you can add multiple messages of any type by clicking the + icon, selecting the desired message type from the dropdown, and providing the relevant content. You also have the flexibility to manage the order and content of your messages: Delete : Remove a message by clicking the delete icon. Copy : Duplicate a message by clicking the copy icon. Reorder : Change the order of messages by dragging and dropping the message boxes. This allows you to precisely control the flow of the conversation.","title":"MESSAGES"},{"location":"admin-guide/prompts/prompts/#welcome-message","text":"The Welcome Message feature allows you to provide an initial message or instruction that is displayed to the user when they interact with the prompt, datasource, or agent. While currently sent to the LLM along with other instructions, it primarily serves as a way to communicate specific guidance or information to the user before they begin interacting with the prompt. Adding a Welcome Message: Locate the Welcome Message input field within the Configuration tab. Type the desired welcome message text into the input field. This could be instructions, reminders, or any other information you want the user to see. Click the Save button to save the configuration. This will make the configured welcome message visible to the user in the Chat section. How the Welcome Message is Used: When a user navigates to the Chat section of the prompt, the configured Welcome Message will be displayed at the top of the chat interface. This provides an immediate notification or instruction, setting the stage for their interaction with the prompt. Examples of Effective Welcome Messages: \"Use this prompt for generating comprehensive test cases based on the provided requirements.\" \"Remember to carefully review the generated output before implementing it.\" \"This prompt is designed to assist with summarizing technical documentation. Please provide the document content below.\"","title":"WELCOME MESSAGE"},{"location":"admin-guide/prompts/prompts/#conversation-starters","text":"The Conversation Starter feature empowers you to configure and add predefined text options that users can click to initiate a conversation or trigger a specific action when executing a prompt. This is particularly useful for guiding users and providing them with quick access to common or recommended interactions, ensuring a consistent and efficient starting point for their engagement with the prompt. Setting Up Conversation Starters: Navigate to the Conversation Starter section within the Configuration tab. Click the + icon. This will open a text input field where you can type the text you want to use as a conversation starter. Enter the desired text for the conversation starter. This should be a clear and actionable phrase or question. Click the Save button to save the configuration. The configured conversation starter will now be available for users. Using Conversation Starters to Initiate Interactions: When a user goes to the Chat section of the prompt, they will see a list of the saved conversation starters. Clicking on a desired starter will automatically populate the chat input field with that text and execute the prompt, streamlining the process of initiating specific tasks or queries. Examples of Effective Conversation Starters: \"Generate test cases for the following user story: [Paste User Story Here]\" \"Summarize the key findings from this research paper.\" \"Translate this document into Spanish.\" \"Explain the concept of [Technical Term].\" By providing these pre-defined options, you make it easier for users to understand the capabilities of the prompt and quickly initiate relevant interactions. By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the prompt more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"admin-guide/prompts/prompts/#variables","text":"The Variables within prompts introduce a powerful layer of dynamic customization, allowing you to create flexible and reusable prompts that can be easily adapted to specific needs or contexts without requiring modifications to the core prompt structure. This feature significantly enhances the versatility and efficiency of your prompts. Understanding Variables: Variables are placeholders within your prompt's Context or Messages that are denoted by double curly brackets, for example, {{user_story}} . These placeholders represent information that might change depending on the specific use case. How Variables Work: Define Variables in Context or Messages : Begin by identifying the elements within your Context or Messages that you want to make dynamic. Replace these static values with variable placeholders using the {{variable_name}} syntax. Choose descriptive names for your variables to easily understand their purpose. Automatic Population in the Variables Section : Once you define a variable in the Context or Messages , it will automatically appear in the VARIABLES section located below. Assign Values to Variables : In the VARIABLES section, you can assign specific values to each defined variable. This is where you provide the actual data that will replace the placeholder when the prompt is executed. This process empowers you to create prompts that can be easily adapted by simply changing the values of the variables, eliminating the need to rewrite the entire prompt for different scenarios. Note : You have the flexibility to define one or more variables within each prompt. Variables can be defined in both the Context and Messages sections, providing flexibility in how you structure your dynamic prompts.","title":"VARIABLES"},{"location":"admin-guide/prompts/prompts/#advanced-settings","text":"For users who require more granular control over the AI model's behavior, ELITEA provides Advanced Settings . These settings allow you to fine-tune the parameters that influence the generation of responses. To access these settings, click the Gear icon on the Configurations tab or SETTINGS section under the Run tab. The following advanced settings are available: Model : This dropdown menu allows you to select the specific Large Language Model (LLM) that will be used to process your prompt. Different models have varying capabilities and performance characteristics. Common options include: gpt-4o : A highly capable and advanced model known for its nuanced understanding and high-quality output. gpt-35-turbo : A more cost-effective and faster model that still provides excellent performance for a wide range of tasks. The choice of model can significantly impact the quality, speed, and cost of your prompt executions. Temperature : This parameter controls the randomness and creativity of the AI's responses. It is a value between 0 and 1 . A lower temperature (closer to 0) results in more predictable and focused responses. The AI will tend to choose the most likely next words, making the output more deterministic and consistent. This is suitable for tasks requiring factual accuracy and precision. A higher temperature (closer to 1 or above) introduces more randomness, leading to more creative and unexpected outputs. The AI will consider less probable words, potentially generating more diverse and novel responses. This is useful for brainstorming, creative writing, or when exploring different possibilities. Top P (0-1) : Also known as nucleus sampling, Top P offers another way to control the randomness of the output. It works by considering the smallest set of most probable tokens whose cumulative probability exceeds the value of P. A lower Top P value (e.g., 0.1) means the AI will only consider a very small, highly probable set of tokens, leading to more focused and deterministic responses. A higher Top P value (e.g., 0.9) allows the AI to consider a broader range of tokens, including less probable ones, resulting in more varied and potentially creative outputs. Top P provides a more dynamic way to control randomness compared to Temperature , as the number of tokens considered can vary depending on the context. Top K : This parameter limits the AI's token selection to the K most likely tokens at each step of the generation process. A lower Top K value (e.g., 10) restricts the AI to choosing from only the top 10 most probable tokens, leading to more focused and predictable responses. A higher Top K value (e.g., 100) allows the AI to choose from a wider range of likely tokens, potentially increasing the diversity and surprise in the output. Top K is useful for controlling the vocabulary and ensuring the AI stays within a certain range of likely words. Maximum Completion Tokens : This setting defines the maximum length of the AI's generated response, measured in tokens. Tokens can be roughly thought of as parts of words. Setting a lower value for Maximum Completion Tokens will result in shorter, more concise responses. This is useful when you need brief answers or summaries. Setting a higher value allows the AI to generate longer, more detailed responses. Be mindful that longer responses may consume more processing resources. By carefully adjusting these Advanced Settings , you can tailor the AI's behavior to suit the specific requirements of your prompt and achieve the desired output characteristics. Experimenting with these parameters can significantly enhance the effectiveness and versatility of your interactions with ELITEA.","title":"ADVANCED SETTINGS"},{"location":"admin-guide/prompts/prompts/#how-to-execute-prompt","text":"Once your prompt is configured, ELITEA offers two primary methods to execute it and obtain the desired output: Chat : This method is designed for interactive, conversational exchanges with the AI model. It's ideal for scenarios where you want to engage in a dialogue, ask follow-up questions, or refine the output through iterative interactions. Completion : This method is more direct, providing a single output based on the prompt's configuration. It's suitable for tasks where you need a straightforward answer, generation, or completion without the need for back-and-forth conversation.","title":"How to Execute Prompt"},{"location":"admin-guide/prompts/prompts/#executing-a-prompt-using-the-chat-option","text":"Navigate to the Run Tab : After configuring your prompt, access the Run tab. This tab provides the interface for executing your prompt and adjusting runtime settings. Review Prompt Configuration : In the Run tab, you'll see a summary of your prompt's setup. Ensure the Context , Messages , and any defined Variables are as intended. If variables are present, provide or adjust their values as needed. Select the AI Model : Choose the desired AI model from the Model dropdown list. The available models (e.g., gpt-4-0125-preview , gpt-35-turbo ) will influence the quality and nature of the generated responses. Adjust Basic Settings : You can quickly adjust the Temperature parameter to influence the creativity and predictability of the AI's responses. A lower temperature results in more focused and deterministic outputs, while a higher temperature encourages more creative and varied responses. Access Advanced Settings (Optional) : For more fine-grained control over the AI's output, check the Advanced Settings . Here, you can adjust parameters like Top P , Top K , and Maximum Completion Tokens . Refer to the Advanced Settings section for detailed information on these parameters. Initiate Interaction : In the chat input box, type your question, statement, or command to initiate the conversation with the AI. This input serves as the starting point for the interaction. Send Your Message : Click the Send icon (often represented by a paper airplane or similar symbol) to submit your input to the AI model. ELITEA will process your request based on the prompt's configuration and the selected settings. The AI's response will then appear in the chat interface. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Executing a Prompt Using the Chat Option:"},{"location":"admin-guide/prompts/prompts/#executing-a-prompt-using-the-completion-option","text":"Navigate to the Run Tab : After configuring your prompt, access the Run tab. This tab serves as the central hub for executing your prompts and managing related settings. Review Prompt Configuration : In the Run tab, carefully review the prompt's setup, including the Context , Messages , and any defined Variables . Ensure everything is configured correctly for your desired outcome. If variables are present, provide or adjust their values as necessary. Select the AI Model : Choose the appropriate AI model from the Model dropdown list. The available models (e.g., gpt-4-0125-preview , gpt-35-turbo ) offer different capabilities and performance characteristics, so select the one that best suits your needs. Adjust Basic Settings : You can quickly adjust the Temperature parameter to control the level of creativity and predictability in the AI's output. A lower temperature leads to more focused and deterministic results, while a higher temperature encourages more varied and creative responses. Access Advanced Settings (Optional) : For more fine-grained control over the AI's output, check the Advanced Settings . Here, you can adjust parameters like Top P , Top K , and Maximum Completion Tokens . Refer to the Advanced Settings section for detailed information on these parameters. Select the Completion Option : Ensure that the Completion option is selected as the execution method. This is typically a radio button or a tab within the Run tab interface. Initiate Execution : Once you have reviewed the configuration and selected the Completion option, click the Run button. ELITEA will then process your prompt based on the defined settings and generate a single, complete output. The result will be displayed in the output area.","title":"Executing a Prompt Using the Completion Option:"},{"location":"admin-guide/prompts/prompts/#managing-prompt-versions-save-create-versions-and-manage","text":"To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them.","title":"Managing Prompt Versions: Save, Create Versions, and Manage"},{"location":"admin-guide/prompts/prompts/#how-to-save-a-prompt","text":"To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt.","title":"How to Save a Prompt:"},{"location":"admin-guide/prompts/prompts/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"admin-guide/prompts/prompts/#how-to-publish-a-prompt","text":"To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button.","title":"How to Publish a Prompt"},{"location":"admin-guide/prompts/prompts/#moderator-review-process","text":"Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data.","title":"Moderator Review Process"},{"location":"admin-guide/prompts/prompts/#possible-outcomes-of-the-review","text":"After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration.","title":"Possible Outcomes of the Review"},{"location":"admin-guide/prompts/prompts/#tracking-the-status-of-prompts","text":"Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication.","title":"Tracking the Status of Prompts"},{"location":"admin-guide/prompts/prompts/#prompt-actions","text":"ELITEA provides a set of convenient actions you can perform on your prompts to manage, share, and organize them effectively. These actions are easily accessible through dedicated icons associated with each prompt. Copy link to clipboard : Clicking the Copy icon will copy a direct link to the current prompt to your clipboard. This allows you to easily share the prompt with colleagues or reference it in other documents. Add to collection : The Bookmark icon allows you to add the current prompt to one of your existing collections. This helps you organize your prompts into logical groups based on topic, project, or any other criteria you find useful. Export prompt : Clicking the Export icon will initiate the process of exporting your prompt. The prompt will be saved as a JSON file to your local device. This file contains all the prompt's configurations, including context, messages, variables, and settings, making it easy to back up or share your prompt outside of ELITEA. Fork prompt : Clicking the Fork icon will initiate the process of creating a copy of the prompt within a different project. This is a useful feature for transferring prompts between projects without needing to export and import them. When you fork a prompt, a complete copy of its configuration is created in the target project, allowing you to modify it independently. Delete Prompt : Clicking the Thrash icon will delete the prompt. Be cautious when using this action, as deleted prompts cannot be recovered.","title":"Prompt Actions"},{"location":"admin-guide/prompts/prompts/#how-to-import-a-prompt","text":"To use the prompts created in other projects, environments, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document.","title":"How to Import a Prompt"},{"location":"admin-guide/prompts/prompts/#public-project-prompts-menu","text":"The Prompts menu within Public project showcases a collection of published and shared prompts within the community.","title":"Public project - Prompts menu"},{"location":"admin-guide/prompts/prompts/#layout-of-the-prompts-menu","text":"The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community.","title":"Layout of the Prompts Menu"},{"location":"admin-guide/prompts/prompts/#engaging-with-published-prompts","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation:","title":"Engaging with Published Prompts"},{"location":"admin-guide/prompts/prompts/#liking-published-prompts","text":"Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt.","title":"Liking Published Prompts"},{"location":"admin-guide/prompts/prompts/#other-actions-for-published-prompts","text":"Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt.s Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Other Actions for Published Prompts"},{"location":"manuals/alita-dial/","text":"Interoperability Guide: ELITEA and EPAM AI Dial Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial. Export Prompts from ELITEA Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it: Exporting the Prompt for AI DIAL: Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format. Import Prompts to EPAM AI Dial Once you have the JSON file from ELITEA, you can easily import it into AI Dial. Importing the Prompt into AI Dial: Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial. Export Prompts from EPAM AI Dial If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA. Import Prompts to ELITEA To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Exporting and Importing Collections from ELITEA to EPAM AI Dial You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial. Troubleshooting File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts. Useful Links ELITEA - User Guide ELITEA - Release Notes Epam AI Dial - User Guide","title":"ELITEA and EPAM AI DIAL"},{"location":"manuals/alita-dial/#interoperability-guide-elitea-and-epam-ai-dial","text":"Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial.","title":"Interoperability Guide: ELITEA and EPAM AI Dial"},{"location":"manuals/alita-dial/#export-prompts-from-elitea","text":"Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it:","title":"Export Prompts from ELITEA"},{"location":"manuals/alita-dial/#exporting-the-prompt-for-ai-dial","text":"Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format.","title":"Exporting the Prompt for AI DIAL:"},{"location":"manuals/alita-dial/#import-prompts-to-epam-ai-dial","text":"Once you have the JSON file from ELITEA, you can easily import it into AI Dial.","title":"Import Prompts to EPAM AI Dial"},{"location":"manuals/alita-dial/#importing-the-prompt-into-ai-dial","text":"Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial.","title":"Importing the Prompt into AI Dial:"},{"location":"manuals/alita-dial/#export-prompts-from-epam-ai-dial","text":"If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA.","title":"Export Prompts from EPAM AI Dial"},{"location":"manuals/alita-dial/#import-prompts-to-elitea","text":"To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt.","title":"Import Prompts to ELITEA"},{"location":"manuals/alita-dial/#exporting-and-importing-collections-from-elitea-to-epam-ai-dial","text":"You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial.","title":"Exporting and Importing Collections from ELITEA to EPAM AI Dial"},{"location":"manuals/alita-dial/#troubleshooting","text":"File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts.","title":"Troubleshooting"},{"location":"manuals/alita-dial/#useful-links","text":"ELITEA - User Guide ELITEA - Release Notes Epam AI Dial - User Guide","title":"Useful Links"},{"location":"manuals/creating-prompts/","text":"How to Create and Publish Useful Prompts for Testing and QA Activities Introduction Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success. Accessing ELITEA HUB To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA. Prompts Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information. How to Create a Prompt Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings: Prompt Requirements for Consistency and Quality When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations. Submitting Your Prompt for Publishing To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt: Review Process by Moderators and Outcome of Prompt Submission Moderator Review Process After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared. Possible Outcomes of the Review After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Statuses of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. To check the status of your submitted prompts, navigate to \" Prompts \" page on the platform, and select the status you wish to view from the dropdown menu. Engagement with Prompts: Liking and Trending Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy. Collections Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. Creating Collection Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about. Adding Prompts to Your Collection To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection. Publishing Your Collection Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication. Engagement with Collections: Liking and Trending Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged. Contribution Why Share Your Prompts? Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement. Rewards and Recognition To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network. Useful Resources ELITEA ELITEA - User Guide ELITEA - Release Notes Prompt Engineering Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"QA - Prompting and Sharing"},{"location":"manuals/creating-prompts/#how-to-create-and-publish-useful-prompts-for-testing-and-qa-activities","text":"","title":"How to Create and Publish Useful Prompts for Testing and QA Activities"},{"location":"manuals/creating-prompts/#introduction","text":"Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success.","title":"Introduction"},{"location":"manuals/creating-prompts/#accessing-elitea-hub","text":"To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA.","title":"Accessing ELITEA HUB"},{"location":"manuals/creating-prompts/#prompts","text":"Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information.","title":"Prompts"},{"location":"manuals/creating-prompts/#how-to-create-a-prompt","text":"Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings:","title":"How to Create a Prompt"},{"location":"manuals/creating-prompts/#prompt-requirements-for-consistency-and-quality","text":"When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations.","title":"Prompt Requirements for Consistency and Quality"},{"location":"manuals/creating-prompts/#submitting-your-prompt-for-publishing","text":"To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt:","title":"Submitting Your Prompt for Publishing"},{"location":"manuals/creating-prompts/#review-process-by-moderators-and-outcome-of-prompt-submission","text":"","title":"Review Process by Moderators and Outcome of Prompt Submission"},{"location":"manuals/creating-prompts/#moderator-review-process","text":"After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared.","title":"Moderator Review Process"},{"location":"manuals/creating-prompts/#possible-outcomes-of-the-review","text":"After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Statuses of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. To check the status of your submitted prompts, navigate to \" Prompts \" page on the platform, and select the status you wish to view from the dropdown menu.","title":"Possible Outcomes of the Review"},{"location":"manuals/creating-prompts/#engagement-with-prompts-liking-and-trending","text":"Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy.","title":"Engagement with Prompts: Liking and Trending"},{"location":"manuals/creating-prompts/#collections","text":"Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"Collections"},{"location":"manuals/creating-prompts/#creating-collection","text":"Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about.","title":"Creating Collection"},{"location":"manuals/creating-prompts/#adding-prompts-to-your-collection","text":"To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.","title":"Adding Prompts to Your Collection"},{"location":"manuals/creating-prompts/#publishing-your-collection","text":"Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication.","title":"Publishing Your Collection"},{"location":"manuals/creating-prompts/#engagement-with-collections-liking-and-trending","text":"Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged.","title":"Engagement with Collections: Liking and Trending"},{"location":"manuals/creating-prompts/#contribution","text":"","title":"Contribution"},{"location":"manuals/creating-prompts/#why-share-your-prompts","text":"Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement.","title":"Why Share Your Prompts?"},{"location":"manuals/creating-prompts/#rewards-and-recognition","text":"To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network.","title":"Rewards and Recognition"},{"location":"manuals/creating-prompts/#useful-resources","text":"","title":"Useful Resources"},{"location":"manuals/creating-prompts/#elitea","text":"ELITEA - User Guide ELITEA - Release Notes","title":"ELITEA"},{"location":"manuals/creating-prompts/#prompt-engineering","text":"Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"Prompt Engineering"},{"location":"manuals/roles/","text":"Roles Management How to access Admin menu: To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/ . Select the project from the dropdown list for which you want to set up or adjust the admin settings. Roles Menu The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the ELITEA HUB\u2192Settings\u2192Projects menu. By understanding and utilizing the Roles menu, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"Roles Management"},{"location":"manuals/roles/#roles-management","text":"","title":"Roles Management"},{"location":"manuals/roles/#how-to-access-admin-menu","text":"To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/ . Select the project from the dropdown list for which you want to set up or adjust the admin settings.","title":"How to access Admin menu:"},{"location":"manuals/roles/#roles-menu","text":"The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the ELITEA HUB\u2192Settings\u2192Projects menu. By understanding and utilizing the Roles menu, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"Roles Menu"},{"location":"release-notes/rn_current/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.4.0 Released on : 15-Jan-2025 Access : ELITEA Platform User Guide : ELITEA - User Guide New Features Nexus Elitea Environment : The new Nexus env is available for all Epamers and can be accessed without enabling EPAM's VPN. Agent Pipelines Framework : This cutting-edge feature allows users to design complex workflows where agents, prompts, tools, and datasources are steps to achieve results. By leveraging a state-of-the-art graph-based approach, users can now craft intricate processes that utilize a wide array of tools and decision-making capabilities, all within a user-friendly environment. New Toolkits for Agents : Enhance agent capabilities with the introduction of several powerful new toolkits, each designed to streamline specific aspects of project management, testing, and documentation: Report Portal : Integrate with Epam's Report Portal for real-time test reporting and analysis, aggregating test results from various frameworks to provide insightful analytics. TestIO : Leverage crowdtesting capabilities with TestIO, allowing agents to manage and deploy test cases to a community of testers for diverse and thorough testing coverage. ADO Boards : Enhance project tracking and agile management by interacting with Azure DevOps Boards, managing tasks, backlogs, and sprints directly from ELITEA. ADO Wiki : Manage and retrieve project documentation efficiently by accessing and updating Azure DevOps Wikis, facilitating better knowledge sharing. ADO Plans : Streamline release and sprint planning within Azure DevOps, managing timelines, iterations, and deliverables effectively. XRAY Cloud : Enhance test management and execution by creating, managing, and executing test cases directly in Jira. QTest : Organize, track, and execute test cases with robust tools for reporting and analytics to enhance test management. Zephyr Scale : Manage large volumes of test cases and cycles in Jira, supporting advanced test planning and metrics. Rally : Access Rally\u2019s agile project management features for better alignment, tracking, and execution of agile practices. GitLab Org : Enable direct interaction with GitLab Org repositories, providing specific project data to support informed decisions. Google Places : Connect to Google using Find places and Find near tools. Sonar : Connect to Sonar Cube and retrieve data using the Get Sonar data tool. SQL : Connect to Postgres and MySQL databases to execute SQL queries/scripts and display tables and data. Export/Import of Agents and Datasources Configuration : Facilitate the easy transfer of setup configurations between different environments or projects. Note : For security reasons, passwords and actual datasets are excluded from the export/import process. Forking Prompts, Agents, and Datasources : Introduce the forking feature to transfer Agents, Datasources, and Prompts between projects without needing to export and import the entities. Note : For security reasons, passwords and actual datasets are excluded from the forking process. Integrations : Enable seamless connections with external platforms such as Jira, Confluence, GitHub, and Testrail, enhancing workflow efficiency by allowing centralized management and improved collaboration across different tools. Configurations : Set up project-specific or personal configurations for Jira, Confluence, GitHub, and Testrail toolkits within the Agent interface, ensuring unique setups based on service URLs for optimal integration management. Magic Prompt Assistant : Auto-generate new prompts based on user input, enhancing the interactive capabilities of ELITEA. UI Enhancements: Full Screen View : Enable a Full Screen view for Context, Conversation Starter, and Welcome Message fields for Agents, Prompts, and Datasources. New BDD Loader : Reduce manual efforts required to update datasources for automation tests, allowing automation QAs to create specific datasources directly from the ELITEA UI. Improved Sorting and Ordering for Projects Dropdown List : Projects are now sorted in alphanumerical order, with Public and Private workspaces shown at the top of the list. Filtering of Entities by Author within Projects : Enhance navigation by allowing users to filter entities (prompts, datasources, collections, and agents) by author. Artifacts : Introduce a new feature allowing the creation of Buckets in ELITEA to save, update (append), read, and delete files using the Artifacts toolkit. Artifacts can be used as temporary file storage. Chat Enhancements : Add the ability to create grouped (Private) chats by adding users and select and show the history of each conversation with options such as All, Interaction, and Last N Messages. Monitoring Enhancements : Included Aggregation functionality and an Acceptance Rate chart. Persist user-selected filters during sessions in Monitoring Tabs for entities and the Monitoring page. Introduce a special ' Monitor ' role to provide a more accurate representation of active project users and usage metrics by hiding specific users (e.g., Epam admins and Support Engineers) from the project users list and excluding them from monitoring calculations. Show monitoring data per entity (for each prompt, datasource, and agent). Add new key metrics, Engagement and Acceptance rate , to provide deeper insights into user interaction and satisfaction: Engagement : Measures the percentage of active users out of all users who logged into ELITEA for the selected period. Acceptance Rate : Tracks the percentage of interactions where users accepted the generated output by copying, downloading, or saving it. Changed Features Entity Redesign : Complete redesign of Prompts, Datasources, and Agents entities. Collections : Enhanced capability to add Datasources and Agents to a Collection, improving organizational efficiency. UI Enhancements for Secrets Page : Improved user interface for managing secrets. Export Prompts and Collections in [DIAL] Format : This option has been removed. Chat Participants : Complete redesign of the Participants page. Maximum Length Option Renaming : The Maximum length is renamed to ' Max Completion Tokens ', with an added option to view available remaining tokens using the ' Remaining tokens ' option. Enable Save, Save as Version, and Discard Buttons in Toolkit Setup : Allow users to save or discard changes without needing to return to the previous screen, reducing confusion and improving efficiency. Known Issues GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Collections Import : After importing Collections, new collections are not being created under the Collections section. Test Connection : The test connection functionality for the toolkit is currently experiencing issues and may not operate correctly. Fixed Issues Confluence Source Filtering : Resolved issues with filtering by Space key and Page IDs. Error When Stopping Dataset in Running Status : Fixed error message displayed when stopping the dataset running process. Datasources - Clean Generated Result Button : Fixed issue where the button was not working in deduplication/list view. Unable to Search and Filter by Tag : Fixed error message displayed during search and filter by tag. Browser Toolkit: Multi Crawler Tool Fails with Validation Error : The Multi Crawler tool in the Browser Toolkit fails with a validation error when attempting to execute a user query to gather information from several web pages. Tags Editing Mode on Prompt's Page : Resolved issue where there was no way to exit from tags editing mode if there weren't any changes, as the Discard button was deactivated. Projects and Users Dropdown Lists on Monitoring Page : Made sortable in alphanumerical order. Projects should have Private and Public categories at the top, followed by an alphabetical list. Users should be sorted alphabetically. ELITEA Unresponsiveness During Agent Execution : Fixed issue where ELITEA became unresponsive when executing an agent with several tools and toolkits. If a tool within the toolkits became unresponsive, the entire platform displayed errors. A page refresh was required to navigate back. Renamed ELITEA Agent Display : Fixed issue where a renamed ELITEA Agent was incorrectly displayed on the Agent View Wizard. Browser Toolkit Tool Selection : Resolved issue where it was not possible to select any tools other than Google without providing an API Key and CSE ID, which were mandatory regardless of the selected tools. Created Secret Visibility : Fixed issue where a created secret did not automatically appear in applicable places such as Integrations, Dataset, and Agent's toolkits. A page refresh was required for the secret to become visible.","title":"RN 1.4.0"},{"location":"release-notes/rn_current/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/rn_current/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn_current/#information","text":"Release Version : 1.4.0 Released on : 15-Jan-2025 Access : ELITEA Platform User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/rn_current/#new-features","text":"Nexus Elitea Environment : The new Nexus env is available for all Epamers and can be accessed without enabling EPAM's VPN. Agent Pipelines Framework : This cutting-edge feature allows users to design complex workflows where agents, prompts, tools, and datasources are steps to achieve results. By leveraging a state-of-the-art graph-based approach, users can now craft intricate processes that utilize a wide array of tools and decision-making capabilities, all within a user-friendly environment. New Toolkits for Agents : Enhance agent capabilities with the introduction of several powerful new toolkits, each designed to streamline specific aspects of project management, testing, and documentation: Report Portal : Integrate with Epam's Report Portal for real-time test reporting and analysis, aggregating test results from various frameworks to provide insightful analytics. TestIO : Leverage crowdtesting capabilities with TestIO, allowing agents to manage and deploy test cases to a community of testers for diverse and thorough testing coverage. ADO Boards : Enhance project tracking and agile management by interacting with Azure DevOps Boards, managing tasks, backlogs, and sprints directly from ELITEA. ADO Wiki : Manage and retrieve project documentation efficiently by accessing and updating Azure DevOps Wikis, facilitating better knowledge sharing. ADO Plans : Streamline release and sprint planning within Azure DevOps, managing timelines, iterations, and deliverables effectively. XRAY Cloud : Enhance test management and execution by creating, managing, and executing test cases directly in Jira. QTest : Organize, track, and execute test cases with robust tools for reporting and analytics to enhance test management. Zephyr Scale : Manage large volumes of test cases and cycles in Jira, supporting advanced test planning and metrics. Rally : Access Rally\u2019s agile project management features for better alignment, tracking, and execution of agile practices. GitLab Org : Enable direct interaction with GitLab Org repositories, providing specific project data to support informed decisions. Google Places : Connect to Google using Find places and Find near tools. Sonar : Connect to Sonar Cube and retrieve data using the Get Sonar data tool. SQL : Connect to Postgres and MySQL databases to execute SQL queries/scripts and display tables and data. Export/Import of Agents and Datasources Configuration : Facilitate the easy transfer of setup configurations between different environments or projects. Note : For security reasons, passwords and actual datasets are excluded from the export/import process. Forking Prompts, Agents, and Datasources : Introduce the forking feature to transfer Agents, Datasources, and Prompts between projects without needing to export and import the entities. Note : For security reasons, passwords and actual datasets are excluded from the forking process. Integrations : Enable seamless connections with external platforms such as Jira, Confluence, GitHub, and Testrail, enhancing workflow efficiency by allowing centralized management and improved collaboration across different tools. Configurations : Set up project-specific or personal configurations for Jira, Confluence, GitHub, and Testrail toolkits within the Agent interface, ensuring unique setups based on service URLs for optimal integration management. Magic Prompt Assistant : Auto-generate new prompts based on user input, enhancing the interactive capabilities of ELITEA. UI Enhancements: Full Screen View : Enable a Full Screen view for Context, Conversation Starter, and Welcome Message fields for Agents, Prompts, and Datasources. New BDD Loader : Reduce manual efforts required to update datasources for automation tests, allowing automation QAs to create specific datasources directly from the ELITEA UI. Improved Sorting and Ordering for Projects Dropdown List : Projects are now sorted in alphanumerical order, with Public and Private workspaces shown at the top of the list. Filtering of Entities by Author within Projects : Enhance navigation by allowing users to filter entities (prompts, datasources, collections, and agents) by author. Artifacts : Introduce a new feature allowing the creation of Buckets in ELITEA to save, update (append), read, and delete files using the Artifacts toolkit. Artifacts can be used as temporary file storage. Chat Enhancements : Add the ability to create grouped (Private) chats by adding users and select and show the history of each conversation with options such as All, Interaction, and Last N Messages. Monitoring Enhancements : Included Aggregation functionality and an Acceptance Rate chart. Persist user-selected filters during sessions in Monitoring Tabs for entities and the Monitoring page. Introduce a special ' Monitor ' role to provide a more accurate representation of active project users and usage metrics by hiding specific users (e.g., Epam admins and Support Engineers) from the project users list and excluding them from monitoring calculations. Show monitoring data per entity (for each prompt, datasource, and agent). Add new key metrics, Engagement and Acceptance rate , to provide deeper insights into user interaction and satisfaction: Engagement : Measures the percentage of active users out of all users who logged into ELITEA for the selected period. Acceptance Rate : Tracks the percentage of interactions where users accepted the generated output by copying, downloading, or saving it.","title":"New Features"},{"location":"release-notes/rn_current/#changed-features","text":"Entity Redesign : Complete redesign of Prompts, Datasources, and Agents entities. Collections : Enhanced capability to add Datasources and Agents to a Collection, improving organizational efficiency. UI Enhancements for Secrets Page : Improved user interface for managing secrets. Export Prompts and Collections in [DIAL] Format : This option has been removed. Chat Participants : Complete redesign of the Participants page. Maximum Length Option Renaming : The Maximum length is renamed to ' Max Completion Tokens ', with an added option to view available remaining tokens using the ' Remaining tokens ' option. Enable Save, Save as Version, and Discard Buttons in Toolkit Setup : Allow users to save or discard changes without needing to return to the previous screen, reducing confusion and improving efficiency.","title":"Changed Features"},{"location":"release-notes/rn_current/#known-issues","text":"GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Collections Import : After importing Collections, new collections are not being created under the Collections section. Test Connection : The test connection functionality for the toolkit is currently experiencing issues and may not operate correctly.","title":"Known Issues"},{"location":"release-notes/rn_current/#fixed-issues","text":"Confluence Source Filtering : Resolved issues with filtering by Space key and Page IDs. Error When Stopping Dataset in Running Status : Fixed error message displayed when stopping the dataset running process. Datasources - Clean Generated Result Button : Fixed issue where the button was not working in deduplication/list view. Unable to Search and Filter by Tag : Fixed error message displayed during search and filter by tag. Browser Toolkit: Multi Crawler Tool Fails with Validation Error : The Multi Crawler tool in the Browser Toolkit fails with a validation error when attempting to execute a user query to gather information from several web pages. Tags Editing Mode on Prompt's Page : Resolved issue where there was no way to exit from tags editing mode if there weren't any changes, as the Discard button was deactivated. Projects and Users Dropdown Lists on Monitoring Page : Made sortable in alphanumerical order. Projects should have Private and Public categories at the top, followed by an alphabetical list. Users should be sorted alphabetically. ELITEA Unresponsiveness During Agent Execution : Fixed issue where ELITEA became unresponsive when executing an agent with several tools and toolkits. If a tool within the toolkits became unresponsive, the entire platform displayed errors. A page refresh was required to navigate back. Renamed ELITEA Agent Display : Fixed issue where a renamed ELITEA Agent was incorrectly displayed on the Agent View Wizard. Browser Toolkit Tool Selection : Resolved issue where it was not possible to select any tools other than Google without providing an API Key and CSE ID, which were mandatory regardless of the selected tools. Created Secret Visibility : Fixed issue where a created secret did not automatically appear in applicable places such as Integrations, Dataset, and Agent's toolkits. A page refresh was required for the secret to become visible.","title":"Fixed Issues"},{"location":"release-notes/archived/rn1/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts. Information Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts. Known Issues N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements. Fixed Issues N/A - This being the first version, there are no previously fixed issues to report.","title":"RN 1.0.0"},{"location":"release-notes/archived/rn1/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/archived/rn1/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts.","title":"Introduction"},{"location":"release-notes/archived/rn1/#information","text":"Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/archived/rn1/#new-features","text":"Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts.","title":"New Features"},{"location":"release-notes/archived/rn1/#known-issues","text":"N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements.","title":"Known Issues"},{"location":"release-notes/archived/rn1/#fixed-issues","text":"N/A - This being the first version, there are no previously fixed issues to report.","title":"Fixed Issues"},{"location":"release-notes/archived/rn2/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention. Known Issues Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Fixed Issues GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"RN 1.0.1"},{"location":"release-notes/archived/rn2/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/archived/rn2/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn2/#information","text":"Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/archived/rn2/#new-features","text":"IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention.","title":"New Features"},{"location":"release-notes/archived/rn2/#known-issues","text":"Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces.","title":"Known Issues"},{"location":"release-notes/archived/rn2/#fixed-issues","text":"GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"Fixed Issues"},{"location":"release-notes/archived/rn3/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns. Changed Features Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding. Known Issues Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication. Fixed Issues Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"RN 1.1.0"},{"location":"release-notes/archived/rn3/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/archived/rn3/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn3/#information","text":"Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/archived/rn3/#new-features","text":"Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns.","title":"New Features"},{"location":"release-notes/archived/rn3/#changed-features","text":"Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding.","title":"Changed Features"},{"location":"release-notes/archived/rn3/#known-issues","text":"Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication.","title":"Known Issues"},{"location":"release-notes/archived/rn3/#fixed-issues","text":"Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"Fixed Issues"},{"location":"release-notes/archived/rn4/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions. Changed Features Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"RN 1.2.0"},{"location":"release-notes/archived/rn4/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/archived/rn4/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn4/#information","text":"Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/archived/rn4/#new-features","text":"Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions.","title":"New Features"},{"location":"release-notes/archived/rn4/#changed-features","text":"Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative.","title":"Changed Features"},{"location":"release-notes/archived/rn4/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/archived/rn4/#fixed-issues","text":"Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"Fixed Issues"},{"location":"release-notes/archived/rn5/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.3.0 Released on : 16-Sep-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features New Navigation Flow : Completely redesigned navigation flow within ELITEA HUB. Access prompts, datasources, agents, and collections through dedicated menus. A new Project Selection dropdown list has been added next to your avatar for easy switching between public and private projects. The 'My Libraries' menu has been completely removed. Light Theme : A new light theme has been added for users who prefer bright and vivid colors. Quickly switch between dark and light themes from the Settings menu. Preloaded LLM Models : Deploy, select, and use locally loaded LLM models to speed up output generation and allow simultaneous calls to LLM models. Secrets : Introducing a secure vault for setting up passwords, tokens, and other authentication options within ELITEA HUB. Configure secrets once and use them across various components like Agent's toolkits. Notifications : New notification functionality to alert users about various events such as prompt publishing status within the ELITEA Hub. ELITEA Extensions : Updated versions of Alita Chat and Alita Chat Code for VSCode and IntelliJ IDEs. These versions support prompt versioning and variables, allowing selection of versions and variable values. Enhanced design for Alita Code in VSCode IDE and improved settings management for Alita Code plugin in IntelliJ IDE. Option to download pre-generated settings for Alita Code from ELITEA Hub \u2192 Configurations page. Pgvector Storage : Added Pgvector storage type for datasources, enhancing indexing, saving, and querying of data. New Agent Types : Introduced new agent types including OpenAI, Llama, and Autogen. Enhanced performance and stability of ReAct and Alita agent types. Bitbucket Toolkit for Agents : Allow your Agent to interact directly with Bitbucket repositories, enhancing version control and development processes. TesTrail Toolkit for Agents : Allow your Agent to interact directly with TestRail test management tool. New tools for Confluence Toolkit : Added Create page , Create pages , Delete page , Update page by id , Update page bt title , Update labels , Update pages , Site search , Search by title , Get page tree and Read page by id tools. Export Datasource : New functionality to export datasource instructions, conversation starters, welcome messages, and settings. Note : Datasets within the datasource will not be exported for security reasons. Welcome Message : Added a welcome message feature for prompts, datasources, and agents, providing additional context. Currently, the welcome message is sent to LLM along with other instructions. Future updates will allow users to configure the delivery of welcome messages. Conversation Starter : Added a feature for prompts and datasources to configure and initiate conversations with predefined questions, queries, or information. Changed Features Chat Functionality : Completely redesigned and improved Chat functionality. Enhanced ability to search and add various participants easily. Fixes implemented for synchronization and speed issues. Now supports agent and prompt versions, as well as prompts with variables. Monitoring : Completely redesigned and enhanced Monitoring functionality. Now supports grouping projects and improved visualization with better charts and graphics. Projects : Redesigned the Settings\u2192Users page to a Projects page, allowing project admins to add new users to projects. Also supports creating/selecting groups for monitoring functionality. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets for Chroma storage type. Workaround : Create a new datasource and reindex, or use Pgvector storage type when creating a datasource. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Prompt Saving Error : Fixed issues with saving prompts if the Name field contains leading spaces from copy/paste actions. GitLab Toolkit - Set Active Branch Tool : Resolved an issue where the 'Set Active Branch' tool was not functioning properly. Users can now successfully set the active branch in GitLab without encountering errors. Typo in Error Message When Selecting 'Update File' from GitLab Tool : Resolved an issue where a typo in the error message appeared when selecting the 'Update file' option from the GitLab tool. Agents Disappear on Scroll and Incorrect Message Displayed : Fixed an issue where agents disappeared from the page when scrolling, and an incorrect message was displayed. A page refresh was required to bring the agents back. User Search Crash in Settings : Resolved an issue where attempting to search for a user via the Teammates 'search box' in Settings\u2192Projects\u2192Users caused the UI to crash. The search functionality now operates smoothly without causing disruptions. Date Selection Crash in Monitoring Settings : Fixed a problem where selecting an incorrect date in the date fields on the Settings\u2192Monitoring page caused the UI to crash. Proper error handling and date validation have been implemented to ensure stability and prevent crashes.","title":"RN 1.3.0"},{"location":"release-notes/archived/rn5/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/archived/rn5/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn5/#information","text":"Release Version : 1.3.0 Released on : 16-Sep-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/archived/rn5/#new-features","text":"New Navigation Flow : Completely redesigned navigation flow within ELITEA HUB. Access prompts, datasources, agents, and collections through dedicated menus. A new Project Selection dropdown list has been added next to your avatar for easy switching between public and private projects. The 'My Libraries' menu has been completely removed. Light Theme : A new light theme has been added for users who prefer bright and vivid colors. Quickly switch between dark and light themes from the Settings menu. Preloaded LLM Models : Deploy, select, and use locally loaded LLM models to speed up output generation and allow simultaneous calls to LLM models. Secrets : Introducing a secure vault for setting up passwords, tokens, and other authentication options within ELITEA HUB. Configure secrets once and use them across various components like Agent's toolkits. Notifications : New notification functionality to alert users about various events such as prompt publishing status within the ELITEA Hub. ELITEA Extensions : Updated versions of Alita Chat and Alita Chat Code for VSCode and IntelliJ IDEs. These versions support prompt versioning and variables, allowing selection of versions and variable values. Enhanced design for Alita Code in VSCode IDE and improved settings management for Alita Code plugin in IntelliJ IDE. Option to download pre-generated settings for Alita Code from ELITEA Hub \u2192 Configurations page. Pgvector Storage : Added Pgvector storage type for datasources, enhancing indexing, saving, and querying of data. New Agent Types : Introduced new agent types including OpenAI, Llama, and Autogen. Enhanced performance and stability of ReAct and Alita agent types. Bitbucket Toolkit for Agents : Allow your Agent to interact directly with Bitbucket repositories, enhancing version control and development processes. TesTrail Toolkit for Agents : Allow your Agent to interact directly with TestRail test management tool. New tools for Confluence Toolkit : Added Create page , Create pages , Delete page , Update page by id , Update page bt title , Update labels , Update pages , Site search , Search by title , Get page tree and Read page by id tools. Export Datasource : New functionality to export datasource instructions, conversation starters, welcome messages, and settings. Note : Datasets within the datasource will not be exported for security reasons. Welcome Message : Added a welcome message feature for prompts, datasources, and agents, providing additional context. Currently, the welcome message is sent to LLM along with other instructions. Future updates will allow users to configure the delivery of welcome messages. Conversation Starter : Added a feature for prompts and datasources to configure and initiate conversations with predefined questions, queries, or information.","title":"New Features"},{"location":"release-notes/archived/rn5/#changed-features","text":"Chat Functionality : Completely redesigned and improved Chat functionality. Enhanced ability to search and add various participants easily. Fixes implemented for synchronization and speed issues. Now supports agent and prompt versions, as well as prompts with variables. Monitoring : Completely redesigned and enhanced Monitoring functionality. Now supports grouping projects and improved visualization with better charts and graphics. Projects : Redesigned the Settings\u2192Users page to a Projects page, allowing project admins to add new users to projects. Also supports creating/selecting groups for monitoring functionality.","title":"Changed Features"},{"location":"release-notes/archived/rn5/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets for Chroma storage type. Workaround : Create a new datasource and reindex, or use Pgvector storage type when creating a datasource. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/archived/rn5/#fixed-issues","text":"Prompt Saving Error : Fixed issues with saving prompts if the Name field contains leading spaces from copy/paste actions. GitLab Toolkit - Set Active Branch Tool : Resolved an issue where the 'Set Active Branch' tool was not functioning properly. Users can now successfully set the active branch in GitLab without encountering errors. Typo in Error Message When Selecting 'Update File' from GitLab Tool : Resolved an issue where a typo in the error message appeared when selecting the 'Update file' option from the GitLab tool. Agents Disappear on Scroll and Incorrect Message Displayed : Fixed an issue where agents disappeared from the page when scrolling, and an incorrect message was displayed. A page refresh was required to bring the agents back. User Search Crash in Settings : Resolved an issue where attempting to search for a user via the Teammates 'search box' in Settings\u2192Projects\u2192Users caused the UI to crash. The search functionality now operates smoothly without causing disruptions. Date Selection Crash in Monitoring Settings : Fixed a problem where selecting an incorrect date in the date fields on the Settings\u2192Monitoring page caused the UI to crash. Proper error handling and date validation have been implemented to ensure stability and prevent crashes.","title":"Fixed Issues"},{"location":"user-guide/export-import/","text":"Export and Import Guide: Managing Prompts, Datasources, and Agents for Backup, Migration, and Collaboration Introduction This user guide provides a comprehensive overview of the Export and Import features within ELITEA. These powerful functionalities allow you to seamlessly transfer your valuable entities \u2013 Prompts , Datasources , and Agents \u2013 between different ELITEA environments, projects, or for backup purposes. The ability to export and import entities offers significant flexibility and control over your AI workflows. You can leverage these features in various scenarios, including: Migrating Entities: Effortlessly move your carefully crafted prompts, configured datasources, and intelligent agents from one ELITEA environment to another. For instance, you can migrate entities from an ELITEA Alita LAB environment to a new Nexus environment. Sharing and Collaboration: Share your entities with colleagues working in different projects or ELITEA instances, fostering collaboration and knowledge sharing. Backup and Recovery: Create backups of your critical entities, ensuring data safety and enabling quick recovery in case of unforeseen issues. Development and Testing: Develop and test entities in a dedicated environment and then easily import them into your production environment. This guide will detail the process of exporting and importing each entity type, along with best practices and practical use cases to help you effectively utilize these features. Import and Export Features: A General Overview The Export feature allows you to save a snapshot of your prompts, datasources, or agents as JSON files. These files contain the complete configuration and relevant data of the entity at the time of export. The Import feature enables you to bring previously exported JSON files back into ELITEA. During the import process, you have the flexibility to configure certain aspects of the imported entity, such as the target project and specific settings. These features provide a convenient and reliable way to manage and transfer your assets within and across ELITEA environments. How to Export Entities ELITEA allows you to export prompts, datasources, and agents individually. The export process is similar for each entity type. Exporting a Prompt Navigate to the Prompts menu within the project containing the prompt you wish to export. Locate the specific prompt you want to export from the list. Hover over the prompt entry, and you will see several icons appear on the right side. Click the Export prompt icon. Your browser will automatically download a JSON file containing the prompt's data to your local device. The exported JSON file includes: All versions of the prompt. The complete configuration of each version, including: Context Messages (System, Assistant, User) Variables and their potential values Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens) Welcome Message Conversation Starters Tags Exporting a Datasource Navigate to the Datasources menu within the project containing the datasource you wish to export. Locate the specific datasource you want to export from the list. Hover over the datasource entry, and you will see several icons appear on the right side. Click the Export datasource prompt. Your browser will automatically download a JSON file containing the datasource's data to your local device. The exported JSON file includes: The complete configuration of the datasource, including: Name and Description Context Welcome Message Conversation Starters Tags Settings for Chat, Search, and Deduplicate functionalities (including selected LLM and Embedding Models) Dataset configurations (including storage details and connection parameters, excluding authentication credentials ) Important Security Note: For security purposes, the authentication information for datasets (such as API Keys, usernames, tokens, and passwords) is not included in the exported datasource file. You will need to re-enter this information when importing the datasource. Exporting an Agent Navigate to the Agents menu within the project containing the agent you wish to export. Locate the specific agent you want to export from the list. Hover over the agent entry, and you will see several icons appear on the right side. Click the Export agent icon. Your browser will automatically download a JSON file containing the agent's data to your local device. The exported JSON file includes: All versions of the agent. The complete configuration of each version, including: Name and Description Context Welcome Message Conversation Starters Tags Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens) Toolkit configurations (including tool details and parameters, excluding authentication credentials ) Important Security Note: For security purposes, the authentication information for toolkits (such as API Keys, usernames, tokens, and passwords) is not included in the exported agent file. You will need to re-enter this information when importing the agent. Exporting Master Agents with Connected Entities ELITEA offers a convenient feature to export a master agent along with all its connected prompts, datasources, and child agents. This is particularly useful for transferring complex AI solutions. If you export a master agent that has other agents, prompts, or datasources configured as toolkits, these nested entities will also be included in the exported JSON file. How to Import Entities ELITEA provides a straightforward import process for prompts, datasources, and agents. Login ELITEA. Click the +Quick button switcher, located in the top right corner of the interface. Click the Import button. Choose the appropiate file (in *.json) from your local device. An Import Wizard will appear, guiding you through the import process. Importing a Prompt Select File: Choose the appropiate prompt file (in *.json) from your local device. Import Wizard - Prompt Options: Select Project: Choose the target project where you want to import the prompt. You can select your Private workspace or any other project where you have the necessary permissions. Select Versions to Import: You can choose to import all versions of the prompt or select specific versions. Select LLM Model: For each version you are importing, you can select the desired LLM Model. If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice before completing the import. Click the Import button in the Import Wizard. The imported prompt will now be available in the Prompts menu of the selected project. Importing a Datasource Select File: Choose the appropiate datasource file (in *.json) from your local device. Import Wizard - Datasource Options: Select Project: Choose the target project where you want to import the datasource. Select Embedding Model: Choose the desired Embedding Model for the datasource. If the Embedding Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice. Configure Models for Chat, Search, and Deduplicate: Select the desired LLM models for the Chat, Search, and Deduplicate functionalities of the datasource. Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk * . This typically includes the Storage type and various authentication parameters for the datasets. Select Datasets to Import: Choose which datasets you want to import along with the datasource. Provide Dataset Authentication: For any datasets requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords). Click the Import button in the Import Wizard. The imported datasource will now be available in the Datasources menu of the selected project. Reindexing Datasets: After successfully importing the datasource, you must open the datasource and initiate the reindexing of the imported datasets. This step is crucial as the actual vector databases are not exported or imported. Importing an Agent Select File: Choose the appropiate agent file (in *.json) from your local device. Import Wizard - Agent Options: Select Project: Choose the target project where you want to import the agent. Select Versions to Import: You can choose to import all versions of the agent or select specific versions. Select LLM Model: For each version you are importing, you can select the desired LLM Model. If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice before completing the import. Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk * . This typically includes various authentication parameters for the agent's toolkits. Select Tools to Import: Choose which tools you want to import along with the agent. Configure Tool Parameters: You can review and reconfigure the available options and parameters for each tool being imported. You can either use the default values from the exported file or customize them as needed. Provide Toolkit Authentication: For any toolkits requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords). Click the Import button in the Import Wizard. The imported agent will now be available in the Agents menu of the selected project. Importing Master Agents with Connected Entities When importing a master agent that contains connected prompts, datasources, or child agents in its toolkits, ELITEA will automatically import these nested entities as well. This simplifies the process of transferring complex AI solutions. Best Practices and Use Cases Regular Backups: Utilize the export feature to create regular backups of your important prompts, datasources, and agents. Store these exported files in a safe location for disaster recovery purposes. Environment Migration: When migrating from one ELITEA environment to another (e.g., from a development to a production environment), export your entities from the source environment and import them into the target environment. Sharing with Colleagues: Export your well-crafted prompts or useful datasources and share the JSON files with colleagues so they can import them into their own projects. Collaborative Development: Developers can work on different parts of an AI solution in separate ELITEA instances and then use export/import to integrate their work. For example, one developer might create a set of prompts, while another configures a datasource. Template Creation: Create a library of reusable prompt and datasource templates by exporting them. These templates can then be easily imported into new projects, saving time and effort. Security Considerations: Remember that authentication credentials for datasets and toolkits are not included in exported files. Ensure you have a secure way to manage and provide these credentials when importing. Testing in Isolation: Export a production agent and import it into a separate testing environment. This allows you to test new changes without impacting the live system. By understanding and utilizing the Export and Import features effectively, you can significantly enhance your workflow within ELITEA, improve collaboration, and ensure the safety and portability of your valuable AI assets.","title":"Export and Import Guide"},{"location":"user-guide/export-import/#export-and-import-guide-managing-prompts-datasources-and-agents-for-backup-migration-and-collaboration","text":"","title":"Export and Import Guide: Managing Prompts, Datasources, and Agents for Backup, Migration, and Collaboration"},{"location":"user-guide/export-import/#introduction","text":"This user guide provides a comprehensive overview of the Export and Import features within ELITEA. These powerful functionalities allow you to seamlessly transfer your valuable entities \u2013 Prompts , Datasources , and Agents \u2013 between different ELITEA environments, projects, or for backup purposes. The ability to export and import entities offers significant flexibility and control over your AI workflows. You can leverage these features in various scenarios, including: Migrating Entities: Effortlessly move your carefully crafted prompts, configured datasources, and intelligent agents from one ELITEA environment to another. For instance, you can migrate entities from an ELITEA Alita LAB environment to a new Nexus environment. Sharing and Collaboration: Share your entities with colleagues working in different projects or ELITEA instances, fostering collaboration and knowledge sharing. Backup and Recovery: Create backups of your critical entities, ensuring data safety and enabling quick recovery in case of unforeseen issues. Development and Testing: Develop and test entities in a dedicated environment and then easily import them into your production environment. This guide will detail the process of exporting and importing each entity type, along with best practices and practical use cases to help you effectively utilize these features.","title":"Introduction"},{"location":"user-guide/export-import/#import-and-export-features-a-general-overview","text":"The Export feature allows you to save a snapshot of your prompts, datasources, or agents as JSON files. These files contain the complete configuration and relevant data of the entity at the time of export. The Import feature enables you to bring previously exported JSON files back into ELITEA. During the import process, you have the flexibility to configure certain aspects of the imported entity, such as the target project and specific settings. These features provide a convenient and reliable way to manage and transfer your assets within and across ELITEA environments.","title":"Import and Export Features: A General Overview"},{"location":"user-guide/export-import/#how-to-export-entities","text":"ELITEA allows you to export prompts, datasources, and agents individually. The export process is similar for each entity type.","title":"How to Export Entities"},{"location":"user-guide/export-import/#exporting-a-prompt","text":"Navigate to the Prompts menu within the project containing the prompt you wish to export. Locate the specific prompt you want to export from the list. Hover over the prompt entry, and you will see several icons appear on the right side. Click the Export prompt icon. Your browser will automatically download a JSON file containing the prompt's data to your local device. The exported JSON file includes: All versions of the prompt. The complete configuration of each version, including: Context Messages (System, Assistant, User) Variables and their potential values Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens) Welcome Message Conversation Starters Tags","title":"Exporting a Prompt"},{"location":"user-guide/export-import/#exporting-a-datasource","text":"Navigate to the Datasources menu within the project containing the datasource you wish to export. Locate the specific datasource you want to export from the list. Hover over the datasource entry, and you will see several icons appear on the right side. Click the Export datasource prompt. Your browser will automatically download a JSON file containing the datasource's data to your local device. The exported JSON file includes: The complete configuration of the datasource, including: Name and Description Context Welcome Message Conversation Starters Tags Settings for Chat, Search, and Deduplicate functionalities (including selected LLM and Embedding Models) Dataset configurations (including storage details and connection parameters, excluding authentication credentials ) Important Security Note: For security purposes, the authentication information for datasets (such as API Keys, usernames, tokens, and passwords) is not included in the exported datasource file. You will need to re-enter this information when importing the datasource.","title":"Exporting a Datasource"},{"location":"user-guide/export-import/#exporting-an-agent","text":"Navigate to the Agents menu within the project containing the agent you wish to export. Locate the specific agent you want to export from the list. Hover over the agent entry, and you will see several icons appear on the right side. Click the Export agent icon. Your browser will automatically download a JSON file containing the agent's data to your local device. The exported JSON file includes: All versions of the agent. The complete configuration of each version, including: Name and Description Context Welcome Message Conversation Starters Tags Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens) Toolkit configurations (including tool details and parameters, excluding authentication credentials ) Important Security Note: For security purposes, the authentication information for toolkits (such as API Keys, usernames, tokens, and passwords) is not included in the exported agent file. You will need to re-enter this information when importing the agent.","title":"Exporting an Agent"},{"location":"user-guide/export-import/#exporting-master-agents-with-connected-entities","text":"ELITEA offers a convenient feature to export a master agent along with all its connected prompts, datasources, and child agents. This is particularly useful for transferring complex AI solutions. If you export a master agent that has other agents, prompts, or datasources configured as toolkits, these nested entities will also be included in the exported JSON file.","title":"Exporting Master Agents with Connected Entities"},{"location":"user-guide/export-import/#how-to-import-entities","text":"ELITEA provides a straightforward import process for prompts, datasources, and agents. Login ELITEA. Click the +Quick button switcher, located in the top right corner of the interface. Click the Import button. Choose the appropiate file (in *.json) from your local device. An Import Wizard will appear, guiding you through the import process.","title":"How to Import Entities"},{"location":"user-guide/export-import/#importing-a-prompt","text":"Select File: Choose the appropiate prompt file (in *.json) from your local device. Import Wizard - Prompt Options: Select Project: Choose the target project where you want to import the prompt. You can select your Private workspace or any other project where you have the necessary permissions. Select Versions to Import: You can choose to import all versions of the prompt or select specific versions. Select LLM Model: For each version you are importing, you can select the desired LLM Model. If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice before completing the import. Click the Import button in the Import Wizard. The imported prompt will now be available in the Prompts menu of the selected project.","title":"Importing a Prompt"},{"location":"user-guide/export-import/#importing-a-datasource","text":"Select File: Choose the appropiate datasource file (in *.json) from your local device. Import Wizard - Datasource Options: Select Project: Choose the target project where you want to import the datasource. Select Embedding Model: Choose the desired Embedding Model for the datasource. If the Embedding Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice. Configure Models for Chat, Search, and Deduplicate: Select the desired LLM models for the Chat, Search, and Deduplicate functionalities of the datasource. Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk * . This typically includes the Storage type and various authentication parameters for the datasets. Select Datasets to Import: Choose which datasets you want to import along with the datasource. Provide Dataset Authentication: For any datasets requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords). Click the Import button in the Import Wizard. The imported datasource will now be available in the Datasources menu of the selected project. Reindexing Datasets: After successfully importing the datasource, you must open the datasource and initiate the reindexing of the imported datasets. This step is crucial as the actual vector databases are not exported or imported.","title":"Importing a Datasource"},{"location":"user-guide/export-import/#importing-an-agent","text":"Select File: Choose the appropiate agent file (in *.json) from your local device. Import Wizard - Agent Options: Select Project: Choose the target project where you want to import the agent. Select Versions to Import: You can choose to import all versions of the agent or select specific versions. Select LLM Model: For each version you are importing, you can select the desired LLM Model. If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically. If the model is not available, the first available model in your environment will be selected as a default. You can manually change the selected model to your preferred choice before completing the import. Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk * . This typically includes various authentication parameters for the agent's toolkits. Select Tools to Import: Choose which tools you want to import along with the agent. Configure Tool Parameters: You can review and reconfigure the available options and parameters for each tool being imported. You can either use the default values from the exported file or customize them as needed. Provide Toolkit Authentication: For any toolkits requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords). Click the Import button in the Import Wizard. The imported agent will now be available in the Agents menu of the selected project.","title":"Importing an Agent"},{"location":"user-guide/export-import/#importing-master-agents-with-connected-entities","text":"When importing a master agent that contains connected prompts, datasources, or child agents in its toolkits, ELITEA will automatically import these nested entities as well. This simplifies the process of transferring complex AI solutions.","title":"Importing Master Agents with Connected Entities"},{"location":"user-guide/export-import/#best-practices-and-use-cases","text":"Regular Backups: Utilize the export feature to create regular backups of your important prompts, datasources, and agents. Store these exported files in a safe location for disaster recovery purposes. Environment Migration: When migrating from one ELITEA environment to another (e.g., from a development to a production environment), export your entities from the source environment and import them into the target environment. Sharing with Colleagues: Export your well-crafted prompts or useful datasources and share the JSON files with colleagues so they can import them into their own projects. Collaborative Development: Developers can work on different parts of an AI solution in separate ELITEA instances and then use export/import to integrate their work. For example, one developer might create a set of prompts, while another configures a datasource. Template Creation: Create a library of reusable prompt and datasource templates by exporting them. These templates can then be easily imported into new projects, saving time and effort. Security Considerations: Remember that authentication credentials for datasets and toolkits are not included in exported files. Ensure you have a secure way to manage and provide these credentials when importing. Testing in Isolation: Export a production agent and import it into a separate testing environment. This allows you to test new changes without impacting the live system. By understanding and utilizing the Export and Import features effectively, you can significantly enhance your workflow within ELITEA, improve collaboration, and ensure the safety and portability of your valuable AI assets.","title":"Best Practices and Use Cases"},{"location":"user-guide/integrations/","text":"","title":"Integrations Guide"},{"location":"user-guide/prompt-magic-assistant/","text":"Prompt Magic Assistant: Your Guide to Effortless Prompt Creation The Prompt Magic Assistant is an innovative feature in ELITEA designed to streamline and enhance the prompt creation process. It provides an interactive workflow that guides you in articulating your needs with precision and creativity, helping you harness the full potential of AI to develop prompts that are clear, context-rich, and tailored to your specific project requirements. This guide will walk you through how to configure and use the Prompt Magic Assistant , providing examples and best practices to help you make the most of this powerful tool. Accessing the Prompt Magic Assistant The Prompt Magic Assistant is available when you are creating a new prompt. Once a prompt is created and saved, the assistant will no longer be available for that specific prompt. To access the Prompt Magic Assistant: Navigate to the Prompts menu within your desired project. Click the + Prompt button on the top right to begin creating a new prompt. This will take you to the Configuration tab. On the Configuration tab, look for the \"Wizard\" icon . This icon indicates the availability of the Prompt Magic Assistant . Click the \"Wizard\" icon to open the assistant. Configuring Your Prompt with the Magic Assistant The Prompt Magic Assistant simplifies the initial setup of your prompt by generating key elements based on your description of the task. Using the Prompt Magic Assistant: Describe Your Task: Once the Magic Assistant window is open, you will see a text input field. Clearly and concisely describe the task you want the prompt to accomplish. The more detailed your description, the better the assistant can understand your needs and generate relevant suggestions. Example: \"I want to generate manual test cases for covering positive, negative, and edge cases. The test cases must be in Gherkin syntax and keep in mind the possibility for easy automation later. The test cases must be generated for the provided acceptance criteria.\" Example: \"You are an experienced Business Analyst tasked with creating a user story. Your goal is to generate a user story that adheres to the INVEST principles and includes proper acceptance criteria. The user story should be user-centric, facilitating effective communication and prioritization between development teams and stakeholders.\" Generate Prompt Ideas: After entering your task description, click the Generate Prompt button. The Magic Assistant will analyze your input and generate suggestions for various prompt elements. What the Magic Assistant Generates Based on your task description, the Prompt Magic Assistant can automatically populate the following fields in the Configuration tab: Prompt Name: A suggested name for your prompt, reflecting the task you described. Prompt Description: A brief explanation of the prompt's purpose, derived from your input. Context: The core instructions and background information for the AI model. This is crucial for guiding the AI to generate the desired output. Messages (if needed): The assistant may suggest pre-defined System , Assistant , or User messages to structure the interaction flow, particularly for more complex tasks. Welcome Message: An optional message displayed to users when they interact with the prompt, providing additional context or instructions. Conversation Starter(s): Predefined text options that users can click to initiate a conversation or trigger a specific action when executing the prompt. Review and Modify The Prompt Magic Assistant provides a great starting point for your prompt creation. However, it's important to remember that you have full control over the generated content. After the Magic Assistant has generated the initial prompt elements: Review the Generated Content: Carefully examine the suggested Prompt Name , Description , Context , Messages , Welcome Message , and Conversation Starters . Modify as Needed: You can freely edit any of the generated fields to refine the prompt according to your specific requirements. This includes: Adjusting the wording for clarity. Adding more specific instructions to the Context . Modifying or adding new Messages . Customizing the Welcome Message for your users. Adding or editing Conversation Starters . Add Tags: Don't forget to add relevant Tags to categorize your prompt for easy searching and organization. Save Your Prompt: Once you are satisfied with the configuration, click the Save button to finalize the creation of your prompt. Examples of Using the Prompt Magic Assistant Example 1: Generating Test Cases Provided Task: \"I want to generate manual test cases for covering positive, negative, and edge cases for a login feature. The test cases should include steps, expected results, and test data. Consider scenarios for valid and invalid credentials.\" Possible Magic Assistant Output: Prompt Name: Generate Login Test Cases Prompt Description: Generates manual test cases for the login feature, covering positive, negative, and edge cases. Context: \"You are a test engineer tasked with generating manual test cases for a login feature. The test cases should include clear steps, expected results, and relevant test data. Consider scenarios for valid and invalid credentials, including edge cases like incorrect password formats and locked accounts.\" Conversation Starters: \"Generate test cases for the login feature.\" Example 2: Creating a User Story Provided Task: \"As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.\" Possible Magic Assistant Output: Prompt Name: Create User Story for Saving Search Preferences Prompt Description: Generates a user story for the ability to save search preferences. Context: \"You are a product owner responsible for writing user stories. Generate a user story for the following need: 'As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.' Ensure the user story follows the standard format and includes clear acceptance criteria.\" Conversation Starters: \"Generate acceptance criteria for this user story.\" Best Practices for Using the Prompt Magic Assistant Be Specific in Your Task Description: The more details you provide in your initial description, the more accurate and relevant the assistant's suggestions will be. Focus on the Desired Outcome: Clearly state what you want the prompt to achieve. Use Action Verbs: Start your task description with action verbs like \"generate,\" \"create,\" \"summarize,\" \"translate,\" etc. Review and Refine: Always review the generated content and make necessary adjustments to ensure it aligns perfectly with your needs. Don't Hesitate to Modify: The Magic Assistant is a starting point. Feel free to completely rewrite any of the generated fields if needed. Add Tags for Organization: Utilize tags to categorize your prompts, making them easier to find and manage in the future. By following these guidelines, you can effectively leverage the ELITEA Prompt Magic Assistant to significantly simplify and enhance your prompt creation workflow, leading to more effective and efficient AI interactions.","title":"Prompt Magic Assistant Guide"},{"location":"user-guide/prompt-magic-assistant/#prompt-magic-assistant-your-guide-to-effortless-prompt-creation","text":"The Prompt Magic Assistant is an innovative feature in ELITEA designed to streamline and enhance the prompt creation process. It provides an interactive workflow that guides you in articulating your needs with precision and creativity, helping you harness the full potential of AI to develop prompts that are clear, context-rich, and tailored to your specific project requirements. This guide will walk you through how to configure and use the Prompt Magic Assistant , providing examples and best practices to help you make the most of this powerful tool.","title":"Prompt Magic Assistant: Your Guide to Effortless Prompt Creation"},{"location":"user-guide/prompt-magic-assistant/#accessing-the-prompt-magic-assistant","text":"The Prompt Magic Assistant is available when you are creating a new prompt. Once a prompt is created and saved, the assistant will no longer be available for that specific prompt. To access the Prompt Magic Assistant: Navigate to the Prompts menu within your desired project. Click the + Prompt button on the top right to begin creating a new prompt. This will take you to the Configuration tab. On the Configuration tab, look for the \"Wizard\" icon . This icon indicates the availability of the Prompt Magic Assistant . Click the \"Wizard\" icon to open the assistant.","title":"Accessing the Prompt Magic Assistant"},{"location":"user-guide/prompt-magic-assistant/#configuring-your-prompt-with-the-magic-assistant","text":"The Prompt Magic Assistant simplifies the initial setup of your prompt by generating key elements based on your description of the task. Using the Prompt Magic Assistant: Describe Your Task: Once the Magic Assistant window is open, you will see a text input field. Clearly and concisely describe the task you want the prompt to accomplish. The more detailed your description, the better the assistant can understand your needs and generate relevant suggestions. Example: \"I want to generate manual test cases for covering positive, negative, and edge cases. The test cases must be in Gherkin syntax and keep in mind the possibility for easy automation later. The test cases must be generated for the provided acceptance criteria.\" Example: \"You are an experienced Business Analyst tasked with creating a user story. Your goal is to generate a user story that adheres to the INVEST principles and includes proper acceptance criteria. The user story should be user-centric, facilitating effective communication and prioritization between development teams and stakeholders.\" Generate Prompt Ideas: After entering your task description, click the Generate Prompt button. The Magic Assistant will analyze your input and generate suggestions for various prompt elements.","title":"Configuring Your Prompt with the Magic Assistant"},{"location":"user-guide/prompt-magic-assistant/#what-the-magic-assistant-generates","text":"Based on your task description, the Prompt Magic Assistant can automatically populate the following fields in the Configuration tab: Prompt Name: A suggested name for your prompt, reflecting the task you described. Prompt Description: A brief explanation of the prompt's purpose, derived from your input. Context: The core instructions and background information for the AI model. This is crucial for guiding the AI to generate the desired output. Messages (if needed): The assistant may suggest pre-defined System , Assistant , or User messages to structure the interaction flow, particularly for more complex tasks. Welcome Message: An optional message displayed to users when they interact with the prompt, providing additional context or instructions. Conversation Starter(s): Predefined text options that users can click to initiate a conversation or trigger a specific action when executing the prompt.","title":"What the Magic Assistant Generates"},{"location":"user-guide/prompt-magic-assistant/#review-and-modify","text":"The Prompt Magic Assistant provides a great starting point for your prompt creation. However, it's important to remember that you have full control over the generated content. After the Magic Assistant has generated the initial prompt elements: Review the Generated Content: Carefully examine the suggested Prompt Name , Description , Context , Messages , Welcome Message , and Conversation Starters . Modify as Needed: You can freely edit any of the generated fields to refine the prompt according to your specific requirements. This includes: Adjusting the wording for clarity. Adding more specific instructions to the Context . Modifying or adding new Messages . Customizing the Welcome Message for your users. Adding or editing Conversation Starters . Add Tags: Don't forget to add relevant Tags to categorize your prompt for easy searching and organization. Save Your Prompt: Once you are satisfied with the configuration, click the Save button to finalize the creation of your prompt.","title":"Review and Modify"},{"location":"user-guide/prompt-magic-assistant/#examples-of-using-the-prompt-magic-assistant","text":"Example 1: Generating Test Cases Provided Task: \"I want to generate manual test cases for covering positive, negative, and edge cases for a login feature. The test cases should include steps, expected results, and test data. Consider scenarios for valid and invalid credentials.\" Possible Magic Assistant Output: Prompt Name: Generate Login Test Cases Prompt Description: Generates manual test cases for the login feature, covering positive, negative, and edge cases. Context: \"You are a test engineer tasked with generating manual test cases for a login feature. The test cases should include clear steps, expected results, and relevant test data. Consider scenarios for valid and invalid credentials, including edge cases like incorrect password formats and locked accounts.\" Conversation Starters: \"Generate test cases for the login feature.\" Example 2: Creating a User Story Provided Task: \"As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.\" Possible Magic Assistant Output: Prompt Name: Create User Story for Saving Search Preferences Prompt Description: Generates a user story for the ability to save search preferences. Context: \"You are a product owner responsible for writing user stories. Generate a user story for the following need: 'As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.' Ensure the user story follows the standard format and includes clear acceptance criteria.\" Conversation Starters: \"Generate acceptance criteria for this user story.\"","title":"Examples of Using the Prompt Magic Assistant"},{"location":"user-guide/prompt-magic-assistant/#best-practices-for-using-the-prompt-magic-assistant","text":"Be Specific in Your Task Description: The more details you provide in your initial description, the more accurate and relevant the assistant's suggestions will be. Focus on the Desired Outcome: Clearly state what you want the prompt to achieve. Use Action Verbs: Start your task description with action verbs like \"generate,\" \"create,\" \"summarize,\" \"translate,\" etc. Review and Refine: Always review the generated content and make necessary adjustments to ensure it aligns perfectly with your needs. Don't Hesitate to Modify: The Magic Assistant is a starting point. Feel free to completely rewrite any of the generated fields if needed. Add Tags for Organization: Utilize tags to categorize your prompts, making them easier to find and manage in the future. By following these guidelines, you can effectively leverage the ELITEA Prompt Magic Assistant to significantly simplify and enhance your prompt creation workflow, leading to more effective and efficient AI interactions.","title":"Best Practices for Using the Prompt Magic Assistant"},{"location":"user-guide/public-project/","text":"Public Project Guide: Explore and Collaborate The Public project in ELITEA serves as a collaborative hub where users can discover, utilize, and appreciate resources shared by the community. It's a space designed to foster knowledge sharing and accelerate innovation by making valuable prompts, agents, and datasources accessible to everyone within your organization. Key Features of the Public Project: Shared Resources: Access a curated collection of prompts, agents, and datasources contributed by other ELITEA users. Community Collaboration: Benefit from the collective expertise and creativity of your colleagues. Discover Best Practices: Explore highly-rated and trending resources to learn from successful implementations. Ready-to-Use Tools: Execute published resources directly to leverage their functionality. Inspiration and Learning: Discover new approaches and techniques by examining how others have built their resources. Accessing the Public Project: The Public project is readily accessible to all ELITEA users by default. You can switch to the Public project from your current project by clicking the Project switcher. Navigating the Public Project The Public project is organized into distinct menus, each dedicated to a specific type of shared resource: Chat : Access to conversations, allowing to add participants (Agents, Prompts, Datasources, Models and Users) from Public project. Prompts: Discover and interact with prompts shared by the community. Datasources: Explore and utilize published datasources. Agents: Find and execute agents created and shared by other users. Collections: Browse and explore curated collections of resources. Each of these menus (except Chat) shares a similar structure, making it easy to navigate and find what you're looking for. Exploring Shared Resources Within each resource menu (Prompts, Datasources, Agents, Collections), you'll find three sub-sections designed to help you discover and engage with the shared content: Latest: This section displays the most recently published resources, giving you a glimpse into the newest additions to the community's shared pool. My Likes: Here, you'll find a personalized list of the resources you've liked. This allows you to easily revisit your favorite and most valuable finds. Trending: This section showcases the most popular resources, ranked by the number of likes they've received. It's a great place to discover highly regarded and widely used resources within the community. Interacting with Published Resources The Public project encourages active participation and appreciation of shared resources. Here's how you can interact with the prompts, datasources, and agents you find: Showing Appreciation: Liking Resources If you find a published prompt, datasource, or agent particularly useful or well-crafted, you can show your appreciation by \"liking\" it. To Like: Click the Heart icon associated with the resource. The icon will typically change color or appearance to indicate that you've liked it. To Unlike: If you change your mind or no longer wish to like a resource, simply click the Heart icon again. Utilizing Published Resources The primary purpose of the Public project is to allow users to leverage the shared resources. You can directly execute published prompts and agents to utilize their functionality. Simply click on the resource's card or name to view its details and find the execution options. Important Note: While you can view and execute resources in the Public project, you cannot directly modify and save changes to the original published version. These resources are intended for execution and inspiration. Incorporating Public Resources into Your Workflow You can leverage valuable resources found in the Public project in several ways: Adding to Collections: Organize useful public prompts, datasources, or agents into your personal collections within your Private project for easy access and management. Exporting Resources: For backup or use in other platforms (if supported), you can export published prompts. Refer to the documentation for your Private project for detailed instructions on adding to collections and exporting resources. Sharing Your Expertise: Publishing Resources While you primarily interact with existing resources in the Public project, you can also contribute your own creations. If you've developed a valuable prompt, agent, or datasource in your Private project, you can submit it for publication to the Public project. The Publication Process: Create and Refine: Develop and thoroughly test your prompt, agent, or datasource in your Private project. Submit for Publication: Initiate the publication process for your resource. This typically involves clicking a \"Publish\" button within the resource's settings. Moderation Review: Resources submitted for publication are reviewed by designated moderators to ensure quality, relevance, and adherence to community guidelines. Approval and Publication: If approved, your resource will be published and become available to the wider ELITEA community in the Public project. Note: Only approved moderators have the ability to add resources to the Public project. Benefits of the Public Project Reduced Redundancy: Avoid recreating commonly used prompts, agents, or datasources by leveraging existing community contributions. Accelerated Development: Quickly find and utilize pre-built resources to speed up your workflows. Enhanced Learning: Discover new techniques and approaches by examining how others have designed their resources. Community Building: Contribute to a shared knowledge base and benefit from the collective expertise of your colleagues. The ELITEA Public project is a valuable place for fostering collaboration and maximizing the potential of AI within your organization. Explore, engage, and contribute to make the most of this shared resource pool.","title":"Public Project Guide"},{"location":"user-guide/public-project/#public-project-guide-explore-and-collaborate","text":"The Public project in ELITEA serves as a collaborative hub where users can discover, utilize, and appreciate resources shared by the community. It's a space designed to foster knowledge sharing and accelerate innovation by making valuable prompts, agents, and datasources accessible to everyone within your organization. Key Features of the Public Project: Shared Resources: Access a curated collection of prompts, agents, and datasources contributed by other ELITEA users. Community Collaboration: Benefit from the collective expertise and creativity of your colleagues. Discover Best Practices: Explore highly-rated and trending resources to learn from successful implementations. Ready-to-Use Tools: Execute published resources directly to leverage their functionality. Inspiration and Learning: Discover new approaches and techniques by examining how others have built their resources. Accessing the Public Project: The Public project is readily accessible to all ELITEA users by default. You can switch to the Public project from your current project by clicking the Project switcher.","title":"Public Project Guide: Explore and Collaborate"},{"location":"user-guide/public-project/#navigating-the-public-project","text":"The Public project is organized into distinct menus, each dedicated to a specific type of shared resource: Chat : Access to conversations, allowing to add participants (Agents, Prompts, Datasources, Models and Users) from Public project. Prompts: Discover and interact with prompts shared by the community. Datasources: Explore and utilize published datasources. Agents: Find and execute agents created and shared by other users. Collections: Browse and explore curated collections of resources. Each of these menus (except Chat) shares a similar structure, making it easy to navigate and find what you're looking for.","title":"Navigating the Public Project"},{"location":"user-guide/public-project/#exploring-shared-resources","text":"Within each resource menu (Prompts, Datasources, Agents, Collections), you'll find three sub-sections designed to help you discover and engage with the shared content: Latest: This section displays the most recently published resources, giving you a glimpse into the newest additions to the community's shared pool. My Likes: Here, you'll find a personalized list of the resources you've liked. This allows you to easily revisit your favorite and most valuable finds. Trending: This section showcases the most popular resources, ranked by the number of likes they've received. It's a great place to discover highly regarded and widely used resources within the community.","title":"Exploring Shared Resources"},{"location":"user-guide/public-project/#interacting-with-published-resources","text":"The Public project encourages active participation and appreciation of shared resources. Here's how you can interact with the prompts, datasources, and agents you find:","title":"Interacting with Published Resources"},{"location":"user-guide/public-project/#showing-appreciation-liking-resources","text":"If you find a published prompt, datasource, or agent particularly useful or well-crafted, you can show your appreciation by \"liking\" it. To Like: Click the Heart icon associated with the resource. The icon will typically change color or appearance to indicate that you've liked it. To Unlike: If you change your mind or no longer wish to like a resource, simply click the Heart icon again.","title":"Showing Appreciation: Liking Resources"},{"location":"user-guide/public-project/#utilizing-published-resources","text":"The primary purpose of the Public project is to allow users to leverage the shared resources. You can directly execute published prompts and agents to utilize their functionality. Simply click on the resource's card or name to view its details and find the execution options. Important Note: While you can view and execute resources in the Public project, you cannot directly modify and save changes to the original published version. These resources are intended for execution and inspiration.","title":"Utilizing Published Resources"},{"location":"user-guide/public-project/#incorporating-public-resources-into-your-workflow","text":"You can leverage valuable resources found in the Public project in several ways: Adding to Collections: Organize useful public prompts, datasources, or agents into your personal collections within your Private project for easy access and management. Exporting Resources: For backup or use in other platforms (if supported), you can export published prompts. Refer to the documentation for your Private project for detailed instructions on adding to collections and exporting resources.","title":"Incorporating Public Resources into Your Workflow"},{"location":"user-guide/public-project/#sharing-your-expertise-publishing-resources","text":"While you primarily interact with existing resources in the Public project, you can also contribute your own creations. If you've developed a valuable prompt, agent, or datasource in your Private project, you can submit it for publication to the Public project. The Publication Process: Create and Refine: Develop and thoroughly test your prompt, agent, or datasource in your Private project. Submit for Publication: Initiate the publication process for your resource. This typically involves clicking a \"Publish\" button within the resource's settings. Moderation Review: Resources submitted for publication are reviewed by designated moderators to ensure quality, relevance, and adherence to community guidelines. Approval and Publication: If approved, your resource will be published and become available to the wider ELITEA community in the Public project. Note: Only approved moderators have the ability to add resources to the Public project.","title":"Sharing Your Expertise: Publishing Resources"},{"location":"user-guide/public-project/#benefits-of-the-public-project","text":"Reduced Redundancy: Avoid recreating commonly used prompts, agents, or datasources by leveraging existing community contributions. Accelerated Development: Quickly find and utilize pre-built resources to speed up your workflows. Enhanced Learning: Discover new techniques and approaches by examining how others have designed their resources. Community Building: Contribute to a shared knowledge base and benefit from the collective expertise of your colleagues. The ELITEA Public project is a valuable place for fostering collaboration and maximizing the potential of AI within your organization. Explore, engage, and contribute to make the most of this shared resource pool.","title":"Benefits of the Public Project"}]}