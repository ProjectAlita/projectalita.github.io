{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Alita Documentation Project Alita is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations. Our Values: Democratize AI Access for all organizational levels with accessible, user-friendly AI technology Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments Foster Collaboration by providing environments where people can share their assets within projects and organization Scale with Your Needs with a platform that scales from small teams to enterprise levels","title":"Welcome to Alita Documentation"},{"location":"#welcome-to-alita-documentation","text":"Project Alita is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations.","title":"Welcome to Alita Documentation"},{"location":"#our-values","text":"Democratize AI Access for all organizational levels with accessible, user-friendly AI technology Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments Foster Collaboration by providing environments where people can share their assets within projects and organization Scale with Your Needs with a platform that scales from small teams to enterprise levels","title":"Our Values:"},{"location":"alita-chat/","text":"Alita Code Chat Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB. Pre-requisite Alita Code Chat depends on Alita Code for VS Code and IntelliJ. Alita Code can be installed through their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace. Features list: Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned. Alita Code Chat for VS code Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code. Installation Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code. Alita Code Chat Usage With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Prompts To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Handling Variables: Variable Input : If the selected prompt requires variables, a pop-up window will appear prompting you to input the necessary values. Variable Configuration : You can adjust or update variable values at any time by clicking the Settings icon. This allows for dynamic changes to the prompt's behavior based on updated inputs. Datasources To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the application that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the Alita Code Chat. Start conversation in the form of a question, statement, or command that simulates human-like interaction . AlitaCodeChat for IntelliJ AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode. Installation Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. AlitaCodeChat for IntelliJ is available in 2 modes: Native - allowing to chat with configured/selected LLM model in AlitaCode settings. React - allowing to interact both with configured/selected LLM model as well as the prompts, datasources and agents configured in ELITEA Hub. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem. Alita Code Chat Usage Prompts To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type / in the chat box. Select the prompt that you want to run. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Handling Variables: Variable Input : If the selected prompt requires variables, a pop-up window will appear prompting you to input the necessary values. Variable Configuration : You can adjust or update variable values at any time by clicking the Settings icon. This allows for dynamic changes to the prompt's behavior based on updated inputs. Datasources To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the application that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction . Additional Interaction Features Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Alita Code Chat"},{"location":"alita-chat/#alita-code-chat","text":"Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB.","title":"Alita Code Chat"},{"location":"alita-chat/#pre-requisite","text":"Alita Code Chat depends on Alita Code for VS Code and IntelliJ. Alita Code can be installed through their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace.","title":"Pre-requisite"},{"location":"alita-chat/#features-list","text":"Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned.","title":"Features list:"},{"location":"alita-chat/#alita-code-chat-for-vs-code","text":"Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code.","title":"Alita Code Chat for VS code"},{"location":"alita-chat/#installation","text":"Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code.","title":"Installation"},{"location":"alita-chat/#alita-code-chat-usage","text":"With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Alita Code Chat Usage"},{"location":"alita-chat/#prompts","text":"To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Handling Variables: Variable Input : If the selected prompt requires variables, a pop-up window will appear prompting you to input the necessary values. Variable Configuration : You can adjust or update variable values at any time by clicking the Settings icon. This allows for dynamic changes to the prompt's behavior based on updated inputs.","title":"Prompts"},{"location":"alita-chat/#datasources","text":"To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"alita-chat/#agents","text":"To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the application that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"alita-chat/#chat","text":"Open the Alita Code Chat. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"alita-chat/#alitacodechat-for-intellij","text":"AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode.","title":"AlitaCodeChat for IntelliJ"},{"location":"alita-chat/#installation_1","text":"Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. AlitaCodeChat for IntelliJ is available in 2 modes: Native - allowing to chat with configured/selected LLM model in AlitaCode settings. React - allowing to interact both with configured/selected LLM model as well as the prompts, datasources and agents configured in ELITEA Hub. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem.","title":"Installation"},{"location":"alita-chat/#alita-code-chat-usage_1","text":"","title":"Alita Code Chat Usage"},{"location":"alita-chat/#prompts_1","text":"To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type / in the chat box. Select the prompt that you want to run. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Handling Variables: Variable Input : If the selected prompt requires variables, a pop-up window will appear prompting you to input the necessary values. Variable Configuration : You can adjust or update variable values at any time by clicking the Settings icon. This allows for dynamic changes to the prompt's behavior based on updated inputs.","title":"Prompts"},{"location":"alita-chat/#datasources_1","text":"To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"alita-chat/#agents_1","text":"To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the application that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"alita-chat/#chat_1","text":"Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"alita-chat/#additional-interaction-features","text":"Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Additional Interaction Features"},{"location":"alita-code/","text":"Alita Code Get Started with Alita Code Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code amd InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience. Why Choose Alita Code? Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts. Key Features Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts powered by Alita Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation Getting Started with Extension Commands Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts with Alita Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together. Alita Code for VS Code Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with Alita Code is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code in the Marketplace and click Install . Setup Once installed, setting up Alita Code to work with your projects is simple. To configure Alita Code effectively, you can adjust settings from the Settings page in Alita. There are two distinct types of settings available to cater to different needs: User Settings are global and apply to all sessions across any workspace. These settings ensure a consistent environment across your projects, providing a uniform experience regardless of the workspace in use. This is particularly useful for general preferences that you want to maintain across all your development activities. Workspace Settings are specific to a particular workspace. This flexibility is crucial when you need to apply different configurations such as project IDs, models, or other specific parameters in various workspaces. For example, in VSCode, you might want to have different project IDs for different projects to maintain separate environments or use different Gen AI models tailored to specific tasks. To configure: From the VS Code Welcome screen, open the repository or folder where your project is located. Access Configuration by going to Settings . Navigate to Extensions \u2192 Alita Code . Select either User or Workspace tab. Configuring Alita Code for Integration with the ELITEA Platform. To connect Alita Code with the ELITEA platform, configure the following settings appropriately: Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alita Code: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA platform, allowing for seamless integration and efficient use of LLM models within your projects. Note : Changes may require restarting VS Code to take effect. Important : For connecting to ELITEA HUB, copy the required settings (URL, ProjectId, Integration Uid, Model Name) from ELITEA HUB \u2192 Settings \u2192 Configuration page. Check and verify that the Alitacode: Verify Ssl is NOT selected. Configuration To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. Alita Code Usage With Alita Code set up, you can now: Create Prompts : Right-click in the editor and navigate to Alita \u2192 Create Prompt to craft new prompts. Extend Context : Enhance the context of an existing prompt by selecting text and choosing Extend Context from the right-click menu. Predict : Generate predictions by selecting Alita Predict after right-clicking selected text. Sync External Prompts : Keep your external prompts up-to-date with Alita Sync External Prompts . Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Extend Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions. This feature significantly boosts productivity by integrating Gen AI tools directly into the testing process for real-time analysis and enhancement. Predict (Execute) Prompt To predict (execute) a prompt directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt : Pick the prompt you wish to execute from the dropdown list. View Predictions : The generated response will be displayed according to the method selected in Alita Code: Default View Mode . Note : You can use default prompts, those you've created, or external prompts synced from ELITEA HUB . Synchronize External Prompts Sync prompts created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita Sync External Prompts from the submenu. Synchronization : The prompts will be synced and added to the prompts.json file, with a .yaml file created for each synced prompt. Usage : These prompts are now ready to be used with Alita: Predict command. Note : To sync and use prompts from ELITEA HUB, tag the prompt with code in ELITEA HUB. By following these detailed steps, you can maximize your productivity and coding efficiency with Alita Code's AI-powered features. AlitaCode for IntelliJ Idea AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with AlitaCode is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install . Setup Once installed, setting up AlitaCode to work with your projects is simple. To configure AlitaCode effectively: Navigate to the to the Settings \u2192 Tools section in IntelliJ. Select the Alita . Start configuration: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita . LLM Auth Token : Provide your Bearer token for the LLM service provider. Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. To check and apply configuration: Click the Reload icon next to the Integration UID . Select the ai_dial as integration and click OK button. To complete the setup click the OK button. Important : For connecting to ELITEA HUB, copy the required settings (URL, Token, Project ID, Integration UID, Model Name) from ELITEA HUB \u2192 Settings \u2192 Configuration page. Configuration To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. AlitaCode Usage With AlitaCode set up, you can now: Create Prompts : Right-click in the editor and navigate to Alita \u2192 Create Prompt to craft new prompts. Extend Context : Enhance the context of an existing prompt by selecting text and choosing Extend Context from the right-click menu. Predict : Generate predictions by selecting Alita Predict after right-clicking selected text. Sync External Prompts : Keep your external prompts up-to-date with Alita Sync External Prompts . Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section.. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. AlitaCode will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Edit Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes. This feature significantly boosts productivity by integrating Gen AI tools directly into the testing process for real-time analysis and enhancement. Predict (Execute) Prompt To predict (execute) a prompt directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt : Pick the prompt you wish to execute from the list and click the OK button. View Predictions : The generated response will be displayed according to the method selected in AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts synced from ELITEA HUB . Synchronize External Prompts Sync prompts created in the ELITEA HUB with your AlitaCode setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts will be synced and added to the prompts.json file. Usage : These prompts are now ready to be used with Alita: Predict command. Note : To sync and use prompts from ELITEA HUB, tag the prompt with code in ELITEA HUB. By following these detailed steps, you can maximize your productivity and coding efficiency with Alita Code's AI-powered features.","title":"Alita Code"},{"location":"alita-code/#alita-code","text":"","title":"Alita Code"},{"location":"alita-code/#get-started-with-alita-code","text":"Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code amd InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience.","title":"Get Started with Alita Code"},{"location":"alita-code/#why-choose-alita-code","text":"Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts.","title":"Why Choose Alita Code?"},{"location":"alita-code/#key-features","text":"Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts powered by Alita Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation","title":"Key Features"},{"location":"alita-code/#getting-started-with-extension-commands","text":"Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts with Alita Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together.","title":"Getting Started with Extension Commands"},{"location":"alita-code/#alita-code-for-vs-code","text":"Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend.","title":"Alita Code for VS Code"},{"location":"alita-code/#installation","text":"Getting started with Alita Code is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code in the Marketplace and click Install .","title":"Installation"},{"location":"alita-code/#setup","text":"Once installed, setting up Alita Code to work with your projects is simple. To configure Alita Code effectively, you can adjust settings from the Settings page in Alita. There are two distinct types of settings available to cater to different needs: User Settings are global and apply to all sessions across any workspace. These settings ensure a consistent environment across your projects, providing a uniform experience regardless of the workspace in use. This is particularly useful for general preferences that you want to maintain across all your development activities. Workspace Settings are specific to a particular workspace. This flexibility is crucial when you need to apply different configurations such as project IDs, models, or other specific parameters in various workspaces. For example, in VSCode, you might want to have different project IDs for different projects to maintain separate environments or use different Gen AI models tailored to specific tasks. To configure: From the VS Code Welcome screen, open the repository or folder where your project is located. Access Configuration by going to Settings . Navigate to Extensions \u2192 Alita Code . Select either User or Workspace tab. Configuring Alita Code for Integration with the ELITEA Platform. To connect Alita Code with the ELITEA platform, configure the following settings appropriately: Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alita Code: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA platform, allowing for seamless integration and efficient use of LLM models within your projects. Note : Changes may require restarting VS Code to take effect. Important : For connecting to ELITEA HUB, copy the required settings (URL, ProjectId, Integration Uid, Model Name) from ELITEA HUB \u2192 Settings \u2192 Configuration page. Check and verify that the Alitacode: Verify Ssl is NOT selected.","title":"Setup"},{"location":"alita-code/#configuration","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuration"},{"location":"alita-code/#alita-code-usage","text":"With Alita Code set up, you can now: Create Prompts : Right-click in the editor and navigate to Alita \u2192 Create Prompt to craft new prompts. Extend Context : Enhance the context of an existing prompt by selecting text and choosing Extend Context from the right-click menu. Predict : Generate predictions by selecting Alita Predict after right-clicking selected text. Sync External Prompts : Keep your external prompts up-to-date with Alita Sync External Prompts .","title":"Alita Code Usage"},{"location":"alita-code/#create-a-prompt","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"alita-code/#extend-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions. This feature significantly boosts productivity by integrating Gen AI tools directly into the testing process for real-time analysis and enhancement.","title":"Extend Prompt Context"},{"location":"alita-code/#predict-execute-prompt","text":"To predict (execute) a prompt directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt : Pick the prompt you wish to execute from the dropdown list. View Predictions : The generated response will be displayed according to the method selected in Alita Code: Default View Mode . Note : You can use default prompts, those you've created, or external prompts synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"alita-code/#synchronize-external-prompts","text":"Sync prompts created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita Sync External Prompts from the submenu. Synchronization : The prompts will be synced and added to the prompts.json file, with a .yaml file created for each synced prompt. Usage : These prompts are now ready to be used with Alita: Predict command. Note : To sync and use prompts from ELITEA HUB, tag the prompt with code in ELITEA HUB. By following these detailed steps, you can maximize your productivity and coding efficiency with Alita Code's AI-powered features.","title":"Synchronize External Prompts"},{"location":"alita-code/#alitacode-for-intellij-idea","text":"AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend.","title":"AlitaCode for IntelliJ Idea"},{"location":"alita-code/#installation_1","text":"Getting started with AlitaCode is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install .","title":"Installation"},{"location":"alita-code/#setup_1","text":"Once installed, setting up AlitaCode to work with your projects is simple. To configure AlitaCode effectively: Navigate to the to the Settings \u2192 Tools section in IntelliJ. Select the Alita . Start configuration: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita . LLM Auth Token : Provide your Bearer token for the LLM service provider. Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. To check and apply configuration: Click the Reload icon next to the Integration UID . Select the ai_dial as integration and click OK button. To complete the setup click the OK button. Important : For connecting to ELITEA HUB, copy the required settings (URL, Token, Project ID, Integration UID, Model Name) from ELITEA HUB \u2192 Settings \u2192 Configuration page.","title":"Setup"},{"location":"alita-code/#configuration_1","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuration"},{"location":"alita-code/#alitacode-usage","text":"With AlitaCode set up, you can now: Create Prompts : Right-click in the editor and navigate to Alita \u2192 Create Prompt to craft new prompts. Extend Context : Enhance the context of an existing prompt by selecting text and choosing Extend Context from the right-click menu. Predict : Generate predictions by selecting Alita Predict after right-clicking selected text. Sync External Prompts : Keep your external prompts up-to-date with Alita Sync External Prompts .","title":"AlitaCode Usage"},{"location":"alita-code/#create-a-prompt_1","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section.. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. AlitaCode will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"alita-code/#edit-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes. This feature significantly boosts productivity by integrating Gen AI tools directly into the testing process for real-time analysis and enhancement.","title":"Edit Prompt Context"},{"location":"alita-code/#predict-execute-prompt_1","text":"To predict (execute) a prompt directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt : Pick the prompt you wish to execute from the list and click the OK button. View Predictions : The generated response will be displayed according to the method selected in AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"alita-code/#synchronize-external-prompts_1","text":"Sync prompts created in the ELITEA HUB with your AlitaCode setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts will be synced and added to the prompts.json file. Usage : These prompts are now ready to be used with Alita: Predict command. Note : To sync and use prompts from ELITEA HUB, tag the prompt with code in ELITEA HUB. By following these detailed steps, you can maximize your productivity and coding efficiency with Alita Code's AI-powered features.","title":"Synchronize External Prompts"},{"location":"alita-dial/","text":"Interoperability Guide: ELITEA and EPAM AI Dial Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial. Export Prompts from ELITEA Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it: Exporting the Prompt for AI DIAL: Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format. Import Prompts to EPAM AI Dial Once you have the JSON file from ELITEA, you can easily import it into AI Dial. Importing the Prompt into AI Dial: Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial. Export Prompts from EPAM AI Dial If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA. Import Prompts to ELITEA To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the My libraries - Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Exporting and Importing Collections from ELITEA to EPAM AI Dial You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial. Troubleshooting File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts. Useful Links ELITEA Prompt Library - User Guide ELITEA Prompt Library - Release Notes Epam AI Dial - User Guide","title":"ELITEA and EPAM AI DIAL"},{"location":"alita-dial/#interoperability-guide-elitea-and-epam-ai-dial","text":"Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial.","title":"Interoperability Guide: ELITEA and EPAM AI Dial"},{"location":"alita-dial/#export-prompts-from-elitea","text":"Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it:","title":"Export Prompts from ELITEA"},{"location":"alita-dial/#exporting-the-prompt-for-ai-dial","text":"Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format.","title":"Exporting the Prompt for AI DIAL:"},{"location":"alita-dial/#import-prompts-to-epam-ai-dial","text":"Once you have the JSON file from ELITEA, you can easily import it into AI Dial.","title":"Import Prompts to EPAM AI Dial"},{"location":"alita-dial/#importing-the-prompt-into-ai-dial","text":"Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial.","title":"Importing the Prompt into AI Dial:"},{"location":"alita-dial/#export-prompts-from-epam-ai-dial","text":"If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA.","title":"Export Prompts from EPAM AI Dial"},{"location":"alita-dial/#import-prompts-to-elitea","text":"To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the My libraries - Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt.","title":"Import Prompts to ELITEA"},{"location":"alita-dial/#exporting-and-importing-collections-from-elitea-to-epam-ai-dial","text":"You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial.","title":"Exporting and Importing Collections from ELITEA to EPAM AI Dial"},{"location":"alita-dial/#troubleshooting","text":"File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts.","title":"Troubleshooting"},{"location":"alita-dial/#useful-links","text":"ELITEA Prompt Library - User Guide ELITEA Prompt Library - Release Notes Epam AI Dial - User Guide","title":"Useful Links"},{"location":"creating-prompts/","text":"How to Create and Publish Useful Prompts for Testing and QA Activities Introduction Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success. Access to ELITEA To access it: Open your browser. Type in https://alita.lab.epam.com in the address bar. Provide your EPAM account to login. Note : No need for registration. After successful login, you are navigated to the Prompts menu. Once you have access, navigate to Discover\u2192My Library menu, where you will be able to create prompts and collections. Note: If you are logging in for the first time into ELITEA, wait for 5 minutes to allow private project initialization to be completed before creating prompts. Note : You need to enable Epam VPN to access ELITEA. Prompts Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information. How to Create a Prompt Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings: Prompt Requirements for Consistency and Quality When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations. Submitting Your Prompt for Publishing To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt: Providing Version: Review Process by Moderators and Outcome of Prompt Submission Moderator Review Process After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared. Possible Outcomes of the Review After the review process, the prompt can have one of the following outcomes: Published : The prompt meets all requirements and is made available in the Prompt Library for the entire network. Feedback for Revision : The prompt has potential but requires changes. Specific feedback is provided for refinement. Rejected : The prompt does not meet the necessary criteria and cannot be published in its current form. Reasons for rejection are shared with the submitter. Statuses of Prompts Users can track the status of their prompts throughout the review process. The following statuses are available: All Statuses : A general view of all submitted prompts irrespective of their current stage. Draft : The prompt is saved but not yet submitted for publishing. Published : The prompt has been approved by moderators and is available in the Library. On Moderation : The prompt is currently being reviewed by the moderators. User Approval : The prompt is pending prompt's author approval for publishing a new version. Rejected : The prompt has been reviewed and rejected for publication. To check the status of your submitted prompts, navigate to \" My libraries \u2192 Prompts \" page on the platform, and select the status you wish to view from the dropdown menu. Engagement with Prompts: Liking and Trending Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy. Collections Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. Creating Collection Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about. Adding Prompts to Your Collection To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection. Publishing Your Collection Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication. Engagement with Collections: Liking and Trending Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged. Contribution Why Share Your Prompts? Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement. Rewards and Recognition To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network. Useful Resources ELITEA ELITEA - User Guide ELITEA - Release Notes Prompt Engineering Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"QA - Prompting and Sharing"},{"location":"creating-prompts/#how-to-create-and-publish-useful-prompts-for-testing-and-qa-activities","text":"","title":"How to Create and Publish Useful Prompts for Testing and QA Activities"},{"location":"creating-prompts/#introduction","text":"Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success.","title":"Introduction"},{"location":"creating-prompts/#access-to-elitea","text":"To access it: Open your browser. Type in https://alita.lab.epam.com in the address bar. Provide your EPAM account to login. Note : No need for registration. After successful login, you are navigated to the Prompts menu. Once you have access, navigate to Discover\u2192My Library menu, where you will be able to create prompts and collections. Note: If you are logging in for the first time into ELITEA, wait for 5 minutes to allow private project initialization to be completed before creating prompts. Note : You need to enable Epam VPN to access ELITEA.","title":"Access to ELITEA"},{"location":"creating-prompts/#prompts","text":"Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information.","title":"Prompts"},{"location":"creating-prompts/#how-to-create-a-prompt","text":"Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings:","title":"How to Create a Prompt"},{"location":"creating-prompts/#prompt-requirements-for-consistency-and-quality","text":"When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations.","title":"Prompt Requirements for Consistency and Quality"},{"location":"creating-prompts/#submitting-your-prompt-for-publishing","text":"To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt: Providing Version:","title":"Submitting Your Prompt for Publishing"},{"location":"creating-prompts/#review-process-by-moderators-and-outcome-of-prompt-submission","text":"","title":"Review Process by Moderators and Outcome of Prompt Submission"},{"location":"creating-prompts/#moderator-review-process","text":"After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared.","title":"Moderator Review Process"},{"location":"creating-prompts/#possible-outcomes-of-the-review","text":"After the review process, the prompt can have one of the following outcomes: Published : The prompt meets all requirements and is made available in the Prompt Library for the entire network. Feedback for Revision : The prompt has potential but requires changes. Specific feedback is provided for refinement. Rejected : The prompt does not meet the necessary criteria and cannot be published in its current form. Reasons for rejection are shared with the submitter. Statuses of Prompts Users can track the status of their prompts throughout the review process. The following statuses are available: All Statuses : A general view of all submitted prompts irrespective of their current stage. Draft : The prompt is saved but not yet submitted for publishing. Published : The prompt has been approved by moderators and is available in the Library. On Moderation : The prompt is currently being reviewed by the moderators. User Approval : The prompt is pending prompt's author approval for publishing a new version. Rejected : The prompt has been reviewed and rejected for publication. To check the status of your submitted prompts, navigate to \" My libraries \u2192 Prompts \" page on the platform, and select the status you wish to view from the dropdown menu.","title":"Possible Outcomes of the Review"},{"location":"creating-prompts/#engagement-with-prompts-liking-and-trending","text":"Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy.","title":"Engagement with Prompts: Liking and Trending"},{"location":"creating-prompts/#collections","text":"Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"Collections"},{"location":"creating-prompts/#creating-collection","text":"Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about.","title":"Creating Collection"},{"location":"creating-prompts/#adding-prompts-to-your-collection","text":"To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.","title":"Adding Prompts to Your Collection"},{"location":"creating-prompts/#publishing-your-collection","text":"Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication.","title":"Publishing Your Collection"},{"location":"creating-prompts/#engagement-with-collections-liking-and-trending","text":"Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged.","title":"Engagement with Collections: Liking and Trending"},{"location":"creating-prompts/#contribution","text":"","title":"Contribution"},{"location":"creating-prompts/#why-share-your-prompts","text":"Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement.","title":"Why Share Your Prompts?"},{"location":"creating-prompts/#rewards-and-recognition","text":"To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network.","title":"Rewards and Recognition"},{"location":"creating-prompts/#useful-resources","text":"","title":"Useful Resources"},{"location":"creating-prompts/#elitea","text":"ELITEA - User Guide ELITEA - Release Notes","title":"ELITEA"},{"location":"creating-prompts/#prompt-engineering","text":"Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"Prompt Engineering"},{"location":"faqs/","text":"Frequently Asked Questions Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with Alita, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of Alita. What You'll Find Here In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what Alita can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use Alita for optimal results. How to Use This Section Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section. Why an FAQ Section? We believe in empowering our users with knowledge. An informed user can better leverage Alita's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly. Let's Dive In! Ready to explore? Great! Your next step towards mastering Alita begins here. Navigate through the questions, uncover new insights, and elevate your Alita experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f FAQs How Can I Integrate Confluence as a Source Type in Alita? Answer Integrating Confluence with Alita allows you to seamlessly connect and utilize your Confluence data within Alita. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for Alita to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps Alita connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data Alita accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup . Example Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : AKk3NjYxMTIyMTY5Oqup3iccFECiScBjE4QK8B3dy444 Username : levon_dadayan@epam.com Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Frequently Asked Questions"},{"location":"faqs/#frequently-asked-questions","text":"Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with Alita, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of Alita.","title":"Frequently Asked Questions"},{"location":"faqs/#what-youll-find-here","text":"In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what Alita can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use Alita for optimal results.","title":"What You'll Find Here"},{"location":"faqs/#how-to-use-this-section","text":"Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section.","title":"How to Use This Section"},{"location":"faqs/#why-an-faq-section","text":"We believe in empowering our users with knowledge. An informed user can better leverage Alita's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly.","title":"Why an FAQ Section?"},{"location":"faqs/#lets-dive-in","text":"Ready to explore? Great! Your next step towards mastering Alita begins here. Navigate through the questions, uncover new insights, and elevate your Alita experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f","title":"Let's Dive In!"},{"location":"faqs/#faqs","text":"","title":"FAQs"},{"location":"faqs/#how-can-i-integrate-confluence-as-a-source-type-in-alita","text":"","title":"How Can I Integrate Confluence as a Source Type in Alita?"},{"location":"faqs/#answer","text":"Integrating Confluence with Alita allows you to seamlessly connect and utilize your Confluence data within Alita. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for Alita to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps Alita connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data Alita accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup .","title":"Answer"},{"location":"faqs/#example","text":"Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : AKk3NjYxMTIyMTY5Oqup3iccFECiScBjE4QK8B3dy444 Username : levon_dadayan@epam.com Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Example"},{"location":"admin-guide/intro/","text":"Introduction to the Admin Guide for ELITEA Solution Welcome to the Admin Guide for Project ELITEA, a comprehensive platform aimed at revolutionizing how organizations manage, develop, and collaborate on LLM assets. At the heart of Project ELITEA lies our commitment to democratizing AI access, embracing creativity, enhancing productivity, and fostering collaboration across all organizational levels. This guide is designed to serve as your roadmap to navigating the extensive features and capabilities of the ELITEA Solution, ensuring you can leverage the full potential of our platform. Purpose of the Admin Guide The Admin Guide is crafted to provide administrators with the knowledge and tools needed to effectively manage and optimize the use of Project ELITEA. Whether you're setting up your first project, integrating new tools, models, or looking to streamline your team's workflow, this guide offers detailed insights and step-by-step instructions to assist you in maximizing the platform's benefits. What Will This Guide Cover? This guide is structured to walk you through several key areas of administration within Project ELITEA, including but not limited to: User Management : Learn how to add, invite, and manage users within your projects, ensuring the right people have the right access. Integrations : Discover how to seamlessly integrate external tools and services with ELITEA, enhancing your project's capabilities. Project Setup : Get up to speed on how to configure your projects for success from the get-go, from setting up environments to customizing settings. Alita SDK : Dive into the Alita SDK to understand how you can extend and customize the platform's functionality to fit your specific needs. Intended Audience This guide is intended for administrators and team leads who are responsible for setting up and managing the ELITEA Solution within their organizations. Whether you're a AI professional or new to managing LLM assets, this guide aims to provide valuable insights and practical advice to help you succeed.","title":"Get Started"},{"location":"admin-guide/intro/#introduction-to-the-admin-guide-for-elitea-solution","text":"Welcome to the Admin Guide for Project ELITEA, a comprehensive platform aimed at revolutionizing how organizations manage, develop, and collaborate on LLM assets. At the heart of Project ELITEA lies our commitment to democratizing AI access, embracing creativity, enhancing productivity, and fostering collaboration across all organizational levels. This guide is designed to serve as your roadmap to navigating the extensive features and capabilities of the ELITEA Solution, ensuring you can leverage the full potential of our platform.","title":"Introduction to the Admin Guide for ELITEA Solution"},{"location":"admin-guide/intro/#purpose-of-the-admin-guide","text":"The Admin Guide is crafted to provide administrators with the knowledge and tools needed to effectively manage and optimize the use of Project ELITEA. Whether you're setting up your first project, integrating new tools, models, or looking to streamline your team's workflow, this guide offers detailed insights and step-by-step instructions to assist you in maximizing the platform's benefits.","title":"Purpose of the Admin Guide"},{"location":"admin-guide/intro/#what-will-this-guide-cover","text":"This guide is structured to walk you through several key areas of administration within Project ELITEA, including but not limited to: User Management : Learn how to add, invite, and manage users within your projects, ensuring the right people have the right access. Integrations : Discover how to seamlessly integrate external tools and services with ELITEA, enhancing your project's capabilities. Project Setup : Get up to speed on how to configure your projects for success from the get-go, from setting up environments to customizing settings. Alita SDK : Dive into the Alita SDK to understand how you can extend and customize the platform's functionality to fit your specific needs.","title":"What Will This Guide Cover?"},{"location":"admin-guide/intro/#intended-audience","text":"This guide is intended for administrators and team leads who are responsible for setting up and managing the ELITEA Solution within their organizations. Whether you're a AI professional or new to managing LLM assets, this guide aims to provide valuable insights and practical advice to help you succeed.","title":"Intended Audience"},{"location":"admin-guide/user/","text":"Managing Users and Roles How to access Admin menu: To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/. Select the project from the dropdown list for which you want to set up or adjust the admin settings. Users Menu In the Users menu, administrators can manage project participants efficiently. Here's how to navigate this section: Adding New Users : Only users with an admin role can invite new members. To do so: Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Users table , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Users : The Users table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name. Roles Menu The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the Users menu. By understanding and utilizing the Users and Roles menus, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"User Management"},{"location":"admin-guide/user/#managing-users-and-roles","text":"","title":"Managing Users and Roles"},{"location":"admin-guide/user/#how-to-access-admin-menu","text":"To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/. Select the project from the dropdown list for which you want to set up or adjust the admin settings.","title":"How to access Admin menu:"},{"location":"admin-guide/user/#users-menu","text":"In the Users menu, administrators can manage project participants efficiently. Here's how to navigate this section: Adding New Users : Only users with an admin role can invite new members. To do so: Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Users table , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Users : The Users table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.","title":"Users Menu"},{"location":"admin-guide/user/#roles-menu","text":"The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the Users menu. By understanding and utilizing the Users and Roles menus, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"Roles Menu"},{"location":"release-notes/rn1/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts. Information Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts. Known Issues N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements. Fixed Issues N/A - This being the first version, there are no previously fixed issues to report.","title":"RN 1.0.0"},{"location":"release-notes/rn1/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/rn1/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts.","title":"Introduction"},{"location":"release-notes/rn1/#information","text":"Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/rn1/#new-features","text":"Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts.","title":"New Features"},{"location":"release-notes/rn1/#known-issues","text":"N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements.","title":"Known Issues"},{"location":"release-notes/rn1/#fixed-issues","text":"N/A - This being the first version, there are no previously fixed issues to report.","title":"Fixed Issues"},{"location":"release-notes/rn2/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention. Known Issues Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Fixed Issues GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"RN 1.0.1"},{"location":"release-notes/rn2/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/rn2/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn2/#information","text":"Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/rn2/#new-features","text":"IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention.","title":"New Features"},{"location":"release-notes/rn2/#known-issues","text":"Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces.","title":"Known Issues"},{"location":"release-notes/rn2/#fixed-issues","text":"GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"Fixed Issues"},{"location":"release-notes/rn3/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns. Changed Features Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding. Known Issues Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication. Fixed Issues Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"RN 1.1.0"},{"location":"release-notes/rn3/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/rn3/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn3/#information","text":"Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/rn3/#new-features","text":"Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns.","title":"New Features"},{"location":"release-notes/rn3/#changed-features","text":"Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding.","title":"Changed Features"},{"location":"release-notes/rn3/#known-issues","text":"Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication.","title":"Known Issues"},{"location":"release-notes/rn3/#fixed-issues","text":"Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"Fixed Issues"},{"location":"release-notes/rn4/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions. Changed Features Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"RN 1.2.0"},{"location":"release-notes/rn4/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/rn4/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn4/#information","text":"Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/rn4/#new-features","text":"Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions.","title":"New Features"},{"location":"release-notes/rn4/#changed-features","text":"Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative.","title":"Changed Features"},{"location":"release-notes/rn4/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/rn4/#fixed-issues","text":"Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"Fixed Issues"},{"location":"release-notes/rn5/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.2.1 Released on : 15-July-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions. Changed Features Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"ELITEA Release Notes"},{"location":"release-notes/rn5/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/rn5/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn5/#information","text":"Release Version : 1.2.1 Released on : 15-July-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/rn5/#new-features","text":"Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions.","title":"New Features"},{"location":"release-notes/rn5/#changed-features","text":"Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative.","title":"Changed Features"},{"location":"release-notes/rn5/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/rn5/#fixed-issues","text":"Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"Fixed Issues"},{"location":"user-guide/agents/","text":"Agents My libraries - Agents Page ELITEA Agents play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. ELITEA Agents is a feature that allows you to create and manage virtual assistants or \"agents\" within the ELITEA interface. These agents are designed to help you accomplish specific tasks or automate certain workflows by leveraging the natural language processing capabilities of GPT models supported by ELITEA. The purpose of Agents in ELITEA is to provide a more efficient way of interacting with the AI models for various use cases. Instead of engaging in open-ended conversations, you can define specific goals, tasks, or workflows for an agent to handle. This can be particularly useful in scenarios where you need to perform repetitive or complex tasks that involve multiple steps or require gathering and processing information from various sources. What are ELITEA Agents? ELITEA Agents are virtual assistants or bots that you can create and customize within the ELITEA interface. Each agent is designed to handle a specific task or set of tasks based on the instructions and capabilities you define for it. Agents bring prompts, datasources and external to LLM toolkits into one mechanism allowing to use integrate decisions made by LLMs and actions required to be taken, like search in Google or creating a Jira Tickets, etc. Agents are capable to work with more external toolkits. How do Agents work? When you create an agent, you provide it with a set of instructions, toolkits or a goal that you want it to accomplish. These instructions can be as simple or complex as needed, and they can include steps, conditions, and actions that the agent should take. The agent then uses the natural language processing capabilities of selected GPT model to understand and execute the instructions you've provided. Integration with External toolkits, Services, and APIs One of the powerful features of ELITEA Agents is their ability to integrate with a wide range of external toolkits, services, and APIs. This integration enables agents to access and interact with different platforms, empowering them to perform more complex and specialized tasks. Below are some examples of integrations that can be set up with ELITEA Agents: Project Management toolkits : ELITEA Agents can be integrated with toolkits like JIRA or Trello to help manage projects, track issues, and collaborate with team members efficiently. Test Management toolkits : Integration with toolkits such as TestRail or qTest can enable agents to assist with test case management, execution, and reporting, enhancing the software testing lifecycle. Documentation and Knowledge Base toolkits : Agents can connect to platforms like Confluence to help create, update, and manage documentation and knowledge bases, ensuring that information is always current and accessible. Version Control Systems : Integration with Git repositories like GitHub or GitLab can allow agents to assist with code management, pull requests, and code reviews, streamlining the development process. APIs and Web Services : ELITEA Agents can interact with various APIs and web services, such as Open APIs to retrieve and process data as needed, providing timely and relevant information. Web Browsers : Agents can be configured to automate tasks within web browsers, such as web scraping, web searching, or automating web-based workflows, which can significantly reduce manual effort. Internal toolkits and Systems : ELITEA Agents can also be integrated with internal ELITEA toolkits (prompts, datasources and agents). By leveraging these integrations, ELITEA Agents can become powerful virtual assistants that help automate and streamline a wide range of tasks across different platforms and toolkits. The specific integrations available may vary based on the capabilities of the ELITEA platform and the APIs or toolkits you want to connect with. It's important to note that setting up these integrations may require additional configuration and authentication steps, such as providing API keys, access tokens, or configuring webhooks or other communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, enabling ELITEA Agents to function effectively within your existing technological ecosystem. Note : For more information, please check Alita Tools and Alita SDK git repos. Creating an Agent To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type. Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter . Click Save . Your newly created agent will subsequently appear on the My Libraries - Agents page. How to Create Instructions The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Instructions Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit). How to Select an Agent Type Choosing the appropriate Agent type is crucial as it dictates the level of detail and the nature of instructions required for the agent to operate effectively. Below is an overview of the available Agent types and their intended use cases: React Description : This Agent type is ideal for straightforward, linear scenarios that require minimal context. Simply specify your requirements, including what actions the agent should perform, and add the necessary toolkits. Utilize fields such as Actor, Goals, Instructions, and Constraints to clearly describe the desired behavior. Best For : Simple tasks with clear, direct instructions. Dial Description : Dial agents are based on Epam AI DIAL technology and are designed to interact with models and functions or tools, specifically restricted to OpenAI models. Best For : Scenarios that require interaction with OpenAI models and can benefit from DIAL's capabilities. Alita Description : Alita agents are a hybrid of OpenAI's and Langchain's ReAct approaches, making them suitable for more complex, open-ended scenarios. Unlike the React type, Alita agents can maintain chat history, which enhances their ability to handle extended interactions. Best For : Complex scenarios that require ongoing interactions and the ability to retain context over time. Not recommended for simple, linear tasks. Raw Description : This is an expert-level configuration similar to the React type but requires a comprehensive description of all aspects, including the exact response format expected from language learning models (LLMs). Best For : Advanced users who need full control over the agent's behavior and responses, and are capable of specifying detailed operational parameters. Each Agent type is designed to cater to different needs and complexities of tasks. Selecting the right type ensures that the agent performs optimally within the specified parameters and scenarios. Instructions for React and Raw Agent Types General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. React Agent Type For the React agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes. How to select and configure Toolkits Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under Tools section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit alrady created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available: Datasource toolkit The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration. Prompt toolkit The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt. Agent toolkit The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration. Browser toolkit The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration. Confluence toolkit The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. Enter your Confluence API key in the provided field. Ensure you handle this key securely. Input the username associated with your Confluence account. Token : Choose this option if you are using a token for authentication. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration. Jira toolkit The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. Enter your Jira API key in the provided field. Ensure you handle this key securely. Input the username associated with your Confluence account. Token : Choose this option if you are using a token for authentication. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration. GitHub toolkit The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method you will use for the GitHub integration: Private Key : Opt for this if you are using a private key for authentication. Input the App ID associated with your GitHub integration and enter your private key in the provided field. Be sure to keep this information secure. Token : Choose this if you prefer to use a personal access token for authentication. Password : Input the username and password associated with your GitHub account. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration. Gitlab toolkit Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method you will use for the Gitlab integration: Token : Choose this if you prefer to use a personal access token for authentication. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration. Open API toolkit The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration. Custom toolkit The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration. Artifact toolkit The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration. How to Setup Conversation Starter The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent. How to Add a Conversation Starter Access the Configuration Panel : Navigate to the agent configuration section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured conversation starter available for use. Using a Conversation Starter Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent. Examples of Conversation Starters \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized. How to Execute Agent To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Managing Agent Versions: Save, Create Versions, and Manage To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them. How to Save an Agent: To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent. How to Create New Versions: For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements. Agents Menu The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents. Layout of the Agents Menu The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community. Engaging with Published Agents Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation: Liking Published Agents Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent. Other Actions for Published Agents Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use. Agents - Helpful Materials To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents. Video Tutorials Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation Practical Examples Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Agents"},{"location":"user-guide/agents/#agents","text":"","title":"Agents"},{"location":"user-guide/agents/#my-libraries-agents-page","text":"ELITEA Agents play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. ELITEA Agents is a feature that allows you to create and manage virtual assistants or \"agents\" within the ELITEA interface. These agents are designed to help you accomplish specific tasks or automate certain workflows by leveraging the natural language processing capabilities of GPT models supported by ELITEA. The purpose of Agents in ELITEA is to provide a more efficient way of interacting with the AI models for various use cases. Instead of engaging in open-ended conversations, you can define specific goals, tasks, or workflows for an agent to handle. This can be particularly useful in scenarios where you need to perform repetitive or complex tasks that involve multiple steps or require gathering and processing information from various sources.","title":"My libraries - Agents Page"},{"location":"user-guide/agents/#what-are-elitea-agents","text":"ELITEA Agents are virtual assistants or bots that you can create and customize within the ELITEA interface. Each agent is designed to handle a specific task or set of tasks based on the instructions and capabilities you define for it. Agents bring prompts, datasources and external to LLM toolkits into one mechanism allowing to use integrate decisions made by LLMs and actions required to be taken, like search in Google or creating a Jira Tickets, etc. Agents are capable to work with more external toolkits.","title":"What are ELITEA Agents?"},{"location":"user-guide/agents/#how-do-agents-work","text":"When you create an agent, you provide it with a set of instructions, toolkits or a goal that you want it to accomplish. These instructions can be as simple or complex as needed, and they can include steps, conditions, and actions that the agent should take. The agent then uses the natural language processing capabilities of selected GPT model to understand and execute the instructions you've provided.","title":"How do Agents work?"},{"location":"user-guide/agents/#integration-with-external-toolkits-services-and-apis","text":"One of the powerful features of ELITEA Agents is their ability to integrate with a wide range of external toolkits, services, and APIs. This integration enables agents to access and interact with different platforms, empowering them to perform more complex and specialized tasks. Below are some examples of integrations that can be set up with ELITEA Agents: Project Management toolkits : ELITEA Agents can be integrated with toolkits like JIRA or Trello to help manage projects, track issues, and collaborate with team members efficiently. Test Management toolkits : Integration with toolkits such as TestRail or qTest can enable agents to assist with test case management, execution, and reporting, enhancing the software testing lifecycle. Documentation and Knowledge Base toolkits : Agents can connect to platforms like Confluence to help create, update, and manage documentation and knowledge bases, ensuring that information is always current and accessible. Version Control Systems : Integration with Git repositories like GitHub or GitLab can allow agents to assist with code management, pull requests, and code reviews, streamlining the development process. APIs and Web Services : ELITEA Agents can interact with various APIs and web services, such as Open APIs to retrieve and process data as needed, providing timely and relevant information. Web Browsers : Agents can be configured to automate tasks within web browsers, such as web scraping, web searching, or automating web-based workflows, which can significantly reduce manual effort. Internal toolkits and Systems : ELITEA Agents can also be integrated with internal ELITEA toolkits (prompts, datasources and agents). By leveraging these integrations, ELITEA Agents can become powerful virtual assistants that help automate and streamline a wide range of tasks across different platforms and toolkits. The specific integrations available may vary based on the capabilities of the ELITEA platform and the APIs or toolkits you want to connect with. It's important to note that setting up these integrations may require additional configuration and authentication steps, such as providing API keys, access tokens, or configuring webhooks or other communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, enabling ELITEA Agents to function effectively within your existing technological ecosystem. Note : For more information, please check Alita Tools and Alita SDK git repos.","title":"Integration with External toolkits, Services, and APIs"},{"location":"user-guide/agents/#creating-an-agent","text":"To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type. Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter . Click Save . Your newly created agent will subsequently appear on the My Libraries - Agents page.","title":"Creating an Agent"},{"location":"user-guide/agents/#how-to-create-instructions","text":"The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests.","title":"How to Create Instructions"},{"location":"user-guide/agents/#how-to-input-instructions","text":"Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit).","title":"How to Input Instructions"},{"location":"user-guide/agents/#how-to-select-an-agent-type","text":"Choosing the appropriate Agent type is crucial as it dictates the level of detail and the nature of instructions required for the agent to operate effectively. Below is an overview of the available Agent types and their intended use cases:","title":"How to Select an Agent Type"},{"location":"user-guide/agents/#react","text":"Description : This Agent type is ideal for straightforward, linear scenarios that require minimal context. Simply specify your requirements, including what actions the agent should perform, and add the necessary toolkits. Utilize fields such as Actor, Goals, Instructions, and Constraints to clearly describe the desired behavior. Best For : Simple tasks with clear, direct instructions.","title":"React"},{"location":"user-guide/agents/#dial","text":"Description : Dial agents are based on Epam AI DIAL technology and are designed to interact with models and functions or tools, specifically restricted to OpenAI models. Best For : Scenarios that require interaction with OpenAI models and can benefit from DIAL's capabilities.","title":"Dial"},{"location":"user-guide/agents/#alita","text":"Description : Alita agents are a hybrid of OpenAI's and Langchain's ReAct approaches, making them suitable for more complex, open-ended scenarios. Unlike the React type, Alita agents can maintain chat history, which enhances their ability to handle extended interactions. Best For : Complex scenarios that require ongoing interactions and the ability to retain context over time. Not recommended for simple, linear tasks.","title":"Alita"},{"location":"user-guide/agents/#raw","text":"Description : This is an expert-level configuration similar to the React type but requires a comprehensive description of all aspects, including the exact response format expected from language learning models (LLMs). Best For : Advanced users who need full control over the agent's behavior and responses, and are capable of specifying detailed operational parameters. Each Agent type is designed to cater to different needs and complexities of tasks. Selecting the right type ensures that the agent performs optimally within the specified parameters and scenarios.","title":"Raw"},{"location":"user-guide/agents/#instructions-for-react-and-raw-agent-types","text":"General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. React Agent Type For the React agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes.","title":"Instructions for React and Raw Agent Types"},{"location":"user-guide/agents/#how-to-select-and-configure-toolkits","text":"Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under Tools section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit alrady created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available:","title":"How to select and configure Toolkits"},{"location":"user-guide/agents/#datasource-toolkit","text":"The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration.","title":"Datasource toolkit"},{"location":"user-guide/agents/#prompt-toolkit","text":"The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt.","title":"Prompt toolkit"},{"location":"user-guide/agents/#agent-toolkit","text":"The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration.","title":"Agent toolkit"},{"location":"user-guide/agents/#browser-toolkit","text":"The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration.","title":"Browser toolkit"},{"location":"user-guide/agents/#confluence-toolkit","text":"The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. Enter your Confluence API key in the provided field. Ensure you handle this key securely. Input the username associated with your Confluence account. Token : Choose this option if you are using a token for authentication. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration.","title":"Confluence toolkit"},{"location":"user-guide/agents/#jira-toolkit","text":"The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. Enter your Jira API key in the provided field. Ensure you handle this key securely. Input the username associated with your Confluence account. Token : Choose this option if you are using a token for authentication. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration.","title":"Jira toolkit"},{"location":"user-guide/agents/#github-toolkit","text":"The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method you will use for the GitHub integration: Private Key : Opt for this if you are using a private key for authentication. Input the App ID associated with your GitHub integration and enter your private key in the provided field. Be sure to keep this information secure. Token : Choose this if you prefer to use a personal access token for authentication. Password : Input the username and password associated with your GitHub account. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration.","title":"GitHub toolkit"},{"location":"user-guide/agents/#gitlab-toolkit","text":"Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method you will use for the Gitlab integration: Token : Choose this if you prefer to use a personal access token for authentication. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration.","title":"Gitlab toolkit"},{"location":"user-guide/agents/#open-api-toolkit","text":"The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration.","title":"Open API toolkit"},{"location":"user-guide/agents/#custom-toolkit","text":"The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration.","title":"Custom toolkit"},{"location":"user-guide/agents/#artifact-toolkit","text":"The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration.","title":"Artifact toolkit"},{"location":"user-guide/agents/#how-to-setup-conversation-starter","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent.","title":"How to Setup Conversation Starter"},{"location":"user-guide/agents/#how-to-add-a-conversation-starter","text":"Access the Configuration Panel : Navigate to the agent configuration section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured conversation starter available for use.","title":"How to Add a Conversation Starter"},{"location":"user-guide/agents/#using-a-conversation-starter","text":"Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent.","title":"Using a Conversation Starter"},{"location":"user-guide/agents/#examples-of-conversation-starters","text":"\"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized.","title":"Examples of Conversation Starters"},{"location":"user-guide/agents/#how-to-execute-agent","text":"To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"How to Execute Agent"},{"location":"user-guide/agents/#managing-agent-versions-save-create-versions-and-manage","text":"To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them.","title":"Managing Agent Versions: Save, Create Versions, and Manage"},{"location":"user-guide/agents/#how-to-save-an-agent","text":"To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent.","title":"How to Save an Agent:"},{"location":"user-guide/agents/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"user-guide/agents/#agents-menu","text":"The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents.","title":"Agents Menu"},{"location":"user-guide/agents/#layout-of-the-agents-menu","text":"The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community.","title":"Layout of the Agents Menu"},{"location":"user-guide/agents/#engaging-with-published-agents","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation:","title":"Engaging with Published Agents"},{"location":"user-guide/agents/#liking-published-agents","text":"Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent.","title":"Liking Published Agents"},{"location":"user-guide/agents/#other-actions-for-published-agents","text":"Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use.","title":"Other Actions for Published Agents"},{"location":"user-guide/agents/#agents-helpful-materials","text":"To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents.","title":"Agents - Helpful Materials"},{"location":"user-guide/agents/#video-tutorials","text":"Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation","title":"Video Tutorials"},{"location":"user-guide/agents/#practical-examples","text":"Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Practical Examples"},{"location":"user-guide/chat/","text":"Conversations ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models. Creating a Conversation Click the + Conversation button located at the top right corner. Provide the Name . By default, it is set to \"New Conversation\". Select the Conversation mode : Public or Private. Select the LLM model from the Model dropdown list, or Datasource from the Datasource dropdown list, or Agent from the Agent dropdown list which you want to use for the conversation. Later, you can add other models, datasources, or agents to the conversation as participants. Optionally, set up the model parameters if you selected the model option: Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Top P (0-1) : Determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K : Limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum Length : Sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list. Private and Public Conversations Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private. Participants Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project which can be added to the conversation to execute them and get responses. Note: Currently only the \"latest\" version of the prompt can be added to the conversation as a participant. Data Sources : Already created data sources within the project which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project which can be added to the conversation to execute them and get responses. Note: Currently only the \"latest\" version of the agent can be added to the conversation as a participant. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants. How to Add a Participant To add a participant to a conversation: Type the letters of the name or description of the available participant in the \"Let\u2019s add participants to your conversation!\" search field. As soon as you see the participant that you need from the proposed list, select it to add. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section. How to Use a Participant Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"No active participant. Let\u2019s choose one to start conversation!\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again. How to Configure/Modify Participants You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. Actions for Conversation The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Chat"},{"location":"user-guide/chat/#conversations","text":"ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models.","title":"Conversations"},{"location":"user-guide/chat/#creating-a-conversation","text":"Click the + Conversation button located at the top right corner. Provide the Name . By default, it is set to \"New Conversation\". Select the Conversation mode : Public or Private. Select the LLM model from the Model dropdown list, or Datasource from the Datasource dropdown list, or Agent from the Agent dropdown list which you want to use for the conversation. Later, you can add other models, datasources, or agents to the conversation as participants. Optionally, set up the model parameters if you selected the model option: Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Top P (0-1) : Determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K : Limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum Length : Sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list.","title":"Creating a Conversation"},{"location":"user-guide/chat/#private-and-public-conversations","text":"Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private.","title":"Private and Public Conversations"},{"location":"user-guide/chat/#participants","text":"Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project which can be added to the conversation to execute them and get responses. Note: Currently only the \"latest\" version of the prompt can be added to the conversation as a participant. Data Sources : Already created data sources within the project which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project which can be added to the conversation to execute them and get responses. Note: Currently only the \"latest\" version of the agent can be added to the conversation as a participant. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants.","title":"Participants"},{"location":"user-guide/chat/#how-to-add-a-participant","text":"To add a participant to a conversation: Type the letters of the name or description of the available participant in the \"Let\u2019s add participants to your conversation!\" search field. As soon as you see the participant that you need from the proposed list, select it to add. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section.","title":"How to Add a Participant"},{"location":"user-guide/chat/#how-to-use-a-participant","text":"Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"No active participant. Let\u2019s choose one to start conversation!\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again.","title":"How to Use a Participant"},{"location":"user-guide/chat/#how-to-configuremodify-participants","text":"You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon.","title":"How to Configure/Modify Participants"},{"location":"user-guide/chat/#actions-for-conversation","text":"The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Actions for Conversation"},{"location":"user-guide/collections/","text":"Collections My libraries - Collections Page The My libraries - Collections page serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've assembled. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections Collections serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. How to Create a Collection Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection. After creation, your new collection will be added to the My Libraries - Collections page. Exploring Collections Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection How to Modify a Collection To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published. How to Filter Prompts within a Collection Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes. How to Publish a Collection To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain public prompts before publication. How to Delete a Collection To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections. How to Export a Collection Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization. Collections Menu The Collections menu is a curated space of grouped prompts shared and published within the community. Layout of the Collections Menu Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community. Engaging with Collections Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage: Liking Collections Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: Simply click on the Heart icon associated with a collection to like it. Note : Should you change your mind, clicking the Heart icon again will allow you to unlike the collection. Other Actions for Collections Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Collections"},{"location":"user-guide/collections/#collections","text":"","title":"Collections"},{"location":"user-guide/collections/#my-libraries-collections-page","text":"The My libraries - Collections page serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've assembled. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections Collections serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"My libraries - Collections Page"},{"location":"user-guide/collections/#how-to-create-a-collection","text":"Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection. After creation, your new collection will be added to the My Libraries - Collections page.","title":"How to Create a Collection"},{"location":"user-guide/collections/#exploring-collections","text":"Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection","title":"Exploring Collections"},{"location":"user-guide/collections/#how-to-modify-a-collection","text":"To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published.","title":"How to Modify a Collection"},{"location":"user-guide/collections/#how-to-filter-prompts-within-a-collection","text":"Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes.","title":"How to Filter Prompts within a Collection"},{"location":"user-guide/collections/#how-to-publish-a-collection","text":"To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain public prompts before publication.","title":"How to Publish a Collection"},{"location":"user-guide/collections/#how-to-delete-a-collection","text":"To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections.","title":"How to Delete a Collection"},{"location":"user-guide/collections/#how-to-export-a-collection","text":"Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization.","title":"How to Export a Collection"},{"location":"user-guide/collections/#collections-menu","text":"The Collections menu is a curated space of grouped prompts shared and published within the community.","title":"Collections Menu"},{"location":"user-guide/collections/#layout-of-the-collections-menu","text":"Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community.","title":"Layout of the Collections Menu"},{"location":"user-guide/collections/#engaging-with-collections","text":"Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage:","title":"Engaging with Collections"},{"location":"user-guide/collections/#liking-collections","text":"Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: Simply click on the Heart icon associated with a collection to like it. Note : Should you change your mind, clicking the Heart icon again will allow you to unlike the collection.","title":"Liking Collections"},{"location":"user-guide/collections/#other-actions-for-collections","text":"Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Other Actions for Collections"},{"location":"user-guide/datasources/","text":"Datasources My libraries - Datasources Page Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information. Creating a Datasource To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation. Your newly created datasource will subsequently appear on the My Libraries - Datasources page. Exploring Datasources Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage. Connecting a Datasource to a Dataset The initial step involves linking your datasource to the desired dataset: Press the + icon to start adding a new dataset. Enter a name for your dataset. Note : This is a non-editable field and cannot be altered post-creation. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded. Source type - File ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Table This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning. Source type - GIT For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Confluence For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance. Source type - QTest Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - a confidential key used for enhanced security during API requests. Password - an option for API access, verifying authorized requesters. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\"). Configuring Transformers Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing. Configuring Summarization Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization Mode - select from available LLMs based on your document\u2019s complexity. Document Summarization - enables summarization of the entire document. Chunk Summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis. Context Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions. Working with Your Dataset After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do: Chat The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation. How to Use Chat Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue. Search The Search feature allows you to quickly locate specific information within your indexed dataset. How to Conduct a Search Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon. Deduplicate Deduplication is a handy feature for identifying duplicate information. How to Run Deduplication Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : Only content that is very similar will be considered duplicates, which means more items will be removed. This can be useful if you want to ensure that only highly unique content remains. Lower values : More content will be considered duplicates, which means more items will be removed. This can be useful if you want to keep more variations of the content. Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Press the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications. Datasources Menu The Datasources menu showcases a collection of published and shared datasources within the community. By default, upon logging in, the user is directed to the Latest page of the Datasources menu, which presents newly published datasources. Layout of the Datasources Menu The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community. Engaging with Published Datasources Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation: Liking Published datasources Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource. Other Actions for Published Datasources Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Datasources"},{"location":"user-guide/datasources/#datasources","text":"","title":"Datasources"},{"location":"user-guide/datasources/#my-libraries-datasources-page","text":"Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information.","title":"My libraries - Datasources Page"},{"location":"user-guide/datasources/#creating-a-datasource","text":"To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation. Your newly created datasource will subsequently appear on the My Libraries - Datasources page.","title":"Creating a Datasource"},{"location":"user-guide/datasources/#exploring-datasources","text":"Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage.","title":"Exploring Datasources"},{"location":"user-guide/datasources/#connecting-a-datasource-to-a-dataset","text":"The initial step involves linking your datasource to the desired dataset: Press the + icon to start adding a new dataset. Enter a name for your dataset. Note : This is a non-editable field and cannot be altered post-creation. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded.","title":"Connecting a Datasource to a Dataset"},{"location":"user-guide/datasources/#source-type-file","text":"ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - File"},{"location":"user-guide/datasources/#source-type-table","text":"This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning.","title":"Source type - Table"},{"location":"user-guide/datasources/#source-type-git","text":"For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - GIT"},{"location":"user-guide/datasources/#source-type-confluence","text":"For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance.","title":"Source type - Confluence"},{"location":"user-guide/datasources/#source-type-qtest","text":"Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - a confidential key used for enhanced security during API requests. Password - an option for API access, verifying authorized requesters. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\").","title":"Source type - QTest"},{"location":"user-guide/datasources/#configuring-transformers","text":"Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing.","title":"Configuring Transformers"},{"location":"user-guide/datasources/#configuring-summarization","text":"Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization Mode - select from available LLMs based on your document\u2019s complexity. Document Summarization - enables summarization of the entire document. Chunk Summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis.","title":"Configuring Summarization"},{"location":"user-guide/datasources/#context","text":"Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions.","title":"Context"},{"location":"user-guide/datasources/#working-with-your-dataset","text":"After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do:","title":"Working with Your Dataset"},{"location":"user-guide/datasources/#chat","text":"The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation.","title":"Chat"},{"location":"user-guide/datasources/#how-to-use-chat","text":"Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue.","title":"How to Use Chat"},{"location":"user-guide/datasources/#search","text":"The Search feature allows you to quickly locate specific information within your indexed dataset.","title":"Search"},{"location":"user-guide/datasources/#how-to-conduct-a-search","text":"Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon.","title":"How to Conduct a Search"},{"location":"user-guide/datasources/#deduplicate","text":"Deduplication is a handy feature for identifying duplicate information.","title":"Deduplicate"},{"location":"user-guide/datasources/#how-to-run-deduplication","text":"Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : Only content that is very similar will be considered duplicates, which means more items will be removed. This can be useful if you want to ensure that only highly unique content remains. Lower values : More content will be considered duplicates, which means more items will be removed. This can be useful if you want to keep more variations of the content. Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Press the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications.","title":"How to Run Deduplication"},{"location":"user-guide/datasources/#datasources-menu","text":"The Datasources menu showcases a collection of published and shared datasources within the community. By default, upon logging in, the user is directed to the Latest page of the Datasources menu, which presents newly published datasources.","title":"Datasources Menu"},{"location":"user-guide/datasources/#layout-of-the-datasources-menu","text":"The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community.","title":"Layout of the Datasources Menu"},{"location":"user-guide/datasources/#engaging-with-published-datasources","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation:","title":"Engaging with Published Datasources"},{"location":"user-guide/datasources/#liking-published-datasources","text":"Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource.","title":"Liking Published datasources"},{"location":"user-guide/datasources/#other-actions-for-published-datasources","text":"Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Other Actions for Published Datasources"},{"location":"user-guide/intro/","text":"Introduction Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with prompts. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts like never before. Key Features: Prompt Management: Create new prompts or modify existing ones with ease, while keeping track of different versions. Collection Integration: Group your prompts into Collections to streamline your workflow or focus on specific themes or projects. Tagging System: Organize your prompts effectively by adding and editing tags for quick retrieval and categorization. Execution with Precision: Execute prompts utilizing various models and parameters to suit your unique needs, offering a tailored experience. Advanced Creation Tools: Use variables, system prompts, Assistant Messages, and User prompts to craft complex prompts with fine-grained control. Flexible Interaction Models: Engage with the Prompt Library through diverse interfaces, whether via Chat or a Completion approach. Powerful Search: Quickly find the prompts and collections you need with a robust search feature that recognizes tags, names, and descriptions. Community Engagement: Create and modify Prompts and Collections, publish your work, and interact with the community through sharing and liking prompts/collections. ELITEA is designed to be intuitive, granting you the freedom to focus on creativity and productivity. Whether you are new to prompting or an experienced creator, our user guide will walk you through every feature, ensuring you maximize your ELITEA experience. Let's embark on this journey to unlock the full potential of your ideas. Access to ELITEA To access ELITEA HUB: Open your browser. Type in https://alita.lab.epam.com in the address bar. Provide your EPAM account to login. Note : No need for registration. After successful login, you are navigated to the Prompts menu. Once you have access, navigate to Discover\u2192My Library menu, where you will be able to create prompts and collections. Note : If you are logging in for the first time into ELITEA, wait for 5 minutes to allow private project initialization to be completed before creating prompts. Note : You need to enable Epam VPN to access ELITEA. ELITEA - Main Interface The ELITEA HUB's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating prompts or collections, Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Prompts, Datasources, Collections, and My Library. Search : A Search box available to find prompts by their names and descriptions. Note: The Search functionality operates within the selected menu and is not universal across the entire application. Quick Navigation Tabs : Tabs enabling users to switch among Latest, My Liked, and Trending pages. The names and content of these tabs will change depending on the menu selected. Page Content : This area displays the latest published content, which varies based on the selected menu. For example, the Prompts menu will show the latest published prompts, and the Collections menu will display the latest published collections. View Switcher : A tool for quickly switching between Card and List views. Quick button : A button that allows for the rapid creation of a new prompt, datasource, application or collection. The function of this button (+Prompt, +Datasource, +Application or +Collection) changes based on the selected menu. Project Switcher : A tool for quickly switching among projects. Note : Becomes available if you are involed in more than one project. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure your Profile, Settings or Log Out of the application. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts and collections with the community. General Navigation and Management Across the Application This section outlines common functionalities and actions available across various menus and pages within the application, aiming to provide a consistent and efficient user experience. These functionalities are shared across: Chat menu: Includes all your private and public conversations. Prompts menu: Including the Latest, My Likes, and Trending pages. Datasources menu: Including the Latest, My Likes, and Trending pages for datasources. Agents menu: Including the Latest, My Likes, and Trending pages for agents. Collections menu: Including the Latest, My Likes, and Trending pages designed for collections. My libraries menu: Including All, Prompts, Datasources, and Collections pages. The context may vary depending on the specific page you're viewing, but the core principles of action and functionality remain consistent, ensuring a unified approach to navigating and managing content within the application. Common Viewing Options Card View : Offers a compact, card-format snapshot of items like prompts or collections, making it easy to visually scan through published materials. Detailed View : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis. Search and Filtering Functionality Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes. Sorting Options (Detailed View Only) By Name : Alphabetically organize published items by their names, providing an effortless method to find specific titles. By Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. By Likes : Order the items by the number of likes they have received. This functionality is applicable on the pages of Prompts, Collections, and Datasources menus, helping surface popular content. By Authors : Sort the items by the author's name. This functionality is applicable on the pages of Prompts, Collections, and Datasources menus, helping surface popular content. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment. Discover - Menus ELITEA consists of the following main menus: Chat : Create and manage your public and private conversations. * Prompts : Browse through an organized showcase of prompts curated and shared by the community. * Datasources : Browse through an organized showcase of datasources and shared by the community. * Agents : Browse through an organized showcase of agents and shared by the community. * Collections : Browse through an organized showcase of prompt collections curated and shared by the community. * My libraries : Manage your personal creative space where you can craft, save, edit, and organize your prompts and collections. Navigation: To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu. Settings The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. Tabs in Settings Settings consists of several tabs, each dedicated to specific functionalities: Profile : Customize your user profile and monitor your engagement within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Users : Manage users within project. This tab is only available for the user within admin permissions within the project. Log out : Securely log out from the ELITEA Hub. Navigation To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section. Profile In the Profile , you\u2019re presented with options to personalize your account and monitor your engagement and resource utilization within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported. Monitoring The Monitoring feature in ELITEA provides a comprehensive overview of the application's usage and performance. This section of the User Guide will walk you through the various charts and statistics available within the Monitoring feature, along with detailed settings to customize your monitoring experience. Configuration Options At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations. Key Metrics Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the application. Tokens In : The number of tokens consumed by the application. Tokens Out : The number of tokens generated by the application. Gb Used : The amount of data processed by the application. Prompts : The total number of prompts created. Datasources : The number of datasources connected. Agents : The count of active agents. Conversations : The number of conversations held. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period. Adoption and Usage Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy. Sentiments The Sentiments section offers a visual representation of the sentiment of inputs and outputs: Human Input : A pie chart showing the sentiment distribution of user inputs. LLM Output : A pie chart displaying the sentiment distribution of the ELITEA's outputs. Accuracy The Accuracy section includes line charts that measure: Relevance : Comparing the relevance of input versus context and output versus input. Reliability : Displaying the reliability score of the application's outputs. Prompt Quality : Chart tracks the quality score of prompts over time, helping you understand the effectiveness of your prompts. Topics Summary Finally, the Topics Summary bar chart categorizes the content into various topics such as Software Development, Requirements Analysis, User Story Creation, and more, providing a breakdown of the subjects addressed by the application. By monitoring these statistics, you can gain valuable insights into the performance and usage of the ELITEA platform, enabling you to make informed decisions to enhance user experience and application efficiency. Configuration The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Chat. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential. Deployments The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations. Users The Users menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Adding New Users : Only users with an admin role can invite new members. To do so: Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Users table , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Users : The Users table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.","title":"Get Started"},{"location":"user-guide/intro/#introduction","text":"Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with prompts. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts like never before. Key Features: Prompt Management: Create new prompts or modify existing ones with ease, while keeping track of different versions. Collection Integration: Group your prompts into Collections to streamline your workflow or focus on specific themes or projects. Tagging System: Organize your prompts effectively by adding and editing tags for quick retrieval and categorization. Execution with Precision: Execute prompts utilizing various models and parameters to suit your unique needs, offering a tailored experience. Advanced Creation Tools: Use variables, system prompts, Assistant Messages, and User prompts to craft complex prompts with fine-grained control. Flexible Interaction Models: Engage with the Prompt Library through diverse interfaces, whether via Chat or a Completion approach. Powerful Search: Quickly find the prompts and collections you need with a robust search feature that recognizes tags, names, and descriptions. Community Engagement: Create and modify Prompts and Collections, publish your work, and interact with the community through sharing and liking prompts/collections. ELITEA is designed to be intuitive, granting you the freedom to focus on creativity and productivity. Whether you are new to prompting or an experienced creator, our user guide will walk you through every feature, ensuring you maximize your ELITEA experience. Let's embark on this journey to unlock the full potential of your ideas.","title":"Introduction"},{"location":"user-guide/intro/#access-to-elitea","text":"To access ELITEA HUB: Open your browser. Type in https://alita.lab.epam.com in the address bar. Provide your EPAM account to login. Note : No need for registration. After successful login, you are navigated to the Prompts menu. Once you have access, navigate to Discover\u2192My Library menu, where you will be able to create prompts and collections. Note : If you are logging in for the first time into ELITEA, wait for 5 minutes to allow private project initialization to be completed before creating prompts. Note : You need to enable Epam VPN to access ELITEA.","title":"Access to ELITEA"},{"location":"user-guide/intro/#elitea-main-interface","text":"The ELITEA HUB's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating prompts or collections, Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Prompts, Datasources, Collections, and My Library. Search : A Search box available to find prompts by their names and descriptions. Note: The Search functionality operates within the selected menu and is not universal across the entire application. Quick Navigation Tabs : Tabs enabling users to switch among Latest, My Liked, and Trending pages. The names and content of these tabs will change depending on the menu selected. Page Content : This area displays the latest published content, which varies based on the selected menu. For example, the Prompts menu will show the latest published prompts, and the Collections menu will display the latest published collections. View Switcher : A tool for quickly switching between Card and List views. Quick button : A button that allows for the rapid creation of a new prompt, datasource, application or collection. The function of this button (+Prompt, +Datasource, +Application or +Collection) changes based on the selected menu. Project Switcher : A tool for quickly switching among projects. Note : Becomes available if you are involed in more than one project. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure your Profile, Settings or Log Out of the application. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts and collections with the community.","title":"ELITEA - Main Interface"},{"location":"user-guide/intro/#general-navigation-and-management-across-the-application","text":"This section outlines common functionalities and actions available across various menus and pages within the application, aiming to provide a consistent and efficient user experience. These functionalities are shared across: Chat menu: Includes all your private and public conversations. Prompts menu: Including the Latest, My Likes, and Trending pages. Datasources menu: Including the Latest, My Likes, and Trending pages for datasources. Agents menu: Including the Latest, My Likes, and Trending pages for agents. Collections menu: Including the Latest, My Likes, and Trending pages designed for collections. My libraries menu: Including All, Prompts, Datasources, and Collections pages. The context may vary depending on the specific page you're viewing, but the core principles of action and functionality remain consistent, ensuring a unified approach to navigating and managing content within the application.","title":"General Navigation and Management Across the Application"},{"location":"user-guide/intro/#common-viewing-options","text":"Card View : Offers a compact, card-format snapshot of items like prompts or collections, making it easy to visually scan through published materials. Detailed View : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis.","title":"Common Viewing Options"},{"location":"user-guide/intro/#search-and-filtering-functionality","text":"Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes.","title":"Search and Filtering Functionality"},{"location":"user-guide/intro/#sorting-options-detailed-view-only","text":"By Name : Alphabetically organize published items by their names, providing an effortless method to find specific titles. By Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. By Likes : Order the items by the number of likes they have received. This functionality is applicable on the pages of Prompts, Collections, and Datasources menus, helping surface popular content. By Authors : Sort the items by the author's name. This functionality is applicable on the pages of Prompts, Collections, and Datasources menus, helping surface popular content. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment.","title":"Sorting Options (Detailed View Only)"},{"location":"user-guide/intro/#discover-menus","text":"ELITEA consists of the following main menus: Chat : Create and manage your public and private conversations. * Prompts : Browse through an organized showcase of prompts curated and shared by the community. * Datasources : Browse through an organized showcase of datasources and shared by the community. * Agents : Browse through an organized showcase of agents and shared by the community. * Collections : Browse through an organized showcase of prompt collections curated and shared by the community. * My libraries : Manage your personal creative space where you can craft, save, edit, and organize your prompts and collections. Navigation: To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu.","title":"Discover - Menus"},{"location":"user-guide/intro/#settings","text":"The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. Tabs in Settings Settings consists of several tabs, each dedicated to specific functionalities: Profile : Customize your user profile and monitor your engagement within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Users : Manage users within project. This tab is only available for the user within admin permissions within the project. Log out : Securely log out from the ELITEA Hub. Navigation To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section.","title":"Settings"},{"location":"user-guide/intro/#profile","text":"In the Profile , you\u2019re presented with options to personalize your account and monitor your engagement and resource utilization within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported.","title":"Profile"},{"location":"user-guide/intro/#monitoring","text":"The Monitoring feature in ELITEA provides a comprehensive overview of the application's usage and performance. This section of the User Guide will walk you through the various charts and statistics available within the Monitoring feature, along with detailed settings to customize your monitoring experience.","title":"Monitoring"},{"location":"user-guide/intro/#configuration-options","text":"At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations.","title":"Configuration Options"},{"location":"user-guide/intro/#key-metrics","text":"Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the application. Tokens In : The number of tokens consumed by the application. Tokens Out : The number of tokens generated by the application. Gb Used : The amount of data processed by the application. Prompts : The total number of prompts created. Datasources : The number of datasources connected. Agents : The count of active agents. Conversations : The number of conversations held. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period.","title":"Key Metrics"},{"location":"user-guide/intro/#adoption-and-usage","text":"Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy.","title":"Adoption and Usage"},{"location":"user-guide/intro/#sentiments","text":"The Sentiments section offers a visual representation of the sentiment of inputs and outputs: Human Input : A pie chart showing the sentiment distribution of user inputs. LLM Output : A pie chart displaying the sentiment distribution of the ELITEA's outputs.","title":"Sentiments"},{"location":"user-guide/intro/#accuracy","text":"The Accuracy section includes line charts that measure: Relevance : Comparing the relevance of input versus context and output versus input. Reliability : Displaying the reliability score of the application's outputs. Prompt Quality : Chart tracks the quality score of prompts over time, helping you understand the effectiveness of your prompts.","title":"Accuracy"},{"location":"user-guide/intro/#topics-summary","text":"Finally, the Topics Summary bar chart categorizes the content into various topics such as Software Development, Requirements Analysis, User Story Creation, and more, providing a breakdown of the subjects addressed by the application. By monitoring these statistics, you can gain valuable insights into the performance and usage of the ELITEA platform, enabling you to make informed decisions to enhance user experience and application efficiency.","title":"Topics Summary"},{"location":"user-guide/intro/#configuration","text":"The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Chat. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential.","title":"Configuration"},{"location":"user-guide/intro/#deployments","text":"The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations.","title":"Deployments"},{"location":"user-guide/intro/#users","text":"The Users menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Adding New Users : Only users with an admin role can invite new members. To do so: Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Users table , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Users : The Users table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.","title":"Users"},{"location":"user-guide/prompts/","text":"Prompts My libraries menu The My libraries menu is a space designed to create prompts, datasources, collections and organize them. My libraries menu consists of the following pages (tabs): All - on this page you can find all your created Prompts, Datasources and Collections. Prompts - on this page you can find all your created Prompts. Datasources - on this page you can find all your created Datasources. Applications - on this page you can find all your created Applications. Collections - on this page you can find all your created Collections. My libraries - Prompts page The My libraries - Prompts page serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted. How to Create a New Prompt In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button on the top right. Fill in the Name , Description , and Context fields. Click Save . Note : Name and Description are non-editable fields and can't be modified after saving the prompt. How to Create Tags In ELITEA, Tags serve as an efficient organizational tool that allows you to categorize and manage your collection of prompts. By assigning relevant tags to each prompt, you create an intuitive labeling system that facilitates quick access and retrieval. Later on, you can filter prompts by these tags, simplifying the process of finding the precise prompt you need among a vast collection, which is especially useful for users with an extensive library of different prompt types and topics. To add a tag to the prompt: Type a tag name or select from pre-existing tags from Tags input box. Press comma or Enter to create/select tag. Click Save to save the prompt with selected tags. Note: User has the flexibility to assign one or more tags to each prompt, enabling a multi-dimensional labeling system. How to Create Context The Context field in ELITEA is a crucial component where users input the necessary background information or instructions that guide the LLM in generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Context Identify Key Information : Before entering data into the Context field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Context field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the model's focus and efficiency. Using Variables : For dynamic content generation, you can incorporate variables directly into the Context. Variables are denoted by double curly braces, e.g., {{variable_name}}. After defining a variable in the Context, you must specify its value in the Variables section to let the model replace the placeholder with the actual data during processing. Prompting Frameworks To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing: CREATE Framework The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. - **Character**: Act as a senior software tester with expertise in regression testing. - **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. - **Examples**: Include scenarios like: - Preconditions: CRM software has been updated to the latest version. - Steps to reproduce: User logs in and accesses the customer data module. - Expected results: User should see updated customer data without any data loss. - **Adjustment**: Focus on critical modules like customer data management and transaction processing. - **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. - **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality. Elavis Saravia Framework This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. - **Instruction**: Generate test cases for user interface consistency across different devices. - **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. - **Input Data**: User accesses the application from different devices. - **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type. CRISPE Framework The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. - **Capacity and Role**: Serve as an automated testing tool expert. - **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. - **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. - **Personality**: Maintain a technical and precise tone throughout the test scripts. - **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results. Editability and Version Control You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate. How to Setup Messages The MESSAGES section is a crucial component that allows users to structure the flow of interaction within a prompt. System Message : Sets the interaction's context and guidelines for the Gen AI, not visible to the user but crucial for defining the Gen AI's behavior. Assistant Message : The Gen AI's responses to user inputs, crafted within the context and constraints set by the system message. User Message : Inputs from the user, serving as prompts for the Gen AI to generate responses, thereby driving the conversation forward. In conversational models, these message types work together within prompts to create a structured and meaningful dialogue. The system message defines the framework, the user message initiates and guides the flow of the conversation, and the assistant message provides the content of the interaction, all contributing to a coherent and purposeful exchange. System Message is a part of the prompt that provides instructions or context directly from the system's perspective. It sets the stage for the interaction, establishing rules, scenarios, or the setting for the Geb AI model to operate within. This is not generated in response to the user but is predefined by the designer of the prompt to guide the interaction. **Example:** **System Message**: \"You are an AI trained to assist in creating detailed and accurate test cases. Focus on clarity and precision, and ensure all responses adhere to software testing standards.\" This message informs the AI of its role in assisting with test case creation, setting expectations for the type of responses it should generate. Assistant Message is the AI's response generated based on the user's input and the context provided by the system message. This message aims to fulfill the user's request for information, assistance, or interaction within the guidelines set by the system message. **Example:** * **User Message**: \"Generate a test case for a login feature with email and password fields.\" * **Assistant Message**: \"Test Case: Login Feature * Objective: Verify that the user can log in using a valid email and password. * Steps: 1. Navigate to the login page. 2. Enter a valid email in the email field. 3. Enter the corresponding password in the password field. 4. Click the login button. * Expected Result: The user is redirected to the homepage after successful login. * Test Data: Use registered email: user@example.com and password: SecurePass123.\" The assistant's message provides a structured test case based on the user's request, adhering to the guidelines set by the system message. User Message is the input or query from the individual interacting with the Gen AI model. These messages are the user's side of the conversation, prompting the Gen AI to generate responses based on the context of the interaction as defined by the system message and the capabilities of the Gen AI. **Example:** **User Message**: \"Can you add a test for password validation error handling?\" This message prompts the assistant to expand on the existing test cases by adding specific scenarios related to error handling. To enhance the interactivity of a prompt, user can add multiple messages of any type by clicking the + icon, selecting the desired message type, and providing the relevant content. Additionally, user have the ability to delete, copy, and reorder messages to best fit the flow of the conversation, easily arranging them by dragging and dropping the message boxes as needed for optimal organization and presentation. How to Use Variables The variables within prompts add a layer of dynamic customization, allowing you to tailor prompts to specific needs or contexts. Variables are denoted by double curly brackets (e.g., {{variable_name}}) and should be defined in the prompt's Context input box. Once a variable is entered into the CONTEXT, it automatically populates the VARIABLES section, where you can assign a value to that variable. This feature empowers users to create flexible and reusable prompts that can be easily adapted by changing the values of the variables as needed, without altering the entire prompt structure. Note : User has the flexibility to define one or more variables in each prompt. Variables can also be defined in Messages . How to Execute Prompt To execute the prompt and get the output you have 2 options: Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Completion - is supplied to generative AI models, such as text or code generators, with the intent of the model continuing or completing the given input. The AI uses the context provided in the prompt to produce a coherent and contextually relevant extension or completion of the text. Executing a Prompt Using the Chat Option: Configure the Prompt : Initialize by providing the necessary context, identifying the prompt with a name, and defining variable values (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Initiate Interaction : Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Executing a Prompt Using the Completion Option: Configure the Prompt : Start by providing the necessary context, naming the prompt, and setting variable values (if needed). Select the AI Model : Choose from the available AI models (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this to modulate the AI's creative or unpredictable outputs. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Choose the Completion option. Initiate Execution : Click the Run button. Managing Prompt Versions: Save, Create Versions, and Manage To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them. How to Save a Prompt: To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt. How to Create New Versions: For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : - Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. - Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. - Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements. How to Publish a Prompt To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button. Moderator Review Process Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data. Possible Outcomes of the Review Post-review, a prompt may be categorized as: Published : Fulfilling all criteria, the prompt is incorporated into the Prompt Library for community access. Feedback for Revision : Identified as promising but necessitating modifications. Constructive comments guide the revision. Rejected : Falling short of the required standards, the prompt is declined for publication. Tracking the Status of Prompts Prompts undergo several statuses through the review phase: All Statuses : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Library. On Moderation : Prompts currently under review. User Approval : The prompt is pending prompt's author approval for publishing a new version. Rejected : Prompts evaluated and declined for publication. For status inquiries on your prompts, direct to the \" My Libraries \u2192 Prompts \" section on the platform and choose the relevant status from the dropdown menu. How to Add Prompt into Collection To add prompts to your collection, follow these steps: Once you've created a collection , you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection . Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection. How to Export a Prompt Exporting prompts allows you to utilize them across different platforms by choosing between two specific formats: [Alita format] - this JSON format is optimized for the ELITEA platform, incorporating ELITEA-centric details such as prompt versioning, variables with their possible values, tags, and model configurations. [DIAL format] - also in JSON format, it's tailored for integration with the Epam AI Dial platform, including only information and structuring relevant to DIAL. Exporting Your Prompt: Initiate the process by clicking the Export prompt icon. Choose your preferred format (Alita or DIAL) for export. The export process will generate a file, which will then be automatically downloaded to your device. This functionality facilitates the transfer and application of your prompts across different platforms by generating easily importable JSON files. How to Import a Prompt To use the prompts created in other platforms, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the My libraries - Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document. Prompts Menu The Prompts menu showcases a collection of published and shared prompts within the community. By default, upon logging in, the user is directed to the Latest page of the Prompts menu, which presents newly published prompts. Layout of the Prompts Menu The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community. Engaging with Published Prompts Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation: Liking Published Prompts Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt. Other Actions for Published Prompts Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt. Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Prompts"},{"location":"user-guide/prompts/#prompts","text":"","title":"Prompts"},{"location":"user-guide/prompts/#my-libraries-menu","text":"The My libraries menu is a space designed to create prompts, datasources, collections and organize them. My libraries menu consists of the following pages (tabs): All - on this page you can find all your created Prompts, Datasources and Collections. Prompts - on this page you can find all your created Prompts. Datasources - on this page you can find all your created Datasources. Applications - on this page you can find all your created Applications. Collections - on this page you can find all your created Collections.","title":"My libraries menu"},{"location":"user-guide/prompts/#my-libraries-prompts-page","text":"The My libraries - Prompts page serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted.","title":"My libraries - Prompts page"},{"location":"user-guide/prompts/#how-to-create-a-new-prompt","text":"In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button on the top right. Fill in the Name , Description , and Context fields. Click Save . Note : Name and Description are non-editable fields and can't be modified after saving the prompt.","title":"How to Create a New Prompt"},{"location":"user-guide/prompts/#how-to-create-tags","text":"In ELITEA, Tags serve as an efficient organizational tool that allows you to categorize and manage your collection of prompts. By assigning relevant tags to each prompt, you create an intuitive labeling system that facilitates quick access and retrieval. Later on, you can filter prompts by these tags, simplifying the process of finding the precise prompt you need among a vast collection, which is especially useful for users with an extensive library of different prompt types and topics. To add a tag to the prompt: Type a tag name or select from pre-existing tags from Tags input box. Press comma or Enter to create/select tag. Click Save to save the prompt with selected tags. Note: User has the flexibility to assign one or more tags to each prompt, enabling a multi-dimensional labeling system.","title":"How to Create Tags"},{"location":"user-guide/prompts/#how-to-create-context","text":"The Context field in ELITEA is a crucial component where users input the necessary background information or instructions that guide the LLM in generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests.","title":"How to Create Context"},{"location":"user-guide/prompts/#how-to-input-context","text":"Identify Key Information : Before entering data into the Context field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Context field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the model's focus and efficiency. Using Variables : For dynamic content generation, you can incorporate variables directly into the Context. Variables are denoted by double curly braces, e.g., {{variable_name}}. After defining a variable in the Context, you must specify its value in the Variables section to let the model replace the placeholder with the actual data during processing.","title":"How to Input Context"},{"location":"user-guide/prompts/#prompting-frameworks","text":"To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing:","title":"Prompting Frameworks"},{"location":"user-guide/prompts/#create-framework","text":"The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. - **Character**: Act as a senior software tester with expertise in regression testing. - **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. - **Examples**: Include scenarios like: - Preconditions: CRM software has been updated to the latest version. - Steps to reproduce: User logs in and accesses the customer data module. - Expected results: User should see updated customer data without any data loss. - **Adjustment**: Focus on critical modules like customer data management and transaction processing. - **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. - **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality.","title":"CREATE Framework"},{"location":"user-guide/prompts/#elavis-saravia-framework","text":"This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. - **Instruction**: Generate test cases for user interface consistency across different devices. - **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. - **Input Data**: User accesses the application from different devices. - **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type.","title":"Elavis Saravia Framework"},{"location":"user-guide/prompts/#crispe-framework","text":"The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. - **Capacity and Role**: Serve as an automated testing tool expert. - **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. - **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. - **Personality**: Maintain a technical and precise tone throughout the test scripts. - **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.","title":"CRISPE Framework"},{"location":"user-guide/prompts/#editability-and-version-control","text":"You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate.","title":"Editability and Version Control"},{"location":"user-guide/prompts/#how-to-setup-messages","text":"The MESSAGES section is a crucial component that allows users to structure the flow of interaction within a prompt. System Message : Sets the interaction's context and guidelines for the Gen AI, not visible to the user but crucial for defining the Gen AI's behavior. Assistant Message : The Gen AI's responses to user inputs, crafted within the context and constraints set by the system message. User Message : Inputs from the user, serving as prompts for the Gen AI to generate responses, thereby driving the conversation forward. In conversational models, these message types work together within prompts to create a structured and meaningful dialogue. The system message defines the framework, the user message initiates and guides the flow of the conversation, and the assistant message provides the content of the interaction, all contributing to a coherent and purposeful exchange. System Message is a part of the prompt that provides instructions or context directly from the system's perspective. It sets the stage for the interaction, establishing rules, scenarios, or the setting for the Geb AI model to operate within. This is not generated in response to the user but is predefined by the designer of the prompt to guide the interaction. **Example:** **System Message**: \"You are an AI trained to assist in creating detailed and accurate test cases. Focus on clarity and precision, and ensure all responses adhere to software testing standards.\" This message informs the AI of its role in assisting with test case creation, setting expectations for the type of responses it should generate. Assistant Message is the AI's response generated based on the user's input and the context provided by the system message. This message aims to fulfill the user's request for information, assistance, or interaction within the guidelines set by the system message. **Example:** * **User Message**: \"Generate a test case for a login feature with email and password fields.\" * **Assistant Message**: \"Test Case: Login Feature * Objective: Verify that the user can log in using a valid email and password. * Steps: 1. Navigate to the login page. 2. Enter a valid email in the email field. 3. Enter the corresponding password in the password field. 4. Click the login button. * Expected Result: The user is redirected to the homepage after successful login. * Test Data: Use registered email: user@example.com and password: SecurePass123.\" The assistant's message provides a structured test case based on the user's request, adhering to the guidelines set by the system message. User Message is the input or query from the individual interacting with the Gen AI model. These messages are the user's side of the conversation, prompting the Gen AI to generate responses based on the context of the interaction as defined by the system message and the capabilities of the Gen AI. **Example:** **User Message**: \"Can you add a test for password validation error handling?\" This message prompts the assistant to expand on the existing test cases by adding specific scenarios related to error handling. To enhance the interactivity of a prompt, user can add multiple messages of any type by clicking the + icon, selecting the desired message type, and providing the relevant content. Additionally, user have the ability to delete, copy, and reorder messages to best fit the flow of the conversation, easily arranging them by dragging and dropping the message boxes as needed for optimal organization and presentation.","title":"How to Setup Messages"},{"location":"user-guide/prompts/#how-to-use-variables","text":"The variables within prompts add a layer of dynamic customization, allowing you to tailor prompts to specific needs or contexts. Variables are denoted by double curly brackets (e.g., {{variable_name}}) and should be defined in the prompt's Context input box. Once a variable is entered into the CONTEXT, it automatically populates the VARIABLES section, where you can assign a value to that variable. This feature empowers users to create flexible and reusable prompts that can be easily adapted by changing the values of the variables as needed, without altering the entire prompt structure. Note : User has the flexibility to define one or more variables in each prompt. Variables can also be defined in Messages .","title":"How to Use Variables"},{"location":"user-guide/prompts/#how-to-execute-prompt","text":"To execute the prompt and get the output you have 2 options: Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Completion - is supplied to generative AI models, such as text or code generators, with the intent of the model continuing or completing the given input. The AI uses the context provided in the prompt to produce a coherent and contextually relevant extension or completion of the text.","title":"How to Execute Prompt"},{"location":"user-guide/prompts/#executing-a-prompt-using-the-chat-option","text":"Configure the Prompt : Initialize by providing the necessary context, identifying the prompt with a name, and defining variable values (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Initiate Interaction : Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Executing a Prompt Using the Chat Option:"},{"location":"user-guide/prompts/#executing-a-prompt-using-the-completion-option","text":"Configure the Prompt : Start by providing the necessary context, naming the prompt, and setting variable values (if needed). Select the AI Model : Choose from the available AI models (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this to modulate the AI's creative or unpredictable outputs. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Choose the Completion option. Initiate Execution : Click the Run button.","title":"Executing a Prompt Using the Completion Option:"},{"location":"user-guide/prompts/#managing-prompt-versions-save-create-versions-and-manage","text":"To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them.","title":"Managing Prompt Versions: Save, Create Versions, and Manage"},{"location":"user-guide/prompts/#how-to-save-a-prompt","text":"To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt.","title":"How to Save a Prompt:"},{"location":"user-guide/prompts/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : - Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. - Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. - Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"user-guide/prompts/#how-to-publish-a-prompt","text":"To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button.","title":"How to Publish a Prompt"},{"location":"user-guide/prompts/#moderator-review-process","text":"Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data.","title":"Moderator Review Process"},{"location":"user-guide/prompts/#possible-outcomes-of-the-review","text":"Post-review, a prompt may be categorized as: Published : Fulfilling all criteria, the prompt is incorporated into the Prompt Library for community access. Feedback for Revision : Identified as promising but necessitating modifications. Constructive comments guide the revision. Rejected : Falling short of the required standards, the prompt is declined for publication.","title":"Possible Outcomes of the Review"},{"location":"user-guide/prompts/#tracking-the-status-of-prompts","text":"Prompts undergo several statuses through the review phase: All Statuses : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Library. On Moderation : Prompts currently under review. User Approval : The prompt is pending prompt's author approval for publishing a new version. Rejected : Prompts evaluated and declined for publication. For status inquiries on your prompts, direct to the \" My Libraries \u2192 Prompts \" section on the platform and choose the relevant status from the dropdown menu.","title":"Tracking the Status of Prompts"},{"location":"user-guide/prompts/#how-to-add-prompt-into-collection","text":"To add prompts to your collection, follow these steps: Once you've created a collection , you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection . Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.","title":"How to Add Prompt into Collection"},{"location":"user-guide/prompts/#how-to-export-a-prompt","text":"Exporting prompts allows you to utilize them across different platforms by choosing between two specific formats: [Alita format] - this JSON format is optimized for the ELITEA platform, incorporating ELITEA-centric details such as prompt versioning, variables with their possible values, tags, and model configurations. [DIAL format] - also in JSON format, it's tailored for integration with the Epam AI Dial platform, including only information and structuring relevant to DIAL.","title":"How to Export a Prompt"},{"location":"user-guide/prompts/#exporting-your-prompt","text":"Initiate the process by clicking the Export prompt icon. Choose your preferred format (Alita or DIAL) for export. The export process will generate a file, which will then be automatically downloaded to your device. This functionality facilitates the transfer and application of your prompts across different platforms by generating easily importable JSON files.","title":"Exporting Your Prompt:"},{"location":"user-guide/prompts/#how-to-import-a-prompt","text":"To use the prompts created in other platforms, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the My libraries - Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document.","title":"How to Import a Prompt"},{"location":"user-guide/prompts/#prompts-menu","text":"The Prompts menu showcases a collection of published and shared prompts within the community. By default, upon logging in, the user is directed to the Latest page of the Prompts menu, which presents newly published prompts.","title":"Prompts Menu"},{"location":"user-guide/prompts/#layout-of-the-prompts-menu","text":"The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community.","title":"Layout of the Prompts Menu"},{"location":"user-guide/prompts/#engaging-with-published-prompts","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation:","title":"Engaging with Published Prompts"},{"location":"user-guide/prompts/#liking-published-prompts","text":"Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt.","title":"Liking Published Prompts"},{"location":"user-guide/prompts/#other-actions-for-published-prompts","text":"Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt. Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Other Actions for Published Prompts"}]}