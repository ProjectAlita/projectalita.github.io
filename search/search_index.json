{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ELITEA Documentation","text":"<p>ELITEA is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations.</p>"},{"location":"#our-values","title":"Our Values:","text":"<ul> <li>Democratize AI Access for all organizational levels with accessible, user-friendly AI technology.</li> <li>Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions.</li> <li>Enhance Productivity by maximizing team efficiency with integrated tools and environments.</li> <li>Foster Collaboration by providing environments where people can share their assets within projects and organization.</li> <li>Scale with Your Needs  with a platform that scales from small teams to enterprise levels.</li> </ul>"},{"location":"admin-guide/agents/agents-examples/","title":"Agents Examples and Materials","text":""},{"location":"admin-guide/agents/agents-examples/#agents-helpful-materials","title":"Agents - Helpful Materials","text":"<p>To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents.</p>"},{"location":"admin-guide/agents/agents-examples/#video-tutorials","title":"Video Tutorials","text":"<p>Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents:</p> <ul> <li>Alita AQA Agent for QAvaJS autromation</li> <li>EBSCO Automated test generation</li> </ul>"},{"location":"admin-guide/agents/agents-examples/#agent-frameworks","title":"Agent Frameworks","text":"<p>General Guidelines for Both Agent Types</p> <p>When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines:</p> <ul> <li>Toolkit Interaction: Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments).</li> <li>Execution Constraints: Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations.</li> </ul> <p>ReAct Agent Type</p> <p>For the ReAct agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools:</p> <pre><code>Example: Test Case Generation\n\n### Objective: \nYou are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit.\n\n### Instructions:\n1. Connect to GitHub Repository:\n   - Use the GitHub toolkit to connect to the specified Git repository.\n   - Ensure you have the necessary permissions to read files from the repository.\n2. Read Files:\n   - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository.\n   - Focus on finding information about datasources.\n3. Analyze Information:\n   - As an expert Software Testing engineer, analyze the information about datasources.\n   - Identify key functionalities and requirements for datasource creation.\n4. Create Test Cases:\n   - Based on your analysis, create three test cases covering datasource creation functionality.\n   - Ensure the test cases are detailed, clear, and follow industry best practices.\n5. Save Test Cases in Jira:\n   - Use the Jira toolkit to create a new Jira Task.\n   - Use the following project: ETSTCC\n   - The created Issue type must be Task.\n   - Ensure the Jira Task has the next available issue ID. \n   - Save the generated test cases in the Description field.\n   - Use the following Label: AI_Generated.\n   - Generate a corresponding Summary and apply it to the Summary field of the Task.\n   - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available.\n\n### Constraints:\n- Execute each toolkit only once.\n- Do not get into a loop.\n- Provide the best possible output based on the available information.\n\n### Example Test Case Format:\nTest Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps:\n\n1. Navigate to the datasource creation page.\n2. Enter valid inputs in all required fields.\n3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed.\n\nTest Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps:\n\n1. Navigate to the datasource creation page.\n2. Leave one or more required fields blank.\n3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled.\n\n### Execution:\n- Follow the instructions step-by-step.\n- Ensure each toolkit is executed only once.\n- Provide the best possible output based on the available information.\n</code></pre> <p>Raw Agent Type</p> <p>For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly:</p> <ul> <li>Preserve Existing Variables: Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality.</li> <li>Avoid Assigning Values to Variables: Leave variables unassigned; they will be automatically populated during execution.</li> <li>Include the following essential sections in your configuration:</li> </ul> <pre><code>  ### Tools:\n{{tools}} \n- Say to user: tool: \"complete_task\", args: \"final_answer\"  - complete message to be communicated to the user, shoudl contain as much details as possible\n\n### Scratchpad\n{{agent_scratchpad}}\n\n### Chat History\n{{chat_history}}\n\n### User Input:\n{{input}}\n\n### Response format\n{\n    \"thoughts\": {\n        \"text\": \"message to a user follow the style of your persona\",\n        \"plan\": \"short bulleted, list that conveys long-term plan\",\n        \"criticism\": \"constructive self-criticism\",\n    },\n    \"tool\": {\n        \"name\": \"tool name\",\n        \"args\": { \"arg name\": \"value\" }\n    }\n}\nYou must answer with only JSON and it could be parsed by Python json.loads\n</code></pre> <p></p> <p>By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes.</p>"},{"location":"admin-guide/agents/agents-examples/#practical-examples","title":"Practical Examples","text":"<p>Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:</p>"},{"location":"admin-guide/prompts/prompts-examples/","title":"Prompts Examples and Materials","text":""},{"location":"admin-guide/prompts/prompts-examples/#prompts-helpful-materials","title":"Prompts - Helpful Materials","text":"<p>To assist you in maximizing the capabilities of Prompts within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Prompts.</p>"},{"location":"admin-guide/prompts/prompts-examples/#prompting-frameworks","title":"Prompting Frameworks","text":"<p>To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing:</p>"},{"location":"admin-guide/prompts/prompts-examples/#create-framework","title":"CREATE Framework","text":"<p>The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras.</p> <pre><code>**Character**: Act as a senior software tester with expertise in regression testing.\n**Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software.\n**Examples**: Include scenarios like:\n  **Preconditions**: CRM software has been updated to the latest version.\n  **Steps to reproduce**: User logs in and accesses the customer data module.\n  **Expected results**: User should see updated customer data without any data loss.\n**Adjustment**: Focus on critical modules like customer data management and transaction processing.\n**Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources.\n**Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality.\n</code></pre>"},{"location":"admin-guide/prompts/prompts-examples/#elavis-saravia-framework","title":"Elavis Saravia Framework","text":"<p>This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator.</p> <pre><code>**Instruction**: Generate test cases for user interface consistency across different devices.\n**Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones.\n**Input Data**: User accesses the application from different devices.\n**Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type.\n</code></pre>"},{"location":"admin-guide/prompts/prompts-examples/#crispe-framework","title":"CRISPE Framework","text":"<p>The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment.</p> <pre><code>**Capacity and Role**: Serve as an automated testing tool expert.\n**Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency.\n**Statement**: Create automated test scripts that simulate multiple user transactions simultaneously.\n**Personality**: Maintain a technical and precise tone throughout the test scripts.\n**Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login).\n</code></pre> <p>By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.</p>"},{"location":"feature-guides/advanced-features/roles/","title":"Roles Management","text":""},{"location":"feature-guides/advanced-features/roles/#how-to-access-admin-menu","title":"How to access Admin menu:","text":"<p>To configure or modify the admin settings for a specific project:</p> <ol> <li>Navigate to <code>https://alita.lab.epam.com/-/configuration/users/</code>.</li> <li>Select the project from the dropdown list for which you want to set up or adjust the admin settings.</li> </ol> <p></p>"},{"location":"feature-guides/advanced-features/roles/#roles-menu","title":"Roles Menu","text":"<p>The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs.</p> <p>Default Roles:</p> <ul> <li>System: Grants comprehensive permissions, including additional administrative capabilities.</li> <li>Admin: Allows full project access and user management.</li> <li>Editor: Provides editing rights within the project without administrative privileges.</li> <li>Viewer: Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions.</li> </ul> <p></p> <p>Customizing Roles:</p> <p>To adjust permissions for any role:</p> <ol> <li>Click the Edit roles icon.</li> <li>Toggle the checkboxes for each permission as needed.</li> <li>Click the Save to apply changes.</li> </ol> <p></p> <p>Creating a New Role:</p> <ol> <li>Click Edit roles.</li> <li>Then Add role. After naming the new role, select the desired permissions. </li> <li>This custom role will now be available for assignment in the ELITEA HUB\u2192Settings\u2192Projects menu.</li> </ol> <p></p> <p>By understanding and utilizing the Roles menu, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.   </p>"},{"location":"feature-guides/core-features/export-import/","title":"Export and Import Guide: Managing Prompts, Datasources, and Agents for Backup, Migration, and Collaboration","text":""},{"location":"feature-guides/core-features/export-import/#introduction","title":"Introduction","text":"<p>This user guide provides a comprehensive overview of the Export and Import features within ELITEA. These powerful functionalities allow you to seamlessly transfer your valuable entities \u2013 Prompts, Datasources, and Agents \u2013 between different ELITEA environments, projects, or for backup purposes.</p> <p>The ability to export and import entities offers significant flexibility and control over your AI workflows. You can leverage these features in various scenarios, including:</p> <ul> <li>Migrating Entities:  Effortlessly move your carefully crafted prompts, configured datasources, and intelligent agents from one ELITEA environment to another. For instance, you can migrate entities from an ELITEA Alita LAB environment to a new Nexus environment.</li> <li>Sharing and Collaboration:  Share your entities with colleagues working in different projects or ELITEA instances, fostering collaboration and knowledge sharing.</li> <li>Backup and Recovery: Create backups of your critical entities, ensuring data safety and enabling quick recovery in case of unforeseen issues.</li> <li>Development and Testing: Develop and test entities in a dedicated environment and then easily import them into your production environment.</li> </ul> <p>This guide will detail the process of exporting and importing each entity type, along with best practices and practical use cases to help you effectively utilize these features.</p>"},{"location":"feature-guides/core-features/export-import/#import-and-export-features-a-general-overview","title":"Import and Export Features: A General Overview","text":"<p>The Export feature allows you to save a snapshot of your prompts, datasources, or agents as JSON files. These files contain the complete configuration and relevant data of the entity at the time of export.</p> <p>The Import feature enables you to bring previously exported JSON files back into ELITEA. During the import process, you have the flexibility to configure certain aspects of the imported entity, such as the target project and specific settings.</p> <p>These features provide a convenient and reliable way to manage and transfer your assets within and across ELITEA environments.</p>"},{"location":"feature-guides/core-features/export-import/#how-to-export-entities","title":"How to Export Entities","text":"<p>ELITEA allows you to export prompts, datasources, and agents individually. The export process is similar for each entity type.</p> <ol> <li>Log in to ELITEA: Access the ELITEA platform using your credentials.</li> <li>Navigate to the Project: Go to the specific project that contains the prompt, datasource, or agent you wish to export.</li> <li>Access the Relevant Menu: Within the project, navigate to the menu corresponding to the entity type you want to export (e.g., Prompts, Datasources, or Agents).</li> <li>Locate the Entity for Export: Find the specific entity you want to export within the list. ELITEA offers two view options, and the export process varies slightly depending on the view you are using:    a. Card List View: If you are viewing your entities in a card format, click on the specific entity's card that you wish to export. This will open the entity's details. Once open, locate and click the Export [entity type] icon (e.g., Export prompt, Export datasource, or Export agent).    b. Table View: If you are viewing your entities in a table format, locate the entity you want to export in the list. In the Actions column, which is usually the last column in the table, click on the ellipsis icon (<code>...</code>) next to the entity. A dropdown menu will appear. Select the Export option from this menu.</li> <li>Automatic Download: Upon clicking the Export icon or selecting the Export option, your web browser will automatically initiate the download of a JSON file. This file contains all the configuration data for the exported entity and will be saved to your local device's default download location.</li> </ol> <p>This process allows you to easily export your ELITEA entities for various purposes, such as sharing them with others or creating backups of your configurations.</p> <p></p>"},{"location":"feature-guides/core-features/export-import/#exporting-a-prompt","title":"Exporting a Prompt","text":"<ol> <li>Navigate to the Prompts menu within the project containing the prompt you wish to export.</li> <li>Locate the specific prompt you want to export.</li> <li>Open the prompt and click the Export prompt icon.</li> <li>Your browser will automatically download a JSON file containing the prompt's data to your local device.</li> </ol> <p>The exported JSON file includes:</p> <ul> <li>All versions of the prompt.</li> <li>The complete configuration of each version, including:<ul> <li>Context</li> <li>Messages (System, Assistant, User)</li> <li>Variables and their potential values</li> <li>Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens)</li> <li>Welcome Message</li> <li>Conversation Starters</li> <li>Tags</li> </ul> </li> </ul> <p></p>"},{"location":"feature-guides/core-features/export-import/#exporting-a-datasource","title":"Exporting a Datasource","text":"<ol> <li>Navigate to the Datasources menu within the project containing the datasource you wish to export.</li> <li>Locate the specific datasource you want to export.</li> <li>Open the datasource and click the Export datasource icon.</li> <li>Your browser will automatically download a JSON file containing the datasource's data to your local device.</li> </ol> <p>The exported JSON file includes:</p> <ul> <li>The complete configuration of the datasource, including:<ul> <li>Name and Description</li> <li>Context</li> <li>Welcome Message</li> <li>Conversation Starters</li> <li>Tags</li> <li>Settings for Chat, Search, and Deduplicate functionalities (including selected LLM and Embedding Models)</li> <li>Dataset configurations (including storage details and connection parameters, excluding authentication credentials)</li> </ul> </li> </ul> <p>Important Security Note: For security purposes, the authentication information for datasets (such as API Keys, usernames, tokens, and passwords) is not included in the exported datasource file. You will need to re-enter this information when importing the datasource.</p>"},{"location":"feature-guides/core-features/export-import/#exporting-an-agent","title":"Exporting an Agent","text":"<ol> <li>Navigate to the Agents menu within the project containing the agent you wish to export.</li> <li>Locate the specific agent you want to export.</li> <li>Open the agent and click the Export agent icon.</li> <li>Your browser will automatically download a JSON file containing the agent's data to your local device.</li> </ol> <p>The exported JSON file includes:</p> <ul> <li>All versions of the agent.</li> <li>The complete configuration of each version, including:<ul> <li>Name and Description</li> <li>Context</li> <li>Welcome Message</li> <li>Conversation Starters</li> <li>Tags</li> <li>Settings (Model, Temperature, Top-P, Top-K, Max Completion Tokens)</li> <li>Toolkit configurations (including tool details and parameters, excluding authentication credentials)</li> </ul> </li> </ul> <p>Important Security Note: For security purposes, the authentication information for toolkits (such as API Keys, usernames, tokens, and passwords) is not included in the exported agent file. You will need to re-enter this information when importing the agent.</p>"},{"location":"feature-guides/core-features/export-import/#exporting-collections","title":"Exporting Collections","text":"<p>Collections in ELITEA provide a powerful way to group and organize various entities such as prompts, datasources, and agents into a single, manageable unit. This organizational structure offers the significant advantage of being able to export an entire collection at once, ensuring that all the entities within that collection are included in the export. This feature is particularly convenient for backing up related items, sharing groups of resources, or transferring sets of configurations between environments.</p> <p>Benefits of Exporting Collections:</p> <ul> <li>Convenient Batch Export: Export all grouped entities (prompts, datasources, and agents) simultaneously, saving time and effort compared to exporting each item individually.</li> <li>Preserve Relationships: Maintain the logical grouping of your entities as defined by the collection structure.</li> <li>Simplified Sharing and Backup: Easily share a related set of resources or create a comprehensive backup of a specific project component.</li> </ul> <p>To export a collection:</p> <ol> <li>Navigate to the Collections menu within the project that contains the collection you wish to export.</li> <li>Locate the specific collection you want to export within the list of available collections.</li> <li>Open the collection by clicking on its name or card.</li> <li>Once the collection is open, you will find an Export Collection icon. Click this icon to initiate the export process.</li> <li>Your browser will automatically download a JSON file to your local device. This file contains the data for the collection itself, along with the configuration details of all the prompts, datasources, and agents currently included within that collection.</li> </ol> <p>This streamlined process allows you to efficiently manage and transfer groups of related assets within ELITEA.</p> <p></p>"},{"location":"feature-guides/core-features/export-import/#how-to-import-entities","title":"How to Import Entities","text":"<p>ELITEA provides a straightforward import process for prompts, datasources, and agents.</p> <ol> <li>Login ELITEA.</li> <li>Click the +Quick button switcher, located in the top right corner of the interface.</li> <li>Click the Import button.</li> <li>Choose the appropiate file (in *.json) from your local device.</li> <li>An Import Wizard will appear, guiding you through the import process.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/export-import/#importing-a-prompt","title":"Importing a Prompt","text":"<ol> <li>Select File: Choose the appropiate prompt file (in *.json) from your local device.</li> <li>Import Wizard - Prompt Options:<ul> <li>Select Project: Choose the target project where you want to import the prompt. You can select your Private workspace or any other project where you have the necessary permissions.</li> <li>Select Versions to Import: You can choose to import all versions of the prompt or select specific versions. Note: It is highly recommended to select and import the 'latest' version of the prompt, otherwise you might have validation errors, preventing successful import, or resulting the imported prompt not to function as expected.</li> <li>Select LLM Model: For each version you are importing, you can select the desired LLM Model.<ul> <li>If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically.</li> <li>If the model is not available, the first available model in your environment will be selected as a default.</li> <li>You can manually change the selected model to your preferred choice before completing the import.</li> </ul> </li> </ul> </li> <li>Click the Import button in the Import Wizard.</li> <li>The imported prompt will now be available in the Prompts menu of the selected project.</li> </ol>"},{"location":"feature-guides/core-features/export-import/#importing-a-datasource","title":"Importing a Datasource","text":"<ol> <li>Select File: Choose the appropiate datasource file (in *.json) from your local device.</li> <li>Import Wizard - Datasource Options:<ul> <li>Select Project: Choose the target project where you want to import the datasource.</li> <li>Select Embedding Model: Choose the desired Embedding Model for the datasource.<ul> <li>If the Embedding Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically.</li> <li>If the model is not available, the first available model in your environment will be selected as a default.</li> <li>You can manually change the selected model to your preferred choice.</li> </ul> </li> <li>Configure Models for Chat, Search, and Deduplicate: Select the desired LLM models for the Chat, Search, and Deduplicate functionalities of the datasource.</li> <li>Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk <code>*</code>. This typically includes the Storage type and various authentication parameters for the datasets.</li> <li>Select Datasets to Import: Choose which datasets you want to import along with the datasource.</li> <li>Provide Dataset Authentication: For any datasets requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords).</li> </ul> </li> <li>Click the Import button in the Import Wizard.</li> <li>The imported datasource will now be available in the Datasources menu of the selected project.</li> <li>Reindexing Datasets: After successfully importing the datasource, you must open the datasource and initiate the reindexing of the imported datasets. This step is crucial as the actual vector databases are not exported or imported.</li> </ol>"},{"location":"feature-guides/core-features/export-import/#importing-an-agent","title":"Importing an Agent","text":"<ol> <li>Select File: Choose the appropiate agent file (in *.json) from your local device.</li> <li>Import Wizard - Agent Options:<ul> <li>Select Project: Choose the target project where you want to import the agent.</li> <li>Select Versions to Import: You can choose to import all versions of the agent or select specific versions. Note: It is highly recommended to select and import the 'latest' version of the agent, otherwise you might have validation errors, preventing successful import, or resulting the imported agent not to function as expected.</li> <li>Select LLM Model: For each version you are importing, you can select the desired LLM Model.<ul> <li>If the LLM Model specified in the exported file is also available in your current ELITEA environment, it will be selected automatically.</li> <li>If the model is not available, the first available model in your environment will be selected as a default.</li> <li>You can manually change the selected model to your preferred choice before completing the import.</li> </ul> </li> <li>Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk <code>*</code>. This typically includes various authentication parameters for the agent's toolkits.</li> <li>Select Tools to Import: Choose which tools you want to import along with the agent.</li> <li>Configure Tool Parameters: You can review and reconfigure the available options and parameters for each tool being imported. You can either use the default values from the exported file or customize them as needed.</li> <li>Provide Toolkit Authentication: For any toolkits requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords).</li> </ul> </li> <li>Click the Import button in the Import Wizard.</li> <li>The imported agent will now be available in the Agents menu of the selected project.</li> </ol>"},{"location":"feature-guides/core-features/export-import/#managing-master-agents-with-connected-entities-exporting-and-importing","title":"Managing Master Agents with Connected Entities: Exporting and Importing","text":"<p>ELITEA simplifies the management of complex AI workflows by providing integrated features for exporting and importing 'master' agents along with their connected entities. This allows for efficient transfer of intricate AI workflows between different ELITEA environments or for creating comprehensive backups.</p> <p>Exporting Master Agents with Connected Entities:</p> <p>ELITEA offers a convenient feature to export a 'master' agent, ensuring that all its directly connected prompts, datasources, and child agents are included in the exported file. This is particularly useful for transferring complex AI solutions between different ELITEA environments or for creating comprehensive backups.</p> <p>When you export a 'master' agent that has other agents, prompts, or datasources configured as toolkits, these nested entities are automatically included in the exported JSON file. This single file contains the configuration details for the 'master' agent and all its connected resources, simplifying the transfer process.</p> <p>Importing Master Agents with Connected Entities:</p> <p>When importing a 'master' agent from an exported file, ELITEA automatically imports all the connected prompts, datasources, and child agents that were included in the file. This streamlined process eliminates the need to import each component individually, making it significantly easier to transfer complex AI workflows between ELITEA environments.</p> <p>Upon importing the 'master' agent's file, ELITEA will create the 'master' agent and all its associated toolkit entities in the target project, preserving the structure and relationships of the original workflow.</p> <p>Benefits of Managing Master Agents with Connected Entities:</p> <ul> <li>Simplified Transfer of Complex Workflows: Move entire AI workflows, including agents and their dependencies, in a single operation.</li> <li>Preservation of Relationships: Maintain the connections and configurations between the 'master' agent and its toolkits during the transfer process.</li> <li>Time Efficiency: Avoid the manual effort of locating and importing each connected entity individually.</li> </ul> <p>How it Works:</p> <ul> <li>Export: When exporting a 'master' agent, ELITEA identifies all the child prompts, datasources, and agents configured as toolkits and includes their configurations in the exported JSON file.</li> <li>Import: During import, ELITEA reads the file and creates the 'master' agent and all its listed toolkit entities in the target project, re-establishing the connections.</li> </ul> <p>Important Considerations:</p> <ul> <li>As with individual entity importing, the actual datasets within datasources will need to be reindexed in the target project after importing the 'master' agent and its connected entities.</li> <li>As with individual entity importing, the authentication details for any configured toolkits and datasets are not copied to the new project. You will need to re-enter the authentication credentials (API Keys, usernames, tokens, passwords) for any toolkits and datasets while importing the 'master' agent.</li> </ul> <p>These integrated features for managing 'master' agents and their connected entities provide a powerful and efficient way to handle complex AI workflows within ELITEA.</p> <p></p>"},{"location":"feature-guides/core-features/export-import/#importing-a-collection","title":"Importing a Collection","text":"<p>ELITEA allows you to import previously exported collection files, streamlining the process of adding multiple related entities to your project. This feature is particularly useful for quickly setting up pre-configured groups of prompts, datasources, and agents.</p> <p>You can import a JSON file that contains all the information of an exported collection. This simplifies the process of adding multiple related entities at once.</p> <p>Important Note: While importing a collection file will successfully import all the prompts, datasources, and agents contained within that file and add them to their respective menus, the Collection entity itself will not be automatically created as part of this import process. This is a current limitation of the platform. The individual entities will be imported, but you will need to manually recreate the collection and add the imported entities to it if you wish to maintain the original grouping. This functionality is planned for future updates.</p> <p>To import a collection file:</p> <ol> <li>Select File: Choose the appropiate collection file (in *.json) from your local device.</li> <li>Import Wizard - Options:<ul> <li>Select Project: Choose the target project where you want to import the entities.</li> <li>Select Entities: Choose the enities that you want to import, make corresponding configurations for each selected entity.</li> </ul> </li> <li>Click the Import button in the Import Wizard.</li> <li>The individual entities will be imported and added to their respective menus.</li> </ol> <p></p> <p>After Importing:</p> <p>After successfully importing the collection file, you will find the individual prompts, datasources, and agents in their respective menus (Prompts, Datasources, Agents). To recreate the original collection structure, you will need to:</p> <ol> <li>Navigate to the Collections menu.</li> <li>Create a new collection.</li> <li>Manually add the imported prompts, datasources, and agents to this newly created collection.</li> </ol> <p>This process ensures that while the collection entity itself is not automatically recreated, all the individual components of the exported collection are successfully imported into your project.</p>"},{"location":"feature-guides/core-features/export-import/#important-considerations-for-importing-entities","title":"Important Considerations for Importing Entities","text":"<ul> <li>File Format: Ensure that the file you are importing is a valid ELITEA file in JSON format for the corresponding entity type. If you are making manual changes to the export file, ensure you save it in the correct JSON format and maintain the structure and required parameters of the file. Incorrect formatting or missing parameters will prevent successful import.</li> <li>Version Compatibility: While ELITEA strives for backward compatibility, importing entities created in significantly older versions of ELITEA might encounter compatibility issues.</li> <li>Context and Dependencies: If the imported entity has dependencies on other entities (e.g., an agent using other prompts, agents or datasources as toolkits), ensure that these dependencies are also present.</li> </ul>"},{"location":"feature-guides/core-features/export-import/#best-practices-and-use-cases","title":"Best Practices and Use Cases","text":"<ul> <li>Regular Backups:  Utilize the export feature to create regular backups of your important prompts, datasources, and agents. Store these exported files in a safe location for disaster recovery purposes.</li> <li>Environment Migration:  When migrating from one ELITEA environment to another (e.g., from a development to a production environment), export your entities from the source environment and import them into the target environment.</li> <li>Sharing with Colleagues: Export your well-crafted prompts or useful datasources, agents and share the JSON files with colleagues so they can import them into their own projects.</li> <li>Collaborative Development:  Developers can work on different parts of an AI solution in separate ELITEA instances and then use export/import to integrate their work. For example, one developer might create a set of prompts, while another configures a datasource and the third one - agents.</li> <li>Template Creation: Create a library of reusable prompt, agent and datasource templates by exporting them. These templates can then be easily imported into new projects, saving time and effort.</li> <li>Security Considerations: Remember that authentication credentials for datasets and toolkits are not included in exported files. Ensure you have a secure way to manage and provide these credentials when importing.</li> <li>Testing in Isolation: Export a production agent and import it into a separate testing environment. This allows you to test new changes without impacting the live system.</li> </ul> <p>By understanding and utilizing the Export and Import features effectively, you can significantly enhance your workflow within ELITEA, improve collaboration, and ensure the safety and portability of your valuable AI assets.</p>"},{"location":"feature-guides/core-features/forking/","title":"Forking Guide: Transferring Entities Between Projects in ELITEA","text":""},{"location":"feature-guides/core-features/forking/#introduction","title":"Introduction","text":"<p>This user guide provides a comprehensive overview of the Forking feature within ELITEA. Forking offers a streamlined method for transferring your valuable entities \u2013 Prompts, Datasources, and Agents \u2013 between different projects within the same ELITEA environment.</p> <p>The ability to fork entities provides a convenient and efficient way to manage your ELITEA assets. You can leverage this feature in various scenarios, including:</p> <ul> <li>Moving Entities Between Projects: Easily transfer prompts, datasources, and agents from one project to another within your current ELITEA environment. This is useful for reorganizing your work, sharing resources between teams, or consolidating entities into a central project.</li> <li>Duplicating Entities for Experimentation: Create a copy of an existing entity in a different project to experiment with modifications or new configurations without affecting the original entity.</li> <li>Sharing Resources Within an Environment: Make your carefully crafted prompts, configured datasources, and intelligent agents available to other projects within the same ELITEA instance.</li> </ul> <p>This guide will detail the process of forking each entity type, along with best practices and practical use cases to help you effectively utilize this feature.</p>"},{"location":"feature-guides/core-features/forking/#forking-feature-a-general-overview","title":"Forking Feature: A General Overview","text":"<p>The Forking feature in ELITEA provides a direct way to copy an existing entity (Prompt, Datasource, or Agent) from its current project to another project within the same ELITEA environment. Think of it as creating a branch or a copy of your entity in a new location.</p> <p>The forking process is conceptually similar to exporting and importing, but it is more direct and integrated within the ELITEA interface, eliminating the need to download and upload files.</p> <p>Important Considerations:</p> <ul> <li>Same Environment Only: Forking is limited to transferring entities between projects within the same ELITEA environment. To move entities between different ELITEA environments (e.g., from  an ELITEA Alita LAB environment to a new Nexus environment ), you should use the Export and Import features.</li> <li>Exclusion of Sensitive Data: For security reasons, the authentication information (such as API Keys, usernames, tokens, and passwords) are NOT being forked automatically. You will need to re-enter this information when forking the entity.</li> <li>No Collection Forking: Currently, forking of Collections is not supported.</li> <li>Preventing Duplicates: You cannot fork the same entity to the same project twice. ELITEA checks the uniqueness of the entity's 'object id' to prevent the creation of duplicates within a single project. If you need to create a duplicate of an entity within the same project, you can use the Export and Import features.</li> </ul>"},{"location":"feature-guides/core-features/forking/#how-to-fork-entities","title":"How to Fork Entities","text":"<p>The process for forking Agents, Prompts, and Datasources is similar.</p> <ol> <li>Log in to ELITEA: Access the ELITEA platform using your credentials.</li> <li>Navigate to the Project: Go to the specific project that contains the prompt, datasource, or agent you wish to fork.</li> <li>Access the Relevant Menu: Within the project, navigate to the menu corresponding to the entity type you want to fork (e.g., Prompts, Datasources, or Agents).</li> <li>Locate the Entity for Fork: Find the specific entity you want to fork within the list. ELITEA offers two view options, and the fork process varies slightly depending on the view you are using:     a. Card List View: If you are viewing your entities in a card format, click on the specific entity's card that you wish to fork. This will open the entity's details. Once open, locate and click the Fork [entity type] icon (e.g., Fork prompt, Fork datasource, or Fork agent).     b. Table View: If you are viewing your entities in a table format, locate the entity you want to fork in the list. In the Actions column, which is usually the last column in the table, click on the ellipsis icon (<code>...</code>) next to the entity. A dropdown menu will appear. Select the Fork option from this menu.</li> <li>A Forking wizard will appear.</li> <li>In the dialog, select the Target Project where you want to create a copy of the entity.</li> <li>Click the Fork button.</li> <li>A copy of the entity will now be created in the selected target project. You will be forwarded to that entity created in the target project.</li> </ol> <p></p> <p></p>"},{"location":"feature-guides/core-features/forking/#forking-a-prompt","title":"Forking a Prompt","text":"<ol> <li>Navigate to the Prompts menu within the project containing the prompt you wish to for.</li> <li>Locate the specific prompt you want to fork.</li> <li>Open the prompt and click the Fork prompt icon.</li> <li>Forking Wizard - Prompt Options:<ul> <li>Select Project: Choose the target project where you want to fork the prompt. You can select your Private workspace or any other project where you have the necessary permissions.</li> <li>Select Versions to Fork: You can choose to fork all versions of the prompt or select specific versions. Note: It is always highly recommended to select and fork the 'latest' version of the prompt, otherwise you might have validation errors, preventing successful fork, or latest version will be cloned from one of the versions</li> <li>Select LLM Model: For each version you are forking, you can select the desired LLM Model. You can manually change the selected model to your preferred choice before completing the fork.</li> </ul> </li> <li>Click the Fork button in the Forking Wizard.</li> <li>A copy of the prompt will now be created in the selected target project. You will be forwarded to that prompt created in the target project.</li> </ol>"},{"location":"feature-guides/core-features/forking/#forking-a-datasource","title":"Forking a Datasource","text":"<ol> <li>Navigate to the Datasources menu within the project containing the datasource you wish to fork.</li> <li>Locate the specific datasource you want to fork.</li> <li>Open the datasource and click the Fork datasource icon.</li> <li>Forking Wizard - Datasource Options:<ul> <li>Select Project: Choose the target project where you want to fork the datasource.</li> <li>Select Embedding Model: Choose the desired Embedding Model for the datasource.        <ul> <li>You can manually change the selected model to your preferred choice.</li> </ul> </li> <li>Configure Models for Chat, Search, and Deduplicate: Select the desired LLM models for the Chat, Search, and Deduplicate functionalities of the datasource.</li> <li>Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk <code>*</code>. This typically includes the Storage type and various authentication parameters for the datasets.</li> <li>Select Datasets to Fork: Choose which datasets you want to fork along with the datasource.</li> <li>Provide Dataset Authentication: For any datasets requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords).</li> </ul> </li> <li>Click the Fork button in the Forking Wizard.</li> <li>A copy of the datasource will now be created in the selected target project. You will be forwarded to that datasource created in the target project.</li> <li>Reindexing Datasets: After successfully forking the datasource, you must initiate the reindexing of the forked datasets. This step is crucial as the actual vector databases are not forked.</li> </ol> <p>Important Note: When forking a datasource, the actual datasets and authentication details are not copied to the new project:</p> <ul> <li>Reconfigure Dataset Connections: You will need to re-enter the storage details and connection parameters, including authentication credentials (API Keys, usernames, tokens, passwords) while forking.</li> <li>Reindex Datasets: You will need to initiate the reindexing of the datasets in the forked datasource within the target project.</li> </ul> <p></p>"},{"location":"feature-guides/core-features/forking/#forking-an-agent","title":"Forking an Agent","text":"<ol> <li>Navigate to the Agents menu within the project containing the agent you wish to fork.</li> <li>Locate the specific agent you want to fork.</li> <li>Open the agent and click the Fork agent icon.</li> <li>Forking Wizard - Agent Options:</li> <li>Select Project: Choose the target project where you want to fork the agent.<ul> <li>Select Versions to Fork: You can choose to fork all versions of the agent or select specific versions. Note: It is always highly recommended to select and fork the 'latest' version of the agent, otherwise you might have validation errors, preventing successful fork, or latest version will be cloned from one of the versions.</li> <li>Select LLM Model: For each version you are forking, you can select the desired LLM Model. You can manually change the selected model to your preferred choice before completing the import.</li> <li>Provide Mandatory Parameters: Fill in all mandatory fields and parameters, which are highlighted with an asterisk <code>*</code>. This typically includes various authentication parameters for the agent's toolkits.</li> <li>Select Tools to Fork: Choose which tools you want to fork along with the agent.</li> <li>Configure Tool Parameters: You can review and reconfigure the available options and parameters for each tool being forked. You can either use the default values from the toolkit or customize them as needed.</li> <li>Provide Toolkit Authentication: For any toolkits requiring authentication, you will need to manually provide the necessary credentials (API Keys, usernames, tokens, passwords).</li> </ul> </li> <li>Click the Fork button in the Forking Wizard.</li> <li>A copy of the agent will now be created in the selected target project. You will be forwarded to that agent created in the target project.</li> </ol> <p>Important Note: When forking an agent, the authentication details for any configured toolkits are not copied to the new project. You will need to re-enter the authentication credentials (API Keys, usernames, tokens, passwords) for any toolkits while forking the agent.</p> <p></p>"},{"location":"feature-guides/core-features/forking/#forking-master-agents-with-connected-entities","title":"Forking Master Agents with Connected Entities","text":"<p>ELITEA's forking feature extends its convenience to complex AI workflows by allowing you to fork a 'master' agent along with all its directly connected entities. When you fork a 'master' agent that has other agents, prompts, or datasources configured as toolkits, these nested entities will also be automatically forked to the target project.</p> <p>This capability significantly simplifies the process of transferring complex AI workflows between projects. Instead of forking each individual component separately, you can fork the main agent, and ELITEA will ensure that all the necessary supporting entities are also copied to the new project.</p> <p>Benefits of Forking Master Agents with Connected Entities:</p> <ul> <li>Simplified Transfer of Complex Workflows: Move entire AI workflows, including agents and their dependencies, in a single operation.</li> <li>Preservation of Relationships: Maintain the connections and configurations between the 'master' agent and its toolkits in the forked version.</li> <li>Time Efficiency: Avoid the manual effort of locating and forking each connected entity individually.</li> </ul> <p>How it Works:</p> <p>When you initiate the forking process for a 'master' agent, ELITEA identifies all the prompts, datasources, and child agents that are configured as toolkits for that 'master' agent. During the forking operation, copies of these connected entities are also created in the target project, ensuring that the forked 'master' agent has access to the necessary resources to function correctly.</p> <p></p> <p>Important Considerations:</p> <ul> <li>As with individual entity forking, the actual datasets within datasources will need to be reindexed in the target project after forking the 'master' agent and its connected entities.</li> <li>As with individual entity forking, the authentication details for any configured toolkits and datasets are not copied to the new project. You will need to re-enter the authentication credentials (API Keys, usernames, tokens, passwords) for any toolkits and datasets while forking the 'master' agent.</li> <li>The forked connected entities will have the same names as their originals. If entities with the same names already exist in the target project, you may encounter naming conflicts.</li> </ul> <p>This feature makes it much easier to replicate and share complex AI workflows across different projects within your ELITEA environment.</p>"},{"location":"feature-guides/core-features/forking/#best-practices-and-use-cases","title":"Best Practices and Use Cases","text":"<ul> <li>Project Reorganization: Use forking to move prompts, datasources, or agents from a temporary or experimental project to a more permanent or production-ready project within the same environment.</li> <li>Team Collaboration: Fork entities into a shared project where multiple team members can access and utilize them.</li> <li>Experimentation and Development: Fork a production prompt or agent into a development project to test new ideas or modifications without risking changes to the original entity.</li> <li>Creating Project-Specific Copies: Fork a general-purpose prompt, agent or datasource into a specific project and then customize it further to meet the unique needs of that project.</li> <li>Streamlining Workflow: Instead of exporting and importing, use forking for quick transfers within the same ELITEA environment, especially when dealing with multiple entities.</li> </ul>"},{"location":"feature-guides/core-features/forking/#when-to-use-forking-vs-exportimport","title":"When to Use Forking vs Export/Import","text":"<ul> <li>Forking: Use forking when you need to transfer entities between projects within the same ELITEA environment. It's a faster and more integrated process for internal transfers.</li> <li>Export/Import: Use Export and Import when you need to:<ul> <li>Transfer entities between different ELITEA environments.</li> <li>Create backups of your entities.</li> <li>Create duplicates of entities within the same project.</li> <li>Share entities with users who may not have access to the same ELITEA environment.</li> </ul> </li> </ul> <p>By understanding and utilizing the Forking feature effectively, you can significantly streamline your workflow within ELITEA, improve collaboration within your environment, and efficiently manage your AI assets across different projects.</p>"},{"location":"feature-guides/core-features/integrations/","title":"Integrations and Configurations Guide","text":""},{"location":"feature-guides/core-features/integrations/#introduction","title":"Introduction","text":"<p>This user guide provides a comprehensive overview of the Integrations feature in ELITEA and how to leverage these integrations through Configurations within Agent toolkits. These powerful functionalities enable seamless connections with external platforms, streamlining workflows and enhancing collaboration across different tools.</p> <p>The ability to integrate with external services and manage their configurations within ELITEA offers significant benefits, including:</p> <ul> <li>Enhanced Workflow Efficiency: Connect ELITEA with your existing tools like Jira, Confluence, GitHub, and TestRail to automate tasks, share information, and reduce manual data entry.</li> <li>Centralized Management: Manage connections to various external services from a single location within ELITEA, simplifying administration and improving visibility.</li> <li>Customized Authentication: Configure authentication settings for external tools at different levels (personal or project-specific) to meet various security and access requirements.</li> <li>Flexibility and Reusability: Create reusable integration configurations that can be easily applied to multiple Agent toolkits, saving time and effort.</li> </ul> <p>This guide will detail the process of setting up Integrations and utilizing Configurations within Agent toolkits, along with best practices and practical use cases to help you effectively leverage these features. </p> <p>Important Note:</p> <p>In ELITEA, your work is organized within three distinct types of spaces:</p> <ul> <li>Private Workspace: This is your personal area within ELITEA. You have exclusive access to all the content you create and manage here. Think of it as your individual sandbox where you can experiment and build your AI solutions. This includes your personal Chats, Agents, Prompts, Datasources, Collections and Artifacts.</li> <li>Team Project: These are collaborative spaces where multiple users are added as team members. Within a Team project, all members have access to the project's content, fostering collaboration and shared development. This shared content includes Chats, Agents, Prompts, Datasources, Collections and Artifacts that belong to that specific project.</li> <li>Public Project: This space allows you to engage with the wider ELITEA community and explore content shared by other users. This shared content includes Chats, Agents, Prompts, Datasources, and Collections.</li> </ul> <p>Understanding the distinction between your Private Workspace, where you have exclusive access to your content, and Team Projects, which are collaborative spaces where team members share access to project resources, is crucial for effectively managing Integrations and Configurations within ELITEA.</p>"},{"location":"feature-guides/core-features/integrations/#integration-feature-connecting-elitea-with-external-platforms","title":"Integration Feature: Connecting ELITEA with External Platforms","text":"<p>The Integrations menu in ELITEA serves as a central hub for establishing connections with external platforms. By configuring integrations, you make these external services available for use within your Agent toolkits.</p> <p>Key Aspects of the Integration Feature:</p> <ul> <li>Centralized Connection Management: The Integrations menu provides a single point of control for managing connections to various external services.</li> <li>Supported Platforms: ELITEA currently supports integrations with Jira, Confluence, GitHub, and TestRail, with plans to add more services in future releases.</li> <li>Reusable Configurations: Once an integration is configured, it can be reused across multiple Agent toolkits within the same project or your Private workspace.</li> <li>Private and Project Level Integrations: You can create integrations within your Private workspace for personal use or within Team projects for shared access among project members.</li> <li>Secure Authentication: ELITEA offers various secure authentication methods for connecting to external platforms, including API Keys, Tokens, Passwords, and Private Keys, with the option to store sensitive credentials securely using Secrets.</li> </ul> <p>Accessing the Integrations Menu:</p> <ol> <li>Log in to ELITEA.</li> <li>Navigate to either your Private workspace or the specific Team project where you want to configure the integration.</li> <li>Click on the Your Avatar icon located at the top right corner of the page to open the Settings sidebar menu.</li> <li>Click the Integrations to navigate to that section.</li> </ol> <p></p> <p></p> <p>Setting up an Integration:</p> <ol> <li>In the Integrations menu, click the + icon to create a new integration.</li> <li>A pop-up window will appear, prompting you to Select Integration Type. Choose the service you want to integrate with (e.g., Confluence, GitHub, Jira, TestRail).</li> <li>You will be presented with a configuration form specific to the selected integration type. Follow the detailed steps below for each service.</li> <li>Configure the Intergation parameters.</li> <li>Click the Save button to finalize the integration setup.</li> </ol> <p></p> <p>After saving, the newly created integration will be added to the Integrations table, making it available for selection and reuse in the Configurations section of your Agent toolkits. You can manage your saved integrations directly from the Integrations table. In the Actions column, click on the ellipsis icon (<code>...</code>) next to a specific integration, you will reveal options to Edit the integration details, Set as Default to make it the default one for that Integration type, or Delete the integration if it's no longer needed.</p>"},{"location":"feature-guides/core-features/integrations/#confluence-integration-setup","title":"Confluence Integration Setup","text":"<p>To enable connection with your Confluence instance:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon in the Integrations menu and select Confluence.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for this integration (e.g., \"Confluence - KB Name\").</li> <li>URL: Enter the base URL of your Confluence instance (e.g., <code>https://kb.epam.com/</code>).</li> <li>Authentication Options: Choose your preferred authentication method:<ul> <li>API Key:<ul> <li>Select API Key.</li> <li>Enter your Confluence API key in the Password field or select a pre-configured Secret from the dropdown.</li> <li>Enter the associated Username for the API key.</li> </ul> </li> <li>Token:<ul> <li>Select Token.</li> <li>Enter your Confluence API token in the Password field or select a pre-configured Secret from the dropdown.</li> </ul> </li> <li>Username:<ul> <li>Select Username.</li> <li>Enter your Confluence Username.</li> <li>Enter your Confluence Password or select a pre-configured Secret from the dropdown.</li> </ul> </li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type:<ul> <li>Cloud: For Confluence instances hosted on Atlassian's cloud.</li> <li>Server: For self-hosted or enterprise Confluence instances. Important Note: For connecting to Epam's Confluence, select Server.</li> </ul> </li> <li>Set as Default: Optionally, check this box to make this integration the default Confluence connection for the Private workspace or Team project.</li> </ul> </li> <li>Save the Integration: Click the Save button.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/integrations/#github-integration-setup","title":"GitHub Integration Setup","text":"<p>To connect with your GitHub repositories:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon in the Integrations menu and select GitHub.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for this integration (e.g., \"GitHub - Repo Name\").</li> <li>Authentication Options: Choose your preferred authentication method:<ul> <li>Private Key:<ul> <li>Select Private Key.</li> <li>Enter the App ID for your GitHub App.</li> <li>Enter the Private Key in the Password field or select a pre-configured Secret.</li> </ul> </li> <li>Token:<ul> <li>Select Token.</li> <li>Enter your GitHub Personal Access Token in the Password field or select a pre-configured Secret.</li> </ul> </li> <li>Password:<ul> <li>Select Password.</li> <li>Enter your GitHub Username.</li> <li>Enter your GitHub account Password in the Password field or select a pre-configured Secret.</li> </ul> </li> <li>Anonymous: Select Anonymous if no authentication is required for the specific GitHub repository you intend to access (typically for public repositories).</li> </ul> </li> <li>Set as Default: Optionally, check this box to make this integration the default GitHub connection for the Private workspace or Team project.</li> </ul> </li> <li>Save the Integration: Click the Save button.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/integrations/#jira-integration-setup","title":"Jira Integration Setup","text":"<p>To enable connection with your Jira instance:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon in the Integrations menu and select Jira.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for this integration (e.g., \"Jira - Project Name\").</li> <li>URL: Enter the base URL of your Jira instance (e.g., <code>https://jiraeu.epam.com/</code>).</li> <li>Authentication Options: Choose your preferred authentication method:<ul> <li>API Key:<ul> <li>Select API Key.</li> <li>Enter your Jira API key in the Password field or select a pre-configured Secret.</li> <li>Enter the associated Username for the API key.</li> </ul> </li> <li>Token:<ul> <li>Select Token.</li> <li>Enter your Jira API token in the Password field or select a pre-configured Secret.</li> </ul> </li> <li>Username:<ul> <li>Select Username.</li> <li>Enter your Jira Username.</li> <li>Enter your Jira Password or select a pre-configured Secret.</li> </ul> </li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type:<ul> <li>Cloud: For Jira instances hosted on Atlassian's cloud.</li> <li>Server: For self-hosted or enterprise Jira instances. Important Note: For connecting to Epam's Jira, select Server.</li> </ul> </li> <li>Set as Default: Optionally, check this box to make this integration the default Jira connection for the Private workspace or Team project.</li> </ul> </li> <li>Save the Integration: Click the Save button.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/integrations/#testrail-integration-setup","title":"TestRail Integration Setup","text":"<p>To connect with your TestRail instance:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon in the Integrations menu and select TestRail.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for this integration (e.g., \"TestRail - Project Name\").</li> <li>URL: Enter the base URL of your TestRail instance (e.g., <code>https://testrail.epam.com/</code>).</li> <li>Email: Enter the email address associated with your TestRail account.</li> <li>Authentication Options: Choose your preferred authentication method:<ul> <li>Password: Enter your TestRail account Password in the Password field or select a pre-configured Secret.</li> </ul> </li> <li>Set as Default: Optionally, check this box to make this integration the default TestRail connection for the Private workspace or Team project.</li> </ul> </li> <li>Save the Integration: Click the Save button.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/integrations/#important-considerations-for-integrations","title":"Important Considerations for Integrations","text":"<p>When setting up integrations in ELITEA, it's important to understand the following constraints and best practices:</p> <ul> <li> <p>Uniqueness per Integration Type:</p> <ul> <li>Jira, Confluence, and TestRail: Within your Private workspace or a Team project, you can create multiple integrations for Jira, Confluence, and TestRail. The uniqueness of these integrations is determined by the URL of the respective service. This means you can connect to different Jira instances, Confluence spaces, or TestRail accounts by creating separate integrations for each unique URL.</li> <li>GitHub:  In contrast to Jira, Confluence, and TestRail, you can create only one GitHub integration within your Private workspace or a Team project. This single integration will serve as the connection point for all your GitHub interactions within that space.</li> </ul> </li> <li> <p>Authentication Verification:  Always double-check the authentication details you provide for each integration. Incorrect credentials will prevent ELITEA from successfully connecting to the external service. Ensure that the API keys, tokens, passwords, or private keys you enter are accurate and have the necessary permissions to access the desired resources on the external platform. Verifying the authentication setup is crucial for ensuring your integrations (and the configurations that use them) function correctly.</p> </li> </ul>"},{"location":"feature-guides/core-features/integrations/#configurations-applying-integrations-to-agent-toolkits","title":"Configurations: Applying Integrations to Agent Toolkits","text":"<p>Configurations provide the mechanism to utilize the integrations you've set up within your Agent toolkits. When configuring a toolkit for Jira, Confluence, GitHub, or TestRail within an Agent, you have the option to select a pre-configured integration, eliminating the need to enter authentication details directly into the toolkit settings.</p> <p>Configuration Options:</p> <p>When configuring a toolkit, you will typically find a dropdown menu or a selection field related to \"Configuration\" or \"Integration.\" This section offers three primary options:</p> <ul> <li>Create manual configuration: This option allows you to enter all the necessary connection details (URL, authentication credentials) directly within the toolkit settings. This is useful for one-off connections or when you don't want to create a reusable integration.</li> <li>Create private configuration: Selecting this option will create a new integration configuration specifically for this toolkit. The entered details will be used for this toolkit and will also be saved as a reusable integration in your Private workspace's Integrations page. This allows you to reuse this configuration in other toolkits within your Private workspace or Team projects.</li> <li>Create project configuration: Similar to the private configuration, this option creates a new integration configuration for the toolkit. The details will be used for this toolkit and will also be saved as a reusable integration in the current Team project's Integrations page, making it available for other agents and toolkits within that project.</li> <li>Select existing integration: This option allows you to choose from the list of integrations that have already been configured in your Private workspace or the current Team project's Integrations page. Selecting an existing integration automatically populates the toolkit's connection details, simplifying the setup process.</li> </ul> <p></p>"},{"location":"feature-guides/core-features/integrations/#create-manual-configuration","title":"Create manual configuration","text":"<ol> <li>Click the + Agent button located at the top right corner or open already created Agent.</li> <li>Click the + icon or open already created toolkit under TOOLS section.</li> <li>Select the desired tool (Confluence, Jira, GitHub, TestRail) from the dropdown list. The New tool configuration section is opened.</li> <li>Select the Manual configuration under the Configuration option.</li> <li>Depending on the selected toolkit fill all required fields and options.</li> <li>Click the Save button to apply changes.</li> </ol>"},{"location":"feature-guides/core-features/integrations/#create-private-configuration","title":"Create private configuration","text":"<ol> <li>Click the + Agent button located at the top right corner or open already created Agent.</li> <li>Click the + icon or open already created toolkit under TOOLS section.</li> <li>Select the desired tool (Confluence, Jira, GitHub, TestRail) from the dropdown list. The New tool configuration section is opened.</li> <li>Select the Create private configuration under the Configuration option.</li> <li>Provide the Configuration Name.</li> <li>Depending on the selected toolkit fill all required fields and options.</li> <li>Click the Save configuration button to save the changes and add this configuration as reusable integration in your Private workspace's Integrations page.</li> </ol>"},{"location":"feature-guides/core-features/integrations/#create-project-configuration","title":"Create project configuration","text":"<ol> <li>Click the + Agent button located at the top right corner or open already created Agent.</li> <li>Click the + icon or open already created toolkit under TOOLS section.</li> <li>Select the desired tool (Confluence, Jira, GitHub, TestRail) from the dropdown list. The New tool configuration section is opened.</li> <li>Select the Create project configuration under the Configuration option.</li> <li>Provide the Configuration Name.</li> <li>Depending on the selected toolkit fill all required fields and options.</li> <li>Click the Save configuration button to save the changes and add this configuration as reusable integration in your Team project's Integrations page.</li> </ol>"},{"location":"feature-guides/core-features/integrations/#configurations-selecting-existing-integrations","title":"Configurations: Selecting existing Integrations","text":"<p>Once you have configured integrations in your Private workspace or within a Team project, these integrations become available for selection when configuring toolkits in your Agents. This allows you to easily reuse established connections to external platforms.</p> <p>When adding or editing a Jira, Confluence, GitHub, or TestRail toolkit in an Agent, you will find a Configuration dropdown list. This list displays all the available integrations of the corresponding type that you can use for that specific toolkit.</p> <p>Identifying Integration Scope:</p> <p>To help you distinguish between integrations configured in your Private workspace and those configured within the current Team project, ELITEA uses distinct icons:</p> <ul> <li>Private Integration: Integrations configured in your Private workspace are indicated by a person icon (\ud83d\udc64) at the beginning of the integration URL or name in the dropdown list.</li> <li>Project Integration: Integrations configured within the current Team project are indicated by a folder icon (\ud83d\udcc1) at the beginning of the integration URL or name.</li> </ul> <p></p> <p></p> <p>Integration Naming Convention:</p> <p>The naming convention for integrations in the dropdown list also helps you identify the specific connection:</p> <ul> <li>Jira, Confluence, and TestRail Integrations: These integrations are listed using their configured URL. This ensures you can easily differentiate between connections to different instances of these tools (e.g., different Jira servers or Confluence spaces).</li> <li>GitHub Integrations: Since only one GitHub integration is allowed per workspace or project, these integrations are simply listed as GitHub.</li> </ul> <p>Toolkit-Specific Integration Filtering:</p> <p>The Configuration dropdown list is context-aware. When configuring a specific type of toolkit (e.g., a Jira toolkit), only integrations of that specific type (Jira integrations) will be displayed for selection. This prevents you from accidentally selecting an integration intended for a different tool.</p> <p>By understanding these visual cues and naming conventions, you can easily select the appropriate pre-configured integration for your Agent toolkit, simplifying the setup process and ensuring consistent authentication.</p>"},{"location":"feature-guides/core-features/integrations/#best-practices-and-use-cases","title":"Best Practices and Use Cases","text":"<p>Here are some examples of how to effectively utilize Integrations and Configurations in your ELITEA workflows:</p>"},{"location":"feature-guides/core-features/integrations/#use-case-1-individual-jira-credentials-for-user-story-management","title":"Use Case 1: Individual Jira Credentials for User Story Management","text":"<ul> <li>Scenario: You are building an agent workflow to create and publish user stories in Jira. You want each Business Analyst (BA) using the agent to authenticate with their own Jira credentials to ensure traceability of who created which user story.</li> <li>Solution:<ol> <li>Instruct each BA to configure their personal Jira integration in their Private workspace's Integrations page.</li> <li>In the project where the agent is being configured, when setting up the Jira toolkit for publishing user stories, select already created Private configuration option. This will allow each BA running the agent to use their own private Jira integration, using their personal credentials for authentication.</li> </ol> </li> </ul>"},{"location":"feature-guides/core-features/integrations/#use-case-2-service-account-for-github-code-access","title":"Use Case 2: Service Account for GitHub Code Access","text":"<ul> <li>Scenario: You are creating an agent workflow to read code from a GitHub repository to generate automation test cases. You have a dedicated service account for accessing the GitHub repository and want to use these credentials consistently for this purpose.</li> <li>Solution:<ol> <li>The team manager or a designated member configures a GitHub integration in the Team project Integrations page using the service account's credentials.</li> <li>When configuring the GitHub toolkit in the agent for reading code, select already created Project configuration option and choose the integration configured with the service account.</li> </ol> </li> </ul>"},{"location":"feature-guides/core-features/integrations/#use-case-3-mixed-authentication-for-confluence-and-testrail-workflow","title":"Use Case 3: Mixed Authentication for Confluence and TestRail Workflow","text":"<ul> <li>Scenario: You are building an agent workflow to read information from Confluence pages and then publish manual test cases in TestRail. You want to use a service account for accessing Confluence but require each Quality Assurance (QA) engineer to use their own TestRail credentials for publishing test cases.</li> <li>Solution:<ol> <li>The team manager configures a Confluence integration in the Team project Integrations page using the service account's credentials.</li> <li>Instruct each QA engineer to configure their personal TestRail integration in their Private workspace's Integrations page.</li> <li>When configuring the agent:<ul> <li>For the Confluence toolkit, use already created Project configuration and choose the service account integration.</li> <li>For the TestRail toolkit, use already created Private configuration option, allowing each QA to use their own TestRail integration.</li> </ul> </li> </ol> </li> </ul> <p>By strategically using Integrations and Configurations, you can create flexible and secure agent workflows that cater to various authentication needs and enhance collaboration within your ELITEA environment.</p>"},{"location":"feature-guides/core-features/monitoring/","title":"ELITEA Monitoring User Guide: Understanding Application Usage and Performance","text":""},{"location":"feature-guides/core-features/monitoring/#introduction","title":"Introduction","text":"<p>This user guide provides a comprehensive overview of the Monitoring feature in ELITEA. This powerful tool is designed to offer deep insights into the application's usage and performance, empowering administrators and users to make informed decisions for optimization and improvement. Whether you're looking to understand user engagement, assess the effectiveness of your  entities (prompts, datasources, agents and conversations), or identify areas for enhancement, the Monitoring feature provides the data and visualizations you need.</p> <p></p> <p>Purpose of the Monitoring Feature:</p> <ul> <li>Gain Insights into Application Usage: Understand how users are interacting with ELITEA, including the frequency of use, active user trends, and popular features.</li> <li>Evaluate Each Entity Performance: Assess the effectiveness of your prompts, datasources, and agents by tracking metrics like user engagement and acceptance rate of AI generated output.</li> <li>Identify Areas for Optimization: Pinpoint areas where user engagement can be improved and understand how effectively AI generated outputs are being utilized.</li> <li>Make Data-Driven Decisions: Utilize concrete data and visualizations to guide your strategies for improving ELITEA's adoption and effectiveness.</li> </ul> <p>How to Use This Guide:</p> <p>This guide is structured to provide a detailed understanding of each aspect of the Monitoring feature. You will find explanations of key metrics, how they are calculated, and how to interpret the various charts and data presented. Whether you are a Chapter Manager, Project Admin, or a user interested in understanding ELITEA usage, this guide will equip you with the knowledge to effectively utilize ELITEA's monitoring capabilities.</p>"},{"location":"feature-guides/core-features/monitoring/#overview-of-monitoring-feature","title":"Overview of Monitoring Feature","text":"<p>The ELITEA Monitoring feature is a powerful analytics tool designed to track and visualize key aspects of application usage and the effectiveness of AI-driven workflows.  It allows users with administrative roles to gain valuable insights into how ELITEA is being adopted and utilized within their projects and portfolios.</p> <p>Key Monitoring Capabilities (Currently in Scope):</p> <ul> <li>User Engagement: Measures how actively users with the \"Monitor\" role are interacting with ELITEA projects. This helps understand the adoption and active usage levels within your teams.</li> <li>Acceptance Rate of AI Generated Output:  Tracks how often users accept and utilize the outputs generated by ELITEA's prompts, datasources and agents. This metric provides insights into the perceived usefulness and quality of the AI-driven assistance provided by ELITEA.</li> </ul> <p>Important Note:</p> <ul> <li>ELITEA's Monitoring feature exclusively tracks activities performed by users who have been assigned the \"Monitor\" role within ELITEA projects. This ensures that the metrics reflect the engagement and usage patterns of designated users who are intended to utilize and benefit from ELITEA's capabilities.</li> <li>It's important to note that Monitoring is a cross-project capability. This means that regardless of which project is currently selected in the Project dropdown menu at the top of the screen, the Monitoring screen will provide data aggregated across all projects that you have Admin access to. This allows for portfolio-level analysis and a holistic view of ELITEA usage across your organization.</li> </ul> <p>Future Enhancements:</p> <p>ELITEA's Monitoring feature is continuously evolving. Future updates will expand the scope of monitoring capabilities to include metrics that measure:</p> <ul> <li>Relevancy of User Input:  Assess how well user inputs align with the intended context and purpose of ELITEA's functionalities.</li> <li>Relevancy of Output Generated by ELITEA: Evaluate the quality and relevance of the outputs generated by ELITEA in relation to user inputs and needs.</li> </ul> <p>These future metrics will provide even deeper insights into the effectiveness and efficiency of ELITEA, allowing for more fine-tuned optimization and improvement.</p> <p>Here's the enhanced section for the ELITEA Monitoring User Guide, detailing Project Types, Grouping, and User Role Assignment for Monitoring:</p>"},{"location":"feature-guides/core-features/monitoring/#project-scope-and-user-roles-in-monitoring","title":"Project Scope and User Roles in Monitoring","text":"<p>ELITEA Monitoring provides flexible options to analyze data at different levels, from individual projects to aggregated group (portfolio) views. Understanding the different project types and user roles is crucial for effectively utilizing the Monitoring feature.</p>"},{"location":"feature-guides/core-features/monitoring/#project-types-in-elitea-monitoring","title":"Project Types in ELITEA Monitoring","text":"<p>ELITEA Monitoring allows you to review data across various project scopes, catering to different analytical needs:</p> <ul> <li>All projects: This option provides a comprehensive, aggregated view of monitoring data across all projects available within your ELITEA deployed environment. This is useful for high-level, organization-wide analysis.</li> <li>Public Project: ELITEA includes a default Public project, accessible to all users. Monitoring data for the Public project can be reviewed separately to understand usage patterns within this shared space.</li> <li>Private Workspace: Each user has a personal Private workspace. You always have access to your own Private workspace and can review its monitoring data in isolation.</li> <li>Team Projects:  These are projects created for specific teams or purposes. Access to Team projects and their monitoring data is controlled by user roles and permissions.</li> <li>Groups (Portfolios): ELITEA allows you to group multiple projects together into user-defined Groups (often referred to as Portfolios). This enables you to aggregate monitoring data across a collection of related projects for portfolio-level reporting and analysis.</li> </ul> <p>Access and Permissions:</p> <p>Your access to monitoring data for different project types depends on your role and permissions within ELITEA:</p> <ul> <li>Project and Group Access Based on Roles:  Within the Monitoring feature, the projects and groups you can select and view data for are determined by your Admin role and project/group memberships.</li> <li>Private Workspace and Public Project Access:  All users will always have access to monitoring data for the Public project and their own Private workspace.</li> </ul>"},{"location":"feature-guides/core-features/monitoring/#grouping-projects-for-portfolio-level-monitoring","title":"Grouping Projects for Portfolio-Level Monitoring","text":"<p>To facilitate portfolio-level reporting and analysis, ELITEA allows you to group multiple projects together. Here's how to create and utilize Project Groups for monitoring:</p> <p>Creating a Project Group:</p> <ol> <li>Select a Team Project: From the Projects dropdown list at the top of the ELITEA interface, select a Team project that you want to include in a group.</li> <li>Navigate to Project Settings: Go to Settings -&gt; Projects page.</li> </ol> <p></p> <ol> <li>Edit Groups: Locate the Groups field (displayed as \"Groups:\") and click the Pencil icon next to it to edit the project's group membership.</li> <li>Create or Select a Group:<ul> <li>Create New Group: To create a new group, type the desired group name in the input field.</li> <li>Select Existing Group: To add the project to an existing group, start typing the name of the group and select it from the dropdown list of existing groups that appears.</li> </ul> </li> <li>Save Group Assignment: Click the \"Save\" button (or a checkmark icon) to add the selected project to the specified group.</li> </ol> <p></p> <ol> <li>Repeat for Other Projects: To add more projects to the same group, select another Team project from the Projects dropdown list and repeat steps 2-5, ensuring you select the same group name in step 4.</li> <li>Access Group Monitoring Data: Navigate to the Monitoring page.</li> <li>Select Project Group in Filters: Click the Projects dropdown in the Filtering Panel. Scroll down the list \u2013 you will now see your newly created Project Group listed at the bottom, along with the individual projects that are members of that group.</li> <li>View Portfolio-Level Metrics: Click on the name of your created Project Group in the Projects dropdown. The Monitoring page will now display aggregated metrics and charts for all projects that are members of that group, providing a Portfolio-level view.</li> </ol> <p></p> <p>Navigating Project Groups and \"All projects\" in Monitoring:</p> <p>When you select a Project Group (or \"All projects\") in the Projects dropdown on the Monitoring page, you will notice a visual representation of the projects included in that scope.</p> <ul> <li>Project Rectangles: Below the \"Projects\" dropdown, you will see a series of selectable rectangles, each representing a project that is part of the selected Group (or all projects if \"All projects\" is selected).</li> <li>Drilling Down into Individual Projects: These rectangles are interactive. By clicking on a specific project rectangle, you can \"drill down\" into the monitoring data for that individual project. The Monitoring page will then update to display metrics and charts specifically for the project you clicked on, allowing for more granular project-level analysis.</li> </ul>"},{"location":"feature-guides/core-features/monitoring/#assigning-the-monitor-role-to-users-in-team-projects","title":"Assigning the \"Monitor\" Role to Users in Team Projects","text":"<p>By default, users are automatically assigned the \"Monitor\" role only within their Private workspace and the Public project. To enable monitoring for users within Team projects, you need to explicitly assign them the \"Monitor\" role within those projects. Only users with the Admin role in a project have the permission to change roles for other users in that project.</p> <p>Assigning the \"Monitor\" Role:</p> <ol> <li>Select the Team Project: From the Projects dropdown at the top of the ELITEA interface, select the Team project where you want to assign the \"Monitor\" role to a user.</li> <li>Navigate to Project Settings: Go to Settings -&gt; Projects page.</li> <li>Locate Teammates Table: Scroll down the \"Projects\" page to find the \"Teammates\" table. This table lists all users who are members of the selected Team project and their assigned roles.</li> <li>Edit User Role: Find the row corresponding to the user to whom you want to assign the \"Monitor\" role. Click the Pencil icon in the \"Role\" column for that user to edit their role.</li> <li>Select \"Monitor\" Role: In the role dropdown menu that appears, select \"Monitor\" as the new role for the user.</li> <li>Apply Changes: Click the Checkmark icon (or \"Save\" button) to apply the role change and save the updated user role.</li> </ol> <p></p> <p>After assigning the \"Monitor\" role to users in your Team projects, their activities within those projects will be included in the ELITEA Monitoring data, allowing you to track their engagement and the effectiveness of ELITEA within your teams.</p>"},{"location":"feature-guides/core-features/monitoring/#accessing-monitoring-within-elitea","title":"Accessing Monitoring Within ELITEA","text":"<p>To access the Monitoring screen in ELITEA, follow these steps:</p> <ol> <li>Open Settings Menu: Click on your user avatar located in the top right corner of the ELITEA interface. This will open the settings menu.</li> <li>Select Monitoring: In the Settings menu, click on the \"Monitoring\" option.</li> <li>Monitoring Landing Page: After selecting \"Monitoring,\" you will be redirected to the Monitoring Landing Page. This page is the central dashboard where you can filter, view, and analyze various monitoring metrics.</li> </ol> <p></p> <p>Key Components of the Monitoring Landing Page:</p> <p>The Monitoring Landing Page is designed to be intuitive and informative, providing a clear overview of ELITEA usage and performance. It is structured into three main panels, each serving a distinct purpose:</p> <p></p> <ul> <li> <p>1. Filtering Panel: Tailoring Your Data View</p> <p>The Filtering Panel, located prominently at the top of the Monitoring Landing Page, is your control center for customizing the data displayed throughout the dashboard.  It allows you to precisely define the scope of your analysis by applying various filters.  By using these filters, you can focus on specific projects, timeframes, Use Cases, or even individual users to gain targeted insights.</p> <p>Here's a breakdown of the filtering options available:</p> <ul> <li> <p>Projects:  This dropdown menu allows you to select the specific projects or pre-configured Portfolio groupings you want to include in your analysis.</p> <ul> <li>Single Project Selection: Choose a specific project from the list to view monitoring data relevant only to that project.</li> <li>Group Selection: Scroll to the bottom of the dropdown to select a user-defined  grouping. This aggregates data across all projects within that Group, providing a high-level overview.</li> <li>All Projects: By default, or by selecting an \"All Projects\" option (if available), you can view data aggregated across all projects you have Admin access to.</li> </ul> </li> <li> <p>Time Period (From &amp; To Dates): These date fields enable you to define a custom reporting period.</p> <ul> <li>\"From\" Date:  Select the starting date for your analysis.</li> <li>\"To\" Date: Select the ending date for your analysis.</li> <li>The Monitoring feature will then calculate metrics and display charts based on data within this specified date range.</li> </ul> </li> <li> <p>Type: This dropdown filter allows you to narrow down the metrics to specific types of ELITEA entities. You can choose to focus on:</p> <ul> <li>Prompts: Analyze metrics related specifically to Prompt usage and performance.</li> <li>Datasources: Focus on metrics related to Datasource access and relevance.</li> <li>Agents:  View metrics related to Agent executions and effectiveness.</li> <li>Conversations: Analyze metrics related to user conversations within ELITEA. This allows you to understand overall conversation trends, user engagement at the conversation level, and acceptance rates within conversations.</li> <li>Prompts, Datasources, Agents, Conversations (Combined):  This option (often the default) aggregates metrics across all three entity types, providing a broader overview.</li> </ul> </li> <li> <p>Name: This dropdown filter becomes active when you select a specific \"Type\" (Prompts, Datasources, or Agents). It allows you to further refine your analysis to a specific entity within the selected type.</p> <ul> <li>\"All Items\": (Default) When \"All Items\" is selected, the metrics will be calculated for all entities of the chosen \"Type\".</li> <li>Specific Entity Selection: Choose a specific Prompt name, Datasource name, Agent name or Conversation name from the list to view metrics for that individual entity only.</li> </ul> </li> <li> <p>Users: This dropdown allows you to filter the data to show activity related to specific users.</p> <ul> <li>\"All Users\": (Default) Metrics are calculated based on the activity of all users with the \"Monitor\" role within the selected projects and timeframe.</li> <li>Specific User Selection: Choose a specific user from the list to view metrics related only to that user's activity.</li> </ul> </li> <li> <p>Aggregation: This dropdown menu allows you to control how the data is grouped and displayed in charts. Choosing the right aggregation level is crucial for visualizing data at the appropriate granularity for your analysis. Available aggregation options include:</p> <ul> <li>Hour: Data is grouped and displayed on an hourly basis. This provides the most granular view, allowing you to identify peak usage times within a day, track hourly fluctuations, and potentially pinpoint immediate issues or usage spikes.</li> <li>Day:  Data is grouped and displayed on a daily basis. This is a common and versatile aggregation level, useful for understanding daily usage patterns, tracking daily active users, and monitoring daily token consumption.</li> <li>Week: Data is aggregated and displayed on a weekly basis. This provides a broader view, smoothing out daily fluctuations and highlighting weekly trends in adoption, engagement, and performance. Weekly aggregation is often suitable for regular weekly reporting and tracking week-over-week changes.</li> <li>Two Weeks: Data is aggregated and displayed over two-week periods. This aggregation level can be particularly useful for teams or projects that operate in two-week sprints. It allows you to align your monitoring reports with sprint cycles and assess performance and usage across a complete sprint.</li> <li>Three Weeks: Data is aggregated and displayed over three-week periods. Similar to the \"Two Weeks\" option, this aggregation is beneficial for teams or projects following three-week sprint cycles. It provides a sprint-level view of metrics, enabling performance evaluation within the context of a three-week iteration.</li> <li>Month: Data is aggregated and displayed on a monthly basis. This provides the broadest overview, smoothing out weekly variations and highlighting long-term trends in adoption, usage, and performance over calendar months. Monthly aggregation is useful for high-level reporting, executive summaries, and identifying long-term patterns.</li> </ul> </li> <li> <p>Refresh Button:  After you have selected your desired filters in the Filtering Panel, click the \"Refresh\" button to apply these filters.  Clicking \"Refresh\" triggers the Monitoring feature to recalculate all metrics and update the charts based on your chosen criteria.</p> </li> <li> <p>Reset Filters Button: Click the \"Reset Filters\" button to clear all currently applied filters and revert the Monitoring Landing Page back to its default view, displaying data for all projects and the default timeframe.</p> </li> </ul> <p>Note on Filter Persistence:</p> <p>ELITEA Monitoring remembers your filter selections during your active session for a seamless analysis experience.</p> <ul> <li>Filters are Auto-Saved: When you click Refresh your filter settings are saved for your current session.</li> <li>Persistence Across Session: Your filters remain active even if you navigate to other ELITEA pages or refresh the Monitoring page.</li> <li>Resetting Filters to Default: Filters are reset to default (\"All Projects,\" \"Default Time Period,\" etc.) only when:<ul> <li>You click the \"Reset Filters\" button.</li> <li>You log out of ELITEA.</li> </ul> </li> </ul> <p>This ensures you maintain your analysis context without re-applying filters repeatedly during your active session.</p> </li> <li> <p>2. Key Metrics Summary Panel: At-a-Glance Performance Indicators</p> <p>The Key Metrics Summary Panel, positioned below the Filtering Panel, provides a concise and easily digestible overview of the most important performance indicators for ELITEA. This panel displays key metrics as numerical values in individual boxes, allowing you to quickly grasp the overall state of application usage and effectiveness based on your applied filters.</p> <p>It's important to understand how filters affect the metrics displayed in this panel:</p> <ul> <li> <p>Project Filter Dependency: The metrics Users, Prompts, Agents, and Conversations are static counts that are only influenced by the \"Projects\" filter.  Selecting different projects or groups in the \"Projects\" dropdown will change these numbers to reflect the totals within those selected projects. However, these static counts are not affected by the \"Time Period,\" \"Type,\" \"Name,\" or \"Users\" filters. They always represent the total number of users, prompts, agents, and conversations ever created within the selected project(s).</p> </li> <li> <p>Dynamically Filtered Metrics: In contrast, the metrics Tokens in, Tokens out, Engagement, and Acceptance Rate are dynamic and respond to all filters applied in the Filtering Panel, including \"Projects,\" \"Time Period,\" \"Type,\" \"Name,\" and \"Users.\" These metrics are recalculated and updated based on the specific filter criteria you set, providing contextually relevant performance indicators for your chosen scope.</p> </li> </ul> <p>The metrics included in this panel are:</p> <ul> <li>Users:  Displays the total number of unique users who have ever interacted with ELITEA within the selected project(s). (Static, Project filter dependent)</li> <li>Tokens in: Shows the total number of tokens generated by LLMs and sent back to ELITEA as responses within the filtered scope. This reflects the output token generation for the applied filters. (Dynamic, All filters dependent)</li> <li>Tokens out: Displays the total number of tokens sent to LLMs by ELITEA within the filtered scope. This represents the input token consumption for the applied filters. (Dynamic, All filters dependent)</li> <li>Engagement: Presents the Engagement Rate as a percentage, indicating the proportion of active users with the \"Monitor\" role within the filtered scope and time period. (Dynamic, All filters dependent)</li> <li>Acceptance Rate: Shows the Acceptance Rate as a percentage, reflecting the proportion of conversations where users accepted the AI-generated output within the filtered scope and time period. (Dynamic, All filters dependent)</li> <li>Prompts: Displays the total number of prompts created within the selected project(s). (Static, Project filter dependent)</li> <li>Agents: Displays the total number of agents created within the selected project(s). (Static, Project filter dependent)</li> <li>Conversations: Displays the total number of conversations initiated within the selected project(s). (Static, Project filter dependent)</li> </ul> <p>Understanding which metrics are static and which are dynamic based on the filters is crucial for correctly interpreting the data presented in the Key Metrics Summary Panel and drawing accurate conclusions about ELITEA usage and performance.</p> </li> <li> <p>3. Visual Metrics Panel: Detailed Charts and Trend Analysis</p> <p>The Visual Metrics Panel, located below the Key Metrics Summary Panel, provides a comprehensive suite of charts and visualizations for in-depth analysis of ELITEA usage, performance, and user sentiment. This panel is organized into several sections, each focusing on a specific aspect of the monitoring data:</p> <ul> <li> <p>Adoption and Usage: This section contains charts that visualize user adoption and overall application usage trends over time.</p> <ul> <li>Active Users Chart:  A bar chart visualizing the number of unique active users for each time interval (e.g., day, week, month) within your selected timeframe. This chart helps you understand user adoption trends and identify periods of high or low activity.  It often distinguishes between \"active\" and \"inactive\" users within each interval.</li> <li>Token Usage Chart: A line chart displaying the trend of token consumption over time. It typically shows two lines:<ul> <li>Tokens in: Representing the number of tokens generated by the LLMs (output tokens).</li> <li>Tokens out: Representing the number of tokens sent to the LLMs (input tokens). This chart helps you monitor token usage patterns, identify potential cost optimization opportunities, and understand the computational demand on the LLM system over time.</li> </ul> </li> </ul> </li> <li> <p>Acceptance Rate: This section features the Acceptance Rate Chart, a bar chart visualizing the number of interactions where users accepted the output versus those where they did not, for the selected period.</p> </li> <li> <p>Sentiments: This section provides insights into user and LLM sentiment through pie charts:</p> <ul> <li>Human Input Chart: A pie chart showing the distribution of sentiment (Positive, Negative, Neutral) in user inputs.</li> <li>LLM Output Chart: A pie chart showing the distribution of sentiment (Positive, Negative, Neutral) in LLM-generated outputs.</li> </ul> </li> <li> <p>Accuracy: This section presents charts related to the accuracy and quality of ELITEA interactions:</p> <ul> <li>Relevance Chart: A line chart displaying the average relevance scores of user inputs (vs. context) and LLM outputs (vs. user inputs) over time.</li> <li>Reliability Chart: A line chart showing the average reliability score of LLM responses over time.</li> <li>Instruction Quality vs Usage Matrix: A 2x2 matrix visualizing the relationship between the quality score and usage frequency of prompts (or other relevant entities).</li> </ul> </li> <li> <p>Topics: This section includes the Topics Chart, a clustered column chart showing the distribution of prompts, datasources, and agents across different identified topics.</p> </li> <li> <p>Topics Summary: This section features the Topics Summary Chart, a clustered column chart showing the distribution of user queries across different identified topics.</p> </li> </ul> <p>These charts, collectively presented in the Visual Metrics Panel, provide a rich and diverse set of visualizations for analyzing ELITEA usage patterns, user sentiment, AI artifact performance, and overall application effectiveness over time.</p> </li> </ul> <p>By effectively utilizing the Filtering Panel and interpreting the information presented in the Key Metrics Summary Panel and Visual Metrics Panel, you can gain a comprehensive understanding of ELITEA usage and performance, enabling data-driven decisions for optimization and continuous improvement.</p>"},{"location":"feature-guides/core-features/monitoring/#metrics","title":"Metrics","text":""},{"location":"feature-guides/core-features/monitoring/#overview","title":"Overview","text":"<p>The Monitoring feature in ELITEA presents a variety of metrics and charts to help you understand different aspects of application usage and performance. This section provides a detailed breakdown of each currently available metric, explaining its purpose, how it is calculated, the formula used, and practical examples to illustrate its interpretation and utilization. Understanding these metrics is key to effectively monitoring ELITEA's adoption, user engagement, and the effectiveness of your AI-powered workflows.</p>"},{"location":"feature-guides/core-features/monitoring/#in-scope-metrics","title":"In-Scope Metrics","text":"<p>Currently, ELITEA Monitoring focuses on two key metrics that provide valuable insights into user interaction and workflow success: Engagement Rate and Acceptance Rate. These metrics are designed to be actionable, helping you identify areas for improvement and measure the impact of your optimization efforts.</p>"},{"location":"feature-guides/core-features/monitoring/#engagement-rate-measuring-user-activity","title":"Engagement Rate: Measuring User Activity","text":"<p>Description:</p> <p>The Engagement Rate metric is a vital indicator of user adoption and active participation within ELITEA. It quantifies the percentage of users with the designated \"Monitor\" role who are actively interacting with ELITEA projects during a specific time period.  A higher Engagement Rate suggests broader adoption and more consistent utilization of ELITEA within your team.</p> <p>Formula: Unpacking the Calculation</p> <pre><code>Engagement Rate = (Number of Active Users with \u201cMonitor\u201d role) / (Total Number of Users with \u201cMonitor\u201d role) * 100%\n</code></pre> <p>Let's break down the components of this formula:</p> <ul> <li>Numerator: Number of Active Users with \u201cMonitor\u201d role: This represents the count of unique individuals who have been assigned the \"Monitor\" role in ELITEA and have demonstrated active engagement during the chosen time frame.  \"Active engagement\" is defined by specific actions (see \"Definition of 'Active User'\" below).</li> <li>Denominator: Total Number of Users with \u201cMonitor\u201d role: This is the total count of all users who have been granted the \"Monitor\" role within the selected Project or Portfolio. This represents the total potential user base for ELITEA monitoring.</li> <li>Multiplication by 100%:  The result of the division is multiplied by 100 to express the Engagement Rate as a percentage, making it easier to interpret and compare.</li> </ul> <p>Calculation Period: The Engagement Rate is calculated for the specific time period defined by the \"From\" and \"To\" dates that you select in the Filtering Panel. This allows you to analyze engagement over different durations, such as weekly, monthly, or custom date ranges.</p> <p>Key Notes:</p> <ul> <li>Calculated per Project or Group:  Engagement Rate is not a global metric. It is calculated and displayed separately for each Project or Group that you select in the \"Projects\" filter. This allows you to compare engagement levels across different teams or areas of your organization.</li> <li>Definition of \"Active User\":  To be counted as an \"active user\" for the Engagement Rate metric, a user with the \"Monitor\" role must have performed at least one of the following actions within the selected timeframe:<ul> <li>Engaged in a Conversation (New or Existing) and Interacted with an ELITEA Entity: This action encompasses both initiating new chat sessions and actively participating in existing ones, demonstrating ongoing engagement with ELITEA's core functionalities. To be considered \"active\" through conversation engagement, the user must have:<ul> <li>Created a new conversation within the Chat interface, OR interacted with an existing conversation.  This means either starting a fresh chat or continuing an ongoing dialogue in a previously created chat.</li> <li>Interacted within that conversation (whether new or existing) with at least one of the following ELITEA entities: an LLM model directly, a Prompt, a Datasource, or an Agent.  Simply viewing a conversation or having it open without actively sending messages to or receiving responses from an ELITEA entity does not qualify as \"active\" usage.</li> </ul> </li> <li>Directly Executed an ELITEA Entity: This action signifies a user directly invoking and utilizing ELITEA's core functionalities outside of a standard chat conversation flow. To be considered \"active\" through this action, the user must have:<ul> <li>Executed (run or triggered) at least one of the following ELITEA entities: a Prompt, a Datasource, or an Agent.  This includes direct executions initiated through any part of the ELITEA interface, not solely within chat conversations.</li> </ul> </li> </ul> </li> </ul> <p>How to Utilize Engagement Rate for Actionable Insights:</p> <p>The User Engagement Rate is not just a number; it's a powerful diagnostic tool to understand ELITEA adoption and guide improvement efforts.</p> <ul> <li>Identify Low Engagement as a Trigger for Action: A consistently low Engagement Rate (e.g., consistently below 50%, or below your expected target) should serve as a trigger for investigation and action. It suggests that a significant portion of users with the \"Monitor\" role are not actively using ELITEA, indicating a potential gap between the intended and actual utilization of the platform.</li> <li>Diagnose Potential Causes of Low Engagement:  A low Engagement Rate prompts you to investigate why users are not engaging. Consider these potential reasons:<ul> <li>Insufficient User Training and Onboarding: Users may be unaware of ELITEA's capabilities, unsure how to use it effectively, or lack the necessary skills to leverage its Use Cases.<ul> <li>Resolution: Implement or enhance user training programs. Provide hands-on workshops, create easily accessible user guides and tutorials, offer personalized onboarding support, and establish channels for users to ask questions and receive guidance.</li> </ul> </li> <li>Lack of Use Case Relevance to User Needs: The currently available Use Cases within ELITEA might not be directly relevant or valuable to the daily tasks and workflows of the intended users. If users don't find the Use Cases helpful for their actual work, they are less likely to engage.<ul> <li>Resolution:  Actively solicit user feedback on the relevance and usefulness of existing Use Cases. Conduct user interviews, surveys, or feedback sessions to understand their specific needs and pain points. Based on this feedback, fine-tune existing Use Cases to better align with user workflows, or prioritize the development of new Use Cases that address unmet needs and provide more tangible value to users' daily activities.</li> </ul> </li> </ul> </li> </ul> <p>Recommendations for Effective Engagement Rate Monitoring:</p> <ul> <li>Establish a Regular Review Cadence:  Make reviewing the Engagement Rate a recurring activity. Weekly reviews are highly recommended to track trends and identify any sudden drops or consistently low engagement levels.</li> <li>Set Weekly Reporting Timeframes:  For consistent weekly tracking, always use the \"From\" and \"To\" date filters to define the reporting period as the past week (e.g., Monday to Sunday of the previous week). This ensures that you capture a complete week's worth of usage data, accounting for variations in weekday vs. weekend activity and potential offshore team usage patterns.</li> </ul> <p>Example Scenario:</p> <p>Let's consider \"Project Alpha\" and analyze its Engagement Rate for the past week (Monday to Sunday):</p> <ul> <li> <p>Data:</p> <ul> <li>Total users with \"Monitor\" role in \"Project Alpha\": 50</li> <li>Number of users in \"Project Alpha\" who were \"active\" (created chats or used workflows) during the past week: 20</li> </ul> </li> <li> <p>Engagement Rate Calculation: (20 Active Users / 50 Total Users) * 100% = 40%</p> </li> <li> <p>Interpretation: An Engagement Rate of 40% for \"Project Alpha\" suggests that a significant majority (60%) of users with the \"Monitor\" role are not actively engaging with ELITEA within this project. This low rate warrants further investigation. You should explore potential reasons for this low engagement, such as lack of training, irrelevant Use Cases, or technical barriers, and implement appropriate resolutions to improve user adoption and utilization.</p> </li> </ul>"},{"location":"feature-guides/core-features/monitoring/#acceptance-rate-gauging-use-case-and-entity-effectiveness","title":"Acceptance Rate: Gauging Use Case and Entity Effectiveness","text":"<p>Description:</p> <p>The Acceptance Rate metric provides crucial insights into the perceived value and successful utilization of ELITEA's AI-powered capabilities, extending beyond just Use Cases to encompass the effectiveness of individual Prompts, Datasources, and Agents. It quantifies the percentage of times users take a defined \"acceptance action\" after interacting with ELITEA, indicating they found the generated output or the outcome of the execution useful and successfully leveraged ELITEA to achieve their intended goal. A higher Acceptance Rate signifies that ELITEA's functionalities are effectively meeting user needs and providing valuable assistance across various interaction types.</p> <p>Formula: Understanding the Broader Acceptance Calculation</p> <pre><code>Acceptance Rate = (Accepted Interactions) / (All Interactions) * 100%\n</code></pre> <p>Let's understand the components of this formula in this broader context:</p> <ul> <li>Numerator: Accepted Interactions: This represents the count of interactions where a user has performed a specific \"acceptance action.\"  Crucially, \"interactions\" now encompass not only conversations but also direct executions of Prompts, Datasources, and Agents. An interaction is deemed \"Accepted\" when the user performs a relevant \"acceptance action\" signaling successful utilization of ELITEA's output or functionality.</li> <li>Denominator: All Interactions: This is the total count of all user interactions within the selected scope (Use Case, Project, timeframe, or entity type).  \"Interactions\" now include all attempts to utilize ELITEA, whether through conversations or direct executions of Prompts, Datasources, and Agents.</li> </ul> <p>Calculation Period: The Acceptance Rate is calculated based on the \"From\" and \"To\" dates selected in the Filtering Panel, allowing you to analyze acceptance over different timeframes and across various types of interactions.</p> <p>Key Notes: Expanding the Definition of \"Accepted Interactions\"</p> <ul> <li> <p>Broader Scope of Acceptance Actions:  The definition of \"Accepted Interactions\" is now expanded to encompass a wider range of user actions that indicate successful utilization of ELITEA, regardless of whether the interaction occurs within a conversation or through direct entity execution.  \"Acceptance actions\" now include:</p> <ul> <li> <p>Keyword Acceptance within Agent Conversations (Explicit Approval): As before, for Agents designed with explicit approval steps, typing a pre-defined \"acceptance keyword\" (e.g., \"approved,\" \"publish\") within a conversation is considered acceptance.</p> </li> <li> <p>Content Copying Actions:  Indicating user utilization of generated text or data:</p> <ul> <li>Manual Text Selection and Copy:  Selecting and copying generated text directly from the ELITEA interface.</li> <li>\"Copy to Clipboard\" Button Usage: Clicking a \"Copy to Clipboard\" button associated with generated output.</li> <li>\"Copy to Messages\" Button Usage (Prompts):  Clicking a \"Copy to Messages\" button specifically available for Prompt executions, indicating the user is incorporating the prompt's output into a conversation.</li> </ul> </li> <li> <p>Table Export/Download Actions (Prompts): For Prompts that generate tabular data, utilizing export or download options signifies acceptance:</p> <ul> <li>\"Download as xlsx\": Downloading generated tables in Excel format.</li> <li>\"Copy as html\": Copying table data in HTML format.</li> <li>\"Copy as markdown\": Copying table data in Markdown format.</li> </ul> </li> <li> <p>Agent Goal Completion Actions (External Service Interaction): For Agents designed to interact with external services, successful goal completion is considered acceptance:</p> <ul> <li>File Creation in GitHub: Agents designed to create files in GitHub repositories.</li> <li>Issue Creation in Jira: Agents designed to create issues in Jira.</li> <li>Page Creation in Confluence: Agents designed to create pages in Confluence.</li> <li>Any other Agent-specific action that signifies successful completion of its intended task in an external system.</li> </ul> </li> <li> <p>Datasource Specific Actions: Actions indicating utilization of data retrieved from Datasources:</p> <ul> <li>Downloading Deduplication Results as Excel File: Downloading the output of deduplication processes from Datasources in Excel format.</li> <li>Copying Search Results: Copying search results obtained from Datasource queries.</li> </ul> </li> <li> <p>Contextual Application: These \"acceptance actions\" are tracked and considered for Acceptance Rate calculations regardless of whether they occur:</p> <ul> <li>Within Chat Conversations: When users interact with Prompts, Datasources, or Agents through the ELITEA Chat interface.</li> <li>During Direct Entity Execution: When users directly execute Prompts, Datasources, or Agents outside of a chat conversation, through other parts of the ELITEA interface.</li> </ul> </li> </ul> </li> </ul> <p>How to Utilize Acceptance Rate for Broader Performance Improvement:</p> <p>The Acceptance Rate, now with its expanded definition, provides a comprehensive measure of user satisfaction and the effectiveness of ELITEA's AI capabilities across various interaction modes.</p> <ul> <li>Identify Areas of Friction and Success Across ELITEA:  A low Acceptance Rate, whether for a specific Use Case, a particular Prompt, a Datasource, or an Agent, points to potential areas of friction, usability issues, or output quality problems that need attention. Conversely, high Acceptance Rates highlight successful functionalities and well-performing entities that are effectively meeting user needs.</li> <li>Diagnose Issues Based on Interaction Type:  Analyze Acceptance Rates in conjunction with the \"Type\" and \"Name\" filters in the Monitoring Panel to pinpoint specific areas for improvement:<ul> <li>Low Prompt Acceptance Rate: Focus on the Prompt itself. Review the prompt's instructions, context, input parameters, and output examples. Experiment with prompt engineering techniques to improve output relevance, clarity, and accuracy. Consider user feedback on specific prompts to identify areas for refinement.</li> <li>Low Agent Acceptance Rate: Analyze the Agent's workflow, the quality of prompts and tools it utilizes, and its overall logic. Debug potential issues in the agent's execution flow, error handling, or interaction with external services.</li> <li>Low Datasource Acceptance Rate: Examine the Datasource's configuration, data quality, and query effectiveness. Ensure the datasource is providing relevant and accurate information for the intended use cases. Investigate if query parameters are being correctly mapped and if the datasource is reliably accessible.</li> </ul> </li> </ul> <p>Recommendations for Comprehensive Acceptance Rate Monitoring:</p> <ul> <li>Weekly Review Remains Crucial: Continue to prioritize weekly reviews of Acceptance Rate metrics to proactively identify and address performance issues across all aspects of ELITEA.</li> <li>Granular Analysis by Type and Name: Leverage the \"Type\" and \"Name\" filters extensively to analyze Acceptance Rates not only by Use Case but also by individual Prompts, Datasources, and Agents. This granular view is essential for pinpointing specific AI artifacts or functionalities that require optimization.</li> <li>Weekly Timeframe for Consistency: Maintain the practice of using a weekly timeframe (e.g., Monday to Sunday of the previous week) for consistent and comparable Acceptance Rate tracking across different entities and time periods.</li> </ul> <p>Example Scenario (Expanded Scope):</p> <p>Let's consider a scenario where you are analyzing the Acceptance Rate for a specific Prompt, \"User Story Creator Prompt,\" used within \"Project Alpha\" over the past week:</p> <ul> <li> <p>Data:</p> <ul> <li>Total Executions of \"User Story Creator Prompt\" in \"Project Gamma\" last week (both within chats and direct executions): 150</li> <li>Number of \"Accepted Interactions\" for \"User Story Creator Prompt\" (users copied output, downloaded table, etc.): 75</li> </ul> </li> <li> <p>Acceptance Rate Calculation: (75 Accepted Interactions / 150 Total Interactions) * 100% = 50%</p> </li> <li> <p>Interpretation: An Acceptance Rate of 50% for the \"Code Summary Prompt\" suggests that this particular prompt is only meeting user needs in half of its executions. This warrants a focused investigation into the prompt's design, output quality, and user expectations. You should review the prompt's instructions, analyze user feedback related to code summarization tasks, and potentially refine the prompt to improve its accuracy, clarity, and usefulness, aiming to increase its Acceptance Rate and ensure it effectively serves its intended purpose within ELITEA.</p> </li> </ul> <p>This enhanced \"Acceptance Rate\" section now provides a much broader and more practical understanding of how to utilize this metric to assess the effectiveness of ELITEA's AI capabilities across Use Cases, Prompts, Datasources, and Agents, whether used in conversations or directly executed. Let me know if you have any further refinements!</p>"},{"location":"feature-guides/core-features/monitoring/#charts","title":"Charts","text":"<p>The Visual Metrics Panel in ELITEA Monitoring provides a rich set of charts and diagrams to help you visually analyze trends, patterns, and key performance indicators. This section provides a detailed explanation of each chart type, guiding you on how to interpret these visualizations to gain actionable insights into ELITEA usage and effectiveness.</p>"},{"location":"feature-guides/core-features/monitoring/#adoption-and-usage-charts-tracking-user-activity-and-resource-consumption","title":"Adoption and Usage Charts: Tracking User Activity and Resource Consumption","text":"<p>These charts provide a visual representation of user adoption and overall application usage trends over time, as well as the consumption of LLM tokens.</p> <p></p>"},{"location":"feature-guides/core-features/monitoring/#active-users-chart-understanding-user-adoption-trends","title":"Active Users Chart: Understanding User Adoption Trends","text":"<p>Purpose: The Active Users Chart helps you visualize user adoption and engagement levels over time. It shows the number of unique active users for each time interval, allowing you to identify trends in user activity and pinpoint periods of high or low engagement.</p> <p>Chart Type: Stacked Bar Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents the Time Interval, based on the \"Aggregation\" level you select in the Filtering Panel (e.g., Day, Week, Month). Each bar on the chart corresponds to a specific time interval.</li> <li>Y-axis (Vertical): Represents the Number of Users.</li> <li>Stacked Bars: Each bar is divided into two stacked segments, representing:<ul> <li>Active Users (Teal/Green segment): The number of active users during that time interval.</li> <li>Inactive Users (Light Gray segment): The number of inactive users (users with \"Monitor\" role who did not perform any \"active\" actions) during that time interval.</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Trend Analysis: Observe the overall trend of the teal/green \"active users\" bars over time. An upward trend indicates increasing user adoption and engagement, while a downward trend may signal declining interest or usability issues.</li> <li>Identify Peak and Low Activity Periods:  Visually identify time intervals (days, weeks, etc.) with the highest and lowest bars for \"active users.\" This can help you understand when ELITEA is most and least utilized.</li> <li>Active vs. Inactive User Ratio:  Compare the relative sizes of the teal/green \"active users\" segment and the light gray \"inactive users\" segment within each bar. A larger teal/green segment indicates a higher proportion of active users for that period, signifying stronger engagement.</li> </ul> <p>Example: If the \"Active Users Chart\" shows consistently increasing teal/green bars over the past few weeks, it indicates positive user adoption and growing engagement with ELITEA. Conversely, if you see a sudden drop in the height of the teal/green bars for a recent week, it might warrant investigation into potential issues affecting user engagement during that period.</p>"},{"location":"feature-guides/core-features/monitoring/#token-usage-chart-monitoring-llm-resource-consumption","title":"Token Usage Chart: Monitoring LLM Resource Consumption","text":"<p>Purpose: The Token Usage Chart is essential for monitoring the consumption of LLM resources within ELITEA. It visualizes the trend of tokens sent to LLMs (Tokens Out - input tokens) and tokens received from LLMs (Tokens In - output tokens) over time, helping you understand the computational demand and potential costs associated with ELITEA usage.</p> <p>Chart Type: Line Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents the Time Interval, based on the \"Aggregation\" level you select in the Filtering Panel (e.g., Day, Week, Month). Each point on the lines corresponds to a specific time interval.</li> <li>Y-axis (Vertical): Represents the Number of Tokens, typically measured in thousands (e.g., 50k, 100k, 150k).</li> <li>Lines: The chart displays two distinct lines, each representing a type of token usage:<ul> <li>Tokens In (Teal/Cyan Line):  Represents the number of tokens generated by LLMs and sent back to ELITEA (output tokens).</li> <li>Tokens Out (Magenta/Purple Line): Represents the number of tokens sent to the LLMs by ELITEA (input tokens).</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Token Usage Trends: Observe the overall trends of both the \"Tokens In\" (teal/cyan) and \"Tokens Out\" (magenta/purple) lines over time. Upward trends indicate increasing LLM resource consumption, while downward trends suggest decreasing usage or more efficient workflows.</li> <li>Input vs. Output Token Ratio: Compare the relative positions and trends of the two lines.  Significant differences in the volume of input vs. output tokens might indicate specific usage patterns or potential areas for optimization. For example, consistently high \"Tokens Out\" with relatively lower \"Tokens In\" might suggest users are sending complex or lengthy queries.</li> <li>Identify Token Spikes: Look for sudden spikes or peaks in either the \"Tokens In\" or \"Tokens Out\" lines. These spikes can highlight periods of unusually high LLM usage, which might warrant further investigation to understand the cause (e.g., a specific event, a new Use Case being heavily utilized).</li> <li>Cost Monitoring (Indirect): While the chart doesn't directly display costs, tracking token usage trends is crucial for cost management, as LLM usage is often billed based on token consumption. Monitoring this chart helps you anticipate potential cost fluctuations and optimize workflows to minimize unnecessary token usage.</li> </ul> <p>Example: If the \"Token Usage Chart\" shows a sharp increase in the \"Tokens Out\" (magenta/purple) line during a particular week, it indicates a surge in input tokens sent to LLMs. This could be due to increased user activity, more complex queries being submitted, or a change in Use Case usage patterns. Further investigation, potentially combined with other monitoring data, can help pinpoint the cause of this token usage spike.</p>"},{"location":"feature-guides/core-features/monitoring/#acceptance-rate-chart-measuring-user-satisfaction-with-ai-outputs","title":"Acceptance Rate Chart: Measuring User Satisfaction with AI Outputs","text":"<p>Purpose: The Acceptance Rate Chart visually represents the overall user satisfaction with the outputs generated by ELITEA. It shows the proportion of user interactions where users took \"acceptance actions\" (indicating satisfaction) versus those where they did not. This chart provides a direct measure of how well ELITEA is meeting user needs and delivering valuable results.</p> <p></p> <p>Chart Type: Stacked Bar Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents the Time Interval, based on the \"Aggregation\" level you select in the Filtering Panel (e.g., Day, Week, Month). Each bar corresponds to a specific time interval.</li> <li>Y-axis (Vertical): Represents the Number of Interactions.</li> <li>Stacked Bars: Each bar is divided into two stacked segments, representing:<ul> <li>Accepted Interactions (Teal/Green segment): The number of user interactions during that time interval that were classified as \"Accepted\" based on user actions (copying output, downloading, explicit approval, etc.).</li> <li>Not Accepted Interactions (Light Gray segment): The number of user interactions during that time interval where users did not perform any \"acceptance actions.\"</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Overall Acceptance Trend: Observe the overall trend of the teal/green \"Accepted Interactions\" bars over time. An upward trend indicates increasing user satisfaction and more effective Use Cases, Prompts, Datasources, or Agents. A downward trend may signal declining user satisfaction or issues with output quality or relevance.</li> <li>Identify Periods of High and Low Acceptance: Visually identify time intervals with the highest and lowest bars for \"Accepted Interactions.\" This can help correlate acceptance rates with specific events, changes in Use Cases, or other factors.</li> <li>Accepted vs. Not Accepted Ratio: Compare the relative sizes of the teal/green \"Accepted Interactions\" segment and the light gray \"Not Accepted Interactions\" segment within each bar. A larger teal/green segment indicates a higher Acceptance Rate for that period, signifying greater user satisfaction and perceived value.</li> </ul> <p>Example: If the \"Acceptance Rate Chart\" shows consistently tall teal/green bars, dominating the light gray \"Not Accepted\" segments, it indicates a high overall Acceptance Rate and suggests that ELITEA is effectively meeting user needs and generating valuable outputs. Conversely, if you observe a significant increase in the light gray \"Not Accepted\" segments, particularly for a specific Use Case or time period, it warrants investigation into potential issues affecting user satisfaction and output quality.</p>"},{"location":"feature-guides/core-features/monitoring/#sentiments-charts-understanding-user-and-ai-tone","title":"Sentiments Charts: Understanding User and AI Tone","text":"<p>These pie charts provide a quick visual overview of the emotional tone expressed in user inputs and generated LLM outputs, helping you assess the overall user experience and the sentiment conveyed by the AI.</p> <p></p>"},{"location":"feature-guides/core-features/monitoring/#human-input-chart-analyzing-user-sentiment","title":"Human Input Chart: Analyzing User Sentiment","text":"<p>Purpose: The Human Input Chart visualizes the distribution of sentiment expressed in user inputs to ELITEA. By analyzing the sentiment of user queries and instructions, you can gain insights into user attitudes, potential frustrations, and areas where users might be expressing negative sentiment that needs to be addressed.</p> <p>Chart Type: Pie Chart</p> <p>Data Displayed:</p> <ul> <li>Pie Chart Slices: The pie chart is divided into three slices, each representing a sentiment category:<ul> <li>Positive (Green slice): Represents the percentage of user inputs classified as having a positive sentiment (e.g., expressing satisfaction, appreciation, optimism).</li> <li>Negative (Orange slice): Represents the percentage of user inputs classified as having a negative sentiment (e.g., expressing frustration, dissatisfaction, criticism).</li> <li>Neutral (Light Blue slice): Represents the percentage of user inputs classified as having a neutral sentiment (e.g., factual questions, objective statements, requests without emotional tone).</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Overall Sentiment Balance:  Examine the relative sizes of the pie chart slices to understand the overall sentiment balance in user inputs. A larger green \"Positive\" slice is generally desirable, indicating a positive user experience.</li> <li>Identify Negative Sentiment Trends:  Pay attention to the size of the orange \"Negative\" slice. A consistently large or increasing \"Negative\" slice might signal user frustration, usability issues, or problems with output quality that are causing negative sentiment.</li> <li>Neutral Sentiment as Baseline: The light blue \"Neutral\" slice represents a baseline level of objective or unemotional communication. While a high \"Neutral\" percentage is not necessarily negative, it's important to consider the context. In some cases, a shift from \"Neutral\" to \"Positive\" might be a desirable outcome of improvements to ELITEA.</li> </ul> <p>Example: If the \"Human Input Chart\" shows a large green \"Positive\" slice and small orange \"Negative\" and light blue \"Neutral\" slices, it indicates that users are generally expressing positive sentiment in their interactions with ELITEA, suggesting a positive user experience. Conversely, a larger orange \"Negative\" slice might prompt further investigation into potential usability issues or areas of user dissatisfaction.</p>"},{"location":"feature-guides/core-features/monitoring/#llm-output-chart-assessing-ai-tone-and-positivity","title":"LLM Output Chart: Assessing AI Tone and Positivity","text":"<p>Purpose: The LLM Output Chart visualizes the distribution of sentiment expressed in the outputs generated by ELITEA's Large Language Models (LLMs). Analyzing the sentiment of LLM responses is crucial for ensuring that the AI is communicating in a helpful, positive, and appropriate tone, contributing to a positive user experience and avoiding unintended negative or unhelpful communication styles.</p> <p>Chart Type: Pie Chart</p> <p>Data Displayed:</p> <ul> <li>Pie Chart Slices: Similar to the \"Human Input Chart\" this pie chart is also divided into three slices, each representing a sentiment category for LLM outputs:<ul> <li>Positive (Green slice): Represents the percentage of LLM outputs classified as having a positive sentiment (e.g., helpful, encouraging, supportive, optimistic).</li> <li>Negative (Orange slice): Represents the percentage of LLM outputs classified as having a negative sentiment (e.g., unhelpful, discouraging, critical, pessimistic).</li> <li>Neutral (Light Blue slice): Represents the percentage of LLM outputs classified as having a neutral sentiment (e.g., factual responses, objective information, task-oriented outputs without emotional tone).</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Desired Positive AI Tone: Aim for a large green \"Positive\" slice in the \"LLM Output Chart.\" This indicates that ELITEA's AI is generally communicating in a positive and helpful tone, contributing to a positive user experience.</li> <li>Minimize Negative LLM Sentiment:  The orange \"Negative\" slice should ideally be minimal. A significant or increasing \"Negative\" slice in LLM outputs is a cause for concern. It might indicate issues with prompt design, agent logic, or underlying LLM behavior that are causing the AI to generate unhelpful, critical, or negatively toned responses.</li> <li>Contextual Neutrality:  The light blue \"Neutral\" slice represents a baseline of objective and task-focused AI communication. While neutrality is often appropriate for factual responses, consider whether a higher proportion of \"Positive\" sentiment in LLM outputs could further enhance user engagement and satisfaction, depending on the specific Use Case and context.</li> </ul> <p>Example: If the \"LLM Output Chart\" shows a dominant green \"Positive\" slice, with minimal orange \"Negative\" and a moderate light blue \"Neutral\" slice, it suggests that ELITEA's AI is generally communicating in a helpful and positive manner. However, if you observe a noticeable increase in the orange \"Negative\" slice, it's crucial to investigate the prompts, agents, or configurations that are leading to these negatively toned outputs and take corrective actions to ensure the AI communicates in a more positive and constructive way.</p>"},{"location":"feature-guides/core-features/monitoring/#accuracy-charts-assessing-relevance-and-reliability","title":"Accuracy Charts: Assessing Relevance and Reliability","text":"<p>These charts provide quantitative measures of the accuracy, relevance, and reliability of ELITEA's AI-powered interactions, helping you evaluate the quality and trustworthiness of the generated outputs and data retrievals.</p> <p></p>"},{"location":"feature-guides/core-features/monitoring/#relevance-chart-measuring-input-and-output-alignment","title":"Relevance Chart: Measuring Input and Output Alignment","text":"<p>Purpose: The Relevance Chart helps you assess the relevance of user inputs to the intended context and the relevance of LLM outputs to the user inputs they are responding to. By tracking relevance scores over time, you can monitor the quality of interactions and identify potential issues with input clarity or output alignment.</p> <p>Chart Type: Line Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents the Time Interval, based on the \"Aggregation\" level you select in the Filtering Panel (e.g., Day, Week, Month). Each point on the lines corresponds to a specific time interval.</li> <li>Y-axis (Vertical): Represents the Relevance Score, typically on a scale from 0 to 5 or 0 to 10, where higher scores indicate greater relevance.</li> <li>Lines: The chart displays two distinct lines, each representing a type of relevance score:<ul> <li>Input vs. Context (Teal/Cyan Line): Represents the average relevance score of user inputs compared to the intended context of the interaction (e.g., the topic of the Use Case, the purpose of the prompt). Higher scores indicate that user inputs are generally well-aligned with the expected context.</li> <li>Output vs. Input (Magenta/Purple Line): Represents the average relevance score of LLM outputs compared to the user inputs they are responding to. Higher scores indicate that LLM outputs are generally relevant and responsive to user queries and instructions.</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Relevance Score Trends: Observe the trends of both the \"Input vs. Context\" (teal/cyan) and \"Output vs. Input\" (magenta/purple) lines over time. Ideally, you want to see consistently high relevance scores for both, indicating that user inputs are clear and focused, and LLM outputs are relevant and on-topic.</li> <li>Identify Relevance Dips: Look for dips or downward trends in either relevance line. A drop in \"Input vs. Context\" relevance might suggest users are providing less focused or less relevant inputs, potentially due to confusion or usability issues. A drop in \"Output vs. Input\" relevance might indicate problems with prompt design, agent logic, or LLM performance, leading to less relevant or off-topic outputs.</li> <li>Compare Input and Output Relevance: Compare the relative levels of the two relevance lines. Ideally, you want both lines to be consistently high and relatively close to each other, indicating a good flow of relevant information between users and the AI system. Significant divergence between the lines might warrant further investigation.</li> </ul> <p>Example: If the \"Relevance Chart\" shows both the \"Input vs. Context\" and \"Output vs. Input\" lines consistently above a score of 4 (on a 0-5 scale), it suggests a high degree of relevance in ELITEA interactions. Users are generally providing relevant inputs, and the AI is generating relevant and responsive outputs. However, if you notice a dip in the \"Output vs. Input\" line below a certain threshold, it might indicate a need to review and refine the prompts or agents responsible for generating those less relevant outputs.</p>"},{"location":"feature-guides/core-features/monitoring/#reliability-chart-assessing-llm-response-consistency","title":"Reliability Chart: Assessing LLM Response Consistency","text":"<p>Purpose: The Reliability Chart focuses specifically on the reliability of LLM responses, measuring the consistency and predictability of the AI's output quality over time. A high Reliability score indicates that the LLM is generating consistently dependable and trustworthy responses.</p> <p>Chart Type: Line Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents the Time Interval, based on the \"Aggregation\" level you select in the Filtering Panel (e.g., Day, Week, Month). Each point on the line corresponds to a specific time interval.</li> <li>Y-axis (Vertical): Represents the Reliability Score, typically on a scale from 0 to 10 or a percentage scale, where higher scores indicate greater reliability.</li> <li>Reliability Score Line (Teal/Cyan Line):  A single line representing the average reliability score of LLM responses for each time interval.</li> </ul> <p>Interpretation:</p> <ul> <li>Reliability Trend: Observe the trend of the teal/cyan \"Reliability Score\" line over time. A consistently high and stable line is desirable, indicating that the LLM is providing dependable and consistent responses.</li> <li>Identify Reliability Drops: Look for dips or downward trends in the Reliability Score line. A drop in reliability might signal issues with the LLM model itself, changes in the input data quality, or problems with the prompts or agents that are relying on the LLM.</li> <li>Benchmark against Target Reliability:  Establish a target reliability score for your ELITEA implementation. Use the Reliability Chart to monitor whether the average reliability score is consistently meeting or exceeding your target.</li> </ul> <p>Example: If the \"Reliability Chart\" shows the \"Reliability Score\" line consistently above 8 (on a 0-10 scale), it suggests that ELITEA's LLM responses are generally highly reliable and consistent. However, if you observe a sudden drop in the Reliability Score below your target threshold, it might indicate a need to investigate potential issues affecting LLM performance or consistency, such as model updates, changes in API configurations, or underlying data quality problems.</p>"},{"location":"feature-guides/core-features/monitoring/#instruction-quality-vs-usage-matrix-optimizing-ai-artifacts","title":"Instruction Quality vs. Usage Matrix: Optimizing AI Artifacts","text":"<p>Purpose: The Instruction Quality vs. Usage Matrix is a powerful 2x2 matrix visualization designed to help you optimize your ELITEA Prompts (and potentially Agents or Datasources in future iterations). It plots the relationship between the \"Quality Score\" of your Prompts and their \"Usage\" frequency, allowing you to identify high-performing, underutilized, or low-quality prompts for targeted improvement efforts.</p> <p>Chart Type: 2x2 Matrix (Scatter Plot within Quadrants)</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents Usage (#Calls), indicating the number of times each Prompt has been executed or called within the selected timeframe.</li> <li>Y-axis (Vertical): Represents Quality Score, reflecting a composite score that combines metrics like Relevance and Reliability to assess the overall quality and effectiveness of each Prompt's instructions.</li> <li>Quadrants: The matrix is divided into four quadrants, each representing a combination of Instruction Quality and Usage levels:<ul> <li>Low Quality, Low Usage (Bottom-Left Quadrant): Contains Prompts with both low Quality Scores and low Usage frequency. These are typically prompts that are underperforming and not being actively utilized.</li> <li>High Quality, Low Usage (Top-Left Quadrant): Contains Prompts with high Quality Scores but low Usage frequency. These are potentially valuable prompts that are not being leveraged to their full potential.</li> <li>High Quality, High Usage (Top-Right Quadrant): Contains Prompts with both high Quality Scores and high Usage frequency. These are your top-performing and most valuable prompts, effectively meeting user needs and being actively utilized.</li> <li>Low Quality, High Usage (Bottom-Right Quadrant): Contains Prompts with low Quality Scores but surprisingly high Usage frequency. These are prompts that are being used frequently despite their lower quality, potentially indicating a critical need for improvement or that users are using them despite their limitations due to lack of better alternatives.</li> </ul> </li> <li>Data Points: Each data point on the matrix represents a Prompt. The position of the data point within the matrix is determined by its \"Quality Score\" (Y-axis) and \"#Calls\" (X-axis). Hovering over a data point typically reveals the name of the Prompt it represents.</li> </ul> <p>Interpretation:</p> <ul> <li>Identify High-Value Prompts (Top-Right Quadrant): Focus on the Prompts located in the \"High Quality, High Usage\" (top-right) quadrant. These are your most valuable assets. Analyze these prompts to understand what makes them successful (e.g., clear instructions, relevant context, effective prompt engineering techniques). Leverage these insights to improve other prompts.</li> <li>Optimize Underutilized High-Quality Prompts (Top-Left Quadrant): Prompts in the \"High Quality, Low Usage\" (top-left) quadrant represent untapped potential. Investigate why these high-quality prompts are not being used more frequently. Potential reasons include:         *   Lack of User Awareness: Users may not know about these valuable prompts. Promote these prompts through training, documentation, or in-app discovery features.         *   Discoverability Issues: Make sure these prompts are easily discoverable and accessible within the ELITEA interface.         *   Limited Use Cases: Explore if the use cases for these prompts can be expanded or better communicated to users.</li> <li>Improve or Retire Low-Quality Prompts (Bottom-Left Quadrant): Prompts in the \"Low Quality, Low Usage\" (bottom-left) quadrant are likely underperforming and not providing value. Consider these options:         *   Improve and Refine: Analyze these prompts to identify specific weaknesses in their instructions, context, or logic. Invest time in prompt engineering to improve their quality and relevance.         *   Retire or Deprecate: If improvement efforts are not successful, or if these prompts are no longer relevant, consider retiring or deprecating them to avoid user confusion and focus on higher-value assets.</li> <li>Address Low-Quality, High-Usage Prompts (Bottom-Right Quadrant - Critical Attention Needed): Prompts in the \"Low Quality, High Usage\" (bottom-right) quadrant are a critical area for attention. These prompts are being used frequently despite their low quality, which is a potential problem. This situation might indicate:         *   Critical Need: Users may be using these low-quality prompts because they address a critical need for which no better alternatives exist within ELITEA.         *   User Frustration: Users might be experiencing frustration and reduced productivity due to the low quality of these frequently used prompts.         *   Prioritize Improvement: Prioritize immediate improvement efforts for prompts in this quadrant.  Focus on significantly enhancing their quality and relevance to better meet the needs of users who are relying on them heavily.</li> </ul> <p>Example: By examining the \"Instruction Quality vs. Usage Matrix,\" you might identify that your \"Code Documentation Prompt\" is located in the \"High Quality, High Usage\" quadrant, indicating it's a valuable and well-utilized asset. On the other hand, you might find a \"Competitor Analysis Prompt\" in the \"Low Quality, High Usage\" quadrant, signaling a critical need to improve this prompt to better serve the users who are frequently relying on it, despite its current shortcomings.</p>"},{"location":"feature-guides/core-features/monitoring/#topics-chart-understanding-content-distribution","title":"Topics Chart: Understanding Content Distribution","text":"<p>Purpose: The Topics Chart provides a visual representation of how your ELITEA Prompts, Datasources, and Agents are distributed across different identified topics or categories. This chart helps you understand the content focus of your AI artifacts and identify areas where you have strong content coverage and areas where you might need to expand your topic coverage.</p> <p></p> <p>Chart Type: Clustered Column Chart</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents Topics identified within ELITEA (e.g., \"User Stories,\" \"Code Documentation,\" \"Competitive Analysis,\" \"Confluence Pages\"). Each cluster of columns corresponds to a specific topic.</li> <li>Y-axis (Vertical): Represents the Number of Items (# Items), indicating the count of ELITEA entities associated with each topic.</li> <li>Clustered Columns: For each topic on the X-axis, you will see a cluster of columns, with each column representing a different type of ELITEA entity:<ul> <li>Prompts (Teal/Cyan Column):  The number of Prompts categorized under that topic.</li> <li>Datasources (Light Blue Column): The number of Datasources categorized under that topic.</li> <li>Agents (Magenta/Purple Column): The number of Agents categorized under that topic.</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>Topic Coverage Distribution: Examine the overall distribution of columns across different topics. This chart provides a visual overview of which topics are well-represented by your ELITEA content (Prompts, Datasources, Agents) and which topics have less coverage.</li> <li>Identify Content Gaps: Look for topics on the X-axis that have very short or missing columns, indicating a lack of Prompts, Datasources, or Agents related to those topics. These \"gaps\" represent potential areas where you need to create new AI artifacts to expand ELITEA's content coverage and address user needs in those areas.</li> <li>Content Focus Areas: Identify topics with tall columns across all entity types (Prompts, Datasources, Agents). These \"focus areas\" represent topics where you have a strong and well-developed set of AI resources within ELITEA.</li> </ul> <p>Example: If the \"Prompt Topics Chart\" shows tall columns for \"User Stories\" and \"Code Documentation\" but very short or no columns for \"Competitive Analysis,\" it indicates that your ELITEA implementation has strong content coverage for user story creation and code documentation tasks, but lacks resources for competitive analysis. This might prompt you to prioritize the creation of new Prompts, Datasources, or Agents focused on competitive analysis to address this content gap and expand ELITEA's capabilities in that area.</p>"},{"location":"feature-guides/core-features/monitoring/#topics-summary-chart-understanding-user-query-focus","title":"Topics Summary Chart: Understanding User Query Focus","text":"<p>Purpose: The Topics Summary Chart provides insights into the topics that users are most frequently querying and interacting with within ELITEA. By analyzing the distribution of user queries across different topics, you can understand user interests, identify popular areas of focus, and ensure that your ELITEA content and functionalities are aligned with user demand.</p> <p></p> <p>Chart Type: Clustered Column Chart (Single Cluster per Topic)</p> <p>Data Displayed:</p> <ul> <li>X-axis (Horizontal): Represents Topics identified within ELITEA (consistent with the \"Prompt Topics Chart\" - e.g., \"User Stories,\" \"Code Documentation,\" \"Competitive Analysis,\" \"Confluence Pages\"). Each column corresponds to a specific topic.</li> <li>Y-axis (Vertical): Represents the Number of Items (# Items), indicating the count of user queries associated with each topic.</li> <li>Columns: For each topic on the X-axis, you will see a single column representing:<ul> <li>User Queries (Teal/Cyan Column): The number of user queries (or interactions) that have been categorized as belonging to that specific topic.</li> </ul> </li> </ul> <p>Interpretation:</p> <ul> <li>User Interest Distribution: Examine the relative heights of the columns across different topics. This chart visually represents the distribution of user interest across various topics within ELITEA. Taller columns indicate topics that users are querying more frequently, signifying higher user interest and demand.</li> <li>Identify Popular Topics: Pinpoint topics with the tallest columns. These are the most popular areas of user interest within ELITEA. Ensure that you have robust and high-quality content (Prompts, Datasources, Agents) available to effectively address user queries and needs in these popular topic areas.</li> <li>Identify Under-Queried Topics: Look for topics with short or very short columns. These are topics that users are querying less frequently. This might indicate:         *   Lack of User Awareness: Users might not be aware that ELITEA has capabilities related to these topics. Consider promoting these functionalities through training or in-app communication.         *   Limited User Need: There might be genuinely less user demand for information or assistance related to these topics.         *   Relevance Issues:  The existing content related to these topics might not be sufficiently relevant or useful to users, leading to lower query frequency.</li> </ul> <p>Example: If the \"Topics Summary Chart\" shows a very tall column for \"User Stories\" and significantly shorter columns for other topics like \"Code Documentation\" or \"Competitive Analysis,\" it indicates that user interest and demand within ELITEA are heavily focused on user story-related tasks and information. This insight might prompt you to prioritize further development and optimization of Use Cases, Prompts, and Agents related to user stories to cater to this high user demand. You might also consider investigating why other topics are less frequently queried and explore strategies to increase user awareness or improve content relevance in those areas.</p> <p>By utilizing these detailed chart explanations and understanding how to interpret the visualizations provided by ELITEA Monitoring, you can gain valuable insights into application usage, user behavior, AI artifact performance, and content effectiveness, enabling data-driven decisions to continuously improve and optimize your ELITEA implementation.</p>"},{"location":"feature-guides/core-features/monitoring/#use-cases-and-reporting-practical-scenarios-for-elitea-monitoring","title":"Use Cases and Reporting: Practical Scenarios for ELITEA Monitoring","text":"<p>The Monitoring feature is not just about viewing charts and metrics; it's about gaining actionable insights to improve ELITEA's value and user experience. This section outlines several practical use case scenarios, demonstrating how you can leverage the Monitoring data to answer key questions, identify areas for optimization, and generate insightful reports.</p> <p>Scenario 1: Tracking Overall ELITEA Adoption and Engagement (Portfolio Level)</p> <ul> <li>Goal:  As a Portfolio Manager, you want to track the overall adoption and engagement of ELITEA across your entire portfolio of projects on a weekly basis. You need to report on user activity and identify any portfolio-wide trends.</li> <li>How to Use Monitoring:<ol> <li>Access Monitoring Landing Page: Navigate to the Monitoring page in ELITEA.</li> <li>Set Project Filter to Portfolio: In the Filtering Panel, select your desired Portfolio grouping from the Projects dropdown menu.</li> <li>Set Time Period to \"Last Week\": Use the From and To Date filters to set the time range to cover the past week (e.g., Monday to Sunday of the previous week).</li> <li>Set Aggregation to \"Week\":  Ensure the Aggregation dropdown is set to \"Week\" for weekly reporting.</li> <li>Apply Filters: Click the \"Refresh\" button.</li> <li>Review Key Metrics Summary Panel:  Focus on the Engagement Rate metric in the Key Metrics Summary Panel. This will give you the overall Engagement Rate for your entire Portfolio for the past week. Note down this percentage for your report.</li> <li>Analyze Adoption and Usage Charts Panel: Examine the Active Users Chart and Token Usage Chart in the Adoption and Usage Charts Panel.<ul> <li>Active Users Chart: Observe the trend of \"Active Users\" over the past weeks (or months, if you expand the timeframe). Is user adoption increasing, decreasing, or stable? Note down any significant trends.</li> <li>Token Usage Chart: Analyze the \"Tokens In\" and \"Tokens Out\" lines. Is token consumption increasing, decreasing, or fluctuating? Correlate token usage trends with user activity trends.</li> </ul> </li> <li>Generate Report:  Compile your findings into a weekly Portfolio Adoption Report. Include:<ul> <li>Portfolio Name and Reporting Week (Date Range).</li> <li>Overall Engagement Rate for the Portfolio (from Key Metrics Summary Panel).</li> <li>Summary of Active User trends (from Active Users Chart - e.g., \"Active users increased by 15% this week\").</li> <li>Summary of Token Usage trends (from Token Usage Chart - e.g., \"Token consumption remained stable compared to last week\").</li> <li>Key Insights and Potential Actions: Based on your analysis, include a brief summary of key insights and any recommended actions (e.g., \"Engagement Rate is healthy, continue current adoption strategies,\" or \"Engagement Rate declined slightly, investigate potential causes and consider targeted training\").</li> </ul> </li> </ol> </li> </ul> <p>Scenario 2: Identifying Underperforming AI entities (Use Case Level Analysis)</p> <ul> <li>Goal: As a Project Admin, you want to identify AI entities within your project that have low user acceptance rates. You suspect that some entities might not be as effective or user-friendly as others and need to pinpoint those for improvement.</li> <li>How to Use Monitoring:<ol> <li>Access Monitoring Landing Page: Navigate to the Monitoring page in ELITEA.</li> <li>Select Your Project: In the Filtering Panel, select your specific project from the Projects dropdown menu.</li> <li>Set Time Period to \"Last Month\": Use the From and To Date filters to set the time range to cover the past month to get a representative sample of Use Case usage.</li> <li>Set Aggregation to \"Week\":  Set the Aggregation to \"Week\" to analyze weekly trends in Acceptance Rate.</li> <li>Filter by \"Type\" and \"Name\":  Leave the \"Type\" filter set to \"Prompts, Datasources, Agents, Conversations\" (or \"All Items\"). Leave the \"Name\" filter set to \"All Items\" initially to get an overview of all Use Cases.</li> <li>Apply Filters: Click the \"Refresh\" button.</li> <li>Review Key Metrics Summary Panel:  Examine the Acceptance Rate metric in the Key Metrics Summary Panel. This provides the overall Acceptance Rate for all Use Cases within your project. Note this baseline value.</li> <li>Analyze Acceptance Rate Chart:  Focus on the Acceptance Rate Chart in the Visual Metrics Panel. Observe the overall Acceptance Rate trend over the past month.</li> <li>Granular Use Case Analysis: Now, use the \"Type\" and \"Name\" filters to analyze Acceptance Rates for individual Use Cases:<ul> <li>Select \"Type\" to \"Conversations\": This will filter the data to focus on conversation-based Use Cases.</li> <li>Use \"Name\" dropdown to select individual Use Case Names one by one: For each Use Case Name, click \"Refresh\" and observe the Acceptance Rate metric in the Key Metrics Summary Panel and the Acceptance Rate Chart. Note down the Acceptance Rate for each Use Case.</li> <li>Identify Low Acceptance Use Cases: Compare the Acceptance Rates of different Use Cases. Identify Use Cases with significantly lower Acceptance Rates compared to the average or your desired benchmark (e.g., Use Cases with Acceptance Rates below 60%).</li> </ul> </li> <li>Investigate Low Acceptance Use Cases: For the Use Cases with low Acceptance Rates, investigate potential causes:<ul> <li>Review User Feedback: Gather user feedback specifically on these underperforming Use Cases.</li> <li>Analyze Use Case Workflow: Examine the design and complexity of the Use Case workflow. Is it intuitive and user-friendly?</li> <li>Evaluate Output Quality: Assess the quality and relevance of the AI-generated outputs for these Use Cases.</li> </ul> </li> <li>Take Action to Improve: Based on your investigation, take targeted actions to improve the low-acceptance Use Cases:<ul> <li>Enhance User Training: Provide more specific training and guidance for these Use Cases.</li> <li>Refine Use Case Design: Simplify the workflow, improve prompts, or adjust agent logic to enhance output quality and user experience.</li> </ul> </li> </ol> </li> </ul> <p>Scenario 3: Monitoring Prompt Performance and Optimizing for Quality</p> <ul> <li>Goal: As a Prompt Engineer, you want to monitor the performance of specific Prompts within your project, identify underperforming prompts, and optimize them for better relevance and reliability.</li> <li>How to Use Monitoring:<ol> <li>Access Monitoring Landing Page: Navigate to the Monitoring page in ELITEA.</li> <li>Select Your Project: In the Filtering Panel, select your specific project from the Projects dropdown menu.</li> <li>Set Time Period to \"Last 3 Months\": Use a longer timeframe (e.g., \"Last 3 Months\") to get a broader performance overview.</li> <li>Set Aggregation to \"Month\": Set Aggregation to \"Month\" for monthly trend analysis.</li> <li>Set \"Type\" to \"Prompts\": In the \"Type\" dropdown, specifically select \"Prompts\" to focus your analysis on prompts.</li> <li>Leave \"Name\" as \"All Items\" initially: Start with an overview of all prompts.</li> <li>Apply Filters: Click the \"Refresh\" button.</li> <li>Analyze Instruction Quality vs. Usage Matrix: Focus on the Instruction Quality vs. Usage Matrix in the Accuracy Charts Panel.<ul> <li>Identify Low-Quality, High-Usage Prompts:  Look for prompts in the Bottom-Right Quadrant (Low Quality, High Usage). These are critical prompts that need immediate attention and improvement. Note down the names of these prompts.</li> <li>Identify High-Quality, Low-Usage Prompts: Look for prompts in the Top-Left Quadrant (High Quality, Low Usage). These are prompts with untapped potential. Note down their names for potential promotion and wider utilization.</li> </ul> </li> <li>Granular Prompt Analysis: For the prompts you identified in step 8 (especially low-quality, high-usage ones), perform a more detailed analysis:<ul> <li>Use \"Name\" Filter:  Select the name of a specific prompt from the \"Name\" dropdown and click \"Refresh.\"</li> <li>Review Key Metrics Summary Panel: Examine the Acceptance Rate, Relevance, and Reliability metrics in the Key Metrics Summary Panel for this specific prompt.</li> <li>Analyze Performance Charts: Focus on the Relevance Chart and Reliability Chart in the Accuracy Charts Panel, and the Acceptance Rate Chart. Observe the trends of these metrics over the past months.</li> </ul> </li> <li>Optimize Prompts: Based on your analysis, take action to optimize underperforming prompts:<ul> <li>Prompt Engineering: Refine the prompt instructions, context, input parameters, and examples to improve output quality and relevance.</li> <li>User Feedback: Gather user feedback specifically on these prompts to understand their pain points and areas for improvement.</li> <li>A/B Testing (If Applicable): If possible, create variations of the prompt and A/B test them to see which version performs better based on monitoring metrics.</li> <li>Promote High-Quality, Low-Usage Prompts: For prompts in the \"High Quality, Low Usage\" quadrant, promote their use through documentation, training, or in-app suggestions to increase their visibility and utilization.</li> </ul> </li> </ol> </li> </ul> <p>These are just a few examples of how you can utilize the ELITEA Monitoring feature for practical analysis and reporting. By strategically applying filters, understanding the metrics and charts, and focusing on specific use cases and entities, you can unlock valuable insights to continuously improve ELITEA's effectiveness and user experience.</p>"},{"location":"feature-guides/core-features/prompt-magic-assistant/","title":"Prompt Magic Assistant: Your Guide to Effortless Prompt Creation","text":"<p>The Prompt Magic Assistant is an innovative feature in ELITEA designed to streamline and enhance the prompt creation process. It provides an interactive workflow that guides you in articulating your needs with precision and creativity, helping you harness the full potential of AI to develop prompts that are clear, context-rich, and tailored to your specific project requirements.</p> <p>This guide will walk you through how to configure and use the Prompt Magic Assistant, providing examples and best practices to help you make the most of this powerful tool.</p>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#accessing-the-prompt-magic-assistant","title":"Accessing the Prompt Magic Assistant","text":"<p>The Prompt Magic Assistant is available when you are creating a new prompt. Once a prompt is created and saved, the assistant will no longer be available for that specific prompt.</p> <p>To access the Prompt Magic Assistant:</p> <ol> <li>Navigate to the Prompts menu within your desired project.</li> <li>Click the + Prompt button on the top right to begin creating a new prompt. This will take you to the Configuration tab.</li> <li>On the Configuration tab, look for the \"Wizard\" icon. This icon indicates the availability of the Prompt Magic Assistant.</li> <li>Click the \"Wizard\" icon to open the assistant.</li> </ol> <p></p>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#configuring-your-prompt-with-the-magic-assistant","title":"Configuring Your Prompt with the Magic Assistant","text":"<p>The Prompt Magic Assistant simplifies the initial setup of your prompt by generating key elements based on your description of the task.</p> <p></p> <p>Using the Prompt Magic Assistant:</p> <ol> <li> <p>Describe Your Task: Once the Magic Assistant window is open, you will see a text input field. Clearly and concisely describe the task you want the prompt to accomplish. The more detailed your description, the better the assistant can understand your needs and generate relevant suggestions.</p> <ul> <li> <p>Example: \"I want to generate manual test cases for covering positive, negative, and edge cases. The test cases must be in Gherkin syntax and keep in mind the possibility for easy automation later. The test cases must be generated for the provided acceptance criteria.\"</p> </li> <li> <p>Example: \"You are an experienced Business Analyst tasked with creating a user story. Your goal is to generate a user story that adheres to the INVEST principles and includes proper acceptance criteria. The user story should be user-centric, facilitating effective communication and prioritization between development teams and stakeholders.\"</p> </li> </ul> </li> <li> <p>Generate Prompt Ideas: After entering your task description, click the Generate Prompt button. The Magic Assistant will analyze your input and generate suggestions for various prompt elements.</p> </li> </ol> <p></p>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#what-the-magic-assistant-generates","title":"What the Magic Assistant Generates","text":"<p>Based on your task description, the Prompt Magic Assistant can automatically populate the following fields in the Configuration tab:</p> <ul> <li>Prompt Name: A suggested name for your prompt, reflecting the task you described.</li> <li>Prompt Description: A brief explanation of the prompt's purpose, derived from your input.</li> <li>Context:  The core instructions and background information for the AI model. This is crucial for guiding the AI to generate the desired output.</li> <li>Messages (if needed):  The assistant may suggest pre-defined System, Assistant, or User messages to structure the interaction flow, particularly for more complex tasks.</li> <li>Welcome Message: An optional message displayed to users when they interact with the prompt, providing additional context or instructions.</li> <li>Conversation Starter(s): Predefined text options that users can click to initiate a conversation or trigger a specific action when executing the prompt.</li> </ul> <p></p>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#review-and-modify","title":"Review and Modify","text":"<p>The Prompt Magic Assistant provides a great starting point for your prompt creation. However, it's important to remember that you have full control over the generated content.</p> <p>After the Magic Assistant has generated the initial prompt elements:</p> <ol> <li>Review the Generated Content: Carefully examine the suggested Prompt Name, Description, Context, Messages, Welcome Message, and Conversation Starters.</li> <li>Modify as Needed: You can freely edit any of the generated fields to refine the prompt according to your specific requirements. This includes:<ul> <li>Adjusting the wording for clarity.</li> <li>Adding more specific instructions to the Context.</li> <li>Modifying or adding new Messages.</li> <li>Customizing the Welcome Message for your users.</li> <li>Adding or editing Conversation Starters.</li> </ul> </li> <li>Add Tags: Don't forget to add relevant Tags to categorize your prompt for easy searching and organization.</li> <li>Save Your Prompt: Once you are satisfied with the configuration, click the Save button to finalize the creation of your prompt.</li> </ol>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#examples-of-using-the-prompt-magic-assistant","title":"Examples of Using the Prompt Magic Assistant","text":"<p>Example 1: Generating Test Cases</p> <ul> <li>Provided Task: \"I want to generate manual test cases for covering positive, negative, and edge cases for a login feature. The test cases should include steps, expected results, and test data. Consider scenarios for valid and invalid credentials.\"</li> <li>Possible Magic Assistant Output:<ul> <li>Prompt Name: Generate Login Test Cases</li> <li>Prompt Description: Generates manual test cases for the login feature, covering positive, negative, and edge cases.</li> <li>Context: \"You are a test engineer tasked with generating manual test cases for a login feature. The test cases should include clear steps, expected results, and relevant test data. Consider scenarios for valid and invalid credentials, including edge cases like incorrect password formats and locked accounts.\"</li> <li>Conversation Starters: \"Generate test cases for the login feature.\"</li> </ul> </li> </ul> <p>Example 2: Creating a User Story</p> <ul> <li>Provided Task: \"As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.\"</li> <li>Possible Magic Assistant Output:<ul> <li>Prompt Name: Create User Story for Saving Search Preferences</li> <li>Prompt Description: Generates a user story for the ability to save search preferences.</li> <li>Context: \"You are a product owner responsible for writing user stories. Generate a user story for the following need: 'As a user, I want to be able to save my search preferences so that I don't have to re-enter them every time I visit the website.' Ensure the user story follows the standard format and includes clear acceptance criteria.\"</li> <li>Conversation Starters: \"Generate acceptance criteria for this user story.\"</li> </ul> </li> </ul>"},{"location":"feature-guides/core-features/prompt-magic-assistant/#best-practices-for-using-the-prompt-magic-assistant","title":"Best Practices for Using the Prompt Magic Assistant","text":"<ul> <li>Be Specific in Your Task Description: The more details you provide in your initial description, the more accurate and relevant the assistant's suggestions will be.</li> <li>Focus on the Desired Outcome: Clearly state what you want the prompt to achieve.</li> <li>Use Action Verbs: Start your task description with action verbs like \"generate,\" \"create,\" \"summarize,\" \"translate,\" etc.</li> <li>Review and Refine: Always review the generated content and make necessary adjustments to ensure it aligns perfectly with your needs.</li> <li>Don't Hesitate to Modify: The Magic Assistant is a starting point. Feel free to completely rewrite any of the generated fields if needed.</li> <li>Add Tags for Organization:  Utilize tags to categorize your prompts, making them easier to find and manage in the future.</li> </ul> <p>By following these guidelines, you can effectively leverage the ELITEA Prompt Magic Assistant to significantly simplify and enhance your prompt creation workflow, leading to more effective and efficient AI interactions.</p>"},{"location":"feature-guides/core-features/public-project/","title":"Public Project Guide: Explore and Collaborate","text":"<p>The Public project in ELITEA serves as a collaborative hub where users can discover, utilize, and appreciate resources shared by the community. It's a space designed to foster knowledge sharing and accelerate innovation by making valuable prompts, agents, and datasources accessible to everyone within your organization.</p> <p>Key Features of the Public Project:</p> <ul> <li>Shared Resources: Access a curated collection of prompts, agents, and datasources contributed by other ELITEA users.</li> <li>Community Collaboration: Benefit from the collective expertise and creativity of your colleagues.</li> <li>Discover Best Practices: Explore highly-rated and trending resources to learn from successful implementations.</li> <li>Ready-to-Use Tools: Execute published resources directly to leverage their functionality.</li> <li>Inspiration and Learning: Discover new approaches and techniques by examining how others have built their resources.</li> </ul> <p>Accessing the Public Project:</p> <p>The Public project is readily accessible to all ELITEA users by default. You can switch to the Public project from your current project by clicking the Project switcher.</p>"},{"location":"feature-guides/core-features/public-project/#navigating-the-public-project","title":"Navigating the Public Project","text":"<p>The Public project is organized into distinct menus, each dedicated to a specific type of shared resource:</p> <ul> <li>Chat: Access to conversations, allowing to add participants (Agents, Prompts, Datasources, Models and Users) from Public project.</li> <li>Prompts: Discover and interact with prompts shared by the community.</li> <li>Datasources: Explore and utilize published datasources.</li> <li>Agents: Find and execute agents created and shared by other users.</li> <li>Collections: Browse and explore curated collections of resources.</li> </ul> <p>Each of these menus (except Chat) shares a similar structure, making it easy to navigate and find what you're looking for.</p>"},{"location":"feature-guides/core-features/public-project/#exploring-shared-resources","title":"Exploring Shared Resources","text":"<p>Within each resource menu (Prompts, Datasources, Agents, Collections), you'll find three sub-sections designed to help you discover and engage with the shared content:</p> <ul> <li>Latest: This section displays the most recently published resources, giving you a glimpse into the newest additions to the community's shared pool.</li> <li>My Likes:  Here, you'll find a personalized list of the resources you've liked. This allows you to easily revisit your favorite and most valuable finds.</li> <li>Trending: This section showcases the most popular resources, ranked by the number of likes they've received. It's a great place to discover highly regarded and widely used resources within the community.</li> </ul>"},{"location":"feature-guides/core-features/public-project/#interacting-with-published-resources","title":"Interacting with Published Resources","text":"<p>The Public project encourages active participation and appreciation of shared resources. Here's how you can interact with the prompts, datasources, and agents you find:</p>"},{"location":"feature-guides/core-features/public-project/#showing-appreciation-liking-resources","title":"Showing Appreciation: Liking Resources","text":"<p>If you find a published prompt, datasource, or agent particularly useful or well-crafted, you can show your appreciation by \"liking\" it.</p> <ul> <li>To Like: Click the Heart icon associated with the resource. The icon will typically change color or appearance to indicate that you've liked it.</li> <li>To Unlike: If you change your mind or no longer wish to like a resource, simply click the Heart icon again.</li> </ul>"},{"location":"feature-guides/core-features/public-project/#utilizing-published-resources","title":"Utilizing Published Resources","text":"<p>The primary purpose of the Public project is to allow users to leverage the shared resources. You can directly execute published prompts and agents to utilize their functionality. Simply click on the resource's card or name to view its details and find the execution options.</p> <p>Important Note: While you can view and execute resources in the Public project, you cannot directly modify and save changes to the original published version. These resources are intended for execution and inspiration.</p>"},{"location":"feature-guides/core-features/public-project/#incorporating-public-resources-into-your-workflow","title":"Incorporating Public Resources into Your Workflow","text":"<p>You can leverage valuable resources found in the Public project in several ways:</p> <ul> <li>Adding to Collections: Organize useful public prompts, datasources, or agents into your personal collections within your Private project for easy access and management.</li> <li>Exporting Resources: For backup or use in other platforms (if supported), you can export published prompts.</li> </ul> <p>Refer to the documentation for your Private project for detailed instructions on adding to collections and exporting resources.</p>"},{"location":"feature-guides/core-features/public-project/#sharing-your-expertise-publishing-resources","title":"Sharing Your Expertise: Publishing Resources","text":"<p>While you primarily interact with existing resources in the Public project, you can also contribute your own creations. If you've developed a valuable prompt, agent, or datasource in your Private project, you can submit it for publication to the Public project.</p> <p>The Publication Process:</p> <ol> <li>Create and Refine: Develop and thoroughly test your prompt, agent, or datasource in your Private project.</li> <li>Submit for Publication:  Initiate the publication process for your resource. This typically involves clicking a \"Publish\" button within the resource's settings.</li> <li>Moderation Review:  Resources submitted for publication are reviewed by designated moderators to ensure quality, relevance, and adherence to community guidelines.</li> <li>Approval and Publication: If approved, your resource will be published and become available to the wider ELITEA community in the Public project.</li> </ol> <p>Note: Only approved moderators have the ability to add resources to the Public project.</p>"},{"location":"feature-guides/core-features/public-project/#benefits-of-the-public-project","title":"Benefits of the Public Project","text":"<ul> <li>Reduced Redundancy: Avoid recreating commonly used prompts, agents, or datasources by leveraging existing community contributions.</li> <li>Accelerated Development: Quickly find and utilize pre-built resources to speed up your workflows.</li> <li>Enhanced Learning: Discover new techniques and approaches by examining how others have designed their resources.</li> <li>Community Building: Contribute to a shared knowledge base and benefit from the collective expertise of your colleagues.</li> </ul> <p>The ELITEA Public project is a valuable place for fostering collaboration and maximizing the potential of AI within your organization. Explore, engage, and contribute to make the most of this shared resource pool.</p>"},{"location":"home/introduction/","title":"Overview of ELITEA Platform","text":"<p>Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with Generative AI. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts, datasources and agents like never before.</p> <p>Key Features:</p> <ul> <li>Prompt Management: Effortlessly create, modify, and manage prompts. Keep track of different versions to ensure you always have access to your best work.</li> <li>Datasources: Play a pivotal role in enhancing the functionalities of ELITEA by integrating user-specific or project-specific data. This not only broadens the LLM's context but also enriches it with tailored information, making your interactions more relevant and insightful.</li> <li>Agents: Customize and create virtual assistants within ELITEA to handle specific tasks or sets of tasks. These agents integrate prompts, datasources, and external toolkits into a cohesive mechanism, enabling actions such as online searches or creating Jira tickets based on decisions made by LLMs.</li> <li>Chat: Combine all ELITEA features in one place with ELITEA Chat, an ultimate feature that allows for dynamic interaction and optimal results. Engage in conversations that utilize natural language to interact with human users and seamlessly integrate feedback from various participants like language models, datasources, and agents.</li> <li>Extensions: Transform your coding workflow with Alita Code and Alita Code Chat the ultimate AI-powered IDE extensions. Integrated seamlessly with VS Code and IntelliJ, these extensions offers intelligent suggestions, automates routine tasks, and provides unmatched adaptability to elevate your coding experience.</li> <li>Collection Integration: Organize your prompts, datasources and agents into Collections for better workflow management or to concentrate on specific themes or projects.</li> <li>Execution with Precision: Tailor the execution of prompts using various models and parameters to meet your specific needs, ensuring a customized experience.</li> <li>Advanced Creation Tools: Craft complex prompts, datasources and agents with precision using tools like variables, system prompts, Assistant Messages, and advanced tools.</li> <li>Powerful Search: Employ a robust search functionality to easily locate prompts, datasources and agents by tags, names, or descriptions.</li> <li>Community Engagement: Engage with the community by creating, modifying, and publishing prompts, datasources and agents. Enhance collaboration through sharing and liking content.</li> </ul> <p>ELITEA is designed to be a versatile and powerful tool, enhancing how you interact with AI technologies and manage data-driven projects. Whether you're coding, creating content, or managing complex data sets, ELITEA provides the tools you need to succeed.</p> <p>Let's embark on this journey to unlock the full potential of your ideas. Our user guide will walk you through every feature, ensuring you maximize your ELITEA experience.</p>"},{"location":"home/introduction/#accessing-elitea","title":"Accessing ELITEA","text":"<p>To access and navigate through ELITEA, follow these steps:</p> <ol> <li>Open Your Browser: Launch your preferred web browser.</li> <li>Enter URL: Type <code>https://nexus.elitea.ai</code> into the address bar and press Enter.</li> <li>Login: Use your EPAM account credentials to log in. Note: Registration is not required.</li> <li>Initial Navigation: Upon successful login, you will be directed to the Chat menu. Note: If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts.</li> <li>Switch Projects: After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar.</li> <li>Explore ELITEA: Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections.</li> </ol> <p>By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA.</p>"},{"location":"how-tos/alita-dial/","title":"Interoperability Guide: ELITEA and EPAM AI Dial","text":"<p>Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial.</p>"},{"location":"how-tos/alita-dial/#export-prompts-from-elitea","title":"Export Prompts from ELITEA","text":"<p>Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it:</p>"},{"location":"how-tos/alita-dial/#exporting-the-prompt-for-ai-dial","title":"Exporting the Prompt for AI DIAL:","text":"<ol> <li>Start the Export: Click on the Export prompt icon.</li> <li>Choose Format: Select the <code>[DIAL] format</code> format when prompted. This format is specially designed for compatibility with EPAM AI Dial.</li> <li>Download: After selecting the format, the file will be downloaded automatically to your device in JSON format.</li> </ol>"},{"location":"how-tos/alita-dial/#import-prompts-to-epam-ai-dial","title":"Import Prompts to EPAM AI Dial","text":"<p>Once you have the JSON file from ELITEA, you can easily import it into AI Dial.</p>"},{"location":"how-tos/alita-dial/#importing-the-prompt-into-ai-dial","title":"Importing the Prompt into AI Dial:","text":"<ol> <li>Begin Import: Click on the Import prompts icon within the AI Dial platform.</li> <li>Select File: Browse your device and select the JSON file you exported from ELITEA.</li> <li>Complete Import: The platform will automatically add the prompt to the Prompts section.</li> <li>Usage: You can now select and use the prompt within AI Dial.</li> </ol>"},{"location":"how-tos/alita-dial/#export-prompts-from-epam-ai-dial","title":"Export Prompts from EPAM AI Dial","text":"<p>If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA.</p> <ol> <li>Prompt Selection: Identify and select the prompt you wish to export.</li> <li>Export: Click the <code>...</code> icon next to your selected prompt and choose the Export option.</li> <li>File Download: The prompt will be exported and downloaded in JSON format, ready for ELITEA.</li> </ol> <p></p>"},{"location":"how-tos/alita-dial/#import-prompts-to-elitea","title":"Import Prompts to ELITEA","text":"<p>To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps.</p> <ol> <li>Initiate Import: Select the Import option within ELITEA.</li> <li>Choose File: Browse and select the exported JSON prompt file.</li> <li>Complete Process: The prompt will be added under the Prompts page in ELITEA.</li> <li>Use Prompt: You can now access and utilize the imported prompt.</li> </ol> <p></p>"},{"location":"how-tos/alita-dial/#exporting-and-importing-collections-from-elitea-to-epam-ai-dial","title":"Exporting and Importing Collections from ELITEA to EPAM AI Dial","text":"<p>You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management.</p> <ol> <li>Export Collection: In ELITEA, select the collection you wish to export and choose the <code>Export Collection</code> option. Select the <code>[DIAL] format</code> for optimal compatibility.</li> <li>Download Collection: The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device.</li> <li>Import into AI Dial: Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder.</li> </ol> <p>This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial.</p>"},{"location":"how-tos/alita-dial/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>File Format: Ensure the prompt file is in JSON format. Other formats won\u2019t be processed.</li> <li>Template Compatibility: ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names.</li> <li>File Structure: If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments.</li> </ul> <p>By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts.</p>"},{"location":"how-tos/alita-dial/#useful-links","title":"Useful Links","text":"<ul> <li>ELITEA - User Guide</li> <li>ELITEA - Release Notes</li> <li>Epam AI Dial - User Guide</li> </ul>"},{"location":"how-tos/creating-prompts/","title":"How to Create and Publish Useful Prompts for Testing and QA Activities","text":""},{"location":"how-tos/creating-prompts/#introduction","title":"Introduction","text":"<p>Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process.</p> <p>The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community.</p> <p>We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices.</p> <p>In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable.</p> <p>Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success.</p>"},{"location":"how-tos/creating-prompts/#accessing-elitea-hub","title":"Accessing ELITEA HUB","text":"<p>To access and navigate through ELITEA HUB, follow these steps:</p> <ol> <li>Open Your Browser: Launch your preferred web browser.</li> <li>Enter URL: Type <code>https://alita.lab.epam.com</code> into the address bar and press Enter.</li> <li>Login: Use your EPAM account credentials to log in. Note: Registration is not required.</li> <li>Initial Navigation: Upon successful login, you will be directed to the Chat menu. Note: If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts.</li> <li>Switch Projects: After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar.</li> <li>Explore ELITEA: Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections.</li> </ol> <p>By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB.</p> <p>Note: You need to enable Epam VPN to access ELITEA.</p> <p></p>"},{"location":"how-tos/creating-prompts/#prompts","title":"Prompts","text":"<p>Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts:</p> <p>Creating Effective Prompts</p> <ol> <li>Relevance: Directly tie your prompt to testing and QA activities to ensure relevance.</li> <li>Clarity: Utilize clear, concise language for better comprehension.</li> <li>Specificity: Clearly mention the testing phase, type, and specific focus area of the prompt.</li> <li>Scalability: Aim for prompts that can be broadly applied across various projects.</li> <li>Security: Avoid including any customer data or sensitive information.</li> </ol>"},{"location":"how-tos/creating-prompts/#how-to-create-a-prompt","title":"How to Create a Prompt","text":"<p>Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value:</p> <ol> <li>Initiate Prompt Creation: Click the + Prompt button located at the top right of your screen to start crafting your prompt.</li> <li>Provide Prompt Details:<ul> <li>Name: Assign a descriptive name that clearly reflects the aim of the prompt.</li> <li>Description: Summarize the purpose of the prompt, detailing what it intends to achieve. Note: The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving.</li> <li>Tag(s): A descriptive Tag(s) for grouping the prompts.</li> <li>Context: Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.).</li> <li>In case the prompt's context contains Variables - then a descriptive variable name.</li> <li>In case the prompt has System or Assistant messages - then those messages must be informative.</li> </ul> </li> <li>Select the Model: Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested.</li> <li>Configure Advanced Settings: Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations.</li> <li>Test Your Prompt: Execute the prompt and review the results to confirm everything functions as intended.</li> <li>Finalize: Click Save to keep your draft or proceed to the next step to share your work with the community.</li> </ol> <p>Providing Name, Description and Context of the prompt:</p> <p></p> <p>Setup Variables:</p> <p></p> <p>Configuring Advanced Settings:</p> <p></p>"},{"location":"how-tos/creating-prompts/#prompt-requirements-for-consistency-and-quality","title":"Prompt Requirements for Consistency and Quality","text":"<p>When crafting your prompt, ensure it includes the following elements for clarity and effectiveness:</p> <ul> <li>Descriptive Name: Clearly indicates the focus of the prompt.<ul> <li>Conciseness: Aim for a name that is brief yet descriptive, ideally under 30 characters.</li> <li>Relevance: Ensure the name directly reflects the content or purpose of the prompt.</li> </ul> </li> <li>Brief Description: Eloquently explains the prompt\u2019s goal.<ul> <li>Specificity: Include specific details about what the prompt is intended to achieve.</li> <li>Brevity: Keep the description concise, aiming for one to two sentences.</li> </ul> </li> <li>Descriptive Tags: Facilitates prompt categorization and searchability.<ul> <li>Relevance: Choose tags that are directly related to the prompt\u2019s content and purpose.</li> <li>Diversity: Use a mix of broad and specific tags to enhance discoverability.</li> </ul> </li> <li>Framework Adherence: Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.).<ul> <li>Consistency: Stick to one framework per prompt to maintain clarity and structure.</li> <li>Documentation: Reference the framework used in the prompt description for clarity.</li> </ul> </li> <li>Variable Clarity: In scenarios with variables, use descriptive names.<ul> <li>Descriptiveness: Use names that clearly indicate what the variable represents.</li> <li>Standardization: Follow a consistent naming convention for variables across prompts.</li> </ul> </li> <li>Informative System Messages: If your prompt uses system or assistant messages, they must be clear and helpful.<ul> <li>Clarity: Ensure messages are straightforward and free of jargon.</li> <li>Guidance: Messages should guide the user on how to interact with the prompt effectively.</li> </ul> </li> <li>Expected Outcomes: Define what successful application of the prompt looks like.<ul> <li>Measurable Criteria: Specify clear, measurable criteria for what constitutes a successful outcome.</li> <li>Examples: Provide examples of successful outcomes to illustrate expectations.</li> </ul> </li> </ul>"},{"location":"how-tos/creating-prompts/#submitting-your-prompt-for-publishing","title":"Submitting Your Prompt for Publishing","text":"<p>To make your prompt available to the wider QA community, follow the steps below for publication:</p> <ol> <li>Publishing Initiation: With your prompt crafted and saved, click the Publish button to start the submission process.</li> <li>Version Naming: Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications.<ul> <li>Length: Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems.</li> <li>Characters: Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments.</li> <li>Clarity: Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions.</li> </ul> </li> <li>Review Submission: Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community.</li> </ol> <p>Publishing the prompt:</p> <p></p>"},{"location":"how-tos/creating-prompts/#review-process-by-moderators-and-outcome-of-prompt-submission","title":"Review Process by Moderators and Outcome of Prompt Submission","text":""},{"location":"how-tos/creating-prompts/#moderator-review-process","title":"Moderator Review Process","text":"<p>After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. </p> <p>The moderators follow a structured evaluation protocol:</p> <ol> <li>Initial Assessment: Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format.</li> <li>Content Review: The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information.</li> <li>Practical Evaluation: Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes.</li> <li>Compliance Check: There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared.</li> </ol>"},{"location":"how-tos/creating-prompts/#possible-outcomes-of-the-review","title":"Possible Outcomes of the Review","text":"<p>After the review process, a prompt can be categorized into one of the following statuses:</p> <ul> <li>Approved: If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community.</li> <li>Rejected: If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration.</li> </ul> <p>Statuses of Prompts</p> <p>Prompts undergo several statuses through the review phase:</p> <ul> <li>All: An overview of all submissions regardless of their review stage.</li> <li>Draft: Saved yet unsubmitted prompts.</li> <li>Published: Moderation-approved prompts, now accessible in the Public project.</li> <li>On Moderation: Prompts currently under review.</li> <li>Approval: This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note: This feature is currently under development and is not available at the moment.</li> <li>Rejected: Prompts evaluated and declined for publication.</li> </ul> <p>To check the status of your submitted prompts, navigate to \"Prompts\" page on the platform, and select the status you wish to view from the dropdown menu.</p>"},{"location":"how-tos/creating-prompts/#engagement-with-prompts-liking-and-trending","title":"Engagement with Prompts: Liking and Trending","text":"<p>Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \"Like\" functionality. Prompts that receive a significant number of likes can appear in the \"Trending\" page of the Prompt Library, highlighting their popularity and usefulness.</p> <p>The \"Trending\" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration.</p> <p></p> <p>By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy.</p>"},{"location":"how-tos/creating-prompts/#collections","title":"Collections","text":"<p>Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes.</p> <p>The Purpose and Usefulness of Collections</p> <p>Collections are immensely valuable for several reasons:</p> <ul> <li>Thematic Organization: They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts.</li> <li>Efficiency: By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied.</li> <li>Sharing Best Practices: Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.</li> </ul>"},{"location":"how-tos/creating-prompts/#creating-collection","title":"Creating Collection","text":"<ol> <li>Click the + Collection button located at the top right corner.</li> <li>You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about.</li> </ol>"},{"location":"how-tos/creating-prompts/#adding-prompts-to-your-collection","title":"Adding Prompts to Your Collection","text":"<p>To add prompts to your collection, follow these steps:</p> <ol> <li>Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection.</li> <li>Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.</li> </ol> <p></p>"},{"location":"how-tos/creating-prompts/#publishing-your-collection","title":"Publishing Your Collection","text":"<p>Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized:</p> <ol> <li>After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance.</li> <li>Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality.</li> <li>Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community.</li> </ol> <p>Note: A Collection must contain public prompts before publication.</p>"},{"location":"how-tos/creating-prompts/#engagement-with-collections-liking-and-trending","title":"Engagement with Collections: Liking and Trending","text":"<p>Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons:</p> <ul> <li>Recognition: Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources.</li> <li>Visibility: Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community.</li> <li>Feedback Mechanism: Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation.</li> </ul> <p>By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged.</p>"},{"location":"how-tos/creating-prompts/#contribution","title":"Contribution","text":""},{"location":"how-tos/creating-prompts/#why-share-your-prompts","title":"Why Share Your Prompts?","text":"<p>Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement.</p>"},{"location":"how-tos/creating-prompts/#rewards-and-recognition","title":"Rewards and Recognition","text":"<p>To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network.</p>"},{"location":"how-tos/creating-prompts/#useful-resources","title":"Useful Resources","text":""},{"location":"how-tos/creating-prompts/#elitea","title":"ELITEA","text":"<ul> <li>ELITEA - User Guide</li> <li>ELITEA - Release Notes</li> </ul>"},{"location":"how-tos/creating-prompts/#prompt-engineering","title":"Prompt Engineering","text":"<ul> <li>Prompt Engineering Foundations</li> <li>EngX AI-Supported Quality Assurance Engineering</li> <li>Guide to Effective Prompting</li> <li>Introduction to Prompt Engineering</li> </ul>"},{"location":"how-tos/faqs/","title":"Frequently Asked Questions","text":"<p>Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with ELITEA, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of ELITEA.</p>"},{"location":"how-tos/faqs/#what-youll-find-here","title":"What You'll Find Here","text":"<p>In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities. Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect:</p> <ul> <li>Getting Started: Step-by-step guides and tips for new users.</li> <li>Features &amp; Functions: Deep dives into what ELITEA can do and how to use its features to your advantage.</li> <li>Troubleshooting: Solutions and workarounds for common issues.</li> <li>Best Practices: Advice on how to efficiently use ELITEA for optimal results.</li> </ul>"},{"location":"how-tos/faqs/#how-to-use-this-section","title":"How to Use This Section","text":"<ul> <li>Browse or Search: Feel free to scroll through the questions or use the search function to find specific topics.</li> <li>Interactive Examples: Where applicable, we've included interactive examples to illustrate solutions.</li> <li>Feedback Loop: Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section.</li> </ul>"},{"location":"how-tos/faqs/#why-an-faq-section","title":"Why an FAQ Section?","text":"<p>We believe in empowering our users with knowledge. An informed user can better leverage ELITEA's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly.</p>"},{"location":"how-tos/faqs/#lets-dive-in","title":"Let's Dive In!","text":"<p>Ready to explore? Great! Your next step towards mastering ELITEA begins here. Navigate through the questions, uncover new insights, and elevate your ELITEA experience. Remember, we're here to support your journey, every step of the way.</p> <p>Happy Exploring! \ud83c\udf1f</p>"},{"location":"how-tos/faqs/#faqs","title":"FAQs","text":""},{"location":"how-tos/faqs/#how-can-i-integrate-confluence-as-a-source-type-in-elitea","title":"How Can I Integrate Confluence as a Source Type in ELITEA?","text":""},{"location":"how-tos/faqs/#answer","title":"Answer","text":"<p>Integrating Confluence with ELITEA allows you to seamlessly connect and utilize your Confluence data within ELITEA. To set up this connection accurately, please follow the comprehensive steps outlined below:</p> <ol> <li>Dataset Name: Assign a descriptive name to your dataset for easy identification.</li> <li>Source Selection: In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source.</li> <li>Confluence URL: Enter the URL of your Confluence space's homepage. This acts as the entry point for ELITEA to access your Confluence content.</li> <li>Authentication: Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer.</li> <li>Username: Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied.</li> <li>Hosting Option: Specify your hosting preference Server or Cloud. This information helps ELITEA connect to the correct Confluence environment.</li> <li>Data Filtering: Choose how you wish to filter the data. You can select by Space Key, Page IDs, or Labels. This step is crucial for refining the data ELITEA accesses, ensuring only relevant content is included in your dataset.</li> <li>Save: After configuring all settings, click Save to finalize the dataset creation.</li> </ol> <p>For more information: please check Datasources - Confluence setup.</p>"},{"location":"how-tos/faqs/#example","title":"Example","text":"<p>Let's walk through a practical scenario to better understand how to implement these steps:</p> <ul> <li>Dataset Name: Functional Testing Armenia - Documentation</li> <li>Source Type: Confluence</li> <li>URL: https://kb.epam.com</li> <li>Token: [your token]</li> <li>Username: [your username]</li> <li>Hosting Option: Server</li> <li>Filtering Option: Labels</li> <li>Labels: ft_armenia</li> </ul> <p>This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/","title":"Pipeline Agent Framework User Guide for ELITEA","text":"<p>Welcome to the Pipeline Agent Framework guide for ELITEA! This guide will help you understand how to create your own intelligent agents within ELITEA, even if you don't have a background in coding. Think of these agents as helpful assistants that can guide users through tasks, answer questions, and automate processes. The Pipeline Agent Framework is specifically designed for creating the instructions that your agents will follow. Pipeline Agents are based on the LangChain backend and work with Azure OpenAI Service integrations.</p> <p>Pipeline agents are designed for orchestrating the work of various entities together like prompts, agents, and datasources. This agent type must be selected when you are writing instructions for so-called 'master' agents.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#what-is-the-pipeline-agent-framework","title":"What is the Pipeline Agent Framework?","text":"<p>Imagine you're building a process step-by-step. The Pipeline Agent Framework allows you to define these steps and how they connect in a clear and organized way. It's like creating a flowchart for your AI agent. You define individual actions (like asking a question or using a tool) and then connect them to create a smooth flow.</p> <p>This framework uses a simple configuration language YAML to define how your agent works. YAML is designed to be easy to read and understand, making it perfect for describing the steps your agent will take. You'll write instructions in YAML that tell ELITEA how your agent should behave.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#core-concepts-the-building-blocks-of-your-pipeline-agent","title":"Core Concepts: The Building Blocks of Your Pipeline Agent","text":"<p>Let's understand the key parts that make up your intelligent agent:</p> <ul> <li>State: Represents the agent's memory defined by user, storing information gathered and used throughout its execution.<ul> <li>The state allows the agent to retain context and use previously acquired information in subsequent steps.</li> <li>It can include default information like messages (conversation history) and custom data defined by the user.</li> </ul> </li> <li>Entry Point: Specifies the starting node of the agent's execution, defining where the agent begins its workflow.<ul> <li>This is the initial step from which the agent's journey begins.</li> </ul> </li> <li>Interruptions: Provide mechanisms to pause the agent's execution at specific points, allowing for user intervention or inspection.<ul> <li>Interruptions can be set to occur before or after a particular node's execution.</li> </ul> </li> <li>Nodes: The fundamental building blocks representing individual actions or steps the agent can take.<ul> <li>These are the verbs of your agent's workflow, defining what the agent does at each stage.</li> <li>Different node types allow for various actions, such as interacting with the user, calling external tools, or performing specific functions.</li> </ul> </li> <li>Transitions: Define the flow and connections between nodes, dictating the sequence of actions the agent follows.<ul> <li>Transitions specify which node the agent should move to after completing the current node's task.</li> <li>They create the directed path through the agent's workflow.</li> </ul> </li> <li>Conditions: Allow for conditional transitions between nodes, where the next step depends on whether a specific rule or condition is met.<ul> <li>Conditions introduce logic into the agent's workflow, enabling it to react differently based on data or user input.</li> </ul> </li> <li>Decisions: Enable the agent to make choices and branch its execution path based on available information or the outcome of a node.<ul> <li>Decision points allow for more dynamic and intelligent agent behavior.</li> <li>The agent can evaluate different conditions and select the appropriate next step.</li> </ul> </li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#state","title":"State","text":"<p>The state is the agent's memory, defined by you, the user. It stores information that the agent gathers and uses throughout its execution. The default state includes <code>messages</code> (the conversation history). You can also define custom states to store other relevant information.</p> <p>Data types for custom states: <code>str</code>, <code>int</code>, <code>list</code>, <code>dict</code></p> <p>Important Note about Agent Memory (State):</p> <p>When you define the <code>state</code> for your Pipeline Agent, you'll encounter two important terms related to user input and conversation history: <code>input</code> and <code>messages</code>. It's crucial to understand the difference between them:</p> <ul> <li><code>input</code> - The Latest User Message: Think of <code>input</code> as the agent's short-term memory of what the user just said or entered.  It always holds the most recent message from the user.  If the user types something new, the value of <code>input</code> is updated to reflect that new message.</li> <li><code>messages</code> - The Entire Conversation History: <code>messages</code>, on the other hand, is like the agent's long-term memory of the entire conversation. It's a list that keeps track of every message exchanged between the user and the agent from the beginning of the interaction.  This includes both the user's messages and the agent's responses.</li> <li><code>messages: list</code> - Always Include in Custom State: If you define a <code>state</code> section in your agent's YAML instructions, you must always include <code>messages: list</code> within it. This is essential for your agent to properly track and maintain the conversation history.  Without <code>messages: list</code> in your custom <code>state</code>, the agent will not be able to remember the ongoing conversation, which is crucial for most interactive agents. If you don't need to define any other custom state variables, you can simply omit the entire <code>state</code> section, and the agent will automatically use the default <code>messages</code> state.</li> </ul> <p>Example 1: State Definition</p> <pre><code>state:\n  jira_project_id: str\n  epic_id: str\n  us_title: str\n  description: str\n  input: str\n  messages: list\n  filtered_sumarized_info: str\n  draft_us: str\n  info_from_datasource: str\n  enhanced_us: str\n</code></pre> <p>Explanation:</p> <p>This <code>state</code> definition indicates that the agent will store information related to:</p> <ul> <li><code>jira_project_id</code>: Jira project ID (string)</li> <li><code>epic_id</code>: Epic ID (string)</li> <li><code>us_title</code>: User story title (string)</li> <li><code>description</code>: User story description (string)</li> <li><code>input</code>: The latest user input (string)</li> <li><code>messages</code>: The entire conversation history as a list of messages (<code>list</code>)</li> <li><code>filtered_sumarized_info</code>: Summarized information (string)</li> <li><code>draft_us</code>: Draft user story (string)</li> <li><code>info_from_datasource</code>: Information from a data source (string)</li> <li><code>enhanced_us</code>: Enhanced user story (string)</li> </ul> <p>Note: If you only need the default <code>messages</code> state, you can omit the <code>state</code> section entirely from your YAML instructions.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#entry-point","title":"Entry Point","text":"<p>The entry_point is defined at the top level of your YAML instructions and specifies the <code>id</code> of the first node that will be executed when the agent starts. This node serves as the starting point of your agent's workflow and the beginning of its journey.</p> <p>Important Note: The <code>entry_point</code> can be any type of node, including <code>llm</code>, <code>function</code>, <code>tool</code>, <code>loop</code>, or <code>loop_tool</code>, depending on the desired starting behavior of your agent.</p> <p>Example 1: <code>llm</code> node as Entry Point</p> <pre><code>entry_point: Conversation Partner\nnodes:\n  - id: Conversation Partner\n    type: llm\n    input: [input]\n    prompt:\n      type: string\n      value: |\n        Hello! I am your User Story creation assistant.\n        To get started, please tell me the Jira Project ID for your user story.\n    output: [jira_project_id]\n    transition: Get Epic ID # Define the next step after this node\n# ... rest of your agent's instructions ...\n</code></pre> <p>Explanation:</p> <p>This entry_point: Conversation Partner definition tells the agent to start its execution from the llm node with the id \"Conversation Partner\". The YAML code snippet also shows the definition of the \"Conversation Partner\" node itself. As the first node, it's an llm type, designed to initiate the conversation by greeting the user and asking for the Jira Project ID.</p> <p>Example 2: <code>function</code> node as Entry Point</p> <pre><code>entry_point: Data Initialization\nnodes:\n  - id: Data Initialization\n    type: function\n    output: [current_date, system_version]\n    input_mapping:\n      # Assuming 'get_system_info' is a function that returns date and version\n      function_call:\n        type: fixed\n        value: get_system_info\n    transition: Main Workflow # Define the next step after this node\n# ... rest of your agent's instructions ...\n</code></pre> <p>Explanation:</p> <p>In this example, entry_point: Data Initialization sets the starting node to be a function node named \"Data Initialization\". This node, defined as a function type, is designed to perform an initial setup task. Here, it's configured to call a hypothetical function get_system_info (via input_mapping) to retrieve the current date and system version and store them in the state as current_date and system_version. The agent then transitions to the \"Main Workflow\" node to begin the core logic.</p> <p>Example 3: <code>loop</code> node as Entry Point</p> <pre><code>entry_point: Process Files\nnodes:\n  - id: Process Files\n    type: loop\n    task: \"Generate a list of file paths from a predefined list: file1.txt, file2.txt, file3.txt. Format each as input: {\\\"file_path\\\": \\\"&lt;file_path&gt;\\\"}\"\n    tool: FileProcessor # Assuming 'FileProcessor' is an agent or prompt to process files\n    transition: END # End after processing all files\n# ... rest of your agent's instructions ...\n</code></pre> <p>Explanation:</p> <p>Here, entry_point: Process Files designates a loop node named \"Process Files\" as the starting point. This example demonstrates starting the agent execution directly with a loop. The loop node is set up to process a predefined list of files. The task instruction defines how to create input for each file, and the tool: FileProcessor will be executed for each file in the list. After processing all files in the loop, the agent transitions to END, completing its execution.</p> <p>Note: These examples illustrate that the entry_point provides flexibility in defining how your Pipeline Agent begins its execution, allowing you to start with user interaction (llm), initial data processing (function), or even directly with a looping mechanism (loop).</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#interruptions","title":"Interruptions","text":"<p>Interruptions are optional attributes you can add at the top level of your YAML file to pause the agent's execution and give control back to the user at specific points during its workflow. This allows for manual review, adjustments, or user-driven decision-making within an automated agent process.</p> <p>You can define two types of interruptions:</p> <ul> <li><code>interrupt_before</code>:  Pauses the agent's execution immediately before a specific node is executed. This is useful when you want to review the inputs or confirm the action before the agent proceeds with a particular step.</li> <li><code>interrupt_after</code>: Pauses the agent's execution immediately after a specific node has finished executing. This is helpful for reviewing the output of a node, providing feedback, or making decisions based on the results of that step before the agent continues to the next node.</li> </ul> <p>Key Features of Interruptions:</p> <ul> <li>Multiple Interruptions Allowed: You can define multiple <code>interrupt_before</code> and <code>interrupt_after</code> points within a single agent. This allows for fine-grained control and review at various stages of a complex workflow.</li> <li>Combined Interrupt Types: You can even use both <code>interrupt_before</code> and <code>interrupt_after</code> interruptions within the same agent. This provides maximum flexibility in designing review and control points in your agent's execution.</li> </ul> <p>Important Note: When you use <code>interrupt_before</code> or <code>interrupt_after</code> in your agent's instructions, it is crucial to ensure that your agent's logic still includes a clear path to the <code>END</code> node. This ensures that even with manual interruptions, the agent's execution can be logically completed and doesn't get stuck in a paused state indefinitely.</p> <p>Example 1: <code>interrupt_before</code> - Review before Content Aggregation</p> <pre><code>entry_point: Conversation Partner\ninterrupt_before: # Define interruptions at the top level\n  - Unified Content Aggregator # Interrupt BEFORE 'Unified Content Aggregator' node\nnodes: # Node definitions\n  - id: Conversation Partner\n    type: llm\n    # ... (rest of Conversation Partner node definition)\n    transition: Unified Content Aggregator\n\n  - id: Unified Content Aggregator # Interruption will occur BEFORE this node starts\n    type: function\n    # ... (rest of Unified Content Aggregator node definition)\n    transition: Draft User Story Creator\n# ... rest of your agent's instructions ...\n</code></pre> <p>Explanation:</p> <p>In this example, <code>interrupt_before: - Unified Content Aggregator</code> is defined at the top level. This means that before the agent starts executing the <code>Unified Content Aggregator</code> node (identified by <code>id: Unified Content Aggregator</code> within the <code>nodes</code> section), the execution will pause, and control will be given back to the user. The user can then review the current state of the agent, potentially make adjustments, and then manually resume the agent's execution.</p> <p>Example 2: <code>interrupt_after</code> - Review User Feedback</p> <pre><code>entry_point: Conversation Partner\ninterrupt_after: # Define interruptions at the top level\n  - Conversation Partner # Interrupt AFTER 'Conversation Partner' node\nnodes: # Node definitions\n  - id: Conversation Partner # Interruption will occur AFTER this node finishes\n    type: llm\n    # ... (rest of Conversation Partner node definition)\n    transition: Unified Content Aggregator\n  - id: Unified Content Aggregator\n    type: function\n    # ... (rest of Unified Content Aggregator node definition)\n    transition: Draft User Story Creator\n# ... rest of your agent's instructions ...\n</code></pre> <p>Explanation:</p> <p>Here, <code>interrupt_after: - Conversation Partner</code> is defined. This will cause the agent to pause immediately after it has finished executing the <code>Conversation Partner</code> node.  After the \"Conversation Partner\" node completes its task (likely interacting with the user), the agent will pause, allowing the user to review the interaction, the agent's response, and the updated state before the agent proceeds to the \"Unified Content Aggregator\" node.</p> <p>Example 3: Using Both <code>interrupt_before</code> and <code>interrupt_after</code></p> <pre><code>entry_point: Conversation Partner\ninterrupt_before: # Define 'interrupt_before'\n  - User Story Publisher # Interrupt BEFORE 'User Story Publisher'\ninterrupt_after: # Define 'interrupt_after'\n  - User Feedback and Approval # Interrupt AFTER 'User Feedback and Approval'\nnodes: # Node definitions\n  - id: Conversation Partner\n    type: llm\n    # ... (rest of Conversation Partner node definition)\n    transition: User Feedback and Approval\n  - id: User Feedback and Approval # Interruption will occur AFTER this node finishes\n    type: llm\n    # ... (rest of User Feedback and Approval node definition)\n    transition: User Story Publisher\n  - id: User Story Publisher # Interruption will occur BEFORE this node starts\n    type: function\n    # ... (rest of User Story Publisher node definition)\n    transition: END\n</code></pre> <p>Explanation:</p> <p>This example demonstrates using both types of interruptions in a single agent.</p> <ul> <li><code>interrupt_after: - User Feedback and Approval</code>: The agent will pause after the \"User Feedback and Approval\" node, allowing review of user feedback and the enhanced user story.</li> <li><code>interrupt_before: - User Story Publisher</code>: The agent will pause before the \"User Story Publisher\" node, allowing a final check before the user story is published to Jira.</li> </ul> <p>By strategically placing <code>interrupt_before</code> and <code>interrupt_after</code> points, you can create Pipeline Agents that offer a balance between automation and user control, ensuring critical steps are reviewed and validated as needed.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#nodes","title":"Nodes","text":"<p>Nodes are the individual actions or steps your agent can take. Each node performs a specific task. Think of them as verbs \u2013 what your agent does. The following Node types are available:</p> <ul> <li>llm: Enables the agent to interact with users using natural language, powered by AI models.<ul> <li>Used for asking questions, providing information, and engaging in conversational exchanges.</li> </ul> </li> <li>tool: Allows the agent to utilize pre-built entities (prompts, agents and datasources) in ELITEA.<ul> <li>Facilitates actions like retrieving data, triggering other agents, or using specific prompts and datasources.</li> </ul> </li> <li>function: Provides a mechanism for the agent to directly call and execute specific ELITEA functionalities with precise control over input mapping.<ul> <li>Offers a more advanced and potentially efficient way to interact with ELITEA's internal capabilities.</li> </ul> </li> <li>loop: Enables the agent to repeatedly execute a specific task or action, often iterating over a list of items or until a condition is met.<ul> <li>Useful for processing collections of data or performing repetitive operations.</li> </ul> </li> <li>loop_tool: Allows the agent to iterate through a list of inputs generated by another ELITEA agent, executing a specified tool or function for each item.<ul> <li>Facilitates workflows where the input for a repetitive task is dynamically generated by another entity.</li> </ul> </li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#common-node-attributes","title":"Common Node Attributes","text":"<p>Nodes have the following common attributes:</p> <ul> <li><code>id</code>: A unique name for this specific step. This helps you refer to this node later in your instructions for transitions, conditions, or decisions.</li> <li><code>type</code>:  Specifies the kind of action this node will perform (e.g., <code>llm</code>, <code>tool</code>, <code>function</code>, <code>loop</code>, <code>loop_tool</code>).</li> <li><code>input</code> (optional):  A list of information the node needs to perform its task. This information is retrieved from the agent's <code>state</code>.</li> <li><code>output</code> (optional): A list of names for the information the node produces after completing its task. This information is then stored back in the agent's <code>state</code> and can be used by subsequent nodes.</li> <li><code>transition</code>:  Specifies the <code>id</code> of the next node the agent should move to after this node is finished. If the value is <code>END</code>, the agent's execution will stop, logically completing the agent's workflow.</li> <li><code>condition</code> (optional):  Allows the agent to conditionally transition to different nodes based on specific rules defined using Jinja2 templating.</li> <li><code>decision</code> (optional): Allows the agent to choose the next node from a predefined list based on available information or the result of the current node's action.</li> </ul> <p>Node types in Detail</p> <p>Here are the different types of nodes you can use to build your agent, with detailed explanations and examples:</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#node-type-llm","title":"Node type: <code>llm</code>","text":"<p>The <code>llm</code> node allows your agent to communicate with the user using the power of Large Language Models (LLMs). You provide a <code>prompt</code> (a question or instruction), and the LLM generates a response.</p> <p>Purpose: To engage in natural language interactions with the user, such as:</p> <ul> <li>Asking questions to gather information.</li> <li>Providing information or explanations.</li> <li>Getting user feedback or approval.</li> </ul> <p>Common Attributes for <code>llm</code> Nodes:</p> <ul> <li><code>id</code>: A unique name for this <code>llm</code> node (e.g., <code>Conversation Partner</code>, <code>User Feedback</code>).</li> <li><code>type</code>:  Always set this to <code>llm</code>.</li> <li><code>prompt</code>: Defines the instruction or question for the LLM.<ul> <li><code>type</code>: Specifies the format of the prompt. Must be either <code>string</code> or <code>fstring</code>.<ul> <li><code>string</code>:  A simple text prompt without any variables.</li> <li><code>fstring</code>: A formatted string prompt that includes variables from the agent's <code>state</code> within the instructions.</li> </ul> </li> <li><code>value</code>: The actual text of the question or instruction. Use <code>|</code> to define multiline prompts.</li> </ul> </li> <li><code>input</code> (optional): A list of state variables that the <code>prompt</code> might need.<ul> <li>For Entry Point <code>llm</code> Nodes: If this <code>llm</code> node is the <code>entry_point</code> of your agent, <code>input: [input]</code> is valid and refers to the initial user input.</li> <li>For Subsequent <code>llm</code> Nodes: <code>input</code> can include any state variables that have been populated as <code>output</code> variables in previous nodes (e.g., <code>input: [input1, input2, messages]</code>). If using <code>fstring</code> prompts, <code>input</code> becomes mandatory to list the variables used in the prompt.</li> </ul> </li> <li><code>output</code> (optional): A list of names for the information you expect to extract from the LLM's response. This information will be stored back in the agent's <code>state</code> and can be used by subsequent nodes. Example: <code>output: [description, jira_project_id, epic_id, us_title]</code></li> <li><code>structured_output</code> (optional):  Set to <code>true</code> if you expect the LLM's response to be in a structured format (like JSON) that makes it easier to extract the <code>output</code> values. Defaults to <code>false</code>. The effectiveness of <code>structured_output: true</code> depends on the capabilities of the selected LLM model.</li> <li><code>messages</code>:  This attribute is implicitly managed by the framework and represents the 'chat_history'. You don't need to define it explicitly in <code>input</code> or <code>output</code> unless you want to explicitly pass the entire chat history as input to the prompt for context.</li> </ul> <p>Example 1: <code>llm</code> node - Simple Text Prompt</p> <pre><code>- id: Conversation Partner\n  type: llm\n  input: [input] # Optional, but included here as the prompt refers to user input (entry point node)\n  prompt:\n    type: string\n    value: |\n      To create a new User Story, I need some information from you. Could you please provide the\n      following details in the specified format?\n      - **Jira Project ID**: (e.g., PLAN)\n      - **EPIC ID**: (e.g., PLAN-128)\n      - **Title**: (e.g., Checkout functionality)\n      - **Description**: (e.g., \"The informative description of future US.\")\n      Once you provide this information, I will ask for your approval (should be 'approved' word) to start the User Story creation process. Make your instructions to user highlighted by using markdown highlight for text.\n  output: [description, jira_project_id, epic_id, us_title]\n  structured_output: true\n  transition: Confluence Extractor # Define the next step here\n</code></pre> <p>Explanation:</p> <ul> <li><code>id: Conversation Partner</code>:  Names this node \"Conversation Partner\".</li> <li><code>type: llm</code>:  Specifies that this is an <code>llm</code> node.</li> <li><code>input: [input]</code>:  Takes the user's initial input as input to the prompt (valid for entry point node).</li> <li><code>prompt</code>:<ul> <li><code>type: string</code>: Indicates a simple text prompt.</li> <li><code>value</code>:  The actual instruction for the LLM, asking the user for user story details.</li> </ul> </li> <li><code>output: [description, jira_project_id, epic_id, us_title]</code>:  Specifies that the agent expects to extract these pieces of information from the user's response and store them in the <code>state</code>.</li> <li><code>structured_output: true</code>: Indicates that the agent expects a structured response to facilitate information extraction.</li> </ul> <p>Example 2: <code>llm</code> node - Parametrized Prompt (<code>fstring</code>)</p> <pre><code>- id: User Feedback and Approval\n  type: llm\n  input: [input, enhanced_us, info_from_datasource] # Mandatory because of fstring prompt\n  output: [enhanced_us] # Mandatory because of fstring prompt\n  prompt:\n    type: fstring\n    value: |\n      When reviewing and updating a user story, ensure its structure and format remain consistent with the original, unless the user specifically requests changes. Present the updated user story in its entirety, enriched with any necessary information, clearly and concisely for user feedback. Use the following variables to guide the process:\n      - **Current User Input:** {input}\n      - **Information from Data Source:** {info_from_datasource}\n      - **Enhanced User Story:** {enhanced_us}\n      Users can provide feedback through free form queries, which will be controlled by the \"Current User Input\" value. If the query contains \"datasource:\", access and incorporate specific data from the identified sources into the enhanced user story via \"Information from Data Source\". Present the full \"Enhanced User Story\" to the user, ensuring that the structure and format remain unchanged.\n      Approval of the enhanced user story can be given by typing \"approved,\" which will publish it to Jira. If no further changes or publication is desired, the user can type \"finish\" to conclude the session.\n  transition: User Story Publisher # Define the next step here\n</code></pre> <p>Explanation:</p> <ul> <li><code>id: User Feedback and Approval</code>: Names this node \"User Feedback and Approval\".</li> <li><code>type: llm</code>: Specifies that this is an <code>llm</code> node.</li> <li><code>input: [input, enhanced_us, info_from_datasource]</code>:  Mandatory because the prompt is an <code>fstring</code> and uses these variables. It takes the user's current input, the enhanced user story, and information from a data source from the agent's <code>state</code>.</li> <li><code>prompt</code>:<ul> <li><code>type: fstring</code>: Indicates a formatted string prompt using variables.</li> <li><code>value</code>: The instruction for the LLM, using placeholders like <code>{input}</code>, <code>{info_from_datasource}</code>, and <code>{enhanced_us}</code> to insert values from the agent's <code>state</code>.</li> </ul> </li> <li><code>output: [enhanced_us]</code>: Mandatory because the prompt is an <code>fstring</code>. Specifies that the agent expects the LLM to potentially modify or confirm the <code>enhanced_us</code>.</li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#node-type-tool","title":"Node type: <code>tool</code>","text":"<p>The <code>tool</code> node allows your agent to utilize pre-built entities within ELITEA, specifically: prompts, agents, and datasources. The <code>tool</code> node is a simpler way to use these entities compared to the <code>function</code> node, but it might be less efficient in terms of token usage and expensive.</p> <p>Purpose: To leverage existing ELITEA entities to perform specific tasks, such as:</p> <ul> <li>Executing a pre-defined prompt.</li> <li>Triggering another ELITEA agent.</li> <li>Querying a datasource to retrieve information.</li> </ul> <p>Common Attributes for <code>tool</code> nodes:</p> <ul> <li><code>id</code>: A unique name for this <code>tool</code> node (e.g., <code>Draft User Story Creator</code>, <code>Data Retriever</code>).</li> <li><code>type</code>: Always set this to <code>tool</code>.</li> <li><code>tool</code>: The name of the specific ELITEA entity (prompt, agent, or datasource) you want to use.</li> <li><code>input</code> (optional): A list of state variables that might be used as input for the tool.</li> <li><code>output</code> (optional): A list of names for the information expected as output from the tool.</li> <li><code>structured_output</code> (optional): Indicates if the tool's output is expected to be structured. Defaults to <code>false</code>.</li> <li><code>transition</code>: The <code>id</code> of the next node to execute after the tool finishes.</li> </ul> <p>Example 1: <code>tool</code> node - Using a Prompt</p> <pre><code>- id: Draft User Story Creator\n  type: tool\n  tool: User Story Draft Prompt  # Assuming 'User Story Draft Prompt' is a defined prompt in ELITEA\n  transition: User Story Enhance Aggregator\n</code></pre> <p>Explanation:</p> <ul> <li><code>id: Draft User Story Creator</code>: Names this node \"Draft User Story Creator\".</li> <li><code>type: tool</code>: Specifies that this is a <code>tool</code> node.</li> <li><code>tool: User Story Draft Prompt</code>:  Specifies that this node will use the ELITEA prompt named \"User Story Draft Prompt\".</li> <li><code>transition: User Story Enhance Aggregator</code>: Defines the next node to be \"User Story Enhance Aggregator\".</li> </ul> <p>Important Note: When using a <code>tool</code> node, the framework will use an LLM in the background to prepare the input data for the specified tool. This can increase token usage and potentially make the execution slower compared to using a <code>function</code> node with explicit input mapping.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#node-type-function","title":"Node type: <code>function</code>","text":"<p>The <code>function</code> node provides a more advanced and efficient way to interact with ELITEA entities (prompts, agents, datasources, and other functionalities). It allows you to directly call and execute specific ELITEA functionalities, but requires you to explicitly define how the inputs for that functionality are prepared using <code>input_mapping</code>. This explicit control over input mapping can lead to better token efficiency and faster execution compared to the <code>tool</code> node.</p> <p>Purpose: To directly utilize specific ELITEA functionalities with precise control over input preparation.</p> <p>Common Attributes for <code>function</code> nodes:</p> <ul> <li><code>id</code>: A unique name for this <code>function</code> node (e.g., <code>Summarize User Story</code>, <code>Publish to Jira</code>).</li> <li><code>type</code>: Always set this to <code>function</code>.</li> <li><code>input</code>: A list of state variables that will be used to prepare the input for the ELITEA entity. This is mandatory.</li> <li><code>output</code>: A list of names for the information that will be returned by the ELITEA entity. This is mandatory.</li> <li> <p><code>input_mapping</code>: Defines how the <code>input</code> variables from the agent's <code>state</code> are mapped to the input parameters of the ELITEA entity being called.</p> <ul> <li>For Agent as Function: If calling an ELITEA agent as a function node, <code>input_mapping</code> typically includes:<ul> <li><code>input_mapping</code>:     <code>task</code>: # 'task' is a common input parameter for agents         <code>type</code>:  # variable, fstring, string, fixed         <code>value</code>:  # state variable, formatted string, text, constant value     <code>chat_history</code>: # 'chat_history' is another common input parameter for agents         <code>type</code>:  # variable, fixed         <code>value</code>:  # 'messages' state variable, [] for empty history <li><code>task</code>: Represents the main instruction or task for the agent being called.<ul> <li><code>type: string</code>: Provides instructions directly as a string without using state variables.</li> <li><code>type: fstring</code>: Provides parametrized instructions using variables from the agent's <code>state</code>.</li> <li><code>type: variable</code>: Uses the value of a state variable as the task instruction.</li> <li><code>type: fixed</code>: Uses a constant, hardcoded value as the task instruction.</li> </ul> </li> <li><code>chat_history</code>:  Defines how chat history is passed to the agent being called.<ul> <li><code>type: fixed</code>:  <code>value: []</code> -  Passes an empty chat history, effectively starting a new conversation with the child agent.</li> <li><code>type: variable</code>: <code>value: messages</code> - Passes the entire current chat history to the child agent.</li> </ul> </li> <li>For Prompt as Function: If calling an ELITEA prompt as a function node, <code>input_mapping</code> might look like:     <code>yaml     input_mapping:       input: # 'input' is a common input parameter for prompts (for prompts without variables)         type: variable         value: &lt;state_variable_name&gt; # The state variable containing the input for the prompt       variable_name: # 'variable_name' -  Use this if the prompt has variables, replace 'variable_name' with the actual variable name in the prompt         type: variable         value: &lt;state_variable_name&gt; # The state variable providing value for the prompt's variable</code><ul> <li><code>input</code>: Used when calling a prompt that doesn't use variables in its instructions.<ul> <li><code>type: variable</code>:  Uses a state variable as input to the prompt.</li> </ul> </li> <li><code>variable_name</code>: Used when calling a prompt that does use variables in its instructions. Replace <code>variable_name</code> with the actual name of the variable used in the prompt.<ul> <li><code>type: variable</code>: Uses a state variable to provide the value for the prompt's variable.</li> <li><code>type: fixed</code>: Uses a fixed, constant value for the prompt's variable. Useful when a variable's value is not crucial and can be a default value (e.g., \"n/a\").</li> </ul> </li> </ul> </li> <li> <p>For Datasource as Function: If calling an ELITEA datasource as a function node, <code>input_mapping</code> typically includes:     <code>yaml     input_mapping:       query: # 'query' is a common input parameter for datasources         type: &lt;type&gt; # variable, string, fstring, fixed         value: &lt;value&gt; # state variable, formatted query string, query text, constant query</code></p> <ul> <li><code>query</code>: Defines the query to be executed against the datasource.<ul> <li><code>type: variable</code>: Uses a state variable as the query.</li> <li><code>type: string</code>: Provides the query directly as a string.</li> <li><code>type: fstring</code>: Creates a dynamic query using variables from the agent's <code>state</code>.</li> <li><code>type: fixed</code>: Uses a constant, hardcoded query.</li> </ul> </li> </ul> <p>Important Note: When using a datasource as a function node, remember to specify the correct <code>tool</code> name in your YAML instructions. Use <code>[ToolNamewithoutspacesPredict]</code> for prediction datasources and <code>[ToolNamewithoutspacesSearch]</code> for search datasources (replace <code>ToolNamewithoutspaces</code> with the actual tool name without spaces).</p> </li> <li> <p><code>transition</code>: The <code>id</code> of the next node to execute after the function call.</p> </li> <p>Example 1: <code>function</code> node - Calling an Agent (variable input mapping)</p> <pre><code>- id: Draft User Story Creator\n  type: function\n  input: [filtered_sumarized_info]\n  output: [draft_us]\n  input_mapping:\n    task: # Input mapping for 'task' parameter of the agent\n      type: variable\n      value: filtered_sumarized_info # Use 'filtered_sumarized_info' state variable as task\n  transition: User Story Enhance Aggregator\n</code></pre> <p>Explanation:</p> <ul> <li><code>input_mapping: task</code>: Maps the input for the <code>task</code> parameter of the agent being called.<ul> <li><code>type: variable</code>: Specifies that the value for <code>task</code> will be taken from a state variable.</li> <li><code>value: filtered_sumarized_info</code>:  Indicates that the value of the <code>filtered_sumarized_info</code> state variable will be used as the <code>task</code>.</li> </ul> </li> </ul> <p>Example 2: <code>function</code> node - Calling an Agent (<code>fstring</code> input mapping)</p> <pre><code>- id: User Story Enhance Aggregator\n  input: [draft_us]\n  output: [enhanced_us]\n  input_mapping:\n    task: # Input mapping for 'task' parameter of the agent\n      type: fstring\n      value: |\n        Enhance the Narrative, Description and Scenarios with AC's for the given draft User Story: {draft_us} # Formatted task instruction\n    chat_history: # Input mapping for 'chat_history' parameter of the agent\n      type: fixed\n      value: [] # Use empty chat history\n  type: function\n  transition: User Feedback and Approval\n</code></pre> <p>Explanation:</p> <ul> <li><code>input_mapping: task</code>: Maps the input for the <code>task</code> parameter of the agent being called.<ul> <li><code>type: fstring</code>: Specifies that the value for <code>task</code> will be created using a formatted string.</li> <li><code>value</code>: Defines the formatted string instruction, including the <code>{draft_us}</code> variable from the agent's <code>state</code>.</li> </ul> </li> <li><code>input_mapping: chat_history</code>: Maps the input for the <code>chat_history</code> parameter.<ul> <li><code>type: fixed</code>: Specifies a fixed value for <code>chat_history</code>.</li> <li><code>value: []</code>:  Sets the <code>chat_history</code> to an empty list, meaning the child agent will start with no prior conversation history.</li> </ul> </li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#node-type-loop","title":"Node type: <code>loop</code>","text":"<p>The <code>loop</code> node allows you to execute a specific task repeatedly, creating a loop within your agent's workflow. You define instructions on how to create the input for each iteration of the loop.</p> <p>Purpose: To perform the same action multiple times, typically for each item in a list or until a certain condition is met. Useful for:</p> <ul> <li>Processing a list of items (e.g., files, user stories).</li> <li>Repeating an action until a desired outcome is achieved.</li> </ul> <p>Common Attributes for <code>loop</code> nodes:</p> <ul> <li><code>id</code>: A unique name for this <code>loop</code> node (e.g., <code>Documentor</code>, <code>Process User Stories</code>).</li> <li><code>type</code>: Always set this to <code>loop</code>.</li> <li><code>task</code>: (Mandatory) Instructions on how to formulate the input for each iteration of the loop. This is usually a text instruction that tells the agent how to extract or create input data from the current <code>state</code> or <code>chat_history</code>.</li> <li><code>tool</code>: The name of the ELITEA entity (agent, prompt, or other tool) that will be executed in each iteration of the loop. Recommendation: Use an ELITEA agent as the <code>tool</code> for more complex loop logic.</li> <li><code>input</code> (optional): A list of state variables that might be used as input for the <code>llm</code> node (if an LLM is used internally to prepare loop inputs based on the <code>task</code> instruction). Providing <code>input</code> can be more token-efficient than relying solely on <code>chat_history</code>.</li> <li><code>output</code> (optional): A list of names for the information produced by the entire <code>loop</code> node after all iterations are complete. If you want to collect and use the results of all loop iterations in subsequent nodes, define <code>output</code>.</li> <li><code>transition</code>: The <code>id</code> of the next node to execute after the loop finishes all iterations.</li> </ul> <p>Example 1: <code>loop</code> node - Documenting Code Files</p> <pre><code>- id: Documentor\n  type: loop\n  task: \"Formulate ALL file paths from chat_history as a list of inputs.\"\n  tool: Code Documentation  # Assuming 'Code Documentation' is a defined prompt or agent in ELITEA\n  transition: END\n</code></pre> <p>Explanation:</p> <ul> <li><code>task</code>: Provides instructions to the agent on how to create input for each loop iteration. In this case, it instructs the agent to:<ol> <li>Extract all file paths mentioned in the <code>chat_history</code>.</li> <li>Format each file path into a dictionary with keys <code>\"task\"</code> (containing the file path) and <code>\"chat_history\"</code> (containing the entire <code>chat_history</code>).</li> </ol> </li> <li><code>tool: Code Documentation</code>: Specifies that in each iteration of the loop, the ELITEA entity named \"Code Documentation\" will be executed. This could be an agent or a prompt designed to generate documentation for a given file path.</li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#node-type-loop_tool","title":"Node type: <code>loop_tool</code>","text":"<p>The <code>loop_tool</code> node is a more advanced loop type that gets the list of inputs for the loop from the output of another ELITEA entity (typically an agent). This is useful when you need to dynamically generate the items to be processed in the loop.</p> <p>Purpose: To iterate through a list of items generated by another ELITEA entity and perform a specific action on each item.</p> <p>Common Attributes for <code>loop_tool</code> nodes:</p> <ul> <li><code>id</code>: A unique name for this <code>loop_tool</code> node (e.g., <code>Process Pages</code>, <code>Generate Documentation</code>).</li> <li><code>type</code>: Always set this to <code>loop_tool</code>.</li> <li><code>tool</code>: The name of the ELITEA entity (agent, prompt, or datasource) that will be executed first to generate the list of inputs for the loop.</li> <li><code>loop_tool</code>: The name of the ELITEA entity (agent, prompt, or other tool) that will be executed for each item in the list generated by the <code>tool</code>. Recommendation: Use an ELITEA agent as the <code>loop_tool</code> for more complex processing within the loop.</li> <li><code>variables_mapping</code>: (Mandatory) Defines how to map the variables from the <code>output</code> of the <code>tool</code> (which generates the input list) to the required input parameters of the <code>loop_tool</code> (which processes each item in the list).<ul> <li>For Agent <code>loop_tool</code>: If the <code>loop_tool</code> is an agent, <code>variables_mapping</code> typically includes mapping to <code>task</code> and <code>chat_history</code> input parameters of the agent.</li> <li>For Other <code>loop_tool</code> Types: If the <code>loop_tool</code> is a prompt or another type of tool, you need to map the output variables of the <code>tool</code> to the input parameters expected by the specific <code>loop_tool</code>. Refer to the documentation of the <code>loop_tool</code> to understand its required input parameters.</li> </ul> </li> <li><code>input</code> (optional): A list of state variables that might be needed as input for the <code>tool</code> (the entity that generates the input list).</li> <li><code>output</code> (optional): A list of names for the information produced by the <code>loop_tool</code> in each iteration.</li> <li><code>structured_output</code> (optional): Indicates whether the output of the <code>loop_tool</code> is expected to be structured. Defaults to <code>false</code>.</li> </ul> <p>Example 1: <code>loop_tool</code> node - Processing Confluence Pages</p> <pre><code>- id: listpages\n  type: loop_tool\n  tool:  list_pages_with_label # Assuming 'list_pages_with_label' is a Confluence toolkit's tool that returns a list of pages\n  structured_output: true # Expect structured output from 'list_pages_with_label'\n  loop_tool: Confluence helper # Assuming 'Confluence helper' is an ELITEA agent to process each Confluence page\n  variables_mapping:\n    id: task # Map 'id' output variable from 'list_pages_with_label' to 'task' input of 'Confluence helper'\n    messages: chat_history # Map 'messages' (likely page content) to 'chat_history' input of 'Confluence helper'\n  transition: END\n</code></pre> <p>Example 2: <code>loop_tool</code> node - Documenting Files from Directory</p> <pre><code>- id: Documentor\n  type: loop_tool\n  tool: alita-sdk_get_files_from_directory # Assuming 'get_files_from_directory' is an GitHub tolkit's tool to get files from a 'alita-sdk' github repositary\n  variables_mapping:\n    file_path: task # Map 'file_path' output variable from 'alita-sdk_get_files_from_directory' to 'task' input of 'Code Documentation'\n    messages: chat_history # Map 'messages' to 'chat_history' input of 'Code Documentation'\n  structured_output: true # Expect structured output from 'alita-sdk_get_files_from_directory'\n  loop_tool: Code Documentation # Assuming 'Code Documentation' is an ELITEA agent to document each file\n  transition: END\n</code></pre>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#transitions","title":"Transitions","text":"<p>Transitions are the connections that define how your agent moves from one node to the next, establishing the sequential flow of its workflow. They dictate the order in which your agent performs actions.</p> <p>Within each node definition in your YAML instructions, the <code>transition</code> attribute is used to specify what happens after the current node finishes its execution. You use the <code>transition</code> attribute to tell the agent which node to go to next or to end the agent's execution.</p> <p>There are two primary ways to use the <code>transition</code> attribute:</p> <ul> <li><code>transition: &lt;node_id&gt;</code>: This is used to move the agent's execution to another node within your pipeline. You replace <code>&lt;node_id&gt;</code> with the <code>id</code> of the node you want the agent to execute next. This creates a link in your workflow, connecting one step to another.</li> <li><code>transition: END</code>: This special value signifies the logical end of your agent's workflow. When a node's <code>transition</code> is set to <code>END</code>, it indicates that after this node completes, the agent's execution should stop gracefully. It is crucial to ensure that all logical paths in your agent's instructions eventually lead to a node with <code>transition: END</code> to prevent unexpected behavior or potential issues with chat history management.</li> </ul> <p>Example 1: Transitioning between <code>llm</code> and <code>function</code> nodes</p> <pre><code>nodes:\n  - id: Get User Input # Define an 'llm' node to get user input\n    type: llm\n    prompt:\n      type: string\n      value: \"Please enter the Epic ID for the User Story you want to create.\"\n    output: [epic_id]\n    transition: Extract Epic Details # Transition to 'Extract Epic Details' node after getting user input\n\n  - id: Extract Epic Details # Define a 'function' node to process the Epic ID\n    type: function\n    input: [epic_id]\n    output: [filtered_epic_info]\n    input_mapping:\n      task:\n        type: fstring\n        value: \"Extract key details for Epic ID: {epic_id}\"\n      chat_history:\n        type: fixed\n        value: []\n    transition: Draft User Story Creator # Transition to 'Draft User Story Creator' node after extracting details\n\n  - id: Draft User Story Creator\n    type: function\n    # ... (rest of Draft User Story Creator node definition) ...\n    transition: END # End agent execution after Draft User Story Creator completes\n</code></pre> <p>Explanation:</p> <p>In this example, we see transitions connecting three nodes:</p> <ol> <li><code>Get User Input</code> (llm node): After the agent gets the <code>epic_id</code> from the user, the <code>transition: Extract Epic Details</code> line ensures that the agent will next execute the node with the <code>id</code> \"Extract Epic Details\".</li> <li><code>Extract Epic Details</code> (function node): Once the \"Extract Epic Details\" node finishes processing the <code>epic_id</code>, the <code>transition: Draft User Story Creator</code> line directs the agent to the \"Draft User Story Creator\" node.</li> <li><code>Draft User Story Creator</code> (function node): Finally, after the \"Draft User Story Creator\" node completes its task, the <code>transition: END</code> line signals that this is the end of the workflow, and the agent's execution should terminate.</li> </ol> <p>Example 2:  Linear Transition with <code>tool</code> node and <code>END</code></p> <pre><code>nodes:\n  - id: Search Datasource # Define a 'tool' node to search a datasource\n    type: tool\n    tool: MyDatasourceSearch # Assuming 'MyDatasourceSearch' is a defined datasource tool in ELITEA\n    input: [user_query]\n    output: [search_results]\n    transition: Display Results # Transition to 'Display Results' node after searching\n\n  - id: Display Results # Define an 'llm' node to display search results to the user\n    type: llm\n    input: [search_results]\n    prompt:\n      type: fstring\n      value: \"Here are the search results I found: {search_results}\"\n    transition: END # End agent execution after displaying results\n</code></pre> <p>Explanation:</p> <p>This example demonstrates a simpler linear flow:</p> <ol> <li><code>Search Datasource</code> (tool node): After the <code>tool</code> node, which searches a datasource, completes its search and retrieves <code>search_results</code>, the <code>transition: Display Results</code> line ensures the agent moves to the \"Display Results\" node.</li> <li><code>Display Results</code> (llm node):  Once the \"Display Results\" node has presented the <code>search_results</code> to the user, the <code>transition: END</code> line is used to terminate the agent's execution, as this is the final step in this particular workflow.</li> </ol> <p>These examples illustrate how the <code>transition</code> attribute is fundamental for defining the sequential flow of actions within your Pipeline Agent, allowing you to create workflows that move from one node to the next in a controlled and logical manner, ultimately leading to the desired <code>END</code> state.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#conditions","title":"Conditions","text":"<p>The <code>condition</code> attribute allows a node to conditionally transition to different next nodes based on whether a specific rule or condition evaluates to true or false. Conditions are defined using Jinja2 templating language, providing powerful logic capabilities within your agent workflow.</p> <p>Common Attributes for <code>condition</code>:</p> <ul> <li><code>condition</code>: Indicates that the transition from this node is conditional.<ul> <li><code>condition_input</code>: (Optional, but strongly recommended) A list of state variables that will be used as input to evaluate the condition. Providing <code>condition_input</code> makes your conditions more readable and efficient by limiting the scope of data Jinja2 needs to access. If omitted, Jinja2 might have access to the entire <code>state</code> or even <code>chat_history</code>, potentially increasing processing overhead.</li> <li><code>condition_definition</code>: (Mandatory) The actual rule or condition to be evaluated, written using Jinja2 templating syntax.</li> </ul> </li> </ul> <p>Jinja2 Templating in <code>condition_definition</code>:</p> <ul> <li>Use <code>{% if &lt;condition&gt; %}</code> to start a conditional block.</li> <li>Use <code>{% elif &lt;condition&gt; %}</code> for \"else if\" conditions (optional, you can have multiple <code>elif</code> blocks).</li> <li>Use <code>{% else %}</code> for the \"else\" case (optional).</li> <li>Use <code>{% endif %}</code> to close the conditional block.</li> <li>Within the Jinja2 template, you can access state variables listed in <code>condition_input</code> or, if <code>condition_input</code> is omitted, potentially access the entire <code>state</code> or <code>messages</code>.</li> <li>Use Jinja2 filters like <code>|lower</code> to modify data (e.g., <code>input|lower</code> converts user input to lowercase for case-insensitive comparisons).</li> </ul> <p>Example 1: <code>condition</code> within an <code>llm</code> node - User Approval Check</p> <pre><code>- id: Get User Story Details\n  type: llm\n  input: [input]\n  prompt:\n    type: string\n    value: \"Please provide the description, Jira Project ID, EPIC ID, and User Story Title.\"\n  output: [description, jira_project_id, epic_id, us_title]\n  structured_output: true\n  condition:\n    condition_input: [description, jira_project_id, epic_id, us_title, input] # Input variables for condition\n    condition_definition: |\n      {% if 'approved' in input|lower and description and jira_project_id and epic_id and us_title %} # Condition logic using Jinja2\n      Unified Content Aggregator # Node to transition to if condition is true\n      {% else %}\n      Conversation Partner # Node to transition to if condition is false\n      {% endif %}\n</code></pre> <p>Explanation:</p> <ul> <li><code>condition_input: [description, jira_project_id, epic_id, us_title, input]</code>: Specifies that these state variables will be used in the condition evaluation.</li> <li><code>condition_definition</code>: Defines the condition using Jinja2:<ul> <li><code>{% if 'approved' in input|lower and description and jira_project_id and epic_id and us_title %}</code>: Checks if the user's <code>input</code> (converted to lowercase) contains \"approved\" AND if <code>description</code>, <code>jira_project_id</code>, <code>epic_id</code>, and <code>us_title</code> state variables have values (are not empty).</li> <li>If the condition is true, the agent transitions to the node with <code>id: Unified Content Aggregator</code>.</li> <li><code>{% else %}</code>: If the condition is false.</li> <li>The agent transitions to the node with <code>id: Conversation Partner</code>.</li> <li><code>{% endif %}</code>: Closes the conditional block.</li> </ul> </li> </ul> <p>Example 2: <code>condition</code> with <code>elif</code> - Multiple Conditional Branches</p> <pre><code>condition:\n  condition_input: [input]\n  condition_definition: |\n    {% if 'approved' in input|lower %}\n    User Story Publisher # Transition to 'User Story Publisher' if user types 'approved'\n    {% elif 'datasource:' in input|lower %}\n    Special # Transition to 'Special' if user types 'datasource:'\n    {% elif 'finish' in input|lower %}\n    END # Transition to 'END' if user types 'finish'\n    {% else %}\n    User Feedback and Approval # Default transition if none of the above conditions are met\n    {% endif %}\n</code></pre> <p>Explanation: This example demonstrates using <code>elif</code> to create multiple conditional branches based on user input. The agent checks for different keywords in the <code>input</code> and transitions to different nodes accordingly.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#decisions","title":"Decisions","text":"<p>The <code>decision</code> attribute empowers a node to act as a branching point in your agent's workflow. It allows the agent to dynamically choose which node to execute next from a set of predefined options, based on the information it has gathered or the outcome of its current action. This introduces intelligent branching and conditional paths into your agent's behavior, making it more flexible and responsive.</p> <p>Common Attributes for <code>decision</code>:</p> <ul> <li><code>decision</code>: This is the main attribute that signals that a node will make a decision about the next step in the workflow. It's a container for the decision-making configuration.<ul> <li><code>nodes</code>: (Mandatory) This is a list of <code>node id</code>s representing the possible nodes that the agent can transition to from this decision point. These are the potential \"next steps\" the agent can take. You must list at least one node ID here.</li> <li><code>description</code>: (Optional) A brief textual explanation of the decision being made at this point. This is purely for documentation purposes and helps in understanding the agent's logic, especially in complex workflows. It's good practice to include a <code>description</code> for clarity.</li> <li><code>decisional_inputs</code>: (Optional, but strongly recommended) A list of <code>state</code> variables that will be used as input for the decision-making process. These are the pieces of information the agent will consider when choosing the next node. While technically optional in the YAML structure, providing <code>decisional_inputs</code> is highly recommended for making your decision logic clear, maintainable, and efficient. It explicitly tells the agent what information to focus on when making the decision.</li> <li><code>default_output</code>: (Mandatory) The <code>id</code> of the node to transition to if none of the specific decision conditions are met (or if the decision logic cannot determine a specific next node). This acts as a fallback path, ensuring that the agent always has a direction to proceed, even if the decision criteria are not explicitly satisfied. You must provide a valid <code>node id</code> as the <code>default_output</code>.</li> </ul> </li> </ul> <p>Example 1: <code>decision</code> within an <code>llm</code> node - Handling User Feedback</p> <pre><code>- id: User Feedback\n  type: llm\n  input: [enhanced_us, input]\n  prompt:\n    type: fstring\n    value: |\n      Please review the enhanced user story:\n      ---\n      {enhanced_us}\n      ---\n      Provide your feedback. Type \"Publish\" to publish the story, \"Edit\" to request changes, or \"Finish\" to end.\n  output: [user_feedback]\n  decision:\n    nodes: [\"Publish Story\", \"Request Clarification\", \"END\", \"User Feedback\"] # Possible next nodes (including looping back to itself)\n    description: \"Decide next step based on user feedback keywords: Publish, Edit, Finish.\" # Description of the decision\n    decisional_inputs: [\"input\"] # Input for decision making: user's latest input\n    default_output: \"User Feedback\" # Default: loop back to 'User Feedback' if input doesn't match keywords\n</code></pre> <p>Explanation:</p> <p>In this enhanced example, the <code>decision</code> attribute is used within the \"User Feedback\" <code>llm</code> node to determine the agent's next action based on the user's response to the user story review prompt.</p> <ol> <li><code>nodes: [\"Publish Story\", \"Request Clarification\", \"END\", \"User Feedback\"]</code>: This list defines the possible nodes the agent can transition to:<ul> <li><code>\"Publish Story\"</code>: To publish the user story.</li> <li><code>\"Request Clarification\"</code>: To ask the user for more details or clarification if they request edits.</li> <li><code>\"END\"</code>: To terminate the agent's execution if the user is finished.</li> <li><code>\"User Feedback\"</code>:  Importantly, it also includes the node itself (<code>\"User Feedback\"</code>). This allows the agent to loop back to the same node if the user's input doesn't clearly indicate one of the other options.</li> </ul> </li> <li><code>description: \"Decide next step based on user feedback keywords: Publish, Edit, Finish.\"</code>: This provides a human-readable description of the decision logic, stating that the agent will look for keywords in the user's feedback to decide the next step.</li> <li><code>decisional_inputs: [\"input\"]</code>: This specifies that the decision will be based on the <code>input</code> state variable, which holds the user's latest message (their feedback in this case).</li> <li><code>default_output: \"User Feedback\"</code>: This is the fallback option. If the agent's decision logic (defined in the background code, not in YAML) cannot clearly determine if the user wants to \"Publish\", \"Edit\", or \"Finish\" based on their <code>input</code>, the agent will default to transitioning back to the <code>\"User Feedback\"</code> node itself. This effectively re-prompts the user for clearer instructions, ensuring the agent doesn't get stuck or proceed incorrectly if the user input is ambiguous.</li> </ol> <p>In summary, the <code>decision</code> attribute provides a powerful mechanism for creating dynamic and intelligent agents that can adapt their workflow based on user input, data analysis, or the outcomes of previous steps. By carefully defining the <code>nodes</code>, <code>decisional_inputs</code>, and <code>default_output</code>, you can build agents that make informed choices and follow branching paths to achieve complex goals.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#creating-your-first-pipeline-agent-in-elitea","title":"Creating Your First Pipeline Agent in ELITEA","text":"<p>Ready to build your own agent? Here's a step-by-step instructions to creating a Pipeline Agent in ELITEA:</p> <ol> <li>Start a New Agent:<ul> <li>Look for the \"+ Agent\" button, located in the top right corner of the ELITEA interface. Click this button to begin creating a new agent.</li> <li>This action will open the Configuration tab for your new agent, where you'll define its settings and behavior.</li> </ul> </li> <li>Name and Describe Your Agent:<ul> <li>In the Configuration tab, you'll see fields for Name and Description.</li> <li>Name: Give your agent a clear and descriptive name. This name will help you easily identify your agent in ELITEA. For example, \"User Story Creator\" or \"Code Documentor\".</li> <li>Description: Write a brief description of what your agent does. This helps you and others understand the agent's purpose at a glance. For example, \"Agent to guide users through creating user stories in Jira.\"</li> </ul> </li> <li>Add Tags (Optional):<ul> <li>The Tags input box allows you to categorize your agent using keywords or labels.</li> <li>You can either type in a new tag name and press Enter, or select from a list of tags you've used before.</li> <li>Tags are helpful for organizing and searching for your agents later, especially if you create many of them.</li> </ul> </li> <li>Choose the Agent Type:<ul> <li>Locate the Agent type dropdown menu in the Configuration tab.</li> <li>Select \"Pipeline\" from the dropdown. This tells ELITEA that you want to create a Pipeline Agent, which uses the YAML-based framework we're discussing in this guide.</li> </ul> </li> <li>Provide YAML Instructions:<ul> <li>This is the heart of creating a Pipeline Agent! In the Instructions field, you will write the YAML code that defines your agent's workflow.</li> <li>Refer to the previous sections of this guide to understand how to write YAML instructions, define nodes, transitions, conditions, and more.</li> <li>Important: Make sure your YAML is correctly formatted, especially the indentation. You can use the YAML Indentation Corrector prompt mentioned in the Troubleshooting section if needed.</li> </ul> </li> <li>Add and Set Up Toolkits:<ul> <li>Scroll down to the Toolkits section in the agent configuration.</li> <li>Toolkits provide your agent with access to various functionalities within ELITEA.</li> <li>Click \"Add Toolkit\" and choose the toolkits your agent needs to perform its tasks. For example, you might need a Jira toolkit to interact with Jira, or a data source toolkit to access external information. Remember to add all agents, datasources and prompts involved in the YAML instructions, as well as other toolkits (if required).</li> <li>After adding a toolkit, you may need to configure it. This might involve, selecting correct version of the toolkit (agent, prompt), selecting corresponding tool (datasource) providing API keys, connection details, or other settings specific to the toolkit. Follow the instructions provided for each toolkit you add.</li> </ul> </li> <li>Configure Conversation Starter and Welcome Message (Optional):<ul> <li>These optional settings allow you to customize the initial interaction with your agent.</li> <li>Conversation Starter: This is a predefined set of questions or prompts that are suggested to the user when they first start a conversation with your agent. It can help guide users on how to interact with the agent.</li> <li>Welcome Message: This is a message that your agent automatically sends to the user when a conversation begins. It can be used to greet the user, explain what the agent can do, or provide initial instructions.</li> <li>You can configure these in the Conversation Starter and Welcome Message sections of the agent configuration.</li> </ul> </li> <li>Save Your Agent:<ul> <li>Once you have filled in the necessary information, provided your YAML instructions, and added toolkits, click the \"Save\" button (usually located at the bottom or top of the configuration page).</li> <li>Saving your agent makes your configuration live and ready to use.</li> </ul> </li> </ol> <p></p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#best-practices-and-use-cases","title":"Best Practices and Use Cases","text":"<ul> <li>Start with a clear goal: Define what you want your agent to achieve before you start building.</li> <li>Break down complex tasks: Divide large tasks into smaller, manageable nodes.</li> <li>Use descriptive node IDs: Choose names that clearly indicate the purpose of each node.</li> <li>Plan your transitions carefully: Ensure a logical flow between nodes.</li> <li>Test your agent thoroughly:  Run your agent through different scenarios to identify and fix any issues.</li> <li>Utilize conditions and decisions for dynamic behavior: Make your agent more intelligent by allowing it to adapt based on user input and data.</li> <li>Leverage the <code>function</code> node for efficiency: When interacting with ELITEA entities, consider using the <code>function</code> node for more direct and potentially token-saving interactions.</li> <li>For Simplicity and Quick Setup, Choose <code>tool</code> nodes: If you are new to Pipeline Agents or prioritize ease of use and rapid agent creation over advanced configuration and token optimization, the <code>tool</code> node is an excellent starting point.  <code>tool</code> nodes offer a simpler way to integrate ELITEA entities (prompts, agents, datasources) into your workflow with less configuration, making them ideal for quickly building functional agents, especially for users who are not yet comfortable with the more detailed input mapping required by <code>function</code> nodes.</li> </ul> <p>Use Cases:</p> <p>Pipeline Agents in ELITEA are particularly powerful for creating \"master\" agents. These master agents are designed for orchestration, meaning they manage and direct the flow between various other agents and ELITEA entities to achieve complex goals. Let's explore some detailed use cases:</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-1-user-story-creation-workflow-manager","title":"Use Case 1: User Story Creation Workflow Manager","text":"<p>Scenario: This agent guides a user through the entire process of creating a well-defined user story in Jira, from gathering initial requirements to publishing the final version.</p> <p>Solution: This agent uses a combination of <code>llm</code> nodes for interacting with the user and <code>function</code> nodes to process information and interact with Jira. The <code>condition</code> node is used for decision-making based on user input.</p> <p>YAML Instructions:</p> <pre><code>state:\n  jira_project_id: str\n  epic_id: str\n  us_title: str\n  description: str\n  input: str\n  messages: list\n  filtered_sumarized_info: str\n  draft_us: str\n  info_from_datasource: str\n  enhanced_us: str\nentry_point: Conversation Partner\ninterrupt_after:\n  - Conversation Partner\n  - User Feedback and Approval\nnodes:\n  - id: Conversation Partner\n    type: llm\n    input: [input]\n    prompt:\n      type: string\n      value: |\n        To create a new User Story, I need some information from you. Could you please provide the following details in the specified format?\n        - **Jira Project ID**: (e.g., PAYMENTS)\n        - **EPIC ID**: (e.g., PAYMENTS-128)\n        - **Title**: (e.g., Checkout functionality)\n        - **Description**: (e.g., \"The informative description of future US.\")\n        Once you provide this information, I will ask for your approval (should be 'approved' word) to start the User Story creation process. Make your instructions to user highlighted by using markdown highlight for text.\n    output: [description, jira_project_id, epic_id, us_title]\n    structured_output: true\n    condition:\n      condition_input: [description, jira_project_id, epic_id, us_title, input]\n      condition_definition: |\n        {% if 'approved' in input|lower and description and jira_project_id and epic_id and us_title %}\n        Unified Content Aggregator\n        {% else %}\n        Conversation Partner\n        {% endif %}\n  - id: Unified Content Aggregator\n    type: function\n    input: [epic_id, description]\n    output: [filtered_sumarized_info]\n    input_mapping:\n      task:\n        type: fstring\n        value: |\n          Epic ID: {epic_id}.\n          Description: {description}\n      chat_history:\n        type: fixed\n        value: []\n    type: function\n    transition: Draft User Story Creator\n  - id: Draft User Story Creator\n    type: function\n    input: [filtered_sumarized_info]\n    output: [draft_us]\n    input_mapping:\n      input:\n        type: variable\n        value: filtered_sumarized_info\n    transition: User Story Enhance Aggregator\n  - id: User Story Enhance Aggregator\n    type: function\n    input: [draft_us]\n    output: [enhanced_us]\n    input_mapping:\n      task:\n        type: fstring\n        value: |\n          Enhance the Narrative, Description and Scenarios with AC's for the given draft User Story: {draft_us}\n      chat_history:\n        type: fixed\n        value: []\n    type: function\n    transition: User Feedback and Approval\n  - id: User Feedback and Approval\n    type: llm\n    input: [input, enhanced_us, info_from_datasource]\n    output: [enhanced_us]\n    prompt:\n      type: fstring\n      value: |\n        When reviewing and updating a user story, ensure its structure and format remain consistent with the original, unless the user specifically requests changes. Present the updated user story in its entirety, enriched with any necessary information, clearly and concisely for user feedback. Use the following variables to guide the process:\n        - **Current User Input:** {input}\n        - **Information from Data Source:** {info_from_datasource}\n        - **Enhanced User Story:** {enhanced_us}\n        Users can provide feedback through free form queries, which will be controlled by the \"Current User Input\" value. If the query contains \"datasource:\", access and incorporate specific data from the identified sources into the enhanced user story via \"Information from Data Source\". Present the full \"Enhanced User Story\" to the user, ensuring that the structure and format remain unchanged.\n        Approval of the enhanced user story can be given by typing \"approved,\" which will publish it to Jira. If no further changes or publication is desired, the user can type \"finish\" to conclude the session.\n    condition:\n      condition_input: [input]\n      condition_definition: |\n        {% if 'approved' in input|lower %}\n        User Story Publisher\n        {% elif 'datasource:' in input|lower %}\n        Special\n        {% elif 'finish' in input|lower %}\n        END\n        {% else %}\n        User Feedback and Approval\n        {% endif %}\n  - id: Special\n    type: function\n    input: [input]\n    output: [info_from_datasource]\n    input_mapping:\n      task:\n        type: variable\n        value: input\n      chat_history:\n        type: fixed\n        value: []\n    type: function\n    transition: User Feedback and Approval\n  - id: User Story Publisher\n    type: function\n    input: [jira_project_id, epic_id, enhanced_us]\n    input_mapping:\n      task:\n        type: fstring\n        value: |\n          Create User Story in Jira using the following details:\n          Project Id: {jira_project_id}\n          Parent Jira Issue ID: {epic_id}\n          User Story content: {enhanced_us}\n      chat_history:\n        type: fixed\n        value: []\n    type: function\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>state</code>: Defines the information the agent will remember, such as Jira details, user input, and the evolving user story.</li> <li><code>entry_point: Conversation Partner</code>: The agent starts by engaging the user with the \"Conversation Partner\" node.</li> <li><code>interrupt_after</code>: Specifies points where the agent will pause and allow user intervention after the \"Conversation Partner\" and \"User Feedback and Approval\" nodes.</li> <li><code>nodes</code>:<ul> <li><code>Conversation Partner</code> (<code>llm</code> node):<ul> <li>Purpose: Gathers initial information (Jira Project ID, Epic ID, Title, Description) from the user using a prompt.</li> <li><code>input: [input]</code>: Takes the user's latest input.</li> <li><code>prompt</code>:  Instructs the user on what information to provide and in what format.</li> <li><code>output: [description, jira_project_id, epic_id, us_title]</code>: Extracts the provided information and stores it in the agent's <code>state</code>.</li> <li><code>condition</code>: Checks if the user has provided all necessary information and typed 'approved'. If so, it moves to \"Unified Content Aggregator\"; otherwise, it loops back to \"Conversation Partner\".</li> </ul> </li> <li><code>Unified Content Aggregator</code> (<code>function</code> node):<ul> <li>Purpose:  Prepares input for the next step by combining the Epic ID and Description.</li> <li><code>input: [epic_id, description]</code>: Uses the Epic ID and Description from the <code>state</code>.</li> <li><code>output: [filtered_sumarized_info]</code>: Stores the combined information.</li> <li><code>input_mapping</code>: Creates a formatted string (<code>fstring</code>) with the Epic ID and Description.</li> <li><code>transition: Draft User Story Creator</code>: Moves to the next step.</li> </ul> </li> <li><code>Draft User Story Creator</code> (<code>function</code> node):<ul> <li>Purpose: Creates a draft user story. This would likely call an internal ELITEA function or another agent.</li> <li><code>input: [filtered_sumarized_info]</code>: Uses the combined information from the previous step.</li> <li><code>output: [draft_us]</code>: Stores the generated draft user story.</li> <li><code>input_mapping</code>:  Passes the <code>filtered_sumarized_info</code> as input.</li> <li><code>transition: User Story Enhance Aggregator</code>: Proceeds to the enhancement phase.</li> </ul> </li> <li><code>User Story Enhance Aggregator</code> (<code>function</code> node):<ul> <li>Purpose: Enhances the draft user story with narratives, descriptions, and acceptance criteria.</li> <li><code>input: [draft_us]</code>: Takes the draft user story as input.</li> <li><code>output: [enhanced_us]</code>: Stores the enhanced user story.</li> <li><code>input_mapping</code>: Uses an <code>fstring</code> to instruct the enhancement process.</li> <li><code>transition: User Feedback and Approval</code>: Moves to get user feedback.</li> </ul> </li> <li><code>User Feedback and Approval</code> (<code>llm</code> node):<ul> <li>Purpose: Presents the enhanced user story to the user for review and gathers feedback.</li> <li><code>input: [input, enhanced_us, info_from_datasource]</code>: Uses the current user input, the enhanced user story, and any information from external data sources.</li> <li><code>prompt</code>:  Provides instructions to the user on how to provide feedback, request data, approve, or finish.</li> <li><code>output: [enhanced_us]</code>: Updates the enhanced user story based on feedback.</li> <li><code>condition</code>: Directs the flow based on user input:<ul> <li><code>approved</code>: Moves to \"User Story Publisher\".</li> <li><code>datasource:</code>: Moves to \"Special\" to fetch data.</li> <li><code>finish</code>: Ends the agent execution.</li> <li>Other input: Loops back to \"User Feedback and Approval\".</li> </ul> </li> </ul> </li> <li><code>Special</code> (<code>function</code> node):<ul> <li>Purpose: Handles requests for incorporating data from external sources.</li> <li><code>input: [input]</code>: Takes the user's input containing the datasource request.</li> <li><code>output: [info_from_datasource]</code>: Stores the fetched data.</li> <li><code>input_mapping</code>: Passes the user's input as the task.</li> <li><code>transition: User Feedback and Approval</code>: Returns to the feedback stage.</li> </ul> </li> <li><code>User Story Publisher</code> (<code>function</code> node):<ul> <li>Purpose: Publishes the approved user story to Jira.</li> <li><code>input: [jira_project_id, epic_id, enhanced_us]</code>: Uses the Jira details and the final user story.</li> <li><code>input_mapping</code>: Creates a formatted string with the Jira details and user story content for publishing.</li> <li><code>transition: END</code>: Completes the agent execution.</li> </ul> </li> </ul> </li> </ol>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-2-user-story-review-workflow-manager","title":"Use Case 2: User Story Review Workflow Manager","text":"<p>Scenario: This agent assists in reviewing and updating existing user stories in Jira. Solution: Similar to the creation workflow, this agent uses <code>llm</code> for user interaction and <code>function</code> nodes to read and update Jira. <code>condition</code> manages the flow based on user input.</p> <p>YAML Instructions:</p> <pre><code>entry_point: Conversation Partner\ninterrupt_after:\n  - Conversation Partner\n  - User Feedback and Approval\nnodes:\n  - id: Conversation Partner\n    type: llm\n    prompt:\n      type: string\n      value: |\n      To review and update User Story, I need some information from you. Could you please provide the following details in the specified format?\n      - **JIRA Ticket ID**: (e.g., US-128)\n      Once you provide this information, I will ask for your approval (should be 'approved' word) to start the US review process. Make your instructions to user highlighted by using markdown highlight for text.\n    condition:\n      condition_input: [messages]\n      condition_definition: |\n        {% if 'approved' in messages[-1]['content']|lower %}\n        Jira_Read\n        {% else %}\n        Conversation Partner\n        {% endif %}\n  - id: Jira_Read\n    type: function\n    transition: User Feedback and Approval\n  - id: User Feedback and Approval\n    type: llm\n    prompt:\n      type: string\n      value: |\n      Ensure that after each review and update, the structure and format of the updated User Story remain consistent with the original, unless the user explicitly requests changes.\n      Present the user story for user review and approval.\n        - **Free format instructions** to make changes.\n        - **Type 'datasource:'** followed by instructions to enhance using datasources.\n        - **Type 'approved'** to publish the enhanced User Story to Jira.\n        - **Type 'finish'** if you don't want to publish the enhanced User Story to Jira or make further changes.\n    condition:\n      condition_input: [messages]\n      condition_definition: |\n        {% if 'approved' in messages[-1]['content']|lower %}\n        Jira_Update\n        {% elif 'datasource:' in messages[-1]['content']|lower %}\n        Special\n        {% elif 'finish' in messages[-1]['content']|lower %}\n        END\n        {% else %}\n        User Feedback and Approval\n        {% endif %}\n  - id: Special\n    type: function\n    transition: User Feedback and Approval\n  - id: Jira_Update\n    type: function\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>entry_point: Conversation Partner</code>: The agent starts by asking for the Jira Ticket ID.</li> <li><code>interrupt_after</code>: Allows user intervention after the initial information gathering and feedback stages.</li> <li><code>nodes</code>:<ul> <li><code>Conversation Partner</code> (<code>llm</code> node):<ul> <li>Purpose: Gets the Jira Ticket ID from the user.</li> <li><code>prompt</code>: Asks for the Jira Ticket ID and approval to start the review.</li> <li><code>condition</code>: Checks if the last message contains 'approved' (case-insensitive). If yes, moves to \"Jira_Read\"; otherwise, stays at \"Conversation Partner\".</li> </ul> </li> <li><code>Jira_Read</code> (<code>function</code> node):<ul> <li>Purpose: Reads the user story details from Jira using the provided Ticket ID.</li> <li><code>transition: User Feedback and Approval</code>: Proceeds to the feedback stage.</li> </ul> </li> <li><code>User Feedback and Approval</code> (<code>llm</code> node):<ul> <li>Purpose: Presents the user story for review and gathers feedback.</li> <li><code>prompt</code>: Provides instructions on how to provide feedback, request data, approve, or finish.</li> <li><code>condition</code>: Directs the flow based on the last message content:<ul> <li><code>approved</code>: Moves to \"Jira_Update\".</li> <li><code>datasource:</code>: Moves to \"Special\".</li> <li><code>finish</code>: Ends the execution.</li> <li>Other input: Loops back to \"User Feedback and Approval\".</li> </ul> </li> </ul> </li> <li><code>Special</code> (<code>function</code> node):<ul> <li>Purpose: Handles requests for incorporating data from external sources (implementation details would be similar to the previous use case).</li> <li><code>transition: User Feedback and Approval</code>: Returns to the feedback stage.</li> </ul> </li> <li><code>Jira_Update</code> (<code>function</code> node):<ul> <li>Purpose: Updates the user story in Jira with the reviewed content.</li> <li><code>transition: END</code>: Completes the agent execution.</li> </ul> </li> </ul> </li> </ol>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-3-code-documentation","title":"Use Case 3: Code Documentation","text":"<p>Scenario: This agent automates the process of generating technical documentation for code files. Solution: This agent uses a <code>tool</code> node to get a list of files and a <code>loop</code> node to iterate through each file and generate documentation.</p> <p>YAML Instructions:</p> <pre><code>entry_point: File List Extractor\nnodes:\n  - id: File List Extractor\n    type: tool\n    transition: Documentor\n  - id: Documentor\n    type: loop\n    task: \"Formulate ALL file paths from chat_history as a list of inputs.\" \n    tool: Code Documentation\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>entry_point: File List Extractor</code>: The agent starts by extracting a list of files.</li> <li><code>nodes</code>:<ul> <li><code>File List Extractor</code> (<code>tool</code> node):<ul> <li>Purpose: Uses a pre-built tool (likely within ELITEA) to get a list of relevant files.</li> <li><code>transition: Documentor</code>: Moves to the documentation generation phase.</li> </ul> </li> <li><code>Documentor</code> (<code>loop</code> node):<ul> <li>Purpose: Iterates through the list of files and generates documentation for each.</li> <li><code>task</code>: Defines how to format the input for the \"Code Documentation\" tool for each file. It instructs the agent to take file paths from the <code>chat_history</code> and format them.</li> <li><code>tool: Code Documentation</code>:  This refers to an ELITEA entity (likely a prompt or another agent) responsible for generating documentation for a given file path.</li> <li><code>transition: END</code>: Completes the agent execution after processing all files.</li> </ul> </li> </ul> </li> </ol>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-4-orchestrating-us-creation-and-test-case-generation","title":"Use Case 4: Orchestrating US Creation and Test Case Generation","text":"<p>Scenario: This master agent orchestrates the creation of a user story followed by the generation of test cases for that user story. Solution: This agent uses <code>tool</code> nodes to trigger other specialized agents for user story creation and test case generation.</p> <p>YAML Instructions:</p> <pre><code>entry_point: BA Agent - Create User Stories\nnodes:\n  - id: BA Agent - Create User Stories\n    type: tool\n    transition: QA Agent - Create Test Cases\n  - id: QA Agent - Create Test Cases\n    type: tool\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>entry_point: BA Agent - Create User Stories</code>: The agent starts by triggering the \"BA Agent - Create User Stories\".</li> <li><code>nodes</code>:<ul> <li><code>BA Agent - Create User Stories</code> (<code>tool</code> node):<ul> <li>Purpose: Triggers another ELITEA agent specifically designed for user story creation.</li> <li><code>transition: QA Agent - Create Test Cases</code>: Once the user story is created, it moves to the test case generation phase.</li> </ul> </li> <li><code>QA Agent - Create Test Cases</code> (<code>tool</code> node):<ul> <li>Purpose: Triggers another ELITEA agent responsible for generating test cases for the newly created user story.</li> <li><code>transition: END</code>: Completes the agent execution after test cases are generated.</li> </ul> </li> </ul> </li> </ol> <p>This use case highlights the power of Pipeline Agents for orchestration. The master agent doesn't perform the detailed tasks itself but delegates them to specialized agents, creating a modular and efficient workflow.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-5-master-bulk-user-story-creation-workflow-manager","title":"Use Case 5: Master - Bulk User Story Creation Workflow Manager","text":"<p>Scenario: This agent acts as a central hub for creating multiple user stories at once and then publishing them either to Jira or Confluence, depending on the user's provided information. Solution: This agent utilizes an <code>llm</code> node for initial input, a <code>tool</code> node to extract relevant information, a <code>tool</code> node to handle the bulk creation, another <code>llm</code> node to prepare data for publishing, and a <code>decision</code> node to route to the appropriate publishing function (<code>tool</code> nodes for Jira and Confluence).</p> <p>YAML Instructions:</p> <pre><code>entry_point: User Input\nnodes:\n  - id: User Input\n    type: llm\n    prompt:\n      type: string\n      value: |\n        Act as a router and route the user query to the appropriate node using the provided user input.\n    transition: Jira Epic Extractor\n  - id: Jira Epic Extractor\n    type: tool\n    transition: Bulk User Stories Creator\n  - id: Bulk User Stories Creator\n    type: tool\n    transition: Story Creator\n  - id: Story Creator\n    type: llm\n    prompt:\n      type: string\n      value: |\n        For publishing, provide the Project and EPIC if using the \"Jira Bulk US Publisher\" node. Provide the Confluence Space Key and Confluence  Parent Page ID if using the \"Confluence Bulk US Publisher\" node. Use the created bulk User Stories from the chat history and pass them unchanged to the next node. Carefully prepare the data for the next node including the initial provided by user input (first message in the chat history).\n    decision:\n      nodes:\n        - Confluence Bulk US Publisher\n        - Jira Bulk US Publisher\n      description: |\n        Select \"Confluence Bulk US Publisher\" if a Confluence Parent Page ID is provided in the user input. If not, select \"Jira Bulk US Publisher.\" Ensure publishing occurs in only one node based on the presence of the Confluence Parent Page ID.\n  - id: Confluence Bulk US Publisher\n    type: tool\n    transition: END\n  - id: Jira Bulk US Publisher\n    type: tool\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>entry_point: User Input</code>: The agent begins by receiving user input in the \"User Input\" node.</li> <li><code>nodes</code>:<ul> <li><code>User Input</code> (<code>llm</code> node):<ul> <li>Purpose: Acts as an initial entry point, receiving the user's request for bulk user story creation. While the prompt itself is simple, in a real-world scenario, this node might contain more elaborate instructions to guide the user on providing the necessary information for bulk creation.</li> <li><code>prompt</code>:  The prompt instructs the LLM to act as a router, preparing to send the user's query to the next appropriate node.</li> <li><code>transition: Jira Epic Extractor</code>:  The agent proceeds to the \"Jira Epic Extractor\" node. Note that the naming of this transition might be slightly misleading as the agent intends to handle both Jira and Confluence publishing. A more generic name like \"Extract Information\" might be more accurate.</li> </ul> </li> <li><code>Jira Epic Extractor</code> (<code>tool</code> node):<ul> <li>Purpose: This node is intended to extract relevant information from the user's input, such as the Jira Epic under which the user stories should be created.</li> <li><code>transition: Bulk User Stories Creator</code>: After extracting the necessary information (presumably the Jira Epic), the agent moves to the \"Bulk User Stories Creator\" node.</li> </ul> </li> <li><code>Bulk User Stories Creator</code> (<code>tool</code> node):<ul> <li>Purpose: This node utilizes a pre-built tool within ELITEA to handle the actual creation of multiple user stories. The specifics of this tool (e.g., how it receives the user story data) are not detailed in the YAML.</li> <li><code>transition: Story Creator</code>: Once the bulk user stories are created, the agent transitions to the \"Story Creator\" node to prepare them for publishing.</li> </ul> </li> <li><code>Story Creator</code> (<code>llm</code> node):<ul> <li>Purpose: This node prepares the created user stories and gathers necessary publishing information from the user.</li> <li><code>prompt</code>: The prompt instructs the user to provide either Jira Project and EPIC details or Confluence Space Key and Confluence  Parent Page ID, depending on where they want to publish the stories. It also emphasizes passing the created bulk User Stories from the chat history to the next node.</li> <li><code>decision</code>: This attribute defines the logic for choosing the appropriate publishing node.<ul> <li><code>nodes</code>: Lists the possible next nodes: \"Confluence Bulk US Publisher\" and \"Jira Bulk US Publisher\".</li> <li><code>description</code>: Explains the decision-making process: if a Confluence Parent Page ID is present in the user input, route to the Confluence publisher; otherwise, route to the Jira publisher. This ensures that the publishing happens in only one of the nodes.</li> </ul> </li> </ul> </li> <li><code>Confluence Bulk US Publisher</code> (<code>tool</code> node):<ul> <li>Purpose: This node utilizes a function within ELITEA to publish the bulk user stories to Confluence.</li> <li><code>transition: END</code>: After publishing to Confluence, the agent's execution is complete.</li> </ul> </li> <li><code>Jira Bulk US Publisher</code> (<code>tool</code> node):<ul> <li>Purpose: This node utilizes a function within ELITEA to publish the bulk user stories to Jira.</li> <li><code>transition: END</code>: After publishing to Jira, the agent's execution is complete.</li> </ul> </li> </ul> </li> </ol> <p>This use case demonstrates a more complex orchestration scenario where the Pipeline Agent acts as a smart router, guiding the user through bulk operations and making decisions based on the provided information to ensure the user stories are published to the correct platform.</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-6-automated-github-code-documentation","title":"Use Case 6: Automated GitHub Code Documentation","text":"<p>Use Case Title: GitHub Code Documentation Generator</p> <p>Scenario: This agent automates the process of generating technical documentation for code files directly from a GitHub repository. It retrieves a list of code files from a specified GitHub repository, generates documentation for each file, and then publishes the generated documentation back to a dedicated documentation branch within the same repository.</p> <p>Solution: This agent leverages the <code>loop_tool</code> node for efficient processing of multiple files. It uses a <code>function</code> node as the initial <code>tool</code> in <code>loop_tool</code> to get the list of code files from GitHub. Then, for each file, it uses a <code>loop_tool</code> (Code Documentation agent - assumed to be pre-existing in ELITEA) to generate the documentation. Finally, it would ideally include a node (not shown in the provided YAML, but conceptually needed) to publish the documentation back to the GitHub repository.</p> <p>YAML Instructions:</p> <pre><code>state:\n  messages: list\n  input: str\n  file_listing: str\nentry_point: File List Extractor\nnodes:\n  - id: File List Extractor\n    type: function\n    input: [input]\n    output: [file_listing]\n    input_mapping:\n      task:\n        type: variable\n        value: input\n      chat_history:\n        type: fixed\n        value: []\n    transition: Documentor\n  - id: Documentor\n    type: loop\n    input: [file_listing] # Corrected input to be file_listing\n    task: \"Formulate ALL file paths from file_listing as a list of inputs. The input values should be of format \\\"{\\\"task\\\": \\\"&lt;file path from file_listing&gt;\\\", \\\"chat_history\\\": [&lt;actual chat history&gt;]}\\\"\" # Improved task instruction\n    tool: Code Documentation # Assuming 'Code Documentation' is an ELITEA agent\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>state</code>: Defines the agent's memory, including:<ul> <li><code>messages</code>:  Conversation history.</li> <li><code>input</code>: User input.</li> <li><code>file_listing</code>:  Will store the list of files retrieved from GitHub.</li> </ul> </li> <li><code>entry_point: File List Extractor</code>: The agent starts by executing the \"File List Extractor\" node.</li> <li><code>nodes</code>:<ul> <li><code>File List Extractor</code> (<code>function</code> node):<ul> <li>Purpose: Retrieves a list of code files from a GitHub repository. This node is designed to call an ELITEA function (or potentially an agent or tool) that interacts with the GitHub API to get the file listing.</li> <li><code>type: function</code>: Specifies this is a <code>function</code> node.</li> <li><code>input: [input]</code>: Takes user input (likely containing GitHub repository details) as input.</li> <li><code>output: [file_listing]</code>: Stores the retrieved list of files in the <code>file_listing</code> state variable.</li> <li><code>input_mapping</code>: Defines how input is prepared for the function call:<ul> <li><code>task</code>: Maps the <code>input</code> state variable to the <code>task</code> parameter of the function. It assumes the function expects the repository details as the 'task'.</li> <li><code>chat_history</code>: Sets <code>chat_history</code> to an empty list, as chat history is likely not relevant for fetching file lists.</li> </ul> </li> <li><code>transition: Documentor</code>:  After retrieving the file list, the agent moves to the \"Documentor\" node.</li> </ul> </li> <li><code>Documentor</code> (<code>loop</code> node):<ul> <li>Purpose: Iterates through the <code>file_listing</code> and generates documentation for each file.</li> <li><code>type: loop</code>: Specifies this is a <code>loop</code> node.</li> <li><code>input: [file_listing]</code>: Takes the <code>file_listing</code> (list of files) as input for the loop.</li> <li><code>task</code>:  Provides instructions on how to create input for each loop iteration. It instructs the agent to:<ul> <li>Formulate file paths from the <code>file_listing</code> (corrected to use <code>file_listing</code> instead of <code>chat_history</code> as in the initial prompt).</li> <li>Format each file path as input in the specified JSON format.</li> </ul> </li> <li><code>tool: Code Documentation</code>: Specifies that for each file in the loop, the ELITEA entity named \"Code Documentation\" will be executed to generate documentation. This is assumed to be a pre-existing agent or prompt in ELITEA designed for code documentation.</li> <li><code>transition: END</code>: After documenting all files in the list, the agent's execution completes.</li> </ul> </li> </ul> </li> </ol> <p>Note: This YAML provides the core logic for fetching files and looping through them for documentation. A complete solution would likely require:</p> <ul> <li>A specific ELITEA function or agent to be called in \"File List Extractor\" that can interact with the GitHub API to retrieve file lists based on user input (e.g., repository URL, branch).</li> <li>A \"Code Documentation\" ELITEA agent or prompt that can generate documentation from a given file path.</li> <li>Potentially, additional nodes to handle publishing the generated documentation back to GitHub, which is not included in this YAML snippet.</li> </ul>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#use-case-7-confluence-page-data-extraction-to-csv","title":"Use Case 7: Confluence Page Data Extraction to CSV","text":"<p>Use Case Title: Confluence Page Metadata to CSV Exporter</p> <p>Scenario: This agent gathers metadata (title, description, page ID) from a list of Confluence pages (identified by labels) and saves this information into a CSV file. This is useful for creating reports, backups, or analyzing Confluence content.</p> <p>Solution: This agent utilizes the <code>loop_tool</code> node for efficient iteration over Confluence pages. It directly calls a Confluence toolkit's tool (<code>list_pages_with_label</code>) as the <code>tool</code> in <code>loop_tool</code> to get the list of pages. Then, for each page (implicitly within the <code>loop_tool</code>'s logic), it extracts the required metadata. Finally, it would require an additional node (not shown) to format and save the extracted data as a CSV file.</p> <p>YAML Instructions:</p> <pre><code>entry_point: listpages\nnodes:\n  - id: listpages\n    type: loop_tool\n    tool:  list_pages_with_label # Direct call to Confluence toolkit's 'list_pages_with_label' tool\n    structured_output: true # Expect structured output from the Confluence tool\n    loop_tool: Confluence helper # While 'Confluence helper' is listed, it might not be strictly needed for *just* data extraction in this simplified example.  A more direct approach might be possible depending on the 'list_pages_with_label' tool's output.\n    variables_mapping:\n      id: task # Map 'id' output variable from 'list_pages_with_label' to 'task' input (though 'Confluence helper' might not need 'task' in this context)\n      messages: chat_history # Map 'messages' to 'chat_history' (likely not used in this data extraction scenario)\n    transition: END\n</code></pre> <p>Detailed Explanation:</p> <ol> <li><code>entry_point: listpages</code>: The agent execution starts at the \"listpages\" node.</li> <li><code>nodes</code>:<ul> <li><code>listpages</code> (<code>loop_tool</code> node):<ul> <li>Purpose:  Retrieves a list of Confluence pages that have a specific label and extracts their metadata.</li> <li><code>type: loop_tool</code>: Specifies this is a <code>loop_tool</code> node.</li> <li><code>tool: list_pages_with_label</code>: Directly calls a tool from the Confluence toolkit named <code>list_pages_with_label</code>. This assumes that the Confluence toolkit is added to the agent and that <code>list_pages_with_label</code> is a valid tool within that toolkit that can retrieve a list of Confluence pages based on labels.</li> <li><code>structured_output: true</code>: Indicates that the output from the <code>list_pages_with_label</code> tool is expected to be in a structured format (likely a list of dictionaries or JSON objects), making it easier to map variables.</li> <li><code>loop_tool: Confluence helper</code>:  While <code>Confluence helper</code> is listed as <code>loop_tool</code>, in this simplified example focused on data extraction, it might not be strictly necessary. The <code>list_pages_with_label</code> tool itself might be sufficient to retrieve the required metadata for each page.  A more efficient approach could potentially directly process the output of <code>list_pages_with_label</code> without needing a separate <code>loop_tool</code>. However, if further processing per page was needed (beyond just listing metadata), then <code>Confluence helper</code> (presumably an agent designed for Confluence page operations) would be relevant as the <code>loop_tool</code>.</li> <li><code>variables_mapping</code>: Defines how to map variables from the output of <code>list_pages_with_label</code> to the input of <code>Confluence helper</code> (though <code>Confluence helper</code>'s role is questionable in this data extraction context):<ul> <li><code>id: task</code>: Maps the <code>id</code> output variable from <code>list_pages_with_label</code> to the <code>task</code> input parameter.  The purpose of this mapping is unclear in this data extraction scenario, as <code>Confluence helper</code> might not need a 'task' for simple metadata extraction.</li> <li><code>messages: chat_history</code>: Maps the <code>messages</code> output variable to <code>chat_history</code>. This mapping is likely not relevant or used in this data extraction scenario.</li> </ul> </li> <li><code>transition: END</code>: After processing all pages (or after the <code>list_pages_with_label</code> tool completes its task), the agent execution ends.</li> </ul> </li> </ul> </li> </ol> <p>Note: This YAML provides a basic structure for extracting Confluence page metadata. A fully functional agent would likely require:</p> <ul> <li>The Confluence toolkit to be added and properly configured in the agent settings.</li> <li>A clear understanding of the output structure of the <code>list_pages_with_label</code> tool to ensure correct <code>variables_mapping</code>.</li> </ul> <p>Okay, I have thoroughly reviewed the \"Troubleshooting\" section of the Pipeline Agent Framework guide, considering the entire guide content and aiming for enhanced clarity, comprehensiveness, and user-friendliness. Here's the improved \"Troubleshooting\" section:</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#troubleshooting-your-pipeline-agents","title":"Troubleshooting Your Pipeline Agents","text":"<p>Building intelligent agents can sometimes involve a bit of debugging! This section is designed to be your go-to guide for diagnosing and resolving common issues you might encounter while creating and running Pipeline Agents in ELITEA.</p> <p>The First Step: Pay Attention to Error Messages!</p> <p>Whenever your agent encounters a problem during execution, ELITEA will display error messages directly in the Chat window. These error messages are your most valuable first clue!  Carefully read and understand these messages, as they often pinpoint the exact location and nature of the issue in your YAML instructions.</p> <p>Here's a breakdown of common problems and step-by-step solutions:</p> <ul> <li> <p>YAML Syntax Errors: The Foundation is Key</p> <ul> <li>Problem: Your agent fails to load or starts with errors due to fundamental mistakes in the YAML structure itself.</li> <li>Solution: YAML is strict about syntax. Double-check these basics:<ul> <li>Correct Key-Value Pairs: Ensure every line follows the <code>key: value</code> format.</li> <li>Consistent Indentation (Spaces, Not Tabs!): YAML uses indentation to define hierarchy. Always use spaces for indentation, and be consistent with the number of spaces at each level.  Incorrect indentation is a very common cause of YAML errors.</li> <li>Proper List Formatting: List items must start with a hyphen <code>(-)</code>.</li> <li>Valid Data Types: Be mindful of the expected data types (e.g., <code>str</code>, <code>int</code>, <code>list</code>, <code>dict</code>) when defining your <code>state</code> and node attributes.</li> <li>No Tabs Allowed: Never use tabs for indentation in YAML. Only spaces are permitted.</li> </ul> </li> </ul> </li> <li> <p>YAML Indentation Issues: The Invisible Enemy</p> <ul> <li>Problem: Your agent's behavior is unpredictable, or it fails to load because of subtle indentation errors in your YAML.</li> <li>Solution: YAML indentation is crucial! Even if you think your indentation is correct, use the YAML Indentation Corrector prompt within ELITEA. This prompt automatically analyzes your YAML code and corrects any indentation problems, saving you significant debugging time.</li> </ul> </li> <li> <p>Agent Won't Start: Entry Point Check</p> <ul> <li>Problem: You expect your agent to begin, but nothing happens.</li> <li>Solution: The <code>entry_point</code> is the agent's starting instruction. Verify that the <code>entry_point</code> value in your YAML file exactly matches the <code>id</code> of the node you intend to be the first step.  Typos or incorrect capitalization will prevent the agent from finding its starting point.</li> </ul> </li> <li> <p>Unexpected Transitions: Wrong Turn in the Workflow</p> <ul> <li>Problem: The agent moves to a node that is not the one you intended after a specific step.</li> <li>Solution: Trace the transition from the node where the unexpected jump occurs. Carefully examine:<ul> <li><code>transition</code> Attribute: For simple transitions, ensure the <code>node_id</code> specified in the <code>transition</code> attribute is spelled correctly and matches the <code>id</code> of the intended next node.</li> <li><code>condition</code> Attribute: If the transition is controlled by a <code>condition</code>, meticulously analyze:<ul> <li><code>condition_input</code>: Are you providing the correct <code>state</code> variables as input to your condition?</li> <li><code>condition_definition</code> (Jinja2 Logic): Is your Jinja2 condition logic correct? Are you using the right variables, operators, and syntax? Test your condition logic step-by-step.</li> </ul> </li> <li><code>decision</code> Attribute: If the transition is based on a <code>decision</code>, review:<ul> <li><code>decisional_inputs</code>: Are you feeding the correct <code>state</code> variables to the decision-making process?</li> <li><code>default_output</code>: Is the <code>default_output</code> node correctly specified for cases where none of the decision criteria are met?</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Node Name Mismatches: Spelling Matters!</p> <ul> <li>Problem: The agent reports errors indicating it cannot find a specific node.</li> <li>Solution: Node <code>id</code>s are case-sensitive and must be spelled exactly the same way throughout your YAML:<ul> <li>Verify Node <code>id</code>s: Double-check the spelling and capitalization of all <code>id</code> values you've assigned to your nodes. Ensure consistency in how you refer to these <code>id</code>s in <code>transition</code>, <code>condition</code>, and <code>decision</code> attributes.</li> <li>ELITEA Toolkit Names (for <code>tool</code> nodes): If you are using <code>tool</code> nodes to call ELITEA entities (prompts, agents, datasources), the <code>tool</code> name in your YAML must perfectly match the name of the toolkit entity in ELITEA. Toolkit names are also case-sensitive.</li> </ul> </li> </ul> </li> <li> <p><code>llm</code> Node Referencing Errors:  ID Consistency</p> <ul> <li>Problem: Transitions, conditions, or decisions are not working correctly when referencing an <code>llm</code> node.</li> <li>Solution:  It's easy to make mistakes when referencing node IDs. Carefully confirm that the <code>id</code> you assigned to your <code>llm</code> node is accurate and that you are using that exact <code>id</code> in all <code>transition</code>, <code>condition</code>, or <code>decision</code> attributes that are supposed to point to your <code>llm</code> node.</li> </ul> </li> <li> <p>Incorrect Data in <code>state</code>: Agent Memory Issues</p> <ul> <li>Problem: Your agent is using or displaying wrong or outdated information.</li> <li>Solution:  The <code>state</code> is your agent's memory. To debug state issues:<ul> <li>Strategic Interruptions: Use <code>interrupt_before</code> and <code>interrupt_after</code> in your YAML to pause the agent at key points in its workflow.</li> <li>Inspect the <code>state</code>: When the agent pauses due to an interruption, examine the current <code>state</code> (the agent's memory). Check the values of your state variables to see if they are being populated correctly, updated as expected, and contain the right data at each step. This helps you track data flow and identify where information might be going wrong.</li> </ul> </li> </ul> </li> <li> <p><code>condition</code> Logic Errors: Jinja2 Debugging</p> <ul> <li>Problem: Conditions are not behaving as you expect, leading to the agent taking the wrong path.</li> <li>Solution:  Conditions use Jinja2 templating. Review your <code>condition_definition</code> with extra care:<ul> <li>Jinja2 Syntax: Ensure you are using correct Jinja2 syntax (<code>{% if %}</code>, <code>{% elif %}</code>, <code>{% else %}</code>, <code>{% endif %}</code>).</li> <li>Variable References: Double-check that you are correctly referencing the <code>state</code> variables you intended to use within the Jinja2 template (especially those listed in <code>condition_input</code>).</li> <li>Logical Operators and Comparisons: Verify that your logical operators (<code>and</code>, <code>or</code>, <code>not</code>) and comparison operators (<code>==</code>, <code>!=</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>, <code>in</code>) are used correctly to express your condition.</li> </ul> </li> </ul> </li> <li> <p><code>function</code> Node Input/Output Mapping Problems: Data Flow Breakdown</p> <ul> <li>Problem: A <code>function</code> node fails to execute correctly, or the ELITEA entity it's calling doesn't receive the right input.</li> <li>Solution: <code>function</code> nodes rely on precise <code>input_mapping</code>. Scrutinize these attributes:<ul> <li><code>input</code> List: Ensure the <code>input</code> list in your <code>function</code> node correctly names the <code>state</code> variables that are supposed to provide data to the function.</li> <li><code>output</code> List: Verify that the <code>output</code> list specifies the correct names for the state variables where the function's results should be stored.</li> <li><code>input_mapping</code> Details:  This is critical! For each parameter you are mapping in <code>input_mapping</code> (like <code>task</code>, <code>query</code>, <code>input</code>, or custom parameters), confirm:<ul> <li><code>type</code>: Is the <code>type</code> (<code>variable</code>, <code>fstring</code>, <code>fixed</code>, <code>string</code>) appropriate for how you want to provide the input value?</li> <li><code>value</code>: Is the <code>value</code> correctly specified? If <code>type: variable</code>, is it the correct <code>state</code> variable name? If <code>type: fstring</code>, is the formatted string template correct, and are the variables within it spelled right? If <code>type: fixed</code> or <code>type: string</code>, is the hardcoded value what you intended?</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Toolkit Configuration Issues: ELITEA Setup</p> <ul> <li>Problem: <code>tool</code> or <code>function</code> nodes that rely on ELITEA toolkits (like Jira, Confluence, Datasources, Agents, Prompts) are not working.</li> <li>Solution: Crucially, ensure that you have added and correctly configured all necessary toolkits in your Agent's Configuration tab in ELITEA.<ul> <li>Add Toolkits: In the Agent's Configuration, go to the \"Toolkits\" section and click \"Add Toolkit.\" Select all the toolkits (Jira, Confluence, Datasources, Agents, Prompts, etc.) that your Pipeline Agent uses in its YAML instructions.</li> <li>Configure Toolkits: After adding toolkits, you often need to configure them. This might involve:<ul> <li>Selecting the correct Toolkit Version: For Agents and Prompts, ensure you select the correct version from the dropdown.</li> <li>Selecting the Right Tool (Datasource): For Datasource toolkits, choose the specific datasource tool you intend to use.</li> <li>Providing Credentials: For Jira, Confluence, and other external services, you'll likely need to provide API keys, usernames, passwords, or connection details as required by the toolkit. Incorrect or missing toolkit configuration is a very common reason for agents to fail.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Debugging Complex Pipelines: Step-by-Step Approach</p> <ul> <li>Problem:  Troubleshooting becomes challenging in agents with many nodes, conditions, and decisions.</li> <li>Solution: Adopt a systematic debugging strategy:<ul> <li>Isolate the Problem: Try to narrow down the issue to a specific node or section of your pipeline. Comment out parts of your YAML temporarily to isolate the area of concern.</li> <li>Step-by-Step Execution Analysis: Mentally walk through your agent's workflow step by step, node by node.</li> <li>Strategic Interruptions (Again!): Use <code>interrupt_before</code> and <code>interrupt_after</code> liberally to pause the agent at multiple points and inspect the <code>state</code> at each stage. This helps you track data flow and pinpoint where logic might be breaking down.</li> <li>Detailed Error Message Review: Re-examine the error messages in the Chat window. Even if they seem cryptic at first, they often contain valuable clues about the location and type of error.</li> </ul> </li> </ul> </li> </ul> <p>By following these troubleshooting steps and systematically checking for common issues, you'll be well-equipped to diagnose and fix problems in your Pipeline Agents, allowing you to build robust and effective intelligent assistants in ELITEA!</p>"},{"location":"how-tos/agents-toolkits/pipeline-agent-framework/#useful-links-and-materials","title":"Useful Links and Materials","text":"<p>To further enhance your understanding and skills in building Pipeline Agents, here are some helpful resources:</p> <ul> <li>ELITEA Agents Configuration: Learn more about configuring and managing agents within ELITEA.</li> <li>Public Agents in Nexus: Discover and study real-world examples of Pipeline Agents created by the ELITEA community. This is a great source of inspiration and practical learning.</li> <li>Alita SDK GitHub Repository: Explore the codebase behind the Pipeline Agent Framework and its nodes. This is a valuable resource for understanding the inner workings and extending its capabilities.</li> <li>YAML Specification: Gain a comprehensive understanding of YAML syntax and structure.</li> <li>Jinja Templating Engine Documentation Master the syntax and features of Jinja2, the templating language used for defining conditions in Pipeline Agents.</li> </ul>"},{"location":"platform-documentation/extensions/alita-chat/","title":"Alita Code Chat","text":"<p>Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB.</p>"},{"location":"platform-documentation/extensions/alita-chat/#pre-requisite","title":"Pre-requisite","text":"<p>Alita Code Chat operates in conjunction with Alita Code for both VS Code and IntelliJ. To utilize Alita Code Chat, you must first install Alita Code from their respective marketplaces:</p> <ul> <li>VS Code: Install Alita Code from the VS Code Marketplace.</li> <li>IntelliJ: Install AlitaCode from the JetBrains Marketplace.</li> </ul> <p>Important: Ensure that Alita Code is not only installed but also properly configured with ELITEA HUB to function correctly. For detailed installation and configuration instructions, please refer to the Alita Code documentation. This step is crucial for enabling the full capabilities of Alita Code Chat within your development environment.</p>"},{"location":"platform-documentation/extensions/alita-chat/#features-list","title":"Features list:","text":"<ul> <li>Chat with ELITEA directly. It will use the model settings set by Alita Code extension.</li> <li>Type trigger chat to add participants to chat: <code>/</code> for prompt, <code>#</code> for datasources and <code>@</code> for agents.</li> </ul> <p>Note: Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned.</p>"},{"location":"platform-documentation/extensions/alita-chat/#alita-code-chat-for-vs-code","title":"Alita Code Chat for VS code","text":"<p>Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code.</p>"},{"location":"platform-documentation/extensions/alita-chat/#installation","title":"Installation","text":"<p>Getting started with Alita Code Chat is straightforward:</p> <ol> <li>Navigate to the Extensions section in VS Code.</li> <li>Search for Alita Code Chat in the Marketplace and click Install.</li> </ol> <p></p> <p>Note: After successful installation Alita Code Chat shortcut will be added to left menu of VS Code.</p>"},{"location":"platform-documentation/extensions/alita-chat/#alita-code-chat-usage","title":"Alita Code Chat Usage","text":"<p>With Alita Code Chat set up, you can now:</p> <ul> <li>Prompts - call and use prompts configured in ELITEA HUB.</li> <li>Datasources - call and use datasources configured in ELITEA HUB.</li> <li>Agents - call and use agents configured in ELITEA HUB.</li> <li>Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement.</li> </ul> <p>Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with <code>code</code> in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the <code>code</code> tag is applied to relevant prompts, datasources, and agents to enable their proper functionality within the ELITEA ecosystem.</p> <p>Additional Interaction Features:</p> <ul> <li>Auto scroll to bottom: This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible.</li> <li>Reload Alita Code Settings: This option allows to reload and update Alita Code settings.</li> <li>Stop generating: To stop generation of output.</li> </ul> <p>Post-Output Actions:</p> <ul> <li>Continue the Dialogue: To keep the conversation going, simply type your next question or command in the chat box and click the Send icon.</li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Delete Output: To remove the current output from the chat, click the Delete icon.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> <li>Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data:<ul> <li>Download as xlsx: Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis.</li> <li>Copy as markdown: Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms.</li> <li>Copy as html: Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.</li> </ul> </li> </ul> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#prompts","title":"Prompts","text":"<p>To call and use Prompts from ELITEA HUB:</p> <ol> <li>Open the Alita Code Chat.</li> <li>Type <code>/</code> in the chat box.</li> <li>Select the prompt that you want to run.<ul> <li>Version Selection: Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon.</li> </ul> </li> <li>Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command)  into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings.</li> <li>If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#datasources","title":"Datasources","text":"<p>To call and use Datasources from ELITEA HUB:</p> <ol> <li>Open the Alita Code Chat.</li> <li>Type <code>#</code> in the chat box.</li> <li>Select the datasource that you want to run.</li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> <li>If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#agents","title":"Agents","text":"<p>To call and use Agents from ELITEA HUB:</p> <ol> <li>Open the Alita Code Chat.</li> <li>Type <code>@</code> in the chat box.</li> <li>Select the prompt that you want to run.<ul> <li>Version Selection: Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon.</li> </ul> </li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> <li>If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#chat","title":"Chat","text":"<ol> <li>Open the AlitaCodeChat.</li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> </ol>"},{"location":"platform-documentation/extensions/alita-chat/#alitacodechat-for-intellij","title":"AlitaCodeChat for IntelliJ","text":"<p>AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode.</p>"},{"location":"platform-documentation/extensions/alita-chat/#installation_1","title":"Installation","text":"<p>Getting started with AlitaCodeChat is straightforward:</p> <ol> <li>Navigate to the Settings\u2192Plugins section in IntelliJ.</li> <li>Search for AlitaCodeChat in the Marketplace and click Install.</li> </ol> <p></p> <p>Alita Chat for IntelliJ offers two distinct modes to cater to different user preferences and integration styles. Each mode is designed to provide a seamless user experience while aligning with specific design philosophies:</p> <ul> <li>Native Mode: This mode is tailored to blend seamlessly with the IntelliJ environment. It adheres to the native design and style guidelines of IntelliJ, ensuring that the interface feels familiar and integrated for users who prefer consistency with their development environment.</li> <li>React Mode: Designed to echo the aesthetics and usability of ELITEA, this mode brings the distinctive look and feel of ELITEA's design language into IntelliJ. It's ideal for users who enjoy the ELITEA interface and wish to have a similar user experience within the IntelliJ platform.</li> </ul> <p>Both modes are crafted to provide a robust and intuitive chat interface, allowing users to choose according to their design preference and familiarity.</p> <p>Note:</p> <ul> <li>After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ.</li> <li>To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues.</li> <li>To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with <code>code</code> in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the <code>code</code> tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem.</li> </ul>"},{"location":"platform-documentation/extensions/alita-chat/#alitacodechat-usage","title":"AlitaCodeChat Usage","text":""},{"location":"platform-documentation/extensions/alita-chat/#prompts_1","title":"Prompts","text":"<p>To call and use Prompts from ELITEA HUB:</p> <ol> <li>Open the AlitaCodeChat.</li> <li>Select the React or Native tab.</li> <li>Type <code>/</code> in the chat box.</li> <li>Select the prompt that you want to run.<ul> <li>Version Selection: Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon.</li> </ul> </li> <li>Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command)  into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings.</li> <li>If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#datasources_1","title":"Datasources","text":"<p>To call and use Datasources from ELITEA HUB:</p> <ol> <li>Open the AlitaCodeChat.</li> <li>Select the React or Native tab.</li> <li>Type <code>#</code> in the chat box.</li> <li>Select the datasource that you want to run.</li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> <li>If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#agents_1","title":"Agents","text":"<p>To call and use Agents from ELITEA HUB:</p> <ol> <li>Open the AlitaCodeChat.</li> <li>Select the React tab.</li> <li>Type <code>@</code> in the chat box.</li> <li>Select the agent that you want to run.<ul> <li>Version Selection: Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon.</li> </ul> </li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> <li>If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-chat/#chat_1","title":"Chat","text":"<ol> <li>Open the AlitaCodeChat.</li> <li>Select either the Native or React tab.</li> <li>Start conversation in the form of a question, statement, or command that simulates human-like interaction.</li> </ol>"},{"location":"platform-documentation/extensions/alita-chat/#additional-interaction-features","title":"Additional Interaction Features","text":"<ul> <li>Auto scroll to bottom: This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible.</li> <li>Reload Alita Code Settings: This option allows to reload and update Alita Code settings.</li> <li>Stop generating: To stop generation of output.</li> </ul> <p>Post-Output Actions:</p> <ul> <li>Continue the Dialogue: To keep the conversation going, simply type your next question or command in the chat box and click the Send icon.</li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Delete Output: To remove the current output from the chat, click the Delete icon.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> <li>Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data:<ul> <li>Download as xlsx: Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis.</li> <li>Copy as markdown: Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms.</li> <li>Copy as html: Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.</li> </ul> </li> </ul> <p> </p>"},{"location":"platform-documentation/extensions/alita-code/","title":"Alita Code","text":""},{"location":"platform-documentation/extensions/alita-code/#get-started-with-alita-code","title":"Get Started with Alita Code","text":"<p>Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code and InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience.</p>"},{"location":"platform-documentation/extensions/alita-code/#why-choose-alita-code","title":"Why Choose Alita Code?","text":"<p>Alita Code is not just another IDE extension. It's a revolutionary tool designed to:</p> <ul> <li>Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance.</li> <li>Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable.</li> <li>Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts.</li> </ul>"},{"location":"platform-documentation/extensions/alita-code/#key-features","title":"Key Features","text":"<p>Alita Code comes packed with features designed to streamline your development process:</p> <ul> <li>AI-powered code suggestions for smarter coding</li> <li>Automated generation of unit tests, integration tests, and automated tests</li> <li>Automatic code commenting for better maintainability</li> <li>Customizable internal prompts for tailored assistance</li> <li>Project-specific external prompts and datasources powered by ELITEA Backend</li> <li>Code explanation and optimization recommendations</li> <li>Seamless native IDE integration</li> <li>Regular updates and enhancements</li> <li>Comprehensive documentation and dedicated support</li> <li>Collaboration-friendly design for team projects</li> <li>Secure and privacy-conscious implementation</li> </ul>"},{"location":"platform-documentation/extensions/alita-code/#alita-code-for-vs-code","title":"Alita Code for VS Code","text":"<p>Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend.</p>"},{"location":"platform-documentation/extensions/alita-code/#installation","title":"Installation","text":"<p>Getting started with Alita Code is straightforward and involves a few simple steps:</p> <ol> <li>Open VS Code and navigate to the Extensions section.</li> <li>In the Marketplace, search for Alita Code and click Install.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#configuration-on-elitea-hub","title":"Configuration on ELITEA HUB","text":"<p>To configure the necessary parameters for the Alita Code extension, follow these steps:</p> <ol> <li>Go to Settings \u2192 Configuration on the ELITEA HUB.</li> <li>Click the + icon to create a new token.</li> <li>Enter a name and set an expiration date for the token.</li> <li>Click Generate to create the token.</li> <li>Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window.</li> <li>From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.).</li> <li>Once the LLM model is selected, the Download VS Code Settings icon will appear next to the created token.</li> <li>Click this icon to download the <code>settings.json</code> file, which contains all necessary configuration information for integration with VS Code.</li> </ol> <p>Note: The <code>settings.json</code> file includes essential information such as Project ID, ELITEA HUB's URL, LLM model, Integration UID, and the generated token.</p> <p>Important: Alternatively, you can manually copy and paste all required parameters into the Alita Code extension's settings in VS Code.</p> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#configuration-on-vs-code","title":"Configuration on VS Code","text":"<p>Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves:</p> <ol> <li>Open your project in VS Code.</li> <li>Navigate to the <code>.vscode</code> folder and open the <code>settings.json</code> file. If this folder does not exist, create it and add a <code>settings.json</code> file.</li> <li>Open the <code>settings.json</code> file downloaded from ELITEA HUB.</li> <li>Copy all information from this file into the <code>.vscode/settings.json</code> file in your project. Note: Be careful not to overwrite other configurations. If previous Alita Code configurations exist, remove them before adding new information.</li> <li>Save the file. The integration settings will now be applied under Alita Code \u2192 Extension Settings \u2192 Workspace tab.</li> <li>Go to Extensions \u2192 Alita Code \u2192 Extension Settings. Open the Workspace tab and verify that all parameters are correctly populated from the <code>settings.json</code> file. Note: Manual adjustments can be made if necessary.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#types-of-settings-in-alita-code","title":"Types of Settings in Alita Code","text":"<p>Alita Code offers two types of settings to cater to different needs:</p> <ul> <li>User Settings: These are global settings that apply to all sessions across any workspace, providing a consistent environment across your projects.</li> <li>Workspace Settings: These are specific to a particular workspace, allowing for tailored configurations such as different project IDs or models, which is essential for managing separate environments or specific tasks.</li> </ul> <p>The following settings are available in both tabs (which can either be prepopulated or manually configured):</p> <p>Main Settings:</p> <ul> <li>Alitacode: LLMServer Url: Enter the URL of your LLM service provider. For connecting to ELITEA Nexus env., use <code>https://nexus.elitea.ai/</code>.</li> <li>Alitacode: LLMAuth Token: Provide your token for authentication with the LLM service provider. For ELITEA Prod env, input the generated Token.</li> <li>Alitacode: Project ID: Input the Project ID for the ELITEA backend.</li> <li>Alitacode: Display Type: Choose how the prediction results are displayed:</li> <li>append - when you run <code>Alita Predict</code> the results will be displayed after the text or part that you have selected.</li> <li>split - when you run <code>Alita Predict</code> the results will be displayed in a separate place (view).</li> <li>replace - when you run <code>Alita Predict</code> the results will be displayed instead of the text or part that you have selected.</li> <li>prepend -when you run <code>Alita predict</code> the results will be displayed before the text or part that you have selected.</li> <li>Alitacode: Verify Ssl: Toggle this setting to verify the LLM service provider's SSL certificate. For Nexus env, keep this checkbox not selected.</li> <li>Alitacode: Enable: Toggle to enable or disable the Alita Code extension as needed.</li> <li>Alitacode: Debug: Toggle to enable or disable the debugging feature as needed.</li> </ul> <p>Integration Settings:</p> <p>Alitacode: Select Integration: Click here to select link to select the available models from dropdown list for above selected environment. Note: After selection the corresponding information will be automatically populated for Alitacode: LLMModel Name, Alitacode: Integration Name and Alitacode: Integration Uid fields. * Alitacode: LLMModel Name: Write manually the desired LLM model name, if you don't want to preopoluate all information from . * Alitacode: Integration Name: This is the integration type which is used for selected LLM model setup in ELITEA\u2192Settings-Integrations page. Will automatically be populated and set after selecting LLM model from Alitacode: Select Integration. * Alitacode: Integration Uid: Enter the Integration UID from the ELITEA backend. Will automatically be populated and set after selecting LLM model from Alitacode: Select Integration.</p> <p>Advanced Settings:</p> <ul> <li>Alitacode: Custom Model Tokens: Set the maximum completion tokens for selected custom model. This setting defines the maximum length of the AI's generated response, measured in tokens.</li> <li>Alitacode: Max Tokens: Set the maximum completion tokens for selected model. This setting defines the maximum length of the AI's generated response, measured in tokens.</li> <li>Alitacode: Temperature: Adjust the temperature setting for the selected model to control the randomness of the output.</li> <li>Alitacode: Top P: Set the Top P value for the selected model. Also known as nucleus sampling, Top P offers another way to control the randomness of the output.</li> <li>Alitacode: Top K: Set the Top K value for the selected model. This parameter limits the AI's token selection to the K most likely tokens at each step of the generation process.</li> </ul> <p>These settings ensure that Alita Code is properly configured to interact with the ELITEA, allowing for seamless integration and efficient use of LLM models within your projects.</p> <p>Note: Restarting VS Code may be necessary for changes to take effect.</p>"},{"location":"platform-documentation/extensions/alita-code/#configuring-alita-code","title":"Configuring Alita Code","text":"<p>To initialize Alita Code in your project:</p> <ol> <li>Open any file and right-click to select Alita \u2192 Alita:Init.</li> <li>This creates a <code>.promptLib</code> folder with default prompts and <code>prompts.json</code> files.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#alita-code-usage","title":"Alita Code Usage","text":""},{"location":"platform-documentation/extensions/alita-code/#getting-started-with-extension-commands","title":"Getting Started with Extension Commands","text":"<p>Jumpstart your Alita Code experience with these essential commands:</p> <ul> <li>Alita: Init: Initialize Alita Code in your workspace by creating a <code>.promptLib</code> folder at the root. Note: After successful initalization the <code>Alita: Init</code> command becomes unavailable.</li> <li>Alita: Create Prompt: Craft a new prompt within the <code>.promptLib</code> folder.</li> <li>Alita: Extend Context: Enhance the context of an existing prompt in the <code>.promptLib</code> folder.</li> <li>Alita: Predict: Choose from a list of prompts and generate predictions based on your selection.</li> <li>Alita: Sync External Prompts: Synchronize your external prompts and datasources with ELITEA Backend.</li> </ul> <p>Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together.</p>"},{"location":"platform-documentation/extensions/alita-code/#synchronize-external-prompts","title":"Synchronize External Prompts","text":"<p>Sync prompts and datasources created in the Alita HUB with your Alita Code setup for seamless integration:</p> <ol> <li>Open <code>prompts.json</code>: Locate and open the <code>prompts.json</code> file.</li> <li>Access Alita Menu: Right-click in the editor to see the Alita menu option.</li> <li>Sync Prompts Option: Select <code>Alita: Sync External Prompts</code> from the submenu.</li> <li>Synchronization: The prompts and datasources will be synced and added to the <code>prompts.json</code> file.</li> <li>Usage: These prompts and datasources are now ready to be used with <code>Alita: Predict</code> command.</li> </ol> <p></p> <p>Note: To sync and use prompts and datasources from ELITEA HUB, tag the prompt with <code>code</code> in ELITEA HUB.</p>"},{"location":"platform-documentation/extensions/alita-code/#create-a-prompt","title":"Create a Prompt","text":"<p>Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one:</p> <ol> <li>Open a File: Start by opening any file from your project, or create a new one.</li> <li>Access Alita Menu: Right-click in the editor view to bring up the context menu, where you'll find the Alita item.</li> <li>Create Prompt Option: Hover over Alita in the menu, and on the second level menu, select <code>Create Prompt</code>.</li> <li>Name Your Prompt: Enter a name for your prompt-template, such as \"Generate unit-tests\".</li> <li>Describe Your Prompt: Press Enter and provide a description for your prompt.</li> <li>Provide Prompt Content: Press Enter again and input the content of your prompt. This can be modified later in the <code>.promptLib</code> folder.</li> <li>Finalize Creation: Hit Enter to finalize. Alita will add a reference to the new prompt in <code>prompts.json</code> and create a corresponding <code>.yaml</code> file in the <code>.promptLib</code> folder, which can be edited to extend content and add examples.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#extend-prompt-context","title":"Extend Prompt Context","text":"<p>Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions:</p> <ol> <li>Open and Select: Open any file from your project and select a portion of the text.</li> <li>Access Alita Menu: Right-click to open the context menu and find the Alita item.</li> <li>Extend Context Option: Hover over Alita and select \"Extend Context\" from the submenu.</li> <li>Choose a Prompt: Pick the prompt you wish to extend the context for from the dropdown list.</li> <li>Extend Context: The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions.</li> </ol>"},{"location":"platform-documentation/extensions/alita-code/#predict-execute-prompt","title":"Predict (Execute) Prompt","text":"<p>To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions:</p> <ol> <li>Open a File and Select Text: Open any project file and select the text you want to analyze or for which you need suggestions.</li> <li>Access Alita Menu: Right-click in the editor view to see the Alita menu item.</li> <li>Predict Option: Hover over Alita and choose <code>Alita Predict</code> from the submenu.</li> <li>Select a Prompt or Datasource:</li> <li>Choose the desired prompt or datasource from the dropdown list.</li> <li>Version Selection: Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately.</li> <li>View Predictions: After execution, the generated response will be displayed in your editor according to the method specified in your Alita Code: Default View Mode settings. This could be appended, replaced, split, or prepended based on your configuration.</li> </ol> <p></p> <p></p> <p>Note: You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB.</p>"},{"location":"platform-documentation/extensions/alita-code/#alitacode-for-intellij-idea","title":"AlitaCode for IntelliJ Idea","text":"<p>AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend.</p>"},{"location":"platform-documentation/extensions/alita-code/#installation_1","title":"Installation","text":"<p>Getting started with Alita Code is straightforward and involves a few simple steps:</p> <ol> <li>Navigate to the Settings\u2192Plugins section in IntelliJ.</li> <li>Search for AlitaCode in the Marketplace and click Install.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#configuration-on-elitea-hub_1","title":"Configuration on ELITEA HUB","text":"<p>To configure the necessary parameters for the Alita Code extension, follow these steps:</p> <ol> <li>Go to Settings \u2192 Configuration on the ELITEA HUB.</li> <li>Click the + icon to create a new token.</li> <li>Enter a name and set an expiration date for the token.</li> <li>Click Generate to create the token.</li> <li>Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window.</li> <li>From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.).</li> <li>Once the LLM model is selected, the Download Jetbrains Settings icon will appear next to the created token.</li> <li>Click this icon to download the <code>alita.xml</code> file, which contains all necessary configuration information (except generated token) for integration with IntelliJ.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#configuration-on-intellij","title":"Configuration on IntelliJ","text":"<p>Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves:</p> <ol> <li>Open your project in IntelliJ.</li> <li>Navigate to the <code>.idea</code> folder and open the <code>alita.xml</code> file. If this folder does not exist, create it and add a <code>alita.xml</code> file.</li> <li>Open the <code>alita.xml</code> file downloaded from ELITEA HUB.</li> <li>Copy all information from this file into the <code>.idea/alita.xml</code> file in your project. Note: If previous Alita Code configurations exist, remove them before adding new information.</li> <li>Save the file. The integration settings will now be applied under Settings \u2192 Tools \u2192 Alita tab.</li> <li>Go to Settings \u2192 Tools \u2192 Alita. Open it and verify that all parameters are correctly populated from the <code>alita.xml</code> file.</li> <li>Copy and paste generated token to the LLM Auth Token field. </li> <li>Check and apply configuration:<ul> <li>Click the Reload icon next to the Integration Name dropdown list.</li> <li>Select the <code>ai_dial</code> as integration and click OK button.</li> </ul> </li> <li>To complete the setup click the OK button.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#settings-in-alita-code","title":"Settings in Alita Code","text":"<p>Alita Code includes the following settings:</p> <ul> <li>LLM Provider: Select the LLM Provider. To connect with ELITEA Hub, select <code>Alita</code> option.</li> <li> <ul> <li>LLM Auth Token: Provide your Bearer token for the LLM service provider.</li> </ul> </li> <li>Provide Settings<ul> <li>Project ID: Enter the Project Id for ELITEA Backend, ignored for OpenAI.</li> <li>LLM Server URL: Enter the URL to your LLM service provider. (e.g. <code>https://alita.lab.epam.com/</code>)</li> <li>Integration Name: To use Epam AI Dial models, select <code>ai_dial</code> option.</li> <li>Integration UID: Enter the AI integration Id from ELITEA Backend, ignored for OpenAI.</li> <li>LLM Model Name: Choose the LLM model from the dropdown list.</li> <li>Custom Model Name: Enter a custom model name if the desired model is not listed. Check the Use custom model checkbox.</li> </ul> </li> <li>Display Type: Select the default display mode for the predictions.</li> <li>append - when you run <code>Alita Predict</code> the results will be displayed after the text or part that you have selected. </li> <li>split - when you run <code>Alita Predict</code> the results will be displayed in a separate place (view).</li> <li>replace - when you run <code>Alita Predict</code> the results will be displayed instead of the text or part that you have selected.  Advanced Settings:</li> <li>Custom Encoding Type: Select the encoding type, default <code>cl100k_base</code>.</li> <li>Custom Model Size: Set the max tokens for custom model, default is <code>4096</code>.</li> <li>LLM Response Timeout: Set the response timeout, default is <code>90</code> seconds. </li> <li>Max Tokens: Set the max tokens for the selected model.</li> <li>Temperature: Adjust the temperature for the selected model.</li> <li>Top K: Set the Top K value for the selected model.</li> <li>Top P: Set the Top P value for the selected model.</li> </ul> <p></p> <p></p> <p></p> <p>These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects.</p> <p>Note: Restarting IntelliJ may be necessary for changes to take effect.</p>"},{"location":"platform-documentation/extensions/alita-code/#configuration","title":"Configuration","text":"<p>To initialize Alita Code in your project:</p> <ol> <li>Open any file and right-click to select Alita \u2192 Alita:Init.</li> <li>This creates a <code>.promptLib</code> folder with default prompts and <code>prompts.json</code> files.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#alitacode-usage","title":"AlitaCode Usage","text":""},{"location":"platform-documentation/extensions/alita-code/#getting-started-with-extension-commands_1","title":"Getting Started with Extension Commands","text":"<p>Jumpstart your Alita Code experience with these essential commands:</p> <ul> <li>Alita: Init: Initialize Alita Code in your workspace by creating a <code>.promptLib</code> folder at the root. Note: After successful initalization the <code>Alita: Init</code> command becomes unavailable.</li> <li>Alita: Create Prompt: Craft a new prompt within the <code>.promptLib</code> folder.</li> <li>Alita: Extend Context: Enhance the context of an existing prompt in the <code>.promptLib</code> folder.</li> <li>Alita: Predict: Choose from a list of prompts and generate predictions based on your selection.</li> <li>Alita: Sync External Prompts: Synchronize your external prompts and datasources with ELITEA Backend.</li> </ul>"},{"location":"platform-documentation/extensions/alita-code/#synchronize-external-prompts_1","title":"Synchronize External Prompts","text":"<p>Sync prompts and datasources created in the ELITEA HUB with your Alita Code setup for seamless integration:</p> <ol> <li>Open <code>prompts.json</code>: Locate and open the <code>prompts.json</code> file.</li> <li>Access Alita Menu: Right-click in the editor to see the Alita Actions item.</li> <li>Sync Prompts Option: Select the Alita: Sync External Prompts option from the submenu.</li> <li>Synchronization: The prompts and datasources will be synced and added to the <code>prompts.json</code> file.</li> <li>Usage: These prompts and datasources are now ready to be used with <code>Alita: Predict</code> command.</li> </ol> <p></p> <p>Note: To sync and use prompts and datasources from ELITEA HUB, tag the prompt with <code>code</code> in ELITEA HUB.</p>"},{"location":"platform-documentation/extensions/alita-code/#create-a-prompt_1","title":"Create a Prompt","text":"<p>Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one:</p> <ol> <li>Open a File: Start by opening any file from your project, or create a new one.</li> <li>Access Alita Menu: Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item.</li> <li>Create Prompt Option: Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt. The Create Prompt window is opened:<ul> <li>Name: Assign a descriptive name that clearly reflects the aim of the prompt.</li> <li>Description: Summarize the purpose of the prompt, detailing what it intends to achieve. </li> <li>Context: Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables, then provide the names and values of the variables in the Variables section.</li> <li>Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings.</li> </ul> </li> <li>Click the Ok button to create a prompt. This can be modified later in the <code>.promptLib</code> folder. Alita Code will add a reference to the new prompt in <code>prompts.json</code> and create a corresponding <code>.yaml</code> file in the <code>.promptLib</code> folder, which can be edited to extend content and add examples.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#edit-prompt-context","title":"Edit Prompt Context","text":"<p>Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions:</p> <ol> <li>Open and Select: Open any file from your project and select a portion of the text.</li> <li>Access Alita Menu: Right-click to open the context menu and find the Alita Actions item.</li> <li>Edit Context Option: Hover over Alita Actions and select Alita: Edit Context from the submenu.</li> <li>Choose a Prompt: Select the prompt you wish to modify for from the list and click the Edit button.</li> <li>Edit Context The selected prompt's <code>yaml</code> file will be opened where you can make the changes.</li> </ol> <p></p>"},{"location":"platform-documentation/extensions/alita-code/#predict-execute-prompt_1","title":"Predict (Execute) Prompt","text":"<p>To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions:</p> <ol> <li>Open a File and Select Text: Open any project file and select the text you want to analyze or for which you need suggestions.</li> <li>Access Alita Menu: Right-click in the editor view to see the Alita Actions item.</li> <li>Predict Option: Hover over Alita Actions and choose Alita: Predict from the submenu.</li> <li>Select a Prompt or Datasource:</li> <li>Choose the desired prompt or datasource from the dropdown list.</li> <li>Version Selection: Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables.</li> <li>Variable Management: If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately.</li> <li>View Predictions: After execution, the generated response will be displayed in your editor according to the method specified in your AlitaCode: Display Type. </li> </ol> <p></p> <p></p> <p>Note: You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB.</p>"},{"location":"platform-documentation/menus/agents/","title":"Agents","text":""},{"location":"platform-documentation/menus/agents/#private-project-agents-menu","title":"Private project - Agents menu","text":"<p>ELITEA Agents are a cornerstone feature within the ELITEA platform, designed to significantly enhance and expand the capabilities of AI technologies. By leveraging the advanced natural language processing capabilities of GPT models, ELITEA Agents serve as virtual assistants or \"agents\" that automate tasks and streamline workflows, providing users with a more efficient and effective way to interact with AI models.</p> <p></p>"},{"location":"platform-documentation/menus/agents/#what-are-elitea-agents","title":"What are ELITEA Agents?","text":"<p>ELITEA Agents are customizable virtual assistants or bots that you can create within the ELITEA interface. Each agent is tailored to handle specific tasks or sets of tasks, based on the instructions and capabilities you define. These agents integrate various components such as prompts, datasources, and external toolkits, allowing them to make informed decisions and perform actions like searching on Google, creating Jira tickets, interacting with your code in GitHub. The flexibility of ELITEA Agents enables them to work with a wide range of external toolkits, making them versatile tools for automating complex workflows.</p>"},{"location":"platform-documentation/menus/agents/#purpose-of-elitea-agents","title":"Purpose of ELITEA Agents","text":"<p>The primary purpose of ELITEA Agents is to provide a structured and efficient way to interact with AI models for diverse use cases. Unlike open-ended conversations, agents are designed to achieve specific goals, tasks, or workflows. This is particularly beneficial in scenarios that involve repetitive or intricate tasks requiring multiple steps or the aggregation and processing of information from various sources. By automating these processes, ELITEA Agents help reduce manual effort and increase productivity.</p>"},{"location":"platform-documentation/menus/agents/#how-do-agents-work","title":"How do Agents work?","text":"<p>Creating an Agent involves defining a set of instructions, toolkits, or goals that the agent is meant to accomplish. These instructions can range from simple to complex, incorporating steps, conditions, and actions that guide the agent's behavior. Once configured, the agent utilizes the natural language processing capabilities of the selected GPT model to interpret and execute the provided instructions. This allows the agent to autonomously perform tasks, make decisions, and adapt to changing conditions without requiring constant human intervention.</p>"},{"location":"platform-documentation/menus/agents/#key-features-of-elitea-agents","title":"Key Features of ELITEA Agents","text":"<ul> <li>Autonomy: ELITEA Agents operate independently, making decisions and taking actions based on predefined goals and instructions.</li> <li>Proactivity: Agents can proactively determine the next steps needed to achieve their objectives, even in the absence of explicit instructions.</li> <li>Integration: By combining prompts, datasources, and external toolkits, agents can seamlessly integrate decision-making processes with actionable tasks.</li> <li>Customization: Users can tailor agents to meet specific needs, defining the scope and complexity of tasks they are designed to handle.</li> <li>Scalability: ELITEA Agents can be scaled to manage a wide array of tasks across different domains, enhancing their utility and effectiveness.</li> </ul> <p>By understanding and utilizing ELITEA Agents, users can unlock the full potential of AI-driven automation, transforming how tasks are managed and executed within the ELITEA platform. This not only improves efficiency but also empowers users to focus on more strategic and creative aspects of their work.</p>"},{"location":"platform-documentation/menus/agents/#integration-with-external-toolkits-services-and-apis","title":"Integration with External Toolkits, Services, and APIs","text":"<p>ELITEA Agents are designed to be highly versatile, capable of integrating with a wide array of external toolkits, services, and APIs. This capability allows agents to extend their functionality beyond the core ELITEA platform, enabling them to perform complex and specialized tasks across various domains. By leveraging these integrations, Agents can act as powerful virtual assistants, automating and streamlining workflows to enhance productivity and efficiency.</p> <ul> <li>Internal Toolkits: - Agents, Datasources, Prompts, and Artifacts: These are the foundational components within ELITEA that agents can utilize to perform tasks, manage data, and execute workflows. By integrating these internal toolkits, agents can seamlessly coordinate actions and decisions within the ELITEA environment.</li> <li>Management Tools: - Jira, Confluence, Bitbucket, Rally: Agents can integrate with these project management and collaboration tools to manage tasks, track issues, and facilitate team collaboration. This integration allows agents to automate project updates, issue tracking, and documentation management, ensuring that teams remain aligned and informed.</li> <li>Test Management Tools - XRAY Cloud, TestRail, Zephyr Scale, QTest: By connecting with test management platforms, agents can assist in managing test cases, executing tests, and generating reports. This integration streamlines the software testing lifecycle, improving accuracy and efficiency in quality assurance processes.</li> <li>Coding Tools: - GitHub, GitLab, GitLab Org, Sonar: Integration with version control and code quality tools enables agents to manage code repositories, facilitate pull requests, and conduct code reviews. This helps streamline the development process, ensuring code integrity and facilitating collaboration among developers.</li> <li>EPAM Tools: - Report Portal, TEST IO: Agents can leverage EPAM-specific tools to enhance reporting and testing capabilities. This integration allows for automated data collection and analysis, providing insights that drive informed decision-making.</li> <li>Azure Tools: - ADO wiki, ADO plans, ADO boards: By integrating with Azure DevOps tools, agents can manage documentation, project plans, and work items. This ensures that development and operations teams can collaborate effectively, maintaining alignment with project goals and timelines.</li> <li>Other Tools: - SQL, Browser, Google Places, Open API, Custom: ELITEA Agents can interact with databases, search web, access location data, and connect with custom APIs. These integrations enable agents to perform data retrieval, automate web-based workflows, and access external data sources, reducing manual effort and enhancing data-driven decision-making.</li> </ul>"},{"location":"platform-documentation/menus/agents/#setting-up-integrations","title":"Setting Up Integrations","text":"<p>To set up these integrations, users may need to perform additional configuration and authentication steps. This includes providing API keys, access tokens, or configuring webhooks and communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, allowing ELITEA Agents to function effectively within your existing technological ecosystem.</p> <p>By harnessing the power of these integrations, ELITEA Agents can automate a wide range of tasks, from project management and software testing to code management and data processing. This not only enhances the capabilities of the ELITEA platform but also empowers users to achieve greater efficiency and productivity in their workflows.</p> <p>Note: For more information, please check Alita Tools and Alita SDK git repos.</p>"},{"location":"platform-documentation/menus/agents/#creating-an-agent","title":"Creating an Agent","text":"<p>To set up a new agent:</p> <ol> <li>Click the + Agent button located at the top right corner.</li> <li>Fill out the Name and Description fields.</li> <li>Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box.</li> <li>Select the Agent type.</li> <li>Provide instructions for selected Agent type in the Instructions field.</li> <li>Add and setup selected toolkits that agent must use.</li> <li>Optionally, add and configure Conversation Starter and Welcome Message. </li> <li>Click Save.</li> </ol> <p></p> <p>Your newly created agent will subsequently appear on the Agents page for your project.</p>"},{"location":"platform-documentation/menus/agents/#how-to-create-instructions","title":"How to Create Instructions","text":"<p>The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests.</p>"},{"location":"platform-documentation/menus/agents/#how-to-input-instructions","title":"How to Input Instructions","text":"<ul> <li>Identify Key Information: Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task.</li> <li>Enter the Details: In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency.</li> <li>Using toolkits: For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit).</li> </ul>"},{"location":"platform-documentation/menus/agents/#how-to-select-an-agent-type","title":"How to Select an Agent Type","text":"<p>Selecting the right Agent type in ELITEA is essential for optimizing the performance and effectiveness of your AI-driven tasks. Each Agent type is designed to leverage specific capabilities and frameworks, catering to different use cases and operational needs. Below is a detailed overview of the available Agent types and their ideal applications:</p>"},{"location":"platform-documentation/menus/agents/#react","title":"ReAct","text":"<ul> <li>Description: The ReAct Agent type is designed for straightforward, linear tasks that require minimal context. Users can specify the desired actions and add necessary toolkits using fields such as Actor, Goals, Instructions, and Constraints to clearly define the agent's behavior.</li> <li>Best For: Simple tasks with clear, direct instructions where the agent's actions are well-defined and do not require extensive context or interaction history.</li> </ul>"},{"location":"platform-documentation/menus/agents/#xmlchat","title":"XMLChat","text":"<ul> <li>Description: Similar to ReAct, but utilizes XML for tool integration instead of JSON. This makes XMLChat more suitable for models like LLama and Anthropic, which may benefit from XML's structured format.</li> <li>Best For: Scenarios where XML is preferred for tool integration, particularly with LLama and Anthropic models.</li> </ul>"},{"location":"platform-documentation/menus/agents/#openai","title":"OpenAI","text":"<ul> <li>Description: OpenAI Agents are built on the LangChain backend and are specifically designed for integrations with Azure OpenAI Service. These agents excel in generating human-like text and handling a wide range of conversational tasks.</li> <li>Best For: Tasks requiring high-quality natural language understanding and generation, such as customer support, content creation, and complex query resolution.</li> </ul>"},{"location":"platform-documentation/menus/agents/#pipeline","title":"Pipeline","text":"<ul> <li>Description: Similar to OpenAI, Pipeline Agents are also based on the LangChain backend and work exclusively with Azure OpenAI Service integrations. They are designed to handle complex workflows and data processing tasks. Instructions must be written in YAML format.</li> <li>Best For: Scenarios that require structured workflows and data processing capabilities, leveraging the power of Azure OpenAI Service.</li> </ul> <p>Each Agent type in ELITEA is crafted to maximize the strengths of its underlying models and frameworks. Selecting the appropriate Agent type based on your specific task requirements and desired outcomes will ensure optimal performance and efficiency. For more detailed guidance on selecting the right Agent type and crafting effective instructions, please refer to the Agent Frameworks document.</p>"},{"location":"platform-documentation/menus/agents/#how-to-select-and-configure-toolkits","title":"How to select and configure Toolkits","text":"<p>Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks.</p> <p>To add a new toolkit:</p> <ol> <li>Click the + icon under TOOLS section.</li> <li>Select the desired tool from the dropdown list. The New tool configuration section is opened.</li> <li>Configure it accordingly to provide agent access to this tool.</li> <li>Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p> <p>To edit already created toolkit:</p> <ol> <li>Click the name of the already created Tool.</li> <li>The New [tool_name] tool configuration section is opened.</li> <li>Modify the configuration of the tool accordingly</li> <li>Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration.</li> </ol> <p>The following internal Tools are available:</p>"},{"location":"platform-documentation/menus/agents/#agent-toolkit","title":"Agent toolkit","text":"<p>The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes.</p> <p>To configure Agent toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Prompt tool from the dropdown list.</li> <li>The New Agent tool configuration section is opened.<ul> <li>Name: Provide informative name for the agent (toolkit).</li> <li>Description: provide informative description for the agent (toolkit).</li> <li>Agent: Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note: If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed.</li> <li>Version: Select the available version of the selected agent from the dropdown list.</li> </ul> </li> <li>Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#datasource-toolkit","title":"Datasource toolkit","text":"<p>The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently.</p> <p>To configure Datasource toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Datasource tool from the dropdown list.</li> <li>The New datasource tool configuration section is opened.<ul> <li>Name: Provide informative name for the datasource (toolkit).</li> <li>Description: Provide informative description for the datasource (toolkit).</li> <li>Datasource: Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note: If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed.</li> <li>Action: Select the required action type that will be used by agent (either Search or Chat). This will allow Agent to use information from selected datasource either by searching it or by chating with it.</li> </ul> </li> <li>Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#prompt-toolkit","title":"Prompt toolkit","text":"<p>The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements.</p> <p>To configure Prompt toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Prompt tool from the dropdown list.</li> <li>The New Prompt tool configuration section is opened.<ul> <li>Name: Provide informative name for the prompt (toolkit).</li> <li>Description: Provide informative description for the prompt (toolkit).</li> <li>Datasource: Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note: If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed.</li> <li>Version: select the available version of the selected prompt from the dropdown list.</li> </ul> </li> <li>Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p>IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt.</p> <p></p>"},{"location":"platform-documentation/menus/agents/#browser-toolkit","title":"Browser toolkit","text":"<p>The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks.</p> <p>To configure Browser toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>From the dropdown list, select the Browser tool to open the configuration settings.</li> <li>The New Browser tool configuration section is opened.<ul> <li>Name: Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions.</li> <li>Description: Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow.</li> <li>API key: Input the API key for the CSE that you have configured for the selected search engine. Note: This is required for Google tool only. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your API key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>CSE ID: Input the Custom Search Engine ID configured for your selected search engine. Note: This is required for Google tool only.</li> <li>Tools: Choose which search engines to integrate by selecting from the available options:<ul> <li>Wiki: Include Wikipedia search capabilities.</li> <li>Single URL Crawler: This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks.</li> <li>Multi URL Crawler: Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources.</li> <li>Get HTML Content: This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data.</li> <li>Google: Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#confluence-toolkit","title":"Confluence toolkit","text":"<p>The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy.</p> <p>To configure Confluence toolkit:</p> <ol> <li>Click the + icon under the Tools section.</li> <li>Select the Confluence tool from the dropdown list.</li> <li>The New Confluence tool configuration section is opened.<ul> <li>Name: Provide an informative name for the Confluence toolkit.</li> <li>Description: Provide a detailed description of the Confluence toolkit's purpose.</li> <li>URL: Enter the URL to your Confluence instance (e.g., <code>https://www.kb.epam.com/</code>). The URL should be the base link as detailed handling is managed via the instructions.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>API Key: Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your API key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. </li> <li>Token: Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type for your Jira setup:<ul> <li>Cloud: If your Confluence is hosted on Atlassian\u2019s cloud.</li> <li>Server: If your Confluence is hosted on your own servers or an enterprise environment. Important Note: When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration.</li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type for your Confluence setup:<ul> <li>Cloud: If your Confluence is hosted on Atlassian\u2019s cloud.</li> <li>Server: If your Confluence is hosted on your own servers or an enterprise environment. Important Note: When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration.</li> </ul> </li> <li>Tools: Enable the specific tools you need for your integration:<ul> <li>Get pages with the label: Check this to retrieve pages associated with a specific label.</li> <li>Search pages: Check this to enable searching for pages within Confluence.</li> <li>Create page: Enable this to allow the agent to create a new page in Confluence.</li> <li>Create pages: Enable this to allow the agent to create multiple pages in Confluence.</li> <li>Get page tree: Enable this to retrieve the hierarchical structure of pages in Confluence.</li> <li>Delete page: Enable this to allow the agent to delete a page.</li> <li>Update page by id: Enable this to allow the agent to update existing page by page id.</li> <li>Update page by title: Enable this to allow the agent to update page by title.</li> <li>Update labels: Enable this to allow the agent to update page labels.</li> <li>Update pages: Enable this to allow the agent to update multiple pages in Confluence.</li> <li>Site search: Enable this to search pages in Confluence.</li> <li>Search by title: Enable this to allow the agent to search existing page by page id.</li> <li>Read page by id: Enable this to allow the agent to read and show the content of the existing page by page id.</li> </ul> </li> <li>Advanced Settings: Configure additional settings to control data fetching and presentation:<ul> <li>Pages limit per request: Set the maximum number of pages to retrieve per request (e.g., <code>5</code>).</li> <li>Max total pages: Define the maximum number of pages to retrieve in total (e.g., <code>10</code>).</li> <li>Number of retries: Specify how many times the tool should retry after a failure (e.g., <code>2</code>).</li> <li>Min retry, sec: Set the minimum number of seconds to wait before retrying (e.g., <code>10</code>).</li> <li>Max retry, sec: Set the maximum number of seconds to wait before retrying (e.g., <code>60</code>).</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#jira-toolkit","title":"Jira toolkit","text":"<p>The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking.</p> <p>To configure Jira toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Jira tool from the dropdown list.</li> <li>The New Jira tool configuration section is opened.<ul> <li>Name: Provide a unique name to identify your Jira toolkit within ELITEA.</li> <li>Description: Offer a concise description of what the integration is intended for.</li> <li>URL: Enter the URL to your Jira instance (e.g., <code>https://www.jira.epam.com/jira/</code>).</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>API Key: Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your API key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. </li> <li>Token: Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type for your Jira setup:<ul> <li>Cloud: If your Jira is hosted on Atlassian\u2019s cloud.</li> <li>Server: If your Jira is hosted on your own servers or an enterprise environment. Important Note: When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration.</li> </ul> </li> <li>Tools - the following tools are avaialble for selection:<ul> <li>Search using JQL: To enable searching for Jira issues using Jira Query Language.</li> <li>Create issue: To allow the creation of new issues within Jira.</li> <li>Update issue: To enable updating existing Jira issues.</li> <li>List comments: To allow showing available comments of the Jira issue.</li> <li>Add comments: To allow adding comments to Jira issues.</li> <li>List projects: To enable listing all Jira projects.</li> <li>Set issue status: To set the status of Jira issues.</li> <li>Get specific field info: To allow getting info from the specific Jira field.</li> </ul> </li> <li>Advanced Settings: Adjust the advanced settings to fine-tune the toolkit's operation:<ul> <li>Verify SSL: Check this to enable SSL verification for secure connections to your Jira instance.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#github-toolkit","title":"GitHub toolkit","text":"<p>The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration.</p> <p>To configure GitHub toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the GitHub tool from the dropdown list.</li> <li>The New GitHub tool configuration section is opened.<ul> <li>Name: Assign a distinctive name to your GitHub toolkit integration.</li> <li>Description: Give a concise description that outlines the integration's intended purpose.</li> <li>Repository: Enter the name of the GitHub repository you wish to integrate (e.g. <code>ProjectAlita/projectalita.github.io</code>)   Main branch: Specify the main branch of your repository, typically <code>main</code>.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>Private Key: Select this option if you are using an Private key for authentication. </li> <li>App ID: Enter the App ID associated with your GitHub integration.</li> <li>Private Key: Enter the configured Private key. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your Private key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.        </li> </ul> </li> <li>Token: Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Password: Select this option if you are using your GitHub account password for authentication.<ul> <li>Password: Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter your password value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. </li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. </li> </ul> </li> </ul> </li> <li>Tools: Enable the tools that you require for interacting with your GitHub repository: <ul> <li>Get issues: Enables retrieval of issues from the repository.</li> <li>Get issue: Allows fetching details of a specific issue.</li> <li>Comment on issue: Permits adding comments to issues.</li> <li>List open pull requests (PRs): Lists all open pull requests.</li> <li>Get pull request: Retrieves details of a specific pull request.</li> <li>List pull request files: Lists the files changed in a pull request.</li> <li>Create pull request: Enables the creation of new pull requests.</li> <li>Create file: Allows for creating new files in the repository.</li> <li>Read file: Enables reading the contents of files.</li> <li>Update file: Permits updating existing files.</li> <li>Delete file: Allows for the deletion of files.</li> <li>List files in branch: Lists all files in a specific branch.</li> <li>List branches in repo: Lists all branches in the repository.</li> <li>Set active branch: Sets a specific branch as the active one.</li> <li>Create branch: Enables the creation of new branches.</li> <li>Get files from directory: Retrieves all files within a specified directory.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#gitlab-toolkit","title":"Gitlab toolkit","text":"<p>Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects.</p> <p>To configure Gitlab toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Gitlab tool from the dropdown list.</li> <li>The New Gitlab tool configuration section is opened.<ul> <li>Name: Assign a distinctive name to your GitHub toolkit integration.</li> <li>Description: Give a concise description that outlines the integration's intended purpose.</li> <li>URL: Enter the URL to your GitLab repository (e.g., <code>https://gitbud.epam.com/</code>).</li> <li>Repository: Enter the name of the Gitlab repository you wish to integrate (e.g., <code>Levon_Dadayan/alitatest</code>)</li> <li>Main branch: Specify the main branch of your repository, typically <code>main</code>.</li> <li>Token: Provide the configured token for authentication. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Tools: Enable the tools that you require for interacting with your Gitlab repository: <ul> <li>Create branch: Allows you to create new branches in the repository.</li> <li>Create pull request: Enables the creation of merge requests in GitLab.</li> <li>Create file: Permits the creation of new files within the repository.</li> <li>Delete file: Provides the option to delete files from the repository.</li> <li>Set active branch: Lets you specify a branch as the active one for operations.</li> <li>List branches in repo: Lists all branches within the specified repository.</li> <li>Get PR changes: Retrieves changes associated with a particular merge request.</li> <li>Create PR change comment: Allows you to comment on changes in a merge request.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#bitbucket-toolkit","title":"Bitbucket toolkit","text":"<p>The Bitbucket toolkit integrates  into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from Bitbucket, facilitating better version control and development process integration.</p> <p>To configure Bitbucket toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Bitbucket tool from the dropdown list.</li> <li>The New Bitbucket tool configuration section is opened.<ul> <li>Name: Assign a distinctive name to your Bitbucket toolkit integration.</li> <li>Description: Give a concise description that outlines the integration's intended purpose.</li> <li>Url: Enter the URL to your Bitbucket repository.</li> <li>Username: Input the Username associated with your Bitbucket account to complete the authentication process.</li> <li>Repository: Enter the name of the Bitbucket repository you wish to integrate (e.g. )   Main branch: Specify the main branch of your repository, typically <code>main</code>.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>Password: Select this option if you are using your Bitbucket account password for authentication you have two choices for providing the necessary credentials:<ul> <li>Password: Enter your password value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. </li> </ul> </li> </ul> </li> <li>Tools: Enable the tools that you require for interacting with your Bitbucket repository: <ul> <li>Create pull request: Enables the creation of new pull requests.</li> <li>Create file: Allows for creating new files in the repository.</li> <li>Read file: Enables reading the contents of files.        </li> <li>List branches in repo: Lists all branches in the repository.</li> <li>Set active branch: Sets a specific branch as the active one.</li> <li>Create branch: Enables the creation of new branches.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New Bitbucket tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#testrail-toolkit","title":"Testrail toolkit","text":"<p>The Testrail toolkit enables a direct integration with Testrauk, allowing users to manage test cases directly from the ELITEA platform.</p> <p>To configure TestTrail toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the TestRail tool from the dropdown list.</li> <li>The New Testrail tool configuration section is opened.<ul> <li>Name: Provide a unique name to identify your Testrail toolkit within ELITEA.</li> <li>Description: Offer a concise description of what the integration is intended for.</li> <li>URL: Enter the URL to your Testrail.</li> <li>Email: Enter the email used for authentication.</li> <li>Password: Enter the password for authentication.</li> <li>Tools - the following tools are avaialble for selection:<ul> <li>Get case: To enable selecting test case.</li> <li>Get cases: To enable selecting test cases.</li> <li>Add case: To enable adding new case into Testrail.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New testrail tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#open-api-toolkit","title":"Open API toolkit","text":"<p>The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources.</p> <p>To configure Open API toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Open API tool from the dropdown list.</li> <li>The New Open API tool configuration section is opened.</li> <li>Name: Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions.</li> <li>Upload your OpenAPI schema by following one of these methods:<ul> <li>Enter Schema: You can directly paste your OpenAPI schema into the text area provided.</li> <li>Drag &amp; Drop: Drag your OpenAPI schema file and drop it into the designated area.</li> <li>Choose File: Click on the <code>choose file</code> link to browse and select your OpenAPI schema file from your local system.</li> </ul> </li> <li>Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display:<ul> <li>Name: The name of the action as defined in the schema.</li> <li>Description: A brief description of what the action does.</li> <li>Method: The HTTP method used for the action (e.g., GET, POST, PUT, DELETE).</li> <li>Path: The endpoint path for the action.</li> </ul> </li> <li>Setting Authentication: Configure the authentication method required for your OpenAPI:<ul> <li>Authentication: Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements.</li> </ul> </li> <li>Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#custom-toolkit","title":"Custom toolkit","text":"<p>The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities.</p> <p>To configure Custom toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Custom toolkit from the dropdown list.</li> <li>The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit:       <code>{        \"name\": \"Custom tool\",        \"description\": \"\",        \"settings\": [],        \"type\": \"custom\"       }</code><ul> <li>name: Provide a unique name for your custom toolkit that will be used to identify it within ELITEA.</li> <li>description: Enter a brief description of what your custom toolkit does or its purpose.</li> <li>settings: Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use.</li> <li>type: This should be set to \"custom\" to indicate that it is a custom tool.</li> </ul> </li> <li>Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax.</li> <li>Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository. This repository contains documentation and examples that can help you build your custom tool.</li> <li>Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#artifact-toolkit","title":"Artifact toolkit","text":"<p>The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket.</p> <p>To configure Artifact toolkit:</p> <ol> <li>Click the + icon under Tools section.</li> <li>Select the Artifact tool from the dropdown list.</li> <li>The New artifact tool configuration section is opened.<ul> <li>Name: Assign a distinctive name to your Artifact toolkit integration.</li> <li>Description: Give a concise description that outlines the integration's intended purpose.</li> <li>Bucket: Specify the bucket name that you want to access or create.</li> <li>Tools: Enable the tools that you require for interacting with your Artifact: <ul> <li>List Files: Lists all files in a specific bucket.</li> <li>Create File: Allows for creating new file in the bucket.</li> <li>Read File: Enables reading the contents of files from the bucket.</li> <li>Delete File: Allows for the deletion of files from the bucket.</li> <li>Append Data: Permits updating the context of existing file in the bucket.</li> </ul> </li> </ul> </li> <li>Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/agents/#welcome-message","title":"WELCOME MESSAGE","text":"<p>The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions.</p> <p>How to Add the Welcome Message:</p> <ol> <li>Add the Welcome Message: Type the welcome message text in the input field.</li> <li>Save the Configuration: After entering the desired text, ensure to save the changes to the agent. This action makes the configured welcome message available to user in the Chat section.</li> </ol> <p>Using the Welcome Message:</p> <p>Go to the Chat section of the datasource. Here, you will see the configured Welcome Message. It will provide additional notification, instruction to the user.</p> <p>Examples of Welcome Message:</p> <ul> <li>\"Use this agent for generating manual test cases\"</li> <li>\"Don't forget to double-check the generated test cases\"</li> </ul> <p></p>"},{"location":"platform-documentation/menus/agents/#conversation-starters","title":"CONVERSATION STARTERS","text":"<p>The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent.</p> <p>How to Add a Conversation Starter:</p> <ol> <li>Access the Configuration Panel: Navigate to the Conversation Starter  section.</li> <li>Add a Conversation Starter: Click the <code>+</code> icon to open the text input field where you can type the text you wish to use as a conversation starter.</li> <li>Save the Configuration: After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use.</li> </ol> <p>Using a Conversation Starter:</p> <p>Initiate a Conversation: Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent.</p> <p>Examples of Conversation Starters:</p> <ul> <li>\"Generate test cases for provided Acceptance Criteria.\"</li> <li>\"Generate automatic test cases for selected [Test_Case_ID].\"</li> </ul> <p></p> <p>By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized.</p>"},{"location":"platform-documentation/menus/agents/#how-to-execute-agent","title":"How to Execute Agent","text":"<p>To execute the agent and get the output you have to:</p> <ol> <li>Configure the Agent: Initialize by providing the necessary instructions, and defining tools (if applicable).</li> <li>Select the AI Model: Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.).</li> <li>Set the Temperature Parameter: Adjust this parameter to control the level of creativity or unpredictability in responses.</li> <li>Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings:<ul> <li>Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses.<ul> <li>Higher values: Responses are more creative and varied, but may be less consistent and more unpredictable.</li> <li>Lower values: Responses are more consistent and predictable, but may be less creative and varied.</li> </ul> </li> <li>Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency.<ul> <li>Higher values: A wider range of words is considered, leading to more creative and diverse responses.</li> <li>Lower values: A narrower range of words is considered, leading to more consistent and predictable responses.</li> </ul> </li> <li>Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability.<ul> <li>Higher values: More words are considered, leading to more diverse and potentially creative responses.</li> <li>Lower values: Fewer words are considered, leading to more predictable and focused responses.</li> </ul> </li> <li>Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired.<ul> <li>Higher values: Responses can be longer and more detailed.</li> <li>Lower values: Responses are shorter and more concise.</li> </ul> </li> </ul> </li> <li>Initiate Interaction: Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command)  into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings.</li> </ol> <p>Additional Interaction Features:</p> <ul> <li>Auto scroll to bottom: This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible.</li> <li>Full Screen Mode: Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen.</li> </ul> <p>Post-Output Actions:</p> <ul> <li>Continue the Dialogue: To keep the conversation going, simply type your next question or command in the chat box and click the Send icon.</li> <li>Copy the Output: Click the Copy to Clipboard icon to copy the generated text for use elsewhere.</li> <li>Regenerate Response: If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response.</li> <li>Delete Output: To remove the current output from the chat, click the Delete icon.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/agents/#managing-agent-versions-save-create-versions-and-manage","title":"Managing Agent Versions: Save, Create Versions, and Manage","text":"<p>To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them.</p>"},{"location":"platform-documentation/menus/agents/#how-to-save-an-agent","title":"How to Save an Agent:","text":"<ul> <li>To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \"latest\" version of your prompt.</li> <li>You can continue to modify your agent and save the changes to the \"latest\" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving.</li> </ul> <p>Remember: The \"latest\" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent.</p>"},{"location":"platform-documentation/menus/agents/#how-to-create-new-versions","title":"How to Create New Versions:","text":"<p>For instances where you need to create and manage different iterations of your agent:</p> <ol> <li>Initiate a New Version: Start by clicking the Save As Version button.</li> <li>Name Your Version: When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. </li> </ol> <p>Best Practices for Version Naming:</p> <ul> <li>Length: Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems.</li> <li>Characters: Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments.</li> <li>Clarity: Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions.</li> </ul> <p>Upon creating a new version of the agent, several options become available to you:</p> <ul> <li>Delete: Remove this version of the agent if it\u2019s no longer needed.</li> <li>Execute: Run this specific version of the agent to see how it performs.</li> <li>Navigate Versions: Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations.</li> </ul> <p>By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements.</p>"},{"location":"platform-documentation/menus/agents/#agents-menu","title":"Agents Menu","text":"<p>The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents.</p>"},{"location":"platform-documentation/menus/agents/#layout-of-the-agents-menu","title":"Layout of the Agents Menu","text":"<p>The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents:</p> <ul> <li>Latest: Displays all recently published agents, providing a fresh look at the newest contributions to the community.</li> <li>My Likes: Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly.</li> <li>Trending: Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community.</li> </ul>"},{"location":"platform-documentation/menus/agents/#engaging-with-published-agents","title":"Engaging with Published Agents","text":"<p>Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation:</p>"},{"location":"platform-documentation/menus/agents/#liking-published-agents","title":"Liking Published Agents","text":"<p>Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality:</p> <ul> <li>To like an agent, click on the Heart icon associated with it.</li> <li>If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent.</li> </ul>"},{"location":"platform-documentation/menus/agents/#other-actions-for-published-agents","title":"Other Actions for Published Agents","text":"<p>Using Published Agent:</p> <ul> <li>View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent.</li> <li>Note: Modifications to a published agent cannot be saved for future use.</li> </ul>"},{"location":"platform-documentation/menus/chat/","title":"Conversations","text":"<p>ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results.</p> <p>In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context.</p> <p>All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu.</p> <p>Conversations support the following functionality:</p> <ul> <li>Public and Private Conversations: Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you.</li> <li>Participants: Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation.</li> <li>Interactions: Interact with added participants, copy generated responses, and more.</li> <li>Managing Conversations: Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation.</li> <li>Playback: During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/chat/#creating-a-conversation","title":"Creating a Conversation","text":"<ol> <li>Click the + Conversation button located at the top right corner or + icon next to CONVERSATIONS.</li> <li>Provide the Name. By default, it is set to \"New Conversation\".</li> <li>After creating Conversation add partiicpants to the conversation by clicking the PARTICIPANTS + button.</li> <li>Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin.</li> </ol> <p>Your newly created conversation will subsequently appear on the Conversation's list.</p>"},{"location":"platform-documentation/menus/chat/#private-and-public-conversations","title":"Private and Public Conversations","text":"<p>Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note: By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users.</p> <p>Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note: Users can't convert public conversations back to private.</p>"},{"location":"platform-documentation/menus/chat/#participants","title":"Participants","text":"<p>Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available:</p> <ul> <li>Models: LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model.</li> <li>Prompts: Already created prompts within the project or public ones which can be added to the conversation to execute them and get responses.</li> <li>Datasources: Already created datasources within the project or public ones which can be added to the conversation to execute them and get responses.</li> <li>Agents: Already created agents within the project or public ones which can be added to the conversation to execute them and get responses.</li> </ul> <p>Note: Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants.</p>"},{"location":"platform-documentation/menus/chat/#how-to-add-a-participant","title":"How to Add a Participant","text":"<p>To add a participant to a conversation:</p> <ol> <li>Click the Add participants button if you just created a conversation or + icon next to PARTICIPANTS.</li> <li>A pop-up window appears.</li> <li>Type the letters of the name or description of the available participant in the Search field. You can also filter and select required participant by type or tags.</li> <li>As soon as you see the participant that you need from the proposed list, click the Chat Now button on the participant card.</li> <li>The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section.</li> </ol> <p>Note: You can also add several participants at once (by clicking in the cards) and then click the Add Participants button.</p> <p></p>"},{"location":"platform-documentation/menus/chat/#how-to-use-a-participant","title":"How to Use a Participant","text":"<ol> <li>Check that the participant is selected and added to the conversation.</li> <li>If you see in the Conversation's main section \"Select from the list or mention participant you wish to engage with.\", then you need to include the participant that you want to use. To do it:<ul> <li>You can either click on the required participant option from the PARTICIPANTS section.</li> <li>Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, &gt; - model. Then select it from the dropdown list.</li> </ul> </li> <li>After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant.</li> <li>To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again.</li> </ol>"},{"location":"platform-documentation/menus/chat/#how-to-configuremodify-participants","title":"How to Configure/Modify Participants","text":"<p>You can easily configure participants that you have added to the conversation.</p> <p>For Models:</p> <ol> <li>Navigate to the model.</li> <li>Click on the Settings icon.</li> <li>You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length.</li> <li>To apply changes, click the &lt; SETTINGS button.</li> <li>You can also restore back to default settings by clicking the Restore icon.</li> </ol> <p></p> <p>For Prompts:</p> <ol> <li>Navigate to the prompt.</li> <li>Click on the Settings icon.</li> <li>Select the version of the prompt. By default the \"latest\" will be selected.</li> <li>You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well.</li> <li>To apply changes, click the &lt; SETTINGS button.</li> <li>You can also restore back to default settings by clicking the Restore icon.</li> </ol> <p></p> <p>For Datasources:</p> <ol> <li>Navigate to the datasource.</li> <li>Click on the Settings icon.</li> <li>You can configure the following settings for the datasource: <ul> <li>Embedding Settings: Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40).</li> <li>Temperature, Top P (0-1), Top K, and Maximum Length.</li> </ul> </li> <li>To apply changes, click the &lt; SETTINGS button.</li> <li>You can also restore back to default settings by clicking the Restore icon.</li> </ol> <p></p> <p>For Agents:</p> <ol> <li>Navigate to the agent.</li> <li>Click on the Settings icon.</li> <li>Select the version of the prompt. By default the \"latest\" will be selected.</li> <li>You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. If the agent has variable(s), you can modify them as well.</li> <li>To apply changes, click the &lt; SETTINGS button.</li> <li>You can also restore back to default settings by clicking the Restore icon.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/chat/#actions-for-conversation","title":"Actions for Conversation","text":"<p>The following actions are available for created conversations from CONVERSATIONS sidebar:</p> <ul> <li>Delete: To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action.</li> <li>Edit: To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action.</li> <li>Export: To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Note: Not applicable now.</li> <li>Make Public: To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private.</li> <li>Playback: The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes.</li> <li>Pin: To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin. Your conversation will be pinned at the top of your conversation's list. Note: You can unpin the conversation by clicking the Unpin action.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/collections/","title":"Collections","text":""},{"location":"platform-documentation/menus/collections/#private-project-collections-menu","title":"Private project - Collections menu","text":"<p>The Collections menu within Private project serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've crafted. </p> <p></p> <p>These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences.</p> <p>The Purpose and Usefulness of Collections</p> <p>The Collection serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users.  Collections are immensely valuable for several reasons:</p> <ul> <li>Thematic Organization: They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts.</li> <li>Efficiency: By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied.</li> <li>Sharing Best Practices: Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.</li> </ul>"},{"location":"platform-documentation/menus/collections/#how-to-create-a-collection","title":"How to Create a Collection","text":"<p>Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection:</p> <ol> <li>Click the + Collection button located at the top right corner of the page.</li> <li>You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection.</li> <li>Click Save to create the collection.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/collections/#exploring-collections","title":"Exploring Collections","text":"<p>Exploring collections is straightforward and insightful:</p> <p>Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents.</p> <p>Within a collection, you can:</p> <ul> <li>View and Open available prompts</li> <li>Modify Collection (Name and Description)</li> <li>Filter Collection by tags</li> <li>Publish Collection</li> <li>Delete Collection</li> <li>Export Collection</li> </ul>"},{"location":"platform-documentation/menus/collections/#how-to-modify-a-collection","title":"How to Modify a Collection","text":"<p>To modify an existing collection:</p> <ol> <li>Click the Edit icon.</li> <li>Update the Name and/or Description of the collection as needed.</li> <li>Click Save to apply the changes.</li> </ol> <p>Note: Modifications are restricted for collections that have already been published.</p>"},{"location":"platform-documentation/menus/collections/#how-to-filter-prompts-within-a-collection","title":"How to Filter Prompts within a Collection","text":"<p>Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes.</p>"},{"location":"platform-documentation/menus/collections/#how-to-publish-a-collection","title":"How to Publish a Collection","text":"<p>To publish a collection:</p> <ol> <li>Ensure the collection is complete and relevant by reviewing its contents.</li> <li>Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance.</li> <li>Once approved, your collection will be published and made available under the Collection menu for community use.</li> </ol> <p>Note: A Collection must contain already published prompts before publication.</p>"},{"location":"platform-documentation/menus/collections/#how-to-delete-a-collection","title":"How to Delete a Collection","text":"<p>To delete a collection:</p> <p>Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library.</p> <p>Note: Deletion is not possible for published collections.</p>"},{"location":"platform-documentation/menus/collections/#how-to-export-a-collection","title":"How to Export a Collection","text":"<p>Exporting a collection allows for its use on different platforms, offering formats tailored to each:</p> <ul> <li><code>[Alita format]</code> - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations.</li> <li><code>[DIAL format]</code> - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring.</li> </ul> <p>Exporting the Collection:</p> <ol> <li>Click the Export prompt icon to begin.</li> <li>Select your preferred format (Alita or DIAL) for the export.</li> <li>An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization.</li> </ol>"},{"location":"platform-documentation/menus/collections/#collections-menu","title":"Collections Menu","text":"<p>The Collections menu is a curated space of grouped prompts shared and published within the community. </p>"},{"location":"platform-documentation/menus/collections/#layout-of-the-collections-menu","title":"Layout of the Collections Menu","text":"<p>Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts:</p> <ul> <li>Latest: Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community.</li> <li>My Likes: Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time.</li> <li>Trending: Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/collections/#engaging-with-collections","title":"Engaging with Collections","text":"<p>Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage:</p>"},{"location":"platform-documentation/menus/collections/#liking-collections","title":"Liking Collections","text":"<p>Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality:</p> <ul> <li>To like a collection, click on the Heart icon associated with it.</li> <li>If you wish to withdraw your like, simply click the Heart icon again to Unlike the collection.</li> </ul>"},{"location":"platform-documentation/menus/collections/#other-actions-for-collections","title":"Other Actions for Collections","text":"<p>Exploring Published Collections:</p> <p>Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents.</p> <p>You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section.</p> <p>Exporting Collections:</p> <p>Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.</p>"},{"location":"platform-documentation/menus/datasources/","title":"Datasources","text":""},{"location":"platform-documentation/menus/datasources/#private-project-datasources-menu","title":"Private project - Datasources menu","text":"<p>Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information.</p> <p></p>"},{"location":"platform-documentation/menus/datasources/#creating-a-datasource","title":"Creating a Datasource","text":"<p>To set up a new datasource and augment your model's capabilities:</p> <ol> <li>Click the + Datasource button located at the top right corner.</li> <li>Fill out the Name and Description fields.</li> <li>Choose an Embedding model from the dropdown list provided.</li> <li>Select the desired Storage type from another dropdown menu.</li> <li>Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box.</li> <li>Click Save to finalize the creation.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/datasources/#exploring-datasources","title":"Exploring Datasources","text":"<p>Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage.</p>"},{"location":"platform-documentation/menus/datasources/#connecting-a-dataset-to-the-datasource","title":"Connecting a Dataset to the Datasource","text":"<p>The initial step involves linking your dataset to the desired datasource:</p> <ol> <li>Press the <code>+</code> icon to start adding a new dataset.</li> <li>Enter a name for your dataset.</li> <li>From the dropdown list, select the source type of your dataset. Available options include:<ul> <li>File: Any supported file type for upload.</li> <li>Table: Supported file types with a table structure, such as CSV or XLSX.</li> <li>GIT: Any accessible Git repository.</li> <li>Confluence: Any Confluence page accessible to you.</li> <li>QTest: Any QTest project accessible to you.</li> </ul> </li> </ol> <p></p> <p>Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded.</p>"},{"location":"platform-documentation/menus/datasources/#source-type-file","title":"Source type - File","text":"<p>ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration.</p> <ul> <li>Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources.</li> <li>Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported file types: PDF, DOCX, TXT, JSON.</li> <li>Advanced Settings - under this section, additional features enable further customization of how your file is processed.<ul> <li>Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages.</li> <li>Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible.</li> </ul> </li> <li>Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs.<ul> <li>TextLoader - optimized for plain text documents, ensuring swift and efficient loading.</li> <li>PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities.</li> </ul> </li> <li>Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., <code>.pdf</code>, <code>.docx</code>, <code>.txt</code>), overriding the default supported types if necessary.</li> <li>Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., <code>.exe</code>, <code>.bin</code>, <code>.png</code>) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#source-type-table","title":"Source type - Table","text":"<p>This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources.</p> <ul> <li>Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources.</li> <li>Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX.</li> <li>Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\").</li> <li>JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file.</li> <li>Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#source-type-git","title":"Source type - GIT","text":"<p>For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type.</p> <ul> <li>Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources.</li> <li>URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links:<ul> <li>SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH: input the SSH Key in the designated field.</li> <li>HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS: if prompted, enter the username and password to authenticate.</li> </ul> </li> </ul> <p>Important Note: To ensure a successful connection, you must clone your Git repository and provide the cloned Git link. Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues.</p> <ul> <li>Branch - here, specify the branch within your Git repository you wish to access. By default, the 'main' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs.</li> <li>Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository.</li> <li>Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time.</li> <li>Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs.<ul> <li>TextLoader: - optimized for plain text documents, ensuring swift and efficient loading.</li> <li>PythonLoader: - best suited for technical or coded documents, offering more sophisticated parsing capabilities.</li> </ul> </li> <li>Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., <code>.pdf</code>, <code>.docx</code>, <code>.txt</code>), overriding the default supported types if necessary.</li> <li>Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., <code>.exe</code>, <code>.bin</code>, <code>.png</code>) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#source-type-confluence","title":"Source type - Confluence","text":"<p>For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type.</p> <ul> <li>Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources.</li> <li>URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. <code>https://www.kb.epam.com/</code> is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence:<ul> <li>API Key: If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. The Secret and Password options are available.</li> <li>Token: Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. The Secret and Password options are available. Note: These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data.</li> </ul> </li> <li>Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site.</li> <li>Hosting Option - choose the appropriate hosting type for your Confluence setup:<ul> <li>Cloud - if your Confluence is hosted on Atlassian\u2019s cloud.</li> <li>Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note: When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note:This distinction is crucial for establishing the correct connection and accessing your data appropriately.</li> </ul> </li> <li>Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by:<ul> <li>Space Key - to fetch pages from specific Confluence spaces.</li> <li>Page IDs - to target specific pages.</li> <li>Labels - to retrieve pages tagged with specific labels.</li> </ul> </li> </ul> <p>Important Note: To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements.</p> <ul> <li>Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented:<ul> <li>Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content.</li> <li>Content Format - select the format in which you wish to view or receive the content. Options include:<ul> <li>View - the page content as displayed in Confluence.</li> <li>Storage - the raw storage format (HTML/XML) used by Confluence.</li> <li>Anonymous - content as it appears to users not logged in.</li> <li>Editor - content in an editable format.</li> </ul> </li> <li>Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times.</li> <li>Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance.</li> </ul> </li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#source-type-qtest","title":"Source type - QTest","text":"<p>Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type.</p> <ul> <li>URL - the link to your QTest. Note: You must provide the link to your QTest in the following format <code>https://&lt;host of your installation of QTest&gt;/api/&lt;api version used&gt;</code></li> <li>QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project.</li> <li>API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access:<ul> <li>Secret - Utilize a confidential key configured in the Secrets feature within ELITEA HUB for enhanced security during API requests. This secret can be selected from the secrets you have set up previously.</li> <li>Password - an option for API access, that verifies authorized requesters through a password.</li> </ul> </li> <li>Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection.</li> <li>DQL for QTest - this setting allows you to query and filter data before indexing it. Utilize DQL (Data Query Language) to define specific criteria that refine the data fetched from QTest, ensuring that only relevant data is processed and indexed.</li> <li>Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation.  Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\").</li> </ul>"},{"location":"platform-documentation/menus/datasources/#transformers","title":"TRANSFORMERS","text":"<p>Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes.</p> <ul> <li>Extract Keywords - options include:<ul> <li>For Document - analyses the entire document for keyword extraction.</li> <li>For Chunks - processes document sections independently for more granular insights.</li> </ul> </li> <li>Keyword Extractor - the only available option is KeyBert, designed for efficient keyword extraction.</li> <li>Keyword Strategy - choices range from Max Sum, to Max MMR High, and Max MMR Low, each offering different focuses on relevance and diversity.</li> <li>Maximum Keyword Count - defines the limit on the number of keywords to be extracted.</li> <li>Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#summarization","title":"SUMMARIZATION","text":"<p>Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes.</p> <ol> <li> <ul> <li>Summarization model - select from available LLMs based on your document\u2019s complexity.</li> </ul> </li> <li> <ul> <li>Document summarization - enables summarization of the entire document.</li> </ul> </li> <li> <ul> <li>Chunk summarization - applies summarization to specific sections or chunks of the document.</li> </ul> </li> <li> <ul> <li>Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size.</li> </ul> </li> </ol> <p></p> <p>Note: Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis.</p>"},{"location":"platform-documentation/menus/datasources/#context","title":"CONTEXT","text":"<p>Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note: By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions.</p> <p></p>"},{"location":"platform-documentation/menus/datasources/#welcome-message","title":"WELCOME MESSAGE","text":"<p>The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions.</p> <p>How to Add the Welcome Message:</p> <ol> <li>Add the Welcome Message: Type the welcome message text in the input field.</li> <li>Save the Configuration: After entering the desired text, ensure to save the changes to the datasource. This action makes the configured welcome message available to user in the Chat section.</li> </ol> <p>Using the Welcome Message:</p> <p>Go to the Chat section of the datasource. Here, you will see the configured Welcome Message. It will provide additional notification, instruction to the user.</p> <p>Examples of Welcome Message:</p> <ul> <li>\"Use this datasource for asking questions about FT Armenia\"</li> <li>\"Don't forget to double-check the generated responses\"</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#conversation-starters","title":"CONVERSATION STARTERS","text":"<p>The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the datasource.</p> <p>How to Add a Conversation Starter:</p> <ol> <li>Access the Configuration Panel: Navigate to the Conversation Starter  section.</li> <li>Add a Conversation Starter: Click the <code>+</code> icon to open the text input field where you can type the text you wish to use as a conversation starter.</li> <li>Save the Configuration: After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use.</li> </ol> <p>Using a Conversation Starter:</p> <p>Initiate a Conversation: Go to the Chat section of the datasource. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the datasource.</p> <p>Examples of Conversation Starters:</p> <ul> <li>\"How to create a prompt?\"</li> <li>\"I am on bench, and want to know what activities can be done\"</li> </ul> <p></p> <p>By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the datasource more efficient and standardized.</p>"},{"location":"platform-documentation/menus/datasources/#working-with-your-dataset","title":"Working with Your Dataset","text":"<p>After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do:</p>"},{"location":"platform-documentation/menus/datasources/#chat","title":"Chat","text":"<p>The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation.</p> <p>To use the Chat and query info:</p> <ol> <li>Select the Embedding model from the dropdown list. Note: It must be the same one which is used for creating the datasource.</li> <li>Choose an Chat model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs.</li> <li>Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note: Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available:<ul> <li>Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. <ul> <li>Higher values: More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing.</li> <li>Lower values: Fewer initial results are retrieved, which can speed up processing but might miss some relevant information.</li> </ul> </li> <li>Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase.<ul> <li>Higher values: More pages per document are considered, which can provide more comprehensive information but may slow down processing.</li> <li>Lower values: Fewer pages per document are considered, which can speed up processing but might miss some important details.</li> </ul> </li> <li>Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope.<ul> <li>Higher values: More search results are returned, which can provide a broader range of information but may include less relevant results.</li> <li>Lower values: Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results.</li> </ul> </li> <li>Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses.<ul> <li>Higher values: Responses are more creative and varied, but may be less consistent and more unpredictable.</li> <li>Lower values: Responses are more consistent and predictable, but may be less creative and varied.</li> </ul> </li> <li>Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency.<ul> <li>Higher values: A wider range of words is considered, leading to more creative and diverse responses.</li> <li>Lower values: A narrower range of words is considered, leading to more consistent and predictable responses.</li> </ul> </li> <li>Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability.<ul> <li>Higher values: More words are considered, leading to more diverse and potentially creative responses.</li> <li>Lower values: Fewer words are considered, leading to more predictable and focused responses.</li> </ul> </li> <li>Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired.<ul> <li>Higher values: Responses can be longer and more detailed.</li> <li>Lower values: Responses are shorter and more concise.</li> </ul> </li> </ul> </li> <li>Type your text in the chat box and click the Send icon to initiate the dialogue.</li> </ol> <p></p> <p>Additional Interaction Features:</p> <ul> <li>Auto scroll to bottom: This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible.</li> <li>Full Screen Mode: Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen.</li> </ul> <p>Post-Output Actions:</p> <ul> <li>Continue the Dialogue: To keep the conversation going, simply type your next question or command in the chat box and click the Send icon.</li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Regenerate Response: If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response.</li> <li>Delete Output: To remove the current output from the chat, click the Delete icon.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> <li>Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data:<ul> <li>Download as xlsx: Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis.</li> <li>Copy as markdown: Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms.</li> <li>Copy as html: Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.</li> </ul> </li> </ul>"},{"location":"platform-documentation/menus/datasources/#search","title":"Search","text":"<p>The Search feature allows you to quickly locate specific information within your indexed dataset.</p> <p>How to Conduct a Search:</p> <ol> <li>Select the Embedding model from the dropdown list. Note: It must be the same one which is used for creating the datasource.</li> <li>Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note: Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available:<ul> <li>Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. <ul> <li>Higher values: More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing.</li> <li>Lower values: Fewer initial results are retrieved, which can speed up processing but might miss some relevant information.</li> </ul> </li> <li>Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase.<ul> <li>Higher values: More pages per document are considered, which can provide more comprehensive information but may slow down processing.</li> <li>Lower values: Fewer pages per document are considered, which can speed up processing but might miss some important details.</li> </ul> </li> <li>Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope.<ul> <li>Higher values: More search results are returned, which can provide a broader range of information but may include less relevant results.</li> <li>Lower values: Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results.</li> </ul> </li> <li>String content - determines whether the system should include or consider specific text data in its processing or generation.</li> </ul> </li> <li>Type your query into the input field and hit the Send icon.</li> </ol> <p></p> <p>Post-Output Actions:</p> <ul> <li>View Selection:  A tool for quickly switching between Code view and List view views.</li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Full Screen Mode: Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> </ul>"},{"location":"platform-documentation/menus/datasources/#deduplicate","title":"Deduplicate","text":"<p>The Deduplication is a handy feature for identifying duplicate information.</p> <p>How to Run Deduplication:</p> <ol> <li>Select the Embedding model from the dropdown list. Note: It must be the same one which is used for creating the datasource.</li> <li>Configure the following settings:<ul> <li>Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores.<ul> <li>Higher values: More items will be excluded, as they will not be considered similar enough. This can be useful if you want to ensure that only highly unique content remains.</li> <li>Lower values: More items will be retained, as they will be considered similar enough. This can be useful if you want to keep more variations of the content.</li> </ul> </li> </ul> </li> <li>Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note: Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available:<ul> <li>Show Additional Metadata - a checkbox option that determines whether to display extra information about the content.<ul> <li>Selected: Additional metadata will be shown, providing more context and details about the content.</li> <li>Not Selected: Additional metadata will not be shown, resulting in a cleaner and simpler display of the content.</li> </ul> </li> <li>Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process.<ul> <li>Specified fields: The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria.</li> <li>No fields specified: All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate.</li> </ul> </li> </ul> </li> <li>Click the Run button to start the process.</li> </ol> <p>Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset.</p> <p>By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications.</p> <p></p> <p>Post-Output Actions:</p> <ul> <li>View Selection:  A tool for quickly switching between Code view and List view views.</li> <li>Show differences: An option allowing to quickly show/hide differences.</li> <li>Download result: Allows you to save the deduplication results directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. </li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Full Screen Mode: Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> </ul>"},{"location":"platform-documentation/menus/datasources/#public-project-datasources-menu","title":"Public project - Datasources menu","text":"<p>The Datasources menu within Public project showcases a collection of published and shared datasources within the community.</p>"},{"location":"platform-documentation/menus/datasources/#layout-of-the-datasources-menu","title":"Layout of the Datasources Menu","text":"<p>The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources:</p> <ul> <li>Latest: Displays all recently published datasources, providing a fresh look at the newest contributions to the community.</li> <li>My Likes: Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly.</li> <li>Trending: Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/datasources/#engaging-with-published-datasources","title":"Engaging with Published Datasources","text":"<p>Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation:</p>"},{"location":"platform-documentation/menus/datasources/#liking-published-datasources","title":"Liking Published Datasources","text":"<p>Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality:</p> <ul> <li>To like a datasource, click on the Heart icon associated with it.</li> <li>If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource.</li> </ul>"},{"location":"platform-documentation/menus/datasources/#other-actions-for-published-datasources","title":"Other Actions for Published Datasources","text":"<p>Using Published Datasources:</p> <ul> <li>View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource.</li> <li>Note: Modifications to a published datasource cannot be saved for future use.</li> </ul>"},{"location":"platform-documentation/menus/overview/","title":"ELITEA Platform Overview","text":""},{"location":"platform-documentation/menus/overview/#elitea-main-interface","title":"ELITEA - Main Interface","text":"<p>The ELITEA's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating new items (conversation, prompt, datasource, agent and collection, importing entities), Tags, and Trending Authors.</p> <p></p> <p>Sections:</p> <ol> <li>Discover Menu: A sidebar menu allowing users to switch among different menus such as Chat, Prompts, Datasources, Agents, Collections and Artifacts.</li> <li>Search: A Search box available to find prompts, datasources, agents and collections by their names and descriptions. Note: The Search functionality operates within the selected menu and is not universal across the entire application.</li> <li>View Switcher: A tool for quickly switching between Card list and Table views.</li> <li>Quick button: A button that allows for the rapid creation of a new conversation, prompt, datasource, agent or collection. The default of this button (<code>+Conversation</code>, <code>+Prompt</code>, <code>+Datasource</code>, <code>+Agent</code> or <code>+Collection</code>) changes based on the selected menu.</li> <li>Notifications: Notification's bell allowing user to get notified about various events such as prompt publishing status within the ELITEA.</li> <li>Project Switcher: A tool for quickly switching among projects.</li> <li>Settings: Accessible by clicking on your user avatar/picture. Here, you can configure various project and profile specific settings.</li> <li>Tags: This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu.</li> <li>Trending Authors: Shows the authors who have recently contributed or shared the most trending prompts, datasources and agents with the community.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/overview/#general-navigation-and-management-across-the-application","title":"General Navigation and Management Across the Application","text":"<p>This section provides an overview of the common functionalities and actions available across various menus and pages within the application. The aim is to ensure a consistent and efficient user experience by maintaining uniformity in navigation and management features across both Private and Public projects.</p> <p>Private Project Navigation:</p> <p>In a Private project, you have exclusive access to your personalized content across the following menus:</p> <ul> <li>Chat menu: Access all your private and public conversations, allowing for seamless communication and collaboration.</li> <li>Prompts menu: View and manage all the prompts you have created, enabling easy modification and reuse.</li> <li>Datasources menu: Contains all the datasources you have developed.</li> <li>Agents menu: Access all your created agents, each designed to perform specific tasks or sets of tasks.</li> <li>Collections menu: Manage your collections of prompts, datasources, and agents, organized for specific projects or themes.</li> <li>Artifacts menu: Utilize the Artifacts toolkit to create Buckets in ELITEA for saving, updating (appending), reading, and deleting files. Artifacts serve as a temporary file storage solution, enhancing your project's data management capabilities.</li> </ul> <p>Public Project Navigation:</p> <p>In a Public project, you can engage with the community and explore content created by other users through the following sections:</p> <ul> <li>Prompts menu: Navigate through the Latest prompts, explore prompts you've liked (My Likes), and discover Trending prompts within the community.</li> <li>Datasources menu: Access the Latest datasources, view datasources you've liked (My Likes), and explore Trending datasources shared by the community.</li> <li>Agents menu: Discover the Latest agents, check out agents you've liked (My Likes), and find Trending agents that are popular in the community.</li> <li>Collections menu: Explore the Latest collections, view collections you've liked (My Likes), and discover Trending collections that are gaining attention.</li> </ul> <p>While the context may vary depending on the specific page you're viewing, the core principles of action and functionality remain consistent. This unified approach ensures that whether you are navigating a private or public project, the experience is intuitive and user-friendly, facilitating effective management and exploration of content within the application.</p>"},{"location":"platform-documentation/menus/overview/#common-viewing-options","title":"Common Viewing Options","text":"<ul> <li>Card list view: Offers a compact, card-format snapshot of items like prompts, datasources, agents and collections, making it easy to visually scan through published materials.</li> <li>Table view: Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis.</li> </ul>"},{"location":"platform-documentation/menus/overview/#search-and-filtering-functionality","title":"Search and Filtering Functionality","text":"<ul> <li>Search: Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content.</li> <li>Filtering: Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes.</li> </ul>"},{"location":"platform-documentation/menus/overview/#sorting-options-detailed-view-only","title":"Sorting Options (Detailed View Only)","text":"<ul> <li>Name &amp; Description: Alphabetically organize published items by their names, providing an effortless method to find specific titles.</li> <li>Create: Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions.</li> <li>Likes: Order the items by the number of likes they have received. This functionality is applicable only for menus within Public project.</li> <li>Authors: Sort the items by the author's name. This functionality is applicable only for menus within Public project.</li> </ul> <p>These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment.</p>"},{"location":"platform-documentation/menus/overview/#discover-menus","title":"Discover - Menus","text":"<p>ELITEA application consists of the following main menus:</p> <ul> <li>Chat </li> <li>Prompts</li> <li>Datasources</li> <li>Agents</li> <li>Collections</li> <li>Artifacts</li> </ul> <p>Navigation:</p> <ol> <li>To naviagte among the menus, click the ELITEA icon on the top left.</li> <li>The Sidebar menu is opened.</li> <li>Click on the menu name to navigate to the desired menu.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/prompts/","title":"Prompts","text":""},{"location":"platform-documentation/menus/prompts/#private-project-prompts-menu","title":"Private project - Prompts menu","text":"<p>The Prompts menu within Private project serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted. </p> <p></p>"},{"location":"platform-documentation/menus/prompts/#how-to-create-a-new-prompt","title":"How to Create a New Prompt","text":"<p>In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models.</p> <ol> <li>Click the + Prompt button located on the top right of the Prompts menu. This action will navigate you to the Configuration tab, where you can define and set up your new prompt.</li> <li>Within the Configuration tab, you will need to fill in the mandatory fields: Name, Description, and Context.<ul> <li>Name: Provide a clear and concise name for your prompt to easily identify it later.</li> <li>Description: Add a brief explanation of the prompt's purpose or intended use.</li> <li>Context:  Enter the foundational information or instructions that will guide the AI model's responses. This is a crucial step in defining the scope and behavior of your prompt.</li> </ul> </li> <li>After filling in the required information, click the Save button to create your prompt.</li> </ol> <p>Note: The Name and Description fields are non-editable after the prompt is saved. Ensure you have entered the correct information before saving. While creating your prompt in the Configuration tab, you can also configure other settings like Tags, Welcome Message, Conversation Starters, and Messages to further customize your prompt's behavior and interaction flow.</p> <p></p> <p>After creating a prompt and saving it, the prompt's interface will be organized into three distinct tabs, each serving a specific purpose in managing and utilizing your prompt:</p> <ul> <li>Run tab: This is your primary interface for executing the prompt. Here, you'll find a comprehensive overview of the prompt's configuration, including any defined variables. If variables are configured, you can input or modify their values before execution. Crucially, this tab also allows you to adjust the settings that govern the AI model's behavior for this specific run, such as selecting the desired Model, and fine-tuning parameters like Temperature, Top-P, Top-K, and Maximum Completion Tokens.</li> <li>Configuration tab: This tab is dedicated to the setup and modification of the prompt's core elements. Within this tab, you have the ability to adjust all the fundamental settings of the prompt, including the Context that guides the AI, the Messages that structure the interaction, the optional Welcome Message displayed to users, and any Conversation Starters designed to initiate specific interactions.</li> <li>Monitoring tab: This tab provides valuable insights into the usage and performance of your prompt. Here, you can access monitoring data related to the prompt's executions, allowing you to track its activity, understand its usage patterns, and potentially identify areas for optimization or refinement. For more information about Monitoring, refer to the Monitoring.</li> </ul> <p>Note: Changes made within both the Run and Configuration tabs can be either saved to update the prompt or discarded to revert to the previous state, providing flexibility and control over your prompt configurations.</p>"},{"location":"platform-documentation/menus/prompts/#tags","title":"Tags","text":"<p>In ELITEA, Tags are a powerful organizational tool that allows you to categorize and manage your collection of prompts, datasources, and agents effectively. Think of them as labels that help you quickly identify and group related items. By assigning relevant tags to each prompt, you create an intuitive labeling system that significantly simplifies access and retrieval. This is particularly beneficial when you have a large number of prompts covering various topics or use cases. You can later filter your prompts by these tags, making it easy to find the precise prompt you need without sifting through an extensive list.</p> <p>Adding Tags to Your Prompt:</p> <ol> <li>Locate the Tags input box within the Configuration tab.</li> <li>Begin typing a tag name. As you type, you may see suggestions for pre-existing tags. You can either select one of these suggestions or continue typing to create a new tag.</li> <li>To finalize a tag, click the Enter key. This will add the tag to your prompt.</li> <li>Click the Save button to save the prompt with the selected tags.</li> </ol> <p>Note: You have the flexibility to assign one or more tags to each prompt, allowing for a multi-dimensional labeling system. This means a single prompt can be associated with multiple categories, enhancing its discoverability.</p> <p></p>"},{"location":"platform-documentation/menus/prompts/#context","title":"CONTEXT","text":"<p>The Context field in ELITEA is a fundamental component where you provide the essential background information, instructions, and guidelines that direct the LLM in generating accurate and relevant responses. This section acts as the foundational knowledge base for the model, enabling it to understand and effectively process your specific requests. A well-defined context is crucial for achieving the desired output from the AI.</p> <p>How to Effectively Input Context:</p> <ul> <li>Identify Key Information: Before you start typing, carefully consider the essential details or instructions the model needs to understand your request effectively. This might include the topic, specific terminology, relevant background information, the desired format of the output, or the specific task you want the model to perform.</li> <li>Enter the Details Clearly and Concisely:  Input the identified information directly into the Context field. Ensure your language is clear, concise, and unambiguous. Avoid unnecessary jargon or overly complex sentences. The more direct and focused your context, the better the model can understand and respond appropriately.</li> <li>Leveraging Variables for Dynamic Content: For situations where you need to introduce dynamic elements into your prompts, you can incorporate variables directly within the Context. Variables are denoted by double curly braces, for example, <code>{{variable_name}}</code>. Once you define a variable in the Context, it will automatically appear in the Variables section, where you can assign a specific value to it. This allows you to create reusable prompts that can be easily adapted for different scenarios by simply changing the variable values.</li> </ul> <p>Note: For comprehensive guidance on crafting effective instructions for your prompts, please refer to the Prompting Frameworks document. This resource provides valuable strategies and examples to help you optimize your prompts for better results.</p>"},{"location":"platform-documentation/menus/prompts/#editability-and-version-control","title":"Editability and Version Control","text":"<p>You can edit the Context field at any time to update or refine the instructions:</p> <ul> <li>Editing Existing Context: Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information.</li> <li>Creating New Versions: If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note: For more information check the Managing Prompt Versions: Save, Create Versions, and Manage.</li> </ul> <p>These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate.</p>"},{"location":"platform-documentation/menus/prompts/#messages","title":"MESSAGES","text":"<p>The MESSAGES section is a powerful feature that allows you to meticulously structure the flow of interaction within a prompt by defining specific roles and content for different participants in the conversation. This section is crucial for creating more complex and nuanced interactions with the LLM model.</p> <p>The MESSAGES utilizes three distinct message types:</p> <ul> <li>System Message: This message sets the overall context, instructions, and guidelines for the Gen AI's behavior. It's like providing the AI with its role and responsibilities for the interaction. This message is not visible to the end-user but is fundamental in shaping the AI's responses.</li> <li>Assistant Message: This represents the Gen AI's responses or contributions within the conversation. You can pre-define Assistant Messages to guide the interaction or provide examples of the desired output format.</li> <li>User Message: This simulates the input or queries from the user interacting with the Gen AI. You can use User Messages to set up specific scenarios or provide examples of how a user might interact with the prompt.</li> </ul> <p>These message types work in concert to create a structured and meaningful dialogue. The System Message establishes the framework, the User Message initiates and guides the conversation flow, and the Assistant Message provides the content of the interaction, all contributing to a coherent and purposeful exchange.</p> <p>Understanding the Message Types:</p> <ul> <li>System Message: Think of this as the \"director's notes\" for the AI. It defines the AI's persona, the task at hand, and any specific rules or constraints it should follow.</li> </ul> <pre><code>System Message: \"You are a helpful AI assistant specialized in providing concise summaries of scientific articles. Focus on extracting the main findings and conclusions.\"\n</code></pre> <ul> <li>Assistant Message: This allows you to pre-program the AI's responses or provide examples of how it should respond to certain user inputs.</li> </ul> <pre><code>User Message: \"What is the main finding of this article?\"\nAssistant Message: \"The main finding of the article is that...\"\n</code></pre> <ul> <li>User Message: This allows you to simulate user input and guide the conversation flow.</li> </ul> <pre><code>User Message: \"Summarize the methodology section.\"\n</code></pre> <p>Managing Messages:</p> <p>To enhance the interactivity of a prompt, you can add multiple messages of any type by clicking the <code>+</code> icon, selecting the desired message type from the dropdown, and providing the relevant content.</p> <p>You also have the flexibility to manage the order and content of your messages:</p> <ul> <li>Delete: Remove a message by clicking the delete icon.</li> <li>Copy: Duplicate a message by clicking the copy icon.</li> <li>Reorder: Change the order of messages by dragging and dropping the message boxes. This allows you to precisely control the flow of the conversation.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/prompts/#welcome-message","title":"WELCOME MESSAGE","text":"<p>The Welcome Message feature allows you to provide an initial message or instruction that is displayed to the user when they interact with the prompt, datasource, or agent. While currently sent to the LLM along with other instructions, it primarily serves as a way to communicate specific guidance or information to the user before they begin interacting with the prompt.</p> <p>Adding a Welcome Message:</p> <ol> <li>Locate the Welcome Message input field within the Configuration tab.</li> <li>Type the desired welcome message text into the input field. This could be instructions, reminders, or any other information you want the user to see.</li> <li>Click the Save button to save the configuration. This will make the configured welcome message visible to the user in the Chat section.</li> </ol> <p>How the Welcome Message is Used:</p> <p>When a user navigates to the Chat section of the prompt, the configured Welcome Message will be displayed at the top of the chat interface. This provides an immediate notification or instruction, setting the stage for their interaction with the prompt.</p> <p>Examples of Effective Welcome Messages:</p> <ul> <li>\"Use this prompt for generating comprehensive test cases based on the provided requirements.\"</li> <li>\"Remember to carefully review the generated output before implementing it.\"</li> <li>\"This prompt is designed to assist with summarizing technical documentation. Please provide the document content below.\"</li> </ul> <p></p>"},{"location":"platform-documentation/menus/prompts/#conversation-starters","title":"CONVERSATION STARTERS","text":"<p>The Conversation Starter feature empowers you to configure and add predefined text options that users can click to initiate a conversation or trigger a specific action when executing a prompt. This is particularly useful for guiding users and providing them with quick access to common or recommended interactions, ensuring a consistent and efficient starting point for their engagement with the prompt.</p> <p>Setting Up Conversation Starters:</p> <ol> <li>Navigate to the Conversation Starter section within the Configuration tab.</li> <li>Click the <code>+</code> icon. This will open a text input field where you can type the text you want to use as a conversation starter.</li> <li>Enter the desired text for the conversation starter. This should be a clear and actionable phrase or question.</li> <li>Click the Save button to save the configuration. The configured conversation starter will now be available for users.</li> </ol> <p>Using Conversation Starters to Initiate Interactions:</p> <p>When a user goes to the Chat section of the prompt, they will see a list of the saved conversation starters. Clicking on a desired starter will automatically populate the chat input field with that text and execute the prompt, streamlining the process of initiating specific tasks or queries.</p> <p>Examples of Effective Conversation Starters:</p> <ul> <li>\"Generate test cases for the following user story: [Paste User Story Here]\"</li> <li>\"Summarize the key findings from this research paper.\"</li> <li>\"Translate this document into Spanish.\"</li> <li>\"Explain the concept of [Technical Term].\"</li> </ul> <p>By providing these pre-defined options, you make it easier for users to understand the capabilities of the prompt and quickly initiate relevant interactions.</p> <p></p> <p>By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the prompt more efficient and standardized.</p>"},{"location":"platform-documentation/menus/prompts/#variables","title":"VARIABLES","text":"<p>The Variables within prompts introduce a powerful layer of dynamic customization, allowing you to create flexible and reusable prompts that can be easily adapted to specific needs or contexts without requiring modifications to the core prompt structure. This feature significantly enhances the versatility and efficiency of your prompts.</p> <p>Understanding Variables:</p> <p>Variables are placeholders within your prompt's Context or Messages that are denoted by double curly brackets, for example, <code>{{user_story}}</code>. These placeholders represent information that might change depending on the specific use case.</p> <p>How Variables Work:</p> <ol> <li>Define Variables in Context or Messages:  Begin by identifying the elements within your Context or Messages that you want to make dynamic. Replace these static values with variable placeholders using the <code>{{variable_name}}</code> syntax. Choose descriptive names for your variables to easily understand their purpose.</li> <li>Automatic Population in the Variables Section: Once you define a variable in the Context or Messages, it will automatically appear in the VARIABLES section located below.</li> <li>Assign Values to Variables: In the VARIABLES section, you can assign specific values to each defined variable. This is where you provide the actual data that will replace the placeholder when the prompt is executed.</li> </ol> <p>This process empowers you to create prompts that can be easily adapted by simply changing the values of the variables, eliminating the need to rewrite the entire prompt for different scenarios.</p> <p>Note: You have the flexibility to define one or more variables within each prompt. Variables can be defined in both the Context and Messages sections, providing flexibility in how you structure your dynamic prompts.</p> <p></p>"},{"location":"platform-documentation/menus/prompts/#advanced-settings","title":"ADVANCED SETTINGS","text":"<p>For users who require more granular control over the AI model's behavior, ELITEA provides Advanced Settings. These settings allow you to fine-tune the parameters that influence the generation of responses. To access these settings, click the Gear icon on the Configurations tab or SETTINGS section under the Run tab.</p> <p>The following advanced settings are available:</p> <ul> <li>Model: This dropdown menu allows you to select the specific Large Language Model (LLM) that will be used to process your prompt. Different models have varying capabilities and performance characteristics. Common options include:<ul> <li><code>gpt-4o</code>: A highly capable and advanced model known for its nuanced understanding and high-quality output.</li> <li><code>gpt-35-turbo</code>: A more cost-effective and faster model that still provides excellent performance for a wide range of tasks. The choice of model can significantly impact the quality, speed, and cost of your prompt executions.</li> </ul> </li> <li>Temperature: This parameter controls the randomness and creativity of the AI's responses. It is a value between <code>0</code> and <code>1</code>.<ul> <li>A lower temperature (closer to 0) results in more predictable and focused responses. The AI will tend to choose the most likely next words, making the output more deterministic and consistent. This is suitable for tasks requiring factual accuracy and precision.</li> <li>A higher temperature (closer to 1 or above) introduces more randomness, leading to more creative and unexpected outputs. The AI will consider less probable words, potentially generating more diverse and novel responses. This is useful for brainstorming, creative writing, or when exploring different possibilities.</li> </ul> </li> <li>Top P (0-1): Also known as nucleus sampling, Top P offers another way to control the randomness of the output. It works by considering the smallest set of most probable tokens whose cumulative probability exceeds the value of P.<ul> <li>A lower Top P value (e.g., 0.1) means the AI will only consider a very small, highly probable set of tokens, leading to more focused and deterministic responses.</li> <li>A higher Top P value (e.g., 0.9) allows the AI to consider a broader range of tokens, including less probable ones, resulting in more varied and potentially creative outputs. Top P provides a more dynamic way to control randomness compared to Temperature, as the number of tokens considered can vary depending on the context.</li> </ul> </li> <li>Top K: This parameter limits the AI's token selection to the K most likely tokens at each step of the generation process.<ul> <li>A lower Top K value (e.g., 10) restricts the AI to choosing from only the top 10 most probable tokens, leading to more focused and predictable responses.</li> <li>A higher Top K value (e.g., 100) allows the AI to choose from a wider range of likely tokens, potentially increasing the diversity and surprise in the output. Top K is useful for controlling the vocabulary and ensuring the AI stays within a certain range of likely words.</li> </ul> </li> <li>Maximum Completion Tokens: This setting defines the maximum length of the AI's generated response, measured in tokens. Tokens can be roughly thought of as parts of words.<ul> <li>Setting a lower value for Maximum Completion Tokens will result in shorter, more concise responses. This is useful when you need brief answers or summaries.</li> <li>Setting a higher value allows the AI to generate longer, more detailed responses. Be mindful that longer responses may consume more processing resources.</li> </ul> </li> </ul> <p>By carefully adjusting these Advanced Settings, you can tailor the AI's behavior to suit the specific requirements of your prompt and achieve the desired output characteristics. Experimenting with these parameters can significantly enhance the effectiveness and versatility of your interactions with ELITEA.</p>"},{"location":"platform-documentation/menus/prompts/#how-to-execute-prompt","title":"How to Execute Prompt","text":"<p>Once your prompt is configured, ELITEA offers two primary methods to execute it and obtain the desired output:</p> <ul> <li>Chat: This method is designed for interactive, conversational exchanges with the AI model. It's ideal for scenarios where you want to engage in a dialogue, ask follow-up questions, or refine the output through iterative interactions.</li> <li>Completion: This method is more direct, providing a single output based on the prompt's configuration. It's suitable for tasks where you need a straightforward answer, generation, or completion without the need for back-and-forth conversation.</li> </ul>"},{"location":"platform-documentation/menus/prompts/#executing-a-prompt-using-the-chat-option","title":"Executing a Prompt Using the Chat Option:","text":"<ol> <li>Navigate to the Run Tab: After configuring your prompt, access the Run tab. This tab provides the interface for executing your prompt and adjusting runtime settings.</li> <li>Review Prompt Configuration: In the Run tab, you'll see a summary of your prompt's setup. Ensure the Context, Messages, and any defined Variables are as intended. If variables are present, provide or adjust their values as needed.</li> <li>Select the AI Model: Choose the desired AI model from the Model dropdown list. The available models (e.g., <code>gpt-4-0125-preview</code>, <code>gpt-35-turbo</code>) will influence the quality and nature of the generated responses.</li> <li>Adjust Basic Settings: You can quickly adjust the Temperature parameter to influence the creativity and predictability of the AI's responses. A lower temperature results in more focused and deterministic outputs, while a higher temperature encourages more creative and varied responses.</li> <li>Access Advanced Settings (Optional): For more fine-grained control over the AI's output, check the Advanced Settings. Here, you can adjust parameters like Top P, Top K, and Maximum Completion Tokens. Refer to the Advanced Settings section for detailed information on these parameters.</li> <li>Initiate Interaction: In the chat input box, type your question, statement, or command to initiate the conversation with the AI. This input serves as the starting point for the interaction.</li> <li>Send Your Message: Click the Send icon (often represented by a paper airplane or similar symbol) to submit your input to the AI model. ELITEA will process your request based on the prompt's configuration and the selected settings. The AI's response will then appear in the chat interface.</li> </ol> <p>Additional Interaction Features:</p> <ul> <li>Auto scroll to bottom: This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible.</li> <li>Full Screen Mode: Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen.</li> </ul> <p>Post-Output Actions:</p> <ul> <li>Continue the Dialogue: To keep the conversation going, simply type your next question or command in the chat box and click the Send icon.</li> <li>Copy the Output: Click the Copy to clipboard icon to copy the generated text for use elsewhere.</li> <li>Append to Assistant Message: Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use.</li> <li>Regenerate Response: If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response.</li> <li>Delete Output: To remove the current output from the chat, click the Delete icon.</li> <li>Purge Chat History: For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.</li> <li>Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data:<ul> <li>Download as xlsx: Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis.</li> <li>Copy as markdown: Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms.</li> <li>Copy as html: Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.</li> </ul> </li> </ul> <p></p>"},{"location":"platform-documentation/menus/prompts/#executing-a-prompt-using-the-completion-option","title":"Executing a Prompt Using the Completion Option:","text":"<ol> <li>Navigate to the Run Tab: After configuring your prompt, access the Run tab. This tab serves as the central hub for executing your prompts and managing related settings.</li> <li>Review Prompt Configuration: In the Run tab, carefully review the prompt's setup, including the Context, Messages, and any defined Variables. Ensure everything is configured correctly for your desired outcome. If variables are present, provide or adjust their values as necessary.</li> <li>Select the AI Model: Choose the appropriate AI model from the Model dropdown list. The available models (e.g., <code>gpt-4-0125-preview</code>, <code>gpt-35-turbo</code>) offer different capabilities and performance characteristics, so select the one that best suits your needs.</li> <li>Adjust Basic Settings:  You can quickly adjust the Temperature parameter to control the level of creativity and predictability in the AI's output. A lower temperature leads to more focused and deterministic results, while a higher temperature encourages more varied and creative responses.</li> <li>Access Advanced Settings (Optional): For more fine-grained control over the AI's output, check the Advanced Settings. Here, you can adjust parameters like Top P, Top K, and Maximum Completion Tokens. Refer to the Advanced Settings section for detailed information on these parameters.</li> <li>Select the Completion Option: Ensure that the Completion option is selected as the execution method. This is typically a radio button or a tab within the Run tab interface.</li> <li>Initiate Execution: Once you have reviewed the configuration and selected the Completion option, click the Run button. ELITEA will then process your prompt based on the defined settings and generate a single, complete output. The result will be displayed in the output area.</li> </ol>"},{"location":"platform-documentation/menus/prompts/#managing-prompt-versions-save-create-versions-and-manage","title":"Managing Prompt Versions: Save, Create Versions, and Manage","text":"<p>To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them.</p>"},{"location":"platform-documentation/menus/prompts/#how-to-save-a-prompt","title":"How to Save a Prompt:","text":"<ul> <li>To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \"latest\" version of your prompt.</li> <li>You can continue to modify your prompt and save the changes to the \"latest\" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving.</li> </ul> <p>Remember: The \"latest\" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt.</p>"},{"location":"platform-documentation/menus/prompts/#how-to-create-new-versions","title":"How to Create New Versions:","text":"<p>For instances where you need to create and manage different iterations of your prompt:</p> <ol> <li>Initiate a New Version: Start by clicking the Save As Version button.</li> <li>Name Your Version: When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. </li> </ol> <p>Best Practices for Version Naming:</p> <ul> <li>Length: Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems.</li> <li>Characters: Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments.</li> <li>Clarity: Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions.</li> </ul> <p></p> <p>Upon creating a new version of the prompt, several options become available to you:</p> <ul> <li>Publish: Make this particular version of the prompt available for use.</li> <li>Delete: Remove this version of the prompt if it\u2019s no longer needed.</li> <li>Execute: Run this specific version of the prompt to see how it performs.</li> <li>Navigate Versions: Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations.</li> </ul> <p></p> <p>By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements.</p>"},{"location":"platform-documentation/menus/prompts/#how-to-publish-a-prompt","title":"How to Publish a Prompt","text":"<p>To make your prompt available to the wider Epam Network and Communities, follow these steps for publication:</p> <ol> <li>Publishing Initiation: With your prompt crafted and saved, initiate the process by clicking the Publish button.</li> <li>Version Naming: Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations.</li> <li>Review Submission: Finalize your submission by clicking Publish, forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance.</li> </ol> <p></p> <p>For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \"Publish version\" pop-up window. It can be published as is or renamed before the final publication step.</p> <p>Note: After publishing, the prompt can be retracted by selecting the Unpublish button.</p>"},{"location":"platform-documentation/menus/prompts/#moderator-review-process","title":"Moderator Review Process","text":"<p>Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld.</p> <p>Evaluative Steps Undertaken by Moderators:</p> <ol> <li>Initial Assessment: An initial examination confirms the prompt's completeness and adherence to the submission guidelines.</li> <li>Content Review: Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security.</li> <li>Practical Evaluation: Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes.</li> <li>Compliance Check: Final verification against community norms and security protocols, ensuring the protection of sensitive data.</li> </ol>"},{"location":"platform-documentation/menus/prompts/#possible-outcomes-of-the-review","title":"Possible Outcomes of the Review","text":"<p>After the review process, a prompt can be categorized into one of the following statuses:</p> <ul> <li>Approved: If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community.</li> <li>Rejected: If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration.</li> </ul>"},{"location":"platform-documentation/menus/prompts/#tracking-the-status-of-prompts","title":"Tracking the Status of Prompts","text":"<p>Prompts undergo several statuses through the review phase:</p> <ul> <li>All: An overview of all submissions regardless of their review stage.</li> <li>Draft: Saved yet unsubmitted prompts.</li> <li>Published: Moderation-approved prompts, now accessible in the Public project.</li> <li>On Moderation: Prompts currently under review.</li> <li>Approval: This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note: This feature is currently under development and is not available at the moment.</li> <li>Rejected: Prompts evaluated and declined for publication.</li> </ul>"},{"location":"platform-documentation/menus/prompts/#prompt-actions","title":"Prompt Actions","text":"<p>ELITEA provides a set of convenient actions you can perform on your prompts to manage, share, and organize them effectively. These actions are easily accessible through dedicated icons associated with each prompt.</p> <ul> <li>Copy link to clipboard: Clicking the Copy icon will copy a direct link to the current prompt to your clipboard. This allows you to easily share the prompt with colleagues or reference it in other documents.</li> <li>Add to collection: The Bookmark icon allows you to add the current prompt to one of your existing collections. This helps you organize your prompts into logical groups based on topic, project, or any other criteria you find useful.</li> <li>Export prompt:  Clicking the Export icon will initiate the process of exporting your prompt. The prompt will be saved as a JSON file to your local device. This file contains all the prompt's configurations, including context, messages, variables, and settings, making it easy to back up or share your prompt outside of ELITEA.</li> <li>Fork prompt: Clicking the Fork icon will initiate the process of creating a copy of the prompt within a different project. This is a useful feature for transferring prompts between projects without needing to export and import them. When you fork a prompt, a complete copy of its configuration is created in the target project, allowing you to modify it independently. </li> <li>Delete Prompt: Clicking the Thrash icon will delete the prompt. Be cautious when using this action, as deleted prompts cannot be recovered.</li> </ul>"},{"location":"platform-documentation/menus/prompts/#how-to-import-a-prompt","title":"How to Import a Prompt","text":"<p>To use the prompts created in other projects, environments, follow these simple steps.</p> <ol> <li>Initiate Import: Select the Import option within ELITEA.</li> <li>Choose File: Browse and select the exported JSON prompt file.</li> <li>Complete Process: The prompt will be added under the Prompts section in ELITEA.</li> <li>Use Prompt: You can now access and utilize the imported prompt.</li> </ol> <p></p> <p>Note: ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document.</p>"},{"location":"platform-documentation/menus/prompts/#public-project-prompts-menu","title":"Public project - Prompts menu","text":"<p>The Prompts menu within Public project showcases a collection of published and shared prompts within the community.</p>"},{"location":"platform-documentation/menus/prompts/#layout-of-the-prompts-menu","title":"Layout of the Prompts Menu","text":"<p>The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts:</p> <ul> <li>Latest: Displays all recently published prompts, providing a fresh look at the newest contributions to the community.</li> <li>My Likes: Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly.</li> <li>Trending: Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/prompts/#engaging-with-published-prompts","title":"Engaging with Published Prompts","text":"<p>Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation:</p>"},{"location":"platform-documentation/menus/prompts/#liking-published-prompts","title":"Liking Published Prompts","text":"<p>Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality:</p> <ul> <li>To like a prompt, click on the Heart icon associated with it.</li> <li>If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt.</li> </ul>"},{"location":"platform-documentation/menus/prompts/#other-actions-for-published-prompts","title":"Other Actions for Published Prompts","text":"<p>Executing Published Prompts:</p> <ul> <li>View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt.s</li> <li>Note: Modifications to a published prompt cannot be saved for future use.</li> </ul> <p></p> <p>Adding Published Prompts to Collections:</p> <p>Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation.</p> <p>Exporting Published Prompts:</p> <p>For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.</p>"},{"location":"platform-documentation/menus/settings/","title":"Settings","text":"<p>The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page.</p> <p>The Settings consists of several tabs and settings each dedicated to specific functionalities:</p> <ul> <li>Profile: Customize your user profile within ELITEA.</li> <li>Monitoring: Keep track of usage statistics by selecting different metrics and timeframes.</li> <li>Configuration: Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Code Chat.</li> <li>Deployments: Handle the management and launching of AI models or services linked to your ELITEA project.</li> <li>Projects: Manage users within project. This tab is only available for the user within admin permissions within the project.</li> <li>Theme: Switch between Dark and Light theme for the whole application.</li> <li>Log out: Securely log out from the ELITEA.</li> </ul> <p>Navigation:</p> <p>To navigate through the Settings menus, follow these steps:</p> <ol> <li>Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu.</li> <li>Select the desired tab by clicking on its name to navigate to that specific section.</li> </ol>"},{"location":"platform-documentation/menus/settings/#profile","title":"Profile","text":"<p>In the Profile, you\u2019re presented with options to personalize your account within ELITEA.</p> <p>About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note: Markdown is supported.</p> <p></p>"},{"location":"platform-documentation/menus/settings/#monitoring","title":"Monitoring","text":"<p>The Monitoring feature in ELITEA is designed to provide a comprehensive overview of the application's usage and performance. This feature is essential for administrators and users who want to gain insights into various aspects of the application, from user engagement to the effectiveness of configured artifacts like prompts, datasources, and agents. By leveraging the detailed charts and statistics available within the Monitoring feature, you can make informed decisions to optimize the performance and user experience of your ELITEA application.</p> <p>This section will guide you through the various components of the Monitoring feature, including configuration options, key metrics, adoption and usage statistics, sentiment analysis, accuracy metrics, prompt topics, and topics summary. Each of these components offers valuable insights that can help you understand how the application is being used and how it can be improved.</p>"},{"location":"platform-documentation/menus/settings/#configuration-options","title":"Configuration Options","text":"<p>At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor:</p> <ul> <li>Projects: A dropdown lits allowing you to select the project. Note: For your Private project, you can only see your private project data. If you have an admin role in another projects, you can select other projects to monitor.</li> <li>From and To Date Fields: These fields are used to select the time period for which you want to see the data.</li> <li>Aggregation: A dropdown list providing options to view aggregated data over different time periods. You can choose from <code>Hour</code>, <code>Day</code>, <code>Week</code>, <code>Two Weeks</code>, <code>Three Weeks</code>, and <code>Month</code> to tailor the data aggregation to your specific needs.</li> <li>Type: A dropdown list allowing you to select among <code>Prompt</code>, <code>Datasource</code>, <code>Agent</code>, and <code>Conversation</code> to focus your monitoring on specific elements.</li> <li>Name: A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations.</li> <li>Users: A dropdown list to select which users' data you want to monitor. Note: For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor.</li> </ul> <p>To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations.</p>"},{"location":"platform-documentation/menus/settings/#key-metrics","title":"Key Metrics","text":"<p>Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system:</p> <ul> <li>Users: The total number of users interacting with the ELITEA application.</li> <li>Tokens In: The number of tokens consumed by the ELITEA application.</li> <li>Tokens Out: The number of tokens generated by the ELITEA application.</li> <li>Engagement: The percentage of active users out of all users who logged into ELITEA for the selected period, indicating the level of interaction with the application.</li> <li>Acceptance rate: The percentage of interactions during the selected period where users accepted the generated output by copying, downloading, or saving it, reflecting user satisfaction and utility of the results.</li> <li>Prompts: The total number of prompts created.</li> <li>Agents: The total number of agents created.</li> <li>Conversations: The total number of conversations created.</li> </ul> <p>These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period.</p> <p></p>"},{"location":"platform-documentation/menus/settings/#adoption-and-usage","title":"Adoption and Usage","text":"<p>Below the key metrics, you'll find the Adoption and Usage section, which includes:</p> <ul> <li>Active Users: A bar chart displaying the number of active users over time.</li> <li>Token Usage: A line chart showing the tokens consumed (In) and generated (Out) over time.</li> </ul> <p>These charts provide insights into user engagement and the application's token economy.</p>"},{"location":"platform-documentation/menus/settings/#acceptance-rate","title":"Acceptance Rate","text":"<p>The Acceptance Rate section provides a comprehensive view of user interactions with the ELITEA application, focusing on how often users accept the generated outputs. This section includes visualizations that help you understand user satisfaction and the effectiveness of the system's responses.</p> <p>Acceptance Rate Chart</p> <p>The Acceptance Rate Chart displays the number of accepted and not accepted interactions for the selected period and filter options. This chart helps you assess how frequently users find the generated outputs useful enough to accept by copying, downloading, or saving them.</p> <ul> <li>Accepted Interactions: This metric shows the count of interactions where user(s) have accepted the generated output, indicating satisfaction and utility.</li> <li>Not Accepted Interactions: This metric reflects the number of interactions where user(s) did not accept the output, suggesting areas for potential improvement in response quality.</li> </ul> <p>By analyzing the Acceptance Rate Chart, you can gain insights into user satisfaction levels and identify opportunities to enhance the effectiveness of the ELITEA application, ultimately improving the overall user experience.</p>"},{"location":"platform-documentation/menus/settings/#sentiments","title":"Sentiments","text":"<p>The Sentiments section provides a visual representation of the emotional tone of both user inputs and the outputs generated by LLMs. Understanding sentiment is crucial for tailoring responses to better meet user needs and improve overall interaction quality.</p>"},{"location":"platform-documentation/menus/settings/#sentiment-analysis-overview","title":"Sentiment Analysis Overview","text":"<p>Sentiment analysis categorizes text into three primary emotional states:</p> <ul> <li>Positive: Indicates a favorable or happy emotional tone.</li> <li>Negative: Indicates an unfavorable or unhappy emotional tone.</li> <li>Neutral: Indicates a neutral or indifferent emotional tone.</li> </ul> <p>ELITEA performs sentiment analysis on user inputs to gauge the user's emotional state. This capability is particularly important for providing high-quality customer service, as the LLM can adjust its response tone and content based on the user's emotions.</p>"},{"location":"platform-documentation/menus/settings/#visual-representation","title":"Visual Representation","text":"<p>The Sentiments section includes two pie charts that offer a clear visual representation of sentiment distribution:</p> <ul> <li>Human Input: This pie chart shows the sentiment distribution of user inputs. It helps you understand how users are feeling when they interact with the LLMs.</li> <li>LLM Output: This pie chart displays the sentiment distribution of LLM's outputs. It helps you ensure that the responses generated by the LLM are appropriate and aligned with user emotions.</li> </ul>"},{"location":"platform-documentation/menus/settings/#practical-applications","title":"Practical Applications","text":"<p>Understanding sentiment can significantly enhance the user experience in several ways:</p> <ul> <li>Customer Service: By analyzing the sentiment of user inputs, LLMs can adjust its responses to be more empathetic and supportive, thereby improving customer satisfaction.</li> <li>User Engagement: Monitoring sentiment trends over time can help you identify patterns in user behavior and adjust your strategies accordingly.</li> <li>Content Moderation: Sentiment analysis can be used to flag potentially harmful or inappropriate content, ensuring a safer and more positive interaction environment.</li> </ul> <p></p>"},{"location":"platform-documentation/menus/settings/#accuracy","title":"Accuracy","text":"<p>The Accuracy section provides detailed insights into the performance and reliability of the ELITEA application. This section includes various metrics and visualizations that help you understand how well the system is responding to user inputs and how effective your configured artifacts (prompts, datasources, agents, conversations) are.</p>"},{"location":"platform-documentation/menus/settings/#relevance","title":"Relevance","text":"<p>The Relevance metric is divided into two key lines:</p> <ul> <li>Input vs Context: This line measures the relevance of the user's input (question or query) against the context of the artifact (prompt, datasource, agent or conversation). In the ELITEA, \"context\" refers to the configured instructions for the artifact. A higher relevance score indicates that the user's input closely matches the context, making it easier for the LLM to provide accurate responses.</li> <li>Output vs Input: This line measures the relevance of the generated output by the LLM against the user's input. A higher relevance score here indicates that the output is closely aligned with the user's query, ensuring that the response is appropriate and useful.</li> </ul> <p>Note: The maximum value for relevance is 6. The higher the score, the better the relevance, indicating a more accurate and contextually appropriate interaction.</p>"},{"location":"platform-documentation/menus/settings/#reliability","title":"Reliability","text":"<p>The Reliability Score answers the question of whether there is enough context to respond accurately to the user's questions or queries. This metric helps you gauge the confidence level of the LLM's responses. Note: The maximum reliability score is 10. A higher score indicates that there is sufficient context to provide a correct and reliable response to the user's query.</p>"},{"location":"platform-documentation/menus/settings/#instruction-quality-vs-usage","title":"Instruction Quality vs Usage","text":"<p>The Instruction Quality vs Usage is a 2x2 matrix that helps you evaluate the effectiveness and utilization of your artifacts (prompts, agents, datasources or conversations):</p> <ul> <li>Low Quality, Low Usage: Artifacts in this box have low quality scores and are rarely used. These artifacts may need to be re-evaluated or improved.</li> <li>High Quality, Low Usage: Artifacts in this box have high quality scores but are not frequently used. Efforts should be made to promote these high-quality artifacts to increase their usage.</li> <li>High Quality, High Usage: Artifacts in this box have high quality scores and are frequently used. These are your most effective artifacts and should be maintained.</li> <li>Low Quality, High Usage: Artifacts in this box have low quality scores but are frequently used. These artifacts should be improved in quality or their usage should be reduced in favor of higher-quality alternatives.</li> </ul> <p>Matrix legend:</p> <ul> <li>Quality Score: The maximum quality score is 4. A higher score indicates better quality.</li> <li>Calls: This metric shows how many times an artifact has been used. Depending on the context (matrix box), a higher number of calls can be either positive or negative.</li> </ul> <p>By analyzing these metrics, you can make informed decisions to improve the accuracy and reliability of your Alita AI application, ensuring a better user experience.</p>"},{"location":"platform-documentation/menus/settings/#prompt-topics","title":"Prompt Topics","text":"<p>The Prompt Topics section provides an automatic classification of the available artifacts (prompts, datasources, and agents) within the Alita AI application. This section helps you understand the distribution and focus areas of your artifacts, enabling you to identify trends and gaps in your content.</p>"},{"location":"platform-documentation/menus/settings/#chart-components","title":"Chart Components","text":"<p>The Prompt Topics section displays a clustered column chart that categorizes your artifacts by topic. This visual representation allows you to quickly see how many prompts, datasources, or agents are associated with each topic. The clustered column chart includes the following components:</p> <ul> <li>Items: Indicates the number of artifacts associated with each topic.</li> <li>Topic Name: Displays the name of each topic, helping you identify the subject matter of your artifacts.</li> </ul>"},{"location":"platform-documentation/menus/settings/#practical-applications_1","title":"Practical Applications","text":"<p>Understanding the distribution of your artifacts across different topics can provide several benefits:</p> <ul> <li>Content Gaps: Identify topics with fewer artifacts, indicating potential areas where additional content may be needed.</li> <li>Content Focus: Recognize topics with a high number of artifacts, helping you understand the primary focus areas of your users.</li> <li>Resource Allocation: Allocate resources more effectively by focusing on topics that require more attention or improvement.</li> </ul> <p></p> <p>By leveraging the insights provided by the Prompt Topics section, you can ensure that your application covers a comprehensive range of topics, enhancing the overall user experience and effectiveness of the application.</p>"},{"location":"platform-documentation/menus/settings/#topics-summary","title":"Topics Summary","text":"<p>The Topics Summary section provides an automatic classification of user inputs, categorizing the topics that users have queried or questioned about. This section helps you understand user interests and the most frequently discussed topics within ELITEA.</p>"},{"location":"platform-documentation/menus/settings/#chart-components_1","title":"Chart Components","text":"<p>The Topics Summary section displays a clustered column chart that categorizes user inputs by topic. This visual representation allows you to quickly see how many times users have queried information for each topic within a selected timeframe. The clustered column chart includes the following components:</p> <ul> <li>Items: Indicates the number of user queries associated with each topic.</li> <li>Topic Name: Displays the name of each topic, helping you identify the subject matter of user queries.</li> </ul>"},{"location":"platform-documentation/menus/settings/#practical-applications_2","title":"Practical Applications","text":"<p>Understanding the distribution of user queries across different topics can provide several benefits:</p> <ul> <li>User Interests: Identify the topics that users are most interested in, allowing you to tailor your content and responses to better meet their needs.</li> <li>Content Gaps: Recognize topics with fewer user queries, indicating potential areas where additional content or promotion may be needed.</li> <li>Trend Analysis: Monitor how user interests evolve over time, helping you stay ahead of emerging trends and adjust your strategies accordingly.</li> </ul> <p>By leveraging the insights provided by the Topics Summary section, you can ensure that ELITEA is aligned with user interests, enhancing the overall user experience and effectiveness of the application.</p> <p></p> <p>The Monitoring feature in ELITEA offers a robust set of tools and metrics to help you understand the performance and usage of your application. By utilizing the various charts and statistics available, you can gain valuable insights into user engagement, sentiment, accuracy, and the distribution of topics within your project. These insights are crucial for making data-driven decisions that can enhance the overall user experience and effectiveness of your ELITEA application.</p> <p>Whether you are looking to improve customer's experience through sentiment analysis, optimize the relevance and reliability of LLM responses, or identify content gaps and user interests, the Monitoring feature provides the necessary data to guide your efforts. By regularly reviewing and analyzing these metrics, you can ensure that your project remains aligned with user needs and continues to perform at its best. By leveraging the comprehensive monitoring capabilities of ELITEA, you can create a more responsive, efficient, and user-friendly application, ultimately leading to higher user satisfaction and better overall performance.</p>"},{"location":"platform-documentation/menus/settings/#configuration","title":"Configuration","text":"<p>The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Code Chat. Note: The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project.</p> <ul> <li>URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests.</li> <li>Project ID &amp; Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment.</li> <li>Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments.</li> <li>Model Name - displays the correct name of selected integration option</li> <li>Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential.</li> </ul> <p>To create a token:</p> <ol> <li>Click the <code>+</code> icon to create a new token.</li> <li>Enter a name and set an expiration date for the token.</li> <li>Click Generate to create the token.</li> <li>Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window.</li> <li>From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.).</li> <li>Once the LLM model is selected, the Download VS Code Settings and the Download Jetbrains Settings icons will appear next to the created token. This allows you to download the configuration files to integrate and configure the ELITEA project with Alita Code extensions on VSCode and IntelliJ respectively. For more information about how to setup it, please refer to the Alita Code Documentation.</li> </ol> <p></p>"},{"location":"platform-documentation/menus/settings/#deployments","title":"Deployments","text":"<p>The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Note: The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project.</p> <ul> <li>Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations.</li> <li>Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations.</li> </ul>"},{"location":"platform-documentation/menus/settings/#creating-a-new-deployment-for-epam-ai-dial","title":"Creating a New Deployment for EPAM AI Dial","text":"<p>To set up a new deployment for EPAM AI Dial within your system, follow these detailed steps:</p> <ol> <li>Obtain API Key: Important: Before proceeding, you must obtain a separate API Key from the EPAM DIAL team. This key is essential for authenticating and enabling communication with the AI Dial services.   </li> <li>API Key Retrieval: Once you have received the API Key and any additional required information via email, return to this page to input these details.</li> <li>Initiate Deployment Creation:  Click the <code>+</code> icon to start creating a new deployment.</li> <li>Select Deployment Type: From the list of available deployment types, select <code>AI Dial</code>.</li> <li>Configure Deployment Details: In the configuration window, fill in the following information:<ul> <li>Name: Enter a descriptive name for the deployment. This name will be displayed alongside LLM models configured with this deployment.</li> <li>API Base: For EPAM AI Dial, use <code>https://ai-proxy.lab.epam.com</code> as the API Base.</li> <li>Secret API Key: Paste the API Key that you received from the AI Dial team.</li> <li>API Version: Enter the API version information provided by the AI Dial team.</li> </ul> </li> <li>Add Models to Deployment:<ul> <li>Click the <code>+</code> icon to add one or more models associated with this deployment. For each model, provide the model's name, maximum input tokens, and capabilities.</li> <li>Important: Ensure that you enter the correct model name as used in EPAM AI DIAL. For detailed information on model specifications and configurations, refer to the EPAM AI Dial documentation.</li> </ul> </li> <li>Click Save to complete the creation of the deployment.</li> </ol> <p>By following these steps, you can successfully create and configure a new deployment for EPAM AI Dial, enabling you to leverage advanced  capabilities within your projects.</p> <p></p>"},{"location":"platform-documentation/menus/settings/#integrations","title":"Integrations","text":"<p>The Integrations menu in ELITEA is designed to enhance the platform's functionality and flexibility by allowing users to connect with essential external tools such as Jira, Confluence, Testrail, and GitHub. These integrations enable seamless data flow and collaboration across different platforms, enhancing productivity and efficiency. Once configured, these integrations can be selected as configurations in the Agent's tool setup for each corresponding tool, allowing for streamlined operations within ELITEA. You can create integrations in both Private workspaces and Team projects, providing versatility in managing your connections.</p>"},{"location":"platform-documentation/menus/settings/#confluence-integration-setup","title":"Confluence Integration Setup","text":"<p>To set up a Confluence integration, follow these step-by-step instructions:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create.</li> <li>Select Confluence: From the available options, select Confluence. This will open a new pop-up window where you can enter the necessary details for the integration.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for the integration, such as \"Conf_Integration\".</li> <li>URL: Enter the Confluence URL for your organization, e.g., <code>https://kb.epam.com/</code>.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>API Key: Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your API key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. </li> <li>Token: Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type for your Jira setup:</li> <li>Cloud: If your Confluence is hosted on Atlassian\u2019s cloud.</li> <li>Server: If your Confluence is hosted on your own servers or an enterprise environment. Important Note: When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration.</li> </ul> </li> <li>Set as Default: Check the checkbox to set this integration as the default.</li> </ul> </li> <li>Save the Integration: Click the Save button to finalize the integration setup. Your Confluence integration is now configured and ready to use.</li> </ol>"},{"location":"platform-documentation/menus/settings/#github-integration-setup","title":"GitHub Integration Setup","text":"<p>For GitHub integration, choose from the following authentication options:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create.</li> <li>Select Confluence: From the available options, select GitHub. This will open a new pop-up window where you can enter the necessary details for the integration.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for the integration, such as \"GitHub_Integration\".</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>Private Key: Select this option if you are using an Private key for authentication. <ul> <li>App ID: Enter the App ID associated with your GitHub integration.</li> <li>Private Key: Enter the configured Private key. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your Private key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.        </li> </ul> </li> </ul> </li> <li>Token: Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Password: Select this option if you are using your GitHub account password for authentication.<ul> <li>Password: Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter your password value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. </li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. </li> </ul> </li> <li>Anonymous: Select this option, if no anuthentication is required.</li> </ul> </li> <li>Set as Default: Check the checkbox to set this integration as the default.</li> </ul> </li> <li>Save the Integration: Click the Save button to finalize the integration setup. Your GitHub integration is now configured and ready to use.</li> </ol>"},{"location":"platform-documentation/menus/settings/#jira-integration-setup","title":"Jira Integration Setup","text":"<p>To set up a Jira integration, follow these step-by-step instructions:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create.</li> <li>Select Jira: From the available options, select Jira. This will open a new pop-up window where you can enter the necessary details for the integration.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for the integration, such as \"Jira_Integration\".</li> <li>URL: Enter the Jira URL for your organization, e.g., <code>https://jiraeu.epam.com/</code>.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>API Key: Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials:<ul> <li>Password: Enter your API key value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Username: Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. </li> <li>Token: Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials:<ul> <li>Password: Enter the your token value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> </ul> </li> <li>Hosting Option: Select the appropriate hosting type for your Jira setup:<ul> <li>Cloud: If your Jira is hosted on Atlassian\u2019s cloud.</li> <li>Server: If your Jira is hosted on your own servers or an enterprise environment. Important Note: When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration.</li> </ul> </li> <li>Set as Default: Check the checkbox to set this integration as the default.</li> </ul> </li> <li>Save the Integration: Click the Save button to finalize the integration setup. Your Jira integration is now configured and ready to use.</li> </ol>"},{"location":"platform-documentation/menus/settings/#testrail-integration-setup","title":"TestRail Integration Setup","text":"<p>To set up a Testrail integration, provide the following details:</p> <ol> <li>Initiate New Integration: Click the <code>+</code> icon to start the process of creating a new integration. A pop-up window will appear, prompting you to select the type of integration you wish to create.</li> <li>Select Jira: From the available options, select TestRail. This will open a new pop-up window where you can enter the necessary details for the integration.</li> <li>Enter Integration Details:<ul> <li>Name: Provide a descriptive name for the integration, such as \"TestRail_Integration\".</li> <li>URL: Enter the TestRail URL for your organization, e.g., <code>https://testrail.epam.com/</code>.</li> <li>Email: Enter the email used for authentication.</li> <li>Authentication Options: Choose your preferred method for secure connection: <ul> <li>Password: Enter your password value directly into the provided field.</li> <li>Secret: Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval.</li> </ul> </li> <li>Set as Default: Check the checkbox to set this integration as the default.</li> </ul> </li> <li>Save the Integration: Click the Save button to finalize the integration setup. Your TestRail integration is now configured and ready to use. </li> </ol> <p>By setting up these integrations, you can streamline workflows and enhance collaboration across different platforms, making ELITEA a more powerful tool for your projects.</p>"},{"location":"platform-documentation/menus/settings/#projects","title":"Projects","text":"<p>The Projects menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Note: It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project.</p>"},{"location":"platform-documentation/menus/settings/#groups","title":"Groups","text":"<p>The Groups feature in ELITEA is designed to facilitate efficient management and monitoring of multiple projects by admins or managers. This feature allows you to consolidate several projects under a single group, making it easier to oversee and coordinate activities across these projects. If you are an admin of two or more projects, you can leverage the Groups feature to organize and monitor your projects collectively:</p> <ul> <li>Create a New Group: Click the Pencil icon to initiate the creation of a new group. You will be prompted to name the group and select the projects you wish to include.</li> <li>Add Projects to Existing Group: If you already have established groups, you can add additional projects to these groups.</li> </ul> <p>This grouping functionality not only simplifies the administrative workload but also enhances the visibility and control over multiple projects, enabling more effective management and monitoring.</p>"},{"location":"platform-documentation/menus/settings/#teammates","title":"Teammates","text":"<p>The Teammates feature in ELITEA is specifically crafted to streamline the process of collaborating within projects by allowing you to invite new users (teammates) and assign them appropriate roles. These roles include system, admin, editor, and viewer, each providing different levels of access and control within the project. Note: Only users with an admin role are empowered to invite new members. This ensures that the invitation and role assignment process is managed by users with appropriate authority and understanding of the project\u2019s needs.</p> <p>Inviting New Teammates:</p> <ol> <li>Enter the prospective member's email address in the Email Address input field.</li> <li>Select their role from the Role dropdown menu. </li> <li>Click the Invite button. </li> <li>An invitation will be sent, and upon their first login, their details will be added to the Teammates, activating their account.</li> </ol> <p></p> <p>Notes</p> <ul> <li>Multiple users can be invited simultaneously by separating email addresses with a comma.</li> <li>For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations.</li> </ul> <p>Managing Teammates:</p> <p>The Teammates table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.</p>"},{"location":"platform-documentation/menus/settings/#secrets","title":"Secrets","text":"<p>The Secrets feature in ELITEA serves as a secure vault designed to store and manage sensitive information such as passwords, tokens, API keys, and other authentication details. This centralized system allows you to configure secrets once and utilize them across various components, such as Agent's toolkits within ELITEA.</p> <p>Creating a Secret:</p> <p>To add a new secret to the vault, follow these steps:</p> <ol> <li>Click the <code>+</code> icon to initiate the creation of a new secret.</li> <li>Enter a descriptive name for the secret to help you identify its use.</li> <li>In the Value field, input the token, password, API key, or any other authentication details.</li> <li>Once configured, this secret can now be selected and used within various components of ELITEA.</li> </ol> <p>Managing Secrets:</p> <p>The management of secrets is straightforward and secure, facilitated by the Secrets table which displays all your configured secrets:</p> <ul> <li>View Secret: Click the Eye icon to reveal the value of a configured secret. This allows you to quickly check the details without modifying them.</li> <li>Copy Secret: Easily copy the secret value to your clipboard (by clicking the hidden value) for use in configurations or integrations.</li> <li>Hide Secret: Hide the secret from the interface to maintain security when not actively managing the secret.</li> <li>Modify Secret: Update the value of the secret if the existing credentials change or need to be corrected.</li> <li>Delete Secret: Remove a secret permanently from the vault if it is no longer needed or if security concerns necessitate its deletion.</li> </ul> <p>This feature enhances the security and efficiency of managing sensitive information within ELITEA, ensuring that authentication details are handled in a secure, centralized manner.</p> <p></p>"},{"location":"release-notes/rn_current/","title":"ELITEA Release Notes","text":""},{"location":"release-notes/rn_current/#introduction","title":"Introduction","text":"<p>ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.</p>"},{"location":"release-notes/rn_current/#information","title":"Information","text":"<ul> <li>Release Version: 1.4.0</li> <li>Released on: 15-Jan-2025</li> <li>Access: ELITEA Platform</li> </ul>"},{"location":"release-notes/rn_current/#new-features","title":"New Features","text":"<ul> <li>Nexus Elitea Environment: The new Nexus env is available for all Epamers and can be accessed without enabling EPAM's VPN.</li> <li>Agent Pipelines Framework: This cutting-edge feature allows users to design complex workflows where agents, prompts, tools, and datasources are steps to achieve results. By leveraging a state-of-the-art graph-based approach, users can now craft intricate processes that utilize a wide array of tools and decision-making capabilities, all within a user-friendly environment.  </li> <li>New Toolkits for Agents: Enhance agent capabilities with the introduction of several powerful new toolkits, each designed to streamline specific aspects of project management, testing, and documentation:<ul> <li>Report Portal: Integrate with Epam's Report Portal for real-time test reporting and analysis, aggregating test results from various frameworks to provide insightful analytics.</li> <li>TestIO: Leverage crowdtesting capabilities with TestIO, allowing agents to manage and deploy test cases to a community of testers for diverse and thorough testing coverage.</li> <li>ADO Boards: Enhance project tracking and agile management by interacting with Azure DevOps Boards, managing tasks, backlogs, and sprints directly from ELITEA.</li> <li>ADO Wiki: Manage and retrieve project documentation efficiently by accessing and updating Azure DevOps Wikis, facilitating better knowledge sharing.</li> <li>ADO Plans: Streamline release and sprint planning within Azure DevOps, managing timelines, iterations, and deliverables effectively.</li> <li>XRAY Cloud: Enhance test management and execution by creating, managing, and executing test cases directly in Jira.</li> <li>QTest: Organize, track, and execute test cases with robust tools for reporting and analytics to enhance test management.</li> <li>Zephyr Scale: Manage large volumes of test cases and cycles in Jira, supporting advanced test planning and metrics.</li> <li>Rally: Access Rally\u2019s agile project management features for better alignment, tracking, and execution of agile practices.</li> <li>GitLab Org: Enable direct interaction with GitLab Org repositories, providing specific project data to support informed decisions.</li> <li>Google Places: Connect to Google using Find places and Find near tools.</li> <li>Sonar: Connect to Sonar Cube and retrieve data using the Get Sonar data tool.</li> <li>SQL: Connect to Postgres and MySQL databases to execute SQL queries/scripts and display tables and data.</li> </ul> </li> <li>Export/Import of Agents and Datasources Configuration: Facilitate the easy transfer of setup configurations between different environments or projects. Note: For security reasons, passwords and actual datasets are excluded from the export/import process.</li> <li>Forking Prompts, Agents, and Datasources: Introduce the forking feature to transfer Agents, Datasources, and Prompts between projects without needing to export and import the entities. Note: For security reasons, passwords and actual datasets are excluded from the forking process.</li> <li>Integrations: Enable seamless connections with external platforms such as Jira, Confluence, GitHub, and Testrail, enhancing workflow efficiency by allowing centralized management and improved collaboration across different tools.</li> <li>Configurations: Set up project-specific or personal configurations for Jira, Confluence, GitHub, and Testrail toolkits within the Agent interface, ensuring unique setups based on service URLs for optimal integration management.</li> <li>Magic Prompt Assistant: Auto-generate new prompts based on user input, enhancing the interactive capabilities of ELITEA.</li> <li>UI Enhancements: Full Screen View: Enable a Full Screen view for Context, Conversation Starter, and Welcome Message fields for Agents, Prompts, and Datasources.</li> <li>New BDD Loader: Reduce manual efforts required to update datasources for automation tests, allowing automation QAs to create specific datasources directly from the ELITEA UI.</li> <li>Improved Sorting and Ordering for Projects Dropdown List: Projects are now sorted in alphanumerical order, with Public and Private workspaces shown at the top of the list.</li> <li>Filtering of Entities by Author within Projects: Enhance navigation by allowing users to filter entities (prompts, datasources, collections, and agents) by author.</li> <li>Artifacts: Introduce a new feature allowing the creation of Buckets in ELITEA to save, update (append), read, and delete files using the Artifacts toolkit. Artifacts can be used as temporary file storage.</li> <li>Chat Enhancements: Add the ability to create grouped (Private) chats by adding users and select and show the history of each conversation with options such as All, Interaction, and Last N Messages.</li> <li>Monitoring Enhancements:<ul> <li>Included Aggregation functionality and an Acceptance Rate chart.</li> <li>Persist user-selected filters during sessions in Monitoring Tabs for entities and the Monitoring page.</li> <li>Introduce a special 'Monitor' role to provide a more accurate representation of active project users and usage metrics by hiding specific users (e.g., Epam admins and Support Engineers) from the project users list and excluding them from monitoring calculations.</li> <li>Show monitoring data per entity (for each prompt, datasource, and agent).</li> <li>Add new key metrics, Engagement and Acceptance rate, to provide deeper insights into user interaction and satisfaction:<ul> <li>Engagement: Measures the percentage of active users out of all users who logged into ELITEA for the selected period.</li> <li>Acceptance Rate: Tracks the percentage of interactions where users accepted the generated output by copying, downloading, or saving it.</li> </ul> </li> </ul> </li> </ul>"},{"location":"release-notes/rn_current/#changed-features","title":"Changed Features","text":"<ul> <li>Entity Redesign: Complete redesign of Prompts, Datasources, and Agents entities.</li> <li>Collections: Enhanced capability to add Datasources and Agents to a Collection, improving organizational efficiency.</li> <li>UI Enhancements for Secrets Page: Improved user interface for managing secrets.</li> <li>Export Prompts and Collections in [DIAL] Format: This option has been removed.</li> <li>Chat Participants: Complete redesign of the Participants page.</li> <li>Maximum Length Option Renaming: The Maximum length is renamed to 'Max Completion Tokens', with an added option to view available remaining tokens using the 'Remaining tokens' option.</li> <li>Enable Save, Save as Version, and Discard Buttons in Toolkit Setup: Allow users to save or discard changes without needing to return to the previous screen, reducing confusion and improving efficiency.</li> </ul>"},{"location":"release-notes/rn_current/#known-issues","title":"Known Issues","text":"<ul> <li>GIT Source Authentication: SSH authentication for GIT sources fails. Workaround: Use HTTPS with Username and Password.</li> <li>Collections Import: After importing Collections, new collections are not being created under the Collections section.</li> <li>Test Connection: The test connection functionality for the toolkit is currently experiencing issues and may not operate correctly.</li> </ul>"},{"location":"release-notes/rn_current/#fixed-issues","title":"Fixed Issues","text":"<ul> <li>Confluence Source Filtering: Resolved issues with filtering by Space key and Page IDs.</li> <li>Error When Stopping Dataset in Running Status: Fixed error message displayed when stopping the dataset running process.</li> <li>Datasources - Clean Generated Result Button: Fixed issue where the button was not working in deduplication/list view.</li> <li>Unable to Search and Filter by Tag: Fixed error message displayed during search and filter by tag.</li> <li>Browser Toolkit: Multi Crawler Tool Fails with Validation Error: The Multi Crawler tool in the Browser Toolkit fails with a validation error when attempting to execute a user query to gather information from several web pages.</li> <li>Tags Editing Mode on Prompt's Page: Resolved issue where there was no way to exit from tags editing mode if there weren't any changes, as the Discard button was deactivated.</li> <li>Projects and Users Dropdown Lists on Monitoring Page: Made sortable in alphanumerical order. Projects should have Private and Public categories at the top, followed by an alphabetical list. Users should be sorted alphabetically.</li> <li>ELITEA Unresponsiveness During Agent Execution: Fixed issue where ELITEA became unresponsive when executing an agent with several tools and toolkits. If a tool within the toolkits became unresponsive, the entire platform displayed errors. A page refresh was required to navigate back.</li> <li>Renamed ELITEA Agent Display: Fixed issue where a renamed ELITEA Agent was incorrectly displayed on the Agent View Wizard.</li> <li>Browser Toolkit Tool Selection: Resolved issue where it was not possible to select any tools other than Google without providing an API Key and CSE ID, which were mandatory regardless of the selected tools.</li> <li>Created Secret Visibility: Fixed issue where a created secret did not automatically appear in applicable places such as Integrations, Dataset, and Agent's toolkits. A page refresh was required for the secret to become visible.</li> </ul>"},{"location":"release-notes/archived/rn1/","title":"Alita Release Notes","text":""},{"location":"release-notes/archived/rn1/#introduction","title":"Introduction","text":"<p>Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts.</p>"},{"location":"release-notes/archived/rn1/#information","title":"Information","text":"<ul> <li>Release Version: 1.0.0</li> <li>Released on: 23-Apr-2024</li> <li>Access: Alita Platform. Note: You need to enable Epam VPN to access Alita.</li> <li>User Guide: Alita - User Guide</li> </ul>"},{"location":"release-notes/archived/rn1/#new-features","title":"New Features","text":"<ul> <li>Create, Modify, and Save Prompts: Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process.</li> <li>Import Prompts: Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition.</li> <li>Version Control: Maintain various versions of prompts in one place, with the capability to effortlessly switch between them.</li> <li>Execution Options: Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently.</li> <li>Publish and Share Prompts: Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing.</li> <li>Engage with Published Prompts: Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement.</li> <li>Organize with Collections and Tags: Group your prompts into Collections and categorize them with Tags for better organization and accessibility.</li> <li>Advanced Search Functionality: Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters.</li> <li>Tag-based Filtering: Filter prompts and collections using tags, making it easier to find relevant content.</li> <li>Datasource Configuration: Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI.</li> <li>Embedding Creation: Users can create Embeddings, adding a layer of sophistication to prompt management.</li> <li>Similarity Search and Deduplication: Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts.</li> </ul>"},{"location":"release-notes/archived/rn1/#known-issues","title":"Known Issues","text":"<p>N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements.</p>"},{"location":"release-notes/archived/rn1/#fixed-issues","title":"Fixed Issues","text":"<p>N/A - This being the first version, there are no previously fixed issues to report.</p>"},{"location":"release-notes/archived/rn2/","title":"Alita Release Notes","text":""},{"location":"release-notes/archived/rn2/#introduction","title":"Introduction","text":"<p>Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.</p>"},{"location":"release-notes/archived/rn2/#information","title":"Information","text":"<ul> <li>Release Version: 1.0.1</li> <li>Released on: 27-May-2024</li> <li>Access: Alita Platform. Note: You need to enable Epam VPN to access Alita.</li> <li>User Guide: Alita - User Guide </li> </ul>"},{"location":"release-notes/archived/rn2/#new-features","title":"New Features","text":"<ul> <li>IDE Extensions: Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments.</li> <li>QTest Integration: Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data.</li> <li>Project Switcher: Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity.</li> <li>Enhanced Search Functionality: Improved search capabilities, enabling more precise and faster retrieval of information across the platform.</li> <li>Dataset Status Indicators: Enhanced user interface for dataset status:<ul> <li>Done: No indicator displayed.</li> <li>Preparing/In Progress: Displays a circular progress indicator using the material default component.</li> <li>Error: Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention.</li> </ul> </li> </ul>"},{"location":"release-notes/archived/rn2/#known-issues","title":"Known Issues","text":"<ul> <li>Database Corruption During Indexing: If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround: It is recommended to create a new datasource and reindex the data within it.</li> <li>Delayed File Finder in Alita HUB: Users may experience delays when opening the file finder in Alita HUB.</li> <li>Prompt Saving Error: There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces.</li> </ul>"},{"location":"release-notes/archived/rn2/#fixed-issues","title":"Fixed Issues","text":"<ul> <li>GUI Freezing During Indexing: Resolved an issue where the frontend would freeze when indexing large files in a dataset.</li> <li>Token Expiry Display: Fixed a bug where expired tokens were not marked as Expired in the Configuration tab.</li> <li>Modal Design Issue: Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.</li> </ul>"},{"location":"release-notes/archived/rn3/","title":"ELITEA Release Notes","text":""},{"location":"release-notes/archived/rn3/#introduction","title":"Introduction","text":"<p>ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.</p>"},{"location":"release-notes/archived/rn3/#information","title":"Information","text":"<ul> <li>Release Version: 1.1.0</li> <li>Released on: 31-May-2024</li> <li>Access: ELITEA Platform. Note: You need to enable Epam VPN to access ELITEA.</li> <li>User Guide: ELITEA - User Guide </li> </ul>"},{"location":"release-notes/archived/rn3/#new-features","title":"New Features","text":"<ul> <li>Agents Framework: Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform.</li> <li>Toolkits Available for Agents:<ul> <li>Prompt Toolkit: Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions.</li> <li>Datasource Toolkit: Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information.</li> <li>OpenAPI Toolkit: Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions.</li> <li>Browser Toolkit: Equip your Agent with search engine capabilities, enabling access to a vast array of online information.</li> <li>Confluence Toolkit: Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy.</li> <li>GitHub Toolkit: Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes.</li> <li>GitLab Toolkit: Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions.</li> <li>Jira Toolkit: Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity.</li> <li>Agent Toolkit: Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects.</li> </ul> </li> <li>Monitoring Enhancements: Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns.</li> </ul>"},{"location":"release-notes/archived/rn3/#changed-features","title":"Changed Features","text":"<ul> <li>Brand Transition: Alita has been rebranded to ELITEA. This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding.</li> </ul>"},{"location":"release-notes/archived/rn3/#known-issues","title":"Known Issues","text":"<ul> <li>Database Corruption During Indexing: There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround: Create a new datasource and reindex the data within it to avoid this issue.</li> <li>Prompt Saving Error: Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces.</li> <li>Datasources - GIT source Authentication Issue: Authentication using SSH for Git source type in Datasource fails. Workaround: Use the HTTPS option with Username and Password for successful authentication.</li> <li>Agent: Confluence tool - Token Authentication type: Authentication using Token for Confluence tool in Agents fails. Workaround: Use the API key option for successful authentication.</li> </ul>"},{"location":"release-notes/archived/rn3/#fixed-issues","title":"Fixed Issues","text":"<ul> <li>Deduplication Enhancements: Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency.</li> <li>Delayed File Finder in ELITEA HUB: Users may experience delays when accessing the file finder in ELITEA HUB.</li> </ul>"},{"location":"release-notes/archived/rn4/","title":"ELITEA Release Notes","text":""},{"location":"release-notes/archived/rn4/#introduction","title":"Introduction","text":"<p>ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.</p>"},{"location":"release-notes/archived/rn4/#information","title":"Information","text":"<ul> <li>Release Version: 1.2.0</li> <li>Released on: 21-June-2024</li> <li>Access: ELITEA Platform. Note: You need to enable Epam VPN to access ELITEA.</li> <li>User Guide: ELITEA - User Guide </li> </ul>"},{"location":"release-notes/archived/rn4/#new-features","title":"New Features","text":"<ul> <li>Chat Functionality: Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration:<ul> <li>Public and Private Conversations: Engage openly with project members or conduct private discussions visible only to selected users.</li> <li>Participants: Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models.</li> <li>Interactions: Seamlessly interact with participants, copy responses, and utilize generated content effectively.</li> <li>Conversation Management: Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts.</li> <li>Playback Feature: Navigate through conversation history with playback controls, allowing you to review without active model engagement.</li> </ul> </li> <li>Artifact Toolkit for Agents: A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval.</li> <li>Jira Toolkit Enhancements: Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks.</li> <li>Browser Toolkit Extensions:<ul> <li>Single URL Crawler: This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks.</li> <li>Multi URL Crawler: Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources.</li> <li>Get HTML Content: This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data.</li> </ul> </li> <li>Alita Agent Type: A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions.</li> </ul>"},{"location":"release-notes/archived/rn4/#changed-features","title":"Changed Features","text":"<ul> <li>Confluence Toolkit Adjustments: Removed the Create Page and Page Exists tools to streamline functionalities.</li> <li>Browser Toolkit Changes: Removed the Duckduckgo search tool.</li> <li>Agent Type Updates: Declared the Raw agent type as obsolete, now reserved for legacy agents only.</li> <li>Datasource Authentication: Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative.</li> </ul>"},{"location":"release-notes/archived/rn4/#known-issues","title":"Known Issues","text":"<ul> <li>Confluence Source Filtering: Issues with filtering by Space key and Page IDs. Workaround: Use the filtering by label option.</li> <li>Database Corruption During Indexing: Risk of database corruption if simultaneous actions occur in different datasets. Workaround: Create a new datasource and reindex.</li> <li>Prompt Saving Error: Issues saving prompts if the Name field contains leading spaces from copy/paste actions.</li> <li>GIT Source Authentication: SSH authentication for GIT sources fails. Workaround: Use HTTPS with Username and Password.</li> </ul>"},{"location":"release-notes/archived/rn4/#fixed-issues","title":"Fixed Issues","text":"<ul> <li>Confluence Tool Authentication: Resolved an issue with Token authentication; users should now use the API key method.</li> <li>GitLab Toolkit: Implemented several fixes to enhance functionality.</li> <li>Browser Toolkit: Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.</li> </ul>"},{"location":"release-notes/archived/rn5/","title":"ELITEA Release Notes","text":""},{"location":"release-notes/archived/rn5/#introduction","title":"Introduction","text":"<p>ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.</p>"},{"location":"release-notes/archived/rn5/#information","title":"Information","text":"<ul> <li>Release Version: 1.3.0</li> <li>Released on: 16-Sep-2024</li> <li>Access: ELITEA Platform. Note: You need to enable Epam VPN to access ELITEA.</li> <li>User Guide: ELITEA - User Guide </li> </ul>"},{"location":"release-notes/archived/rn5/#new-features","title":"New Features","text":"<ul> <li>New Navigation Flow: Completely redesigned navigation flow within ELITEA HUB. Access prompts, datasources, agents, and collections through dedicated menus. A new Project Selection dropdown list has been added next to your avatar for easy switching between public and private projects. The 'My Libraries' menu has been completely removed.</li> <li>Light Theme: A new light theme has been added for users who prefer bright and vivid colors. Quickly switch between dark and light themes from the Settings menu.</li> <li>Preloaded LLM Models: Deploy, select, and use locally loaded LLM models to speed up output generation and allow simultaneous calls to LLM models.</li> <li>Secrets: Introducing a secure vault for setting up passwords, tokens, and other authentication options within ELITEA HUB. Configure secrets once and use them across various components like Agent's toolkits.</li> <li>Notifications: New notification functionality to alert users about various events such as prompt publishing status within the ELITEA Hub.</li> <li>ELITEA Extensions: Updated versions of Alita Chat and Alita Chat Code for VSCode and IntelliJ IDEs. These versions support prompt versioning and variables, allowing selection of versions and variable values. Enhanced design for Alita Code in VSCode IDE and improved settings management for Alita Code plugin in IntelliJ IDE. Option to download pre-generated settings for Alita Code from ELITEA Hub \u2192 Configurations page.</li> <li>Pgvector Storage: Added Pgvector storage type for datasources, enhancing indexing, saving, and querying of data.</li> <li>New Agent Types: Introduced new agent types including OpenAI, Llama, and Autogen. Enhanced performance and stability of ReAct and Alita agent types.</li> <li>Bitbucket Toolkit for Agents: Allow your Agent to interact directly with Bitbucket repositories, enhancing version control and development processes.</li> <li>TesTrail Toolkit for Agents: Allow your Agent to interact directly with TestRail test management tool.</li> <li>New tools for Confluence Toolkit: Added <code>Create page</code>, <code>Create pages</code>, <code>Delete page</code>, <code>Update page by id</code>, <code>Update page bt title</code>, <code>Update labels</code>, <code>Update pages</code>, <code>Site search</code>, <code>Search by title</code>, <code>Get page tree</code> and <code>Read page by id</code> tools.</li> <li>Export Datasource: New functionality to export datasource instructions, conversation starters, welcome messages, and settings. Note: Datasets within the datasource will not be exported for security reasons.</li> <li>Welcome Message: Added a welcome message feature for prompts, datasources, and agents, providing additional context. Currently, the welcome message is sent to LLM along with other instructions. Future updates will allow users to configure the delivery of welcome messages.</li> <li>Conversation Starter: Added a feature for prompts and datasources to configure and initiate conversations with predefined questions, queries, or information.</li> </ul>"},{"location":"release-notes/archived/rn5/#changed-features","title":"Changed Features","text":"<ul> <li>Chat Functionality: Completely redesigned and improved Chat functionality. Enhanced ability to search and add various participants easily. Fixes implemented for synchronization and speed issues. Now supports agent and prompt versions, as well as prompts with variables.</li> <li>Monitoring: Completely redesigned and enhanced Monitoring functionality. Now supports grouping projects and improved visualization with better charts and graphics.</li> <li>Projects: Redesigned the Settings\u2192Users page to a Projects page, allowing project admins to add new users to projects. Also supports creating/selecting groups for monitoring functionality.</li> </ul>"},{"location":"release-notes/archived/rn5/#known-issues","title":"Known Issues","text":"<ul> <li>Confluence Source Filtering: Issues with filtering by Space key and Page IDs. Workaround: Use the filtering by label option.</li> <li>Database Corruption During Indexing: Risk of database corruption if simultaneous actions occur in different datasets for Chroma storage type. Workaround: Create a new datasource and reindex, or use Pgvector storage type when creating a datasource.</li> <li>GIT Source Authentication: SSH authentication for GIT sources fails. Workaround: Use HTTPS with Username and Password.</li> </ul>"},{"location":"release-notes/archived/rn5/#fixed-issues","title":"Fixed Issues","text":"<ul> <li>Prompt Saving Error: Fixed issues with saving prompts if the Name field contains leading spaces from copy/paste actions.</li> <li>GitLab Toolkit - Set Active Branch Tool: Resolved an issue where the 'Set Active Branch' tool was not functioning properly. Users can now successfully set the active branch in GitLab without encountering errors.</li> <li>Typo in Error Message When Selecting 'Update File' from GitLab Tool: Resolved an issue where a typo in the error message appeared when selecting the 'Update file' option from the GitLab tool.</li> <li>Agents Disappear on Scroll and Incorrect Message Displayed: Fixed an issue where agents disappeared from the page when scrolling, and an incorrect message was displayed. A page refresh was required to bring the agents back.</li> <li>User Search Crash in Settings: Resolved an issue where attempting to search for a user via the Teammates 'search box' in Settings\u2192Projects\u2192Users caused the UI to crash. The search functionality now operates smoothly without causing disruptions.</li> <li>Date Selection Crash in Monitoring Settings: Fixed a problem where selecting an incorrect date in the date fields on the Settings\u2192Monitoring page caused the UI to crash. Proper error handling and date validation have been implemented to ensure stability and prevent crashes.</li> </ul>"},{"location":"support-resources/contact-support/","title":"How to Contact ELITEA Support","text":"<p>We understand that you may encounter questions or issues while using ELITEA. Our dedicated engineers and support team are always ready to assist you. This guide outlines how to reach us and provides best practices for reporting issues to ensure a quick and efficient resolution.</p>"},{"location":"support-resources/contact-support/#contacting-elitea-support","title":"Contacting ELITEA Support","text":"<p>The primary way to reach our support team is via email:</p> <ul> <li>Email: SupportAlita@epam.com</li> </ul> <p>Please use this email address for all support-related inquiries.</p>"},{"location":"support-resources/contact-support/#how-to-report-issues-and-ask-questions-effectively","title":"How to Report Issues and Ask Questions Effectively","text":"<p>To help us quickly understand and resolve your issue, please provide as much relevant information as possible in your support request. The more details you include, the faster we can assist you.</p> <p>Here's a breakdown of the information we need, categorized by the type of issue you're experiencing:</p>"},{"location":"support-resources/contact-support/#general-information-mandatory-for-all-issues","title":"General Information (Mandatory for All Issues)","text":"<p>Regardless of the specific issue, please include the following in your email:</p> <ol> <li>ELITEA Environment: Specify the ELITEA environment where you are encountering the problem (e.g., \"Nexus,\" \"Alita Lab,\" \"EYE\").</li> <li>Project Details:<ul> <li>Project Name: Provide the name of the specific project within the ELITEA environment where the issue occurs.</li> <li>Workspace Type: Indicate whether this is your \"Private\" workspace or a \"Team\" project.</li> </ul> </li> <li>Issue Description:<ul> <li>Clear and Concise: Provide a clear and concise description of the issue you are experiencing.</li> <li>Expected Result: Explain what you were trying to achieve and what the expected outcome should have been.</li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#issues-with-agents","title":"Issues with Agents","text":"<p>If you are experiencing issues with an agent, please include the following information:</p> <ol> <li>Agent Instructions:<ul> <li>Screenshot or Text: Provide a screenshot of the agent's instructions or copy and paste the text of the instructions directly into your email. This allows us to understand the agent's configuration.</li> </ul> </li> <li>Used Toolkits and Configuration:<ul> <li>Screenshot or Text: If your agent uses specific toolkits (e.g., prompts, datasources, other agents, Jira, Confluence, etc.), provide screenshots of their configurations. This helps us understand how the toolkits are set up.</li> </ul> </li> <li>Your Query/Question:<ul> <li>Exact Text: Provide the exact query or question you used to execute the agent. This helps us replicate the issue.</li> </ul> </li> <li>Error Text (if applicable):<ul> <li>Copy from Chat Window: If you encountered an error, expand the error window, click the \"show all\" button for the error message in the Chat window, and copy the full error text into your email. This provides us with detailed error information.</li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#issues-with-datasources","title":"Issues with Datasources","text":"<p>For issues related to datasources, please provide the following:</p> <ol> <li>Datasource Configuration:<ul> <li>Screenshot: Provide a screenshot of your datasource configuration settings.</li> </ul> </li> <li>Datasource Instructions:<ul> <li>Screenshot: If you have specific instructions for the datasource, provide a screenshot of those instructions.</li> </ul> </li> <li>Dataset Configuration:<ul> <li>Screenshot: Provide a screenshot of the dataset configuration settings.</li> </ul> </li> <li>Dataset Error Logs (if applicable):<ul> <li>Download and Attach: If you encounter errors with datasets, download the error log file from the dataset and attach it to your email.</li> </ul> </li> <li>Advanced Settings:<ul> <li>Screenshot: If the issue relates to the Chat, Search, or Deduplicate tabs, provide a screenshot of the advanced settings in those tabs.</li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#issues-with-prompts","title":"Issues with Prompts","text":"<p>If you are experiencing issues with a specific prompt, please include:</p> <ol> <li>Prompt Instructions:<ul> <li>Screenshot: Provide a screenshot of the prompt's instructions.</li> </ul> </li> <li>Configurations:<ul> <li>Screenshot or Text: Provide screenshots or text of the prompt's configurations, including variable setup, selected LLM model, temperature settings, and other relevant parameters.</li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#issues-with-alita-code-and-alita-code-chat-extensions","title":"Issues with Alita Code and Alita Code Chat Extensions","text":"<p>For issues related to the Alita Code or Alita Code Chat extensions, please provide the following:</p> <ol> <li>Environment Connection:<ul> <li>ELITEA Environment: Specify the ELITEA environment to which you are connecting the Alita Code extension (e.g., \"Nexus,\" \"Alita Lab,\" \"EYE\")..</li> </ul> </li> <li>Extension Version:<ul> <li>IDE Type: Indicate whether you are using the VSCode or JetBrains version of the extension.</li> </ul> </li> <li>Alita Code Configuration:<ul> <li>Screenshot: Provide a screenshot of the Alita Code configuration settings within the extension's settings.</li> </ul> </li> <li>Error Messages (if applicable):<ul> <li>Screenshot or Text: Provide a screenshot or copy and paste the text of any error messages you receive while using the extension or connecting it to an ELITEA project.</li> </ul> </li> <li>Issue Description:<ul> <li>Detailed Description: Provide a detailed description of the issue you are experiencing. Please specify whether it is:<ul> <li>A connection issue to an ELITEA project.</li> <li>An execution issue (e.g., problems executing prompts or datasources).</li> <li>A synchronization issue (e.g., problems syncing prompts or datasources).</li> <li>An issue with running Alita Code Chat (e.g., problems executing prompts, agents, or datasources). </li> </ul> </li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#issues-with-eliteas-other-features","title":"Issues with ELITEA's Other Features","text":"<p>For issues related to other features, please provide:</p> <ol> <li>Issue Description:<ul> <li>Detailed Description: Provide a detailed description of the issue you are experiencing.</li> </ul> </li> <li>Screenshots:<ul> <li>Visual Context: Include screenshots that illustrate the issue.</li> </ul> </li> <li>Dev Tools Console Log (if applicable):<ul> <li>Screenshot or Text: If you are comfortable using your browser's developer tools, copy and paste any relevant error messages from the console log or the screenhsot into your email.</li> </ul> </li> </ol>"},{"location":"support-resources/contact-support/#best-practices-for-reporting-issues","title":"Best Practices for Reporting Issues","text":"<ul> <li>Be Specific: The more specific you are, the easier it is for us to understand the issue.</li> <li>Provide Context: Explain what you were trying to do and what you expected to happen.</li> <li>Include Screenshots: Visual aids are often very helpful in understanding the problem.</li> <li>One Issue per Email: If you have multiple unrelated issues, please send separate emails for each. This helps us track and resolve them more efficiently.</li> <li>Be Patient: Our support team will do their best to respond to your request as quickly as possible.</li> </ul> <p>By following these guidelines, you can help us provide you with the best possible support experience. We appreciate your cooperation and look forward to assisting you with your ELITEA journey!</p>"},{"location":"support-resources/contact-support/#before-contacting-support-explore-available-resources","title":"Before Contacting Support: Explore Available Resources","text":"<p>Before reaching out to the support team, we encourage you to explore the available resources. Often, you can find answers to your questions or solutions to common issues by:</p> <ul> <li>Reviewing Documentation: Check the official ELITEA documentation for the specific feature you are using.</li> <li>Watching Video Materials: Look for video tutorials or demonstrations that might cover the topic.</li> <li>Checking Configurations: Double-check your configurations and settings to ensure they are correct.</li> </ul>"},{"location":"support-resources/contact-support/#join-the-elitea-alita-community","title":"Join the ELITEA (Alita) Community","text":"<p>We also encourage you to ask questions and share your experiences with other ELITEA users in our community on Viva Engage:</p> <p>ELITEA (Alita) Community</p> <p>This is a great place to connect with other users, learn from their experiences, and get help from the community.</p>"}]}