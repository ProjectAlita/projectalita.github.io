{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to ELITEA Documentation ELITEA is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations. Our Values: Democratize AI Access for all organizational levels with accessible, user-friendly AI technology. Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments. Foster Collaboration by providing environments where people can share their assets within projects and organization. Scale with Your Needs with a platform that scales from small teams to enterprise levels.","title":"Welcome to ELITEA Documentation"},{"location":"#welcome-to-elitea-documentation","text":"ELITEA is a platform designed to streamline the management, development, and collaboration of Large Language Model (LLM) assets within organizations.","title":"Welcome to ELITEA Documentation"},{"location":"#our-values","text":"Democratize AI Access for all organizational levels with accessible, user-friendly AI technology. Embrace Creativity by providing a flexible, intuitive environment for innovative AI solutions. Enhance Productivity by maximizing team efficiency with integrated tools and environments. Foster Collaboration by providing environments where people can share their assets within projects and organization. Scale with Your Needs with a platform that scales from small teams to enterprise levels.","title":"Our Values:"},{"location":"faqs/","text":"Frequently Asked Questions Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with Alita, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of Alita. What You'll Find Here In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what Alita can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use Alita for optimal results. How to Use This Section Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section. Why an FAQ Section? We believe in empowering our users with knowledge. An informed user can better leverage Alita's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly. Let's Dive In! Ready to explore? Great! Your next step towards mastering Alita begins here. Navigate through the questions, uncover new insights, and elevate your Alita experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f FAQs How Can I Integrate Confluence as a Source Type in Alita? Answer Integrating Confluence with Alita allows you to seamlessly connect and utilize your Confluence data within Alita. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for Alita to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps Alita connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data Alita accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup . Example Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : AKk3NjYxMTIyMTY5Oqup3iccFECiScBjE4QK8B3dy444 Username : levon_dadayan@epam.com Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Frequently Asked Questions"},{"location":"faqs/#frequently-asked-questions","text":"Hello there! \ud83d\udc4b We're thrilled you're here. Whether you're an experienced user or just starting your journey with Alita, questions might pop up, and that's perfectly okay! Our Frequently Asked Questions section is a treasure trove of information designed to help you navigate and make the most out of Alita.","title":"Frequently Asked Questions"},{"location":"faqs/#what-youll-find-here","text":"In this dedicated space, we aim to address a wide array of inquiries, covering everything from basic operations to more advanced functionalities . Our FAQs are carefully curated to ensure clarity, relevance, and usefulness. Here's a sneak peek of what to expect: Getting Started : Step-by-step guides and tips for new users. Features & Functions : Deep dives into what Alita can do and how to use its features to your advantage. Troubleshooting : Solutions and workarounds for common issues. Best Practices : Advice on how to efficiently use Alita for optimal results.","title":"What You'll Find Here"},{"location":"faqs/#how-to-use-this-section","text":"Browse or Search : Feel free to scroll through the questions or use the search function to find specific topics. Interactive Examples : Where applicable, we've included interactive examples to illustrate solutions. Feedback Loop : Got a question not covered here? Let us know! Your inquiries help us improve and expand our FAQ section.","title":"How to Use This Section"},{"location":"faqs/#why-an-faq-section","text":"We believe in empowering our users with knowledge. An informed user can better leverage Alita's capabilities, leading to a more satisfying experience. Plus, this self-service resource aims to provide immediate answers, saving you time and getting you back on track quickly.","title":"Why an FAQ Section?"},{"location":"faqs/#lets-dive-in","text":"Ready to explore? Great! Your next step towards mastering Alita begins here. Navigate through the questions, uncover new insights, and elevate your Alita experience. Remember, we're here to support your journey, every step of the way. Happy Exploring! \ud83c\udf1f","title":"Let's Dive In!"},{"location":"faqs/#faqs","text":"","title":"FAQs"},{"location":"faqs/#how-can-i-integrate-confluence-as-a-source-type-in-alita","text":"","title":"How Can I Integrate Confluence as a Source Type in Alita?"},{"location":"faqs/#answer","text":"Integrating Confluence with Alita allows you to seamlessly connect and utilize your Confluence data within Alita. To set up this connection accurately, please follow the comprehensive steps outlined below: Dataset Name : Assign a descriptive name to your dataset for easy identification. Source Selection : In the 'Source Type' dropdown, choose 'Confluence' to set it as your data source. Confluence URL : Enter the URL of your Confluence space's homepage. This acts as the entry point for Alita to access your Confluence content. Authentication : Supply the API Key or Token required for authenticating your access to the Confluence data. This ensures secure connection and data transfer. Username : Input your Confluence username. This is necessary for authentication purposes and to ensure proper permissions are applied. Hosting Option : Specify your hosting preference Server or Cloud . This information helps Alita connect to the correct Confluence environment. Data Filtering : Choose how you wish to filter the data. You can select by Space Key , Page IDs , or Labels . This step is crucial for refining the data Alita accesses, ensuring only relevant content is included in your dataset. Save : After configuring all settings, click Save to finalize the dataset creation. For more information : please check Datasources - Confluence setup .","title":"Answer"},{"location":"faqs/#example","text":"Let's walk through a practical scenario to better understand how to implement these steps: Dataset Name : Functional Testing Armenia - Documentation Source Type : Confluence URL : https://kb.epam.com Token : AKk3NjYxMTIyMTY5Oqup3iccFECiScBjE4QK8B3dy444 Username : levon_dadayan@epam.com Hosting Option : Server Filtering Option : Labels Labels : ft_armenia This example demonstrates a hypothetical setup for illustrative purposes only. Ensure you replace the placeholder information with your actual data during configuration.","title":"Example"},{"location":"manuals/alita-dial/","text":"Interoperability Guide: ELITEA and EPAM AI Dial Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial. Export Prompts from ELITEA Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it: Exporting the Prompt for AI DIAL: Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format. Import Prompts to EPAM AI Dial Once you have the JSON file from ELITEA, you can easily import it into AI Dial. Importing the Prompt into AI Dial: Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial. Export Prompts from EPAM AI Dial If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA. Import Prompts to ELITEA To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Exporting and Importing Collections from ELITEA to EPAM AI Dial You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial. Troubleshooting File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts. Useful Links ELITEA - User Guide ELITEA - Release Notes Epam AI Dial - User Guide","title":"ELITEA and EPAM AI DIAL"},{"location":"manuals/alita-dial/#interoperability-guide-elitea-and-epam-ai-dial","text":"Welcome to the user-friendly manual on using ELITEA and EPAM AI Dial seamlessly together. This guide walks you through the steps to export from one platform and import into another, ensuring a hassle-free interoperation between ELITEA and EPAM AI Dial.","title":"Interoperability Guide: ELITEA and EPAM AI Dial"},{"location":"manuals/alita-dial/#export-prompts-from-elitea","text":"Exporting a prompt in ELITEA enables you to use it on different platforms including EPAM AI Dial. Here\u2019s how to do it:","title":"Export Prompts from ELITEA"},{"location":"manuals/alita-dial/#exporting-the-prompt-for-ai-dial","text":"Start the Export : Click on the Export prompt icon. Choose Format : Select the [DIAL] format format when prompted. This format is specially designed for compatibility with EPAM AI Dial. Download : After selecting the format, the file will be downloaded automatically to your device in JSON format.","title":"Exporting the Prompt for AI DIAL:"},{"location":"manuals/alita-dial/#import-prompts-to-epam-ai-dial","text":"Once you have the JSON file from ELITEA, you can easily import it into AI Dial.","title":"Import Prompts to EPAM AI Dial"},{"location":"manuals/alita-dial/#importing-the-prompt-into-ai-dial","text":"Begin Import : Click on the Import prompts icon within the AI Dial platform. Select File : Browse your device and select the JSON file you exported from ELITEA. Complete Import : The platform will automatically add the prompt to the Prompts section. Usage : You can now select and use the prompt within AI Dial.","title":"Importing the Prompt into AI Dial:"},{"location":"manuals/alita-dial/#export-prompts-from-epam-ai-dial","text":"If you have developed or customized prompts in EPAM AI Dial, you can easily export them for use in ELITEA. Prompt Selection : Identify and select the prompt you wish to export. Export : Click the ... icon next to your selected prompt and choose the Export option. File Download : The prompt will be exported and downloaded in JSON format, ready for ELITEA.","title":"Export Prompts from EPAM AI Dial"},{"location":"manuals/alita-dial/#import-prompts-to-elitea","text":"To use the prompts created or exported from EPAM AI Dial in ELITEA, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts page in ELITEA. Use Prompt : You can now access and utilize the imported prompt.","title":"Import Prompts to ELITEA"},{"location":"manuals/alita-dial/#exporting-and-importing-collections-from-elitea-to-epam-ai-dial","text":"You can also export entire collections from ELITEA and import them into EPAM AI Dial for broader prompt management. Export Collection : In ELITEA, select the collection you wish to export and choose the Export Collection option. Select the [DIAL] format for optimal compatibility. Download Collection : The collection, encompassing multiple prompts, will be exported as a JSON file and automatically downloaded to your device. Import into AI Dial : Upon importing the collection file into EPAM AI Dial, please note that the included prompts will be added as separate items, not as a unified folder. This feature enhances workflow efficiency by allowing bulk transferring of prompts between the platforms, albeit without retaining the folder structure during import into AI Dial.","title":"Exporting and Importing Collections from ELITEA to EPAM AI Dial"},{"location":"manuals/alita-dial/#troubleshooting","text":"File Format : Ensure the prompt file is in JSON format. Other formats won\u2019t be processed. Template Compatibility : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. File Structure : If you encounter any unrecognized errors, open the exported JSON file in a text editor. Validate its structure and formatting against the Jinja template requirements, making any necessary adjustments. By following these detailed steps, you should be able to smoothly export and import prompts and collections between ELITEA and EPAM AI Dial, enhancing your productivity and efficiency in creating and managing prompts.","title":"Troubleshooting"},{"location":"manuals/alita-dial/#useful-links","text":"ELITEA - User Guide ELITEA - Release Notes Epam AI Dial - User Guide","title":"Useful Links"},{"location":"manuals/creating-prompts/","text":"How to Create and Publish Useful Prompts for Testing and QA Activities Introduction Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success. Accessing ELITEA HUB To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA. Prompts Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information. How to Create a Prompt Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings: Prompt Requirements for Consistency and Quality When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations. Submitting Your Prompt for Publishing To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt: Review Process by Moderators and Outcome of Prompt Submission Moderator Review Process After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared. Possible Outcomes of the Review After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Statuses of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. To check the status of your submitted prompts, navigate to \" Prompts \" page on the platform, and select the status you wish to view from the dropdown menu. Engagement with Prompts: Liking and Trending Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy. Collections Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. Creating Collection Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about. Adding Prompts to Your Collection To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection. Publishing Your Collection Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication. Engagement with Collections: Liking and Trending Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged. Contribution Why Share Your Prompts? Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement. Rewards and Recognition To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network. Useful Resources ELITEA ELITEA - User Guide ELITEA - Release Notes Prompt Engineering Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"QA - Prompting and Sharing"},{"location":"manuals/creating-prompts/#how-to-create-and-publish-useful-prompts-for-testing-and-qa-activities","text":"","title":"How to Create and Publish Useful Prompts for Testing and QA Activities"},{"location":"manuals/creating-prompts/#introduction","text":"Welcome to our comprehensive guide designed to empower our Testing and Quality Assurance (QA) community in the crafting and sharing of valuable prompts, specifically tailored for an array of testing activities. In today's rapidly evolving software development landscape, the adoption of Generative AI Tools has become increasingly instrumental in augmenting our testing efforts. These cutting-edge tools offer unparalleled capabilities in automating and innovating processes ranging from generating test cases and creating detailed test plans to formulating comprehensive test strategies and writing automation scripts. Additionally, they play a critical role in generating realistic and diverse test data, facilitating a more thorough and effective testing process. The intention behind this activity is twofold: to streamline the process of prompt generation that leverages Gen AI Tools, ensuring that these prompts become potent tools in identifying and resolving defects, bolstering product quality, and refining our testing strategies. Moreover, it seeks to evolve our QA community to actively contribute to and share their expertise through valuable prompts. By participating in enriching our Prompt Library, you not only aid in creating a substantial repository of resources but also contribute to a culture of knowledge sharing and collective growth within our community. We encourage you to share prompts across various domains, including but not limited to, generating test cases, creating comprehensive test plans and strategies, developing automation scripts, and generating test data. This endeavor will not only help elevate the efficiency and effectiveness of our testing processes but also foster innovation and creativity within our QA practices. In leveraging Gen AI tools, it is imperative to always review the generated outputs meticulously to ensure they not only meet our stringent quality standards but also strictly adhere to Epam\u2019s security guidelines and policies. Our collective commitment to maintaining the highest level of security and protecting sensitive information is paramount and non-negotiable. Your contribution to this initiative will play a pivotal role in enhancing our testing capabilities, driving quality improvements, and maintaining our competitive edge in delivering superior software solutions. Let us embark on this journey together, fostering a vibrant and collaborative QA community that thrives on innovation, excellence, and shared success.","title":"Introduction"},{"location":"manuals/creating-prompts/#accessing-elitea-hub","text":"To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA.","title":"Accessing ELITEA HUB"},{"location":"manuals/creating-prompts/#prompts","text":"Prompts are essentially instructions or scenarios designed to generate outcomes to assist QA activities. The effectiveness of the prompts directly correlates with the efficiency and accuracy of our testing efforts. To ensure that every prompt we create serves its purpose effectively, it\u2019s crucial to adhere to several foundational principles. These guidelines not only help in crafting prompts that are valuable and practical but also ensure that they align with our overarching goals of security, versatility, and clarity in our QA processes. With this context in mind, let\u2019s delve into the core principles that should guide the creation of effective prompts: Creating Effective Prompts Relevance : Directly tie your prompt to testing and QA activities to ensure relevance. Clarity : Utilize clear, concise language for better comprehension. Specificity : Clearly mention the testing phase, type, and specific focus area of the prompt. Scalability : Aim for prompts that can be broadly applied across various projects. Security : Avoid including any customer data or sensitive information.","title":"Prompts"},{"location":"manuals/creating-prompts/#how-to-create-a-prompt","text":"Creating a prompt involves capturing essential details that guide the testing process effectively. Here is how you can create a prompt that adds value: Initiate Prompt Creation : Click the + Prompt button located at the top right of your screen to start crafting your prompt. Provide Prompt Details : Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Note : The Name and Description fields are crucial for others to understand the prompt\u2019s purpose and are not editable after saving. Tag(s) : A descriptive Tag(s) for grouping the prompts. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables - then a descriptive variable name. In case the prompt has System or Assistant messages - then those messages must be informative. Select the Model : Choose the appropriate model (e.g., gpt-3.5-turbo, gpt-4-0125-preview, etc.) for which the prompt has been tailored and tested. Configure Advanced Settings : Tune the output of your prompt by adjusting configurations such as Temperature, Top P, Top K, and Maximum length, ensuring the prompt's output aligns with expectations. Test Your Prompt : Execute the prompt and review the results to confirm everything functions as intended. Finalize : Click Save to keep your draft or proceed to the next step to share your work with the community. Providing Name, Description and Context of the prompt: Setup Variables: Configuring Advanced Settings:","title":"How to Create a Prompt"},{"location":"manuals/creating-prompts/#prompt-requirements-for-consistency-and-quality","text":"When crafting your prompt, ensure it includes the following elements for clarity and effectiveness: Descriptive Name : Clearly indicates the focus of the prompt. Conciseness : Aim for a name that is brief yet descriptive, ideally under 30 characters. Relevance : Ensure the name directly reflects the content or purpose of the prompt. Brief Description : Eloquently explains the prompt\u2019s goal. Specificity : Include specific details about what the prompt is intended to achieve. Brevity : Keep the description concise, aiming for one to two sentences. Descriptive Tags : Facilitates prompt categorization and searchability. Relevance : Choose tags that are directly related to the prompt\u2019s content and purpose. Diversity : Use a mix of broad and specific tags to enhance discoverability. Framework Adherence : Ensures the prompt aligns with accepted Prompt creation frameworks (e.g., CREATE, CRISPE, Elavis Saravia, etc.). Consistency : Stick to one framework per prompt to maintain clarity and structure. Documentation : Reference the framework used in the prompt description for clarity. Variable Clarity : In scenarios with variables, use descriptive names. Descriptiveness : Use names that clearly indicate what the variable represents. Standardization : Follow a consistent naming convention for variables across prompts. Informative System Messages : If your prompt uses system or assistant messages, they must be clear and helpful. Clarity : Ensure messages are straightforward and free of jargon. Guidance : Messages should guide the user on how to interact with the prompt effectively. Expected Outcomes : Define what successful application of the prompt looks like. Measurable Criteria : Specify clear, measurable criteria for what constitutes a successful outcome. Examples : Provide examples of successful outcomes to illustrate expectations.","title":"Prompt Requirements for Consistency and Quality"},{"location":"manuals/creating-prompts/#submitting-your-prompt-for-publishing","text":"To make your prompt available to the wider QA community, follow the steps below for publication: Publishing Initiation : With your prompt crafted and saved, click the Publish button to start the submission process. Version Naming : Provide an informative version name (e.g., Gen-1.0) in the pop-up window. This name should reflect the content or purpose of the prompt, aiding in version control and future modifications. Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Review Submission : Click Publish to submit your prompt for the moderation review process. This step is crucial to ensure the quality and relevance of prompts available to the QA community. Publishing the prompt:","title":"Submitting Your Prompt for Publishing"},{"location":"manuals/creating-prompts/#review-process-by-moderators-and-outcome-of-prompt-submission","text":"","title":"Review Process by Moderators and Outcome of Prompt Submission"},{"location":"manuals/creating-prompts/#moderator-review-process","text":"After a prompt is submitted for publication, it enters a critical assessment phase led by our designated moderators. Our moderators are QA professionals with a broad understanding of what constitutes a high-quality, effective prompt. The review process aims to ensure that each prompt meets our standards for relevance, clarity, security, and overall utility. The moderators follow a structured evaluation protocol: Initial Assessment : Moderators perform an initial check to ensure that the prompt submission is complete and adheres to the submission format. Content Review : The content of the prompt is closely examined for its relevance to QA activities, clarity of instructions, adherence to accepted frameworks, and the security of information. Practical Evaluation : Moderators assess the prompt\u2019s practical application, reviewing variables, system messages for clarity, and the feasibility of expected outcomes. Compliance Check : There's a final compliance check against our community guidelines and security policies to ensure no sensitive information is shared.","title":"Moderator Review Process"},{"location":"manuals/creating-prompts/#possible-outcomes-of-the-review","text":"After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Statuses of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. To check the status of your submitted prompts, navigate to \" Prompts \" page on the platform, and select the status you wish to view from the dropdown menu.","title":"Possible Outcomes of the Review"},{"location":"manuals/creating-prompts/#engagement-with-prompts-liking-and-trending","text":"Once a prompt is published, it becomes an essential resource for the QA community. You are encouraged to engage with these prompts through our \" Like \" functionality. Prompts that receive a significant number of likes can appear in the \" Trending \" page of the Prompt Library, highlighting their popularity and usefulness. The \" Trending \" page serves as a quick reference for discovering highly valued prompts within the community. To like a prompt, simply click on the heart icon associated with the prompt in the Prompt Library. Your engagement helps in identifying the most impactful prompts, enriching our QA processes and driving a culture of continuous improvement and collaboration. By understanding and participating in the review process, you are contributing to a shared knowledge base that benefits the entire QA community. Your efforts and interactions, including submitting, refining, and liking prompts, play a crucial role in enhancing our collective testing efficacy.","title":"Engagement with Prompts: Liking and Trending"},{"location":"manuals/creating-prompts/#collections","text":"Following the creation and publishing of individual prompts, the next step is the organization and further dissemination of these prompts through Collections. Collections serve as a means to group prompts by theme, project, testing phase, or any other meaningful categorization that enhances accessibility and usefulness for the QA community. This section will guide you through creating collections, adding prompts to them, publishing these collections, and how your peers can interact with them through likes. The Purpose and Usefulness of Collections Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time for our QA engineers by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"Collections"},{"location":"manuals/creating-prompts/#creating-collection","text":"Click the + Collection button located at the top right corner. You will be prompted to fill in the Name and Description fields. Remember, these fields are essential as they give the first impression and understanding of what your collection is about.","title":"Creating Collection"},{"location":"manuals/creating-prompts/#adding-prompts-to-your-collection","text":"To add prompts to your collection, follow these steps: Once you've created a collection, you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection. Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.","title":"Adding Prompts to Your Collection"},{"location":"manuals/creating-prompts/#publishing-your-collection","text":"Publishing your collection makes it available to the entire QA network, allowing others to benefit from the curated set of prompts you've organized: After adding the desired prompts to your collection, open the collection and review the content to ensure completeness and relevance. Click the Publish icon to submit your collection for review. This process is similar to publishing individual prompts, where your collection will be reviewed for adherence to our guidelines and overall quality. Once approved, your collection will be published and accessible from the Collection menu, ready to be used by the community. Note : A Collection must contain public prompts before publication.","title":"Publishing Your Collection"},{"location":"manuals/creating-prompts/#engagement-with-collections-liking-and-trending","text":"Just as with individual prompts, users are encouraged to engage with collections through likes. This interaction is crucial for several reasons: Recognition : Liking a collection serves as a form of recognition and appreciation for the contributor's effort in curating valuable resources. Visibility : Collections with a high number of likes gain visibility and are more likely to appear in the \"Trending\" page, ensuring that the most useful collections are easily accessible to the community. Feedback Mechanism : Likes serve as a feedback mechanism, helping contributors understand the impact and usefulness of their collections, guiding future efforts in prompt and collection creation. By actively creating, contributing to, and engaging with collections, QA engineers enhance the shared knowledge base and support the continuous improvement of testing practices within the community. Collections not only facilitate access to valuable testing resources but also foster a collaborative environment where knowledge and best practices are freely exchanged.","title":"Engagement with Collections: Liking and Trending"},{"location":"manuals/creating-prompts/#contribution","text":"","title":"Contribution"},{"location":"manuals/creating-prompts/#why-share-your-prompts","text":"Sharing your prompts not only contributes to the collective knowledge of our QA community but also highlights your expertise and creativity. By contributing, you\u2019re directly impacting the efficiency and efficacy of our testing processes, encouraging a culture of innovation and continuous improvement.","title":"Why Share Your Prompts?"},{"location":"manuals/creating-prompts/#rewards-and-recognition","text":"To acknowledge the value of your contributions, we have an Appreciation Program in place. Leading contributors will be recognized by the Management Team. Your innovation could lead the way in defining our testing standards - an opportunity to shine and be recognized among your peers. By following these enhanced guidelines and utilizing the provided resources, you're well on your way to creating impactful prompts that can significantly improve our QA practices. Let's work together to build a richer, more effective Prompt Library for everyone in our network.","title":"Rewards and Recognition"},{"location":"manuals/creating-prompts/#useful-resources","text":"","title":"Useful Resources"},{"location":"manuals/creating-prompts/#elitea","text":"ELITEA - User Guide ELITEA - Release Notes","title":"ELITEA"},{"location":"manuals/creating-prompts/#prompt-engineering","text":"Prompt Engineering Foundations EngX AI-Supported Quality Assurance Engineering Guide to Effective Prompting Introduction to Prompt Engineering","title":"Prompt Engineering"},{"location":"manuals/roles/","text":"Roles Management How to access Admin menu: To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/ . Select the project from the dropdown list for which you want to set up or adjust the admin settings. Roles Menu The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the ELITEA HUB\u2192Settings\u2192Projects menu. By understanding and utilizing the Roles menu, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"Roles Management"},{"location":"manuals/roles/#roles-management","text":"","title":"Roles Management"},{"location":"manuals/roles/#how-to-access-admin-menu","text":"To configure or modify the admin settings for a specific project: Navigate to https://alita.lab.epam.com/-/configuration/users/ . Select the project from the dropdown list for which you want to set up or adjust the admin settings.","title":"How to access Admin menu:"},{"location":"manuals/roles/#roles-menu","text":"The Roles menu allows for the detailed configuration of permissions across default and custom roles, tailoring access to the project's needs. Default Roles : System : Grants comprehensive permissions, including additional administrative capabilities. Admin : Allows full project access and user management. Editor : Provides editing rights within the project without administrative privileges. Viewer : Limits access to viewing permissions, excluding any create, read, update, delete (CRUD) actions. Customizing Roles : To adjust permissions for any role: Click the Edit roles icon. Toggle the checkboxes for each permission as needed. Click the Save to apply changes. Creating a New Role : Click Edit roles . Then Add role . After naming the new role, select the desired permissions. This custom role will now be available for assignment in the ELITEA HUB\u2192Settings\u2192Projects menu. By understanding and utilizing the Roles menu, administrators can ensure that project participants have the appropriate access levels, fostering a secure and efficient collaborative environment.","title":"Roles Menu"},{"location":"release-notes/rn_current/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.3.0 Released on : 16-Sep-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features New Navigation Flow : Completely redesigned navigation flow within ELITEA HUB. Access prompts, datasources, agents, and collections through dedicated menus. A new Project Selection dropdown list has been added next to your avatar for easy switching between public and private projects. The 'My Libraries' menu has been completely removed. Light Theme : A new light theme has been added for users who prefer bright and vivid colors. Quickly switch between dark and light themes from the Settings menu. Preloaded LLM Models : Deploy, select, and use locally loaded LLM models to speed up output generation and allow simultaneous calls to LLM models. Secrets : Introducing a secure vault for setting up passwords, tokens, and other authentication options within ELITEA HUB. Configure secrets once and use them across various components like Agent's toolkits. Notifications : New notification functionality to alert users about various events such as prompt publishing status within the ELITEA Hub. ELITEA Extensions : Updated versions of Alita Chat and Alita Chat Code for VSCode and IntelliJ IDEs. These versions support prompt versioning and variables, allowing selection of versions and variable values. Enhanced design for Alita Code in VSCode IDE and improved settings management for Alita Code plugin in IntelliJ IDE. Option to download pre-generated settings for Alita Code from ELITEA Hub \u2192 Configurations page. Pgvector Storage : Added Pgvector storage type for datasources, enhancing indexing, saving, and querying of data. New Agent Types : Introduced new agent types including OpenAI, Llama, and Autogen. Enhanced performance and stability of ReAct and Alita agent types. Bitbucket Toolkit for Agents : Allow your Agent to interact directly with Bitbucket repositories, enhancing version control and development processes. TesTrail Toolkit for Agents : Allow your Agent to interact directly with TestRail test management tool. New tools for Confluence Toolkit : Added Create page , Create pages , Delete page , Update page by id , Update page bt title , Update labels , Update pages , Site search , Search by title , Get page tree and Read page by id tools. Export Datasource : New functionality to export datasource instructions, conversation starters, welcome messages, and settings. Note : Datasets within the datasource will not be exported for security reasons. Welcome Message : Added a welcome message feature for prompts, datasources, and agents, providing additional context. Currently, the welcome message is sent to LLM along with other instructions. Future updates will allow users to configure the delivery of welcome messages. Conversation Starter : Added a feature for prompts and datasources to configure and initiate conversations with predefined questions, queries, or information. Changed Features Chat Functionality : Completely redesigned and improved Chat functionality. Enhanced ability to search and add various participants easily. Fixes implemented for synchronization and speed issues. Now supports agent and prompt versions, as well as prompts with variables. Monitoring : Completely redesigned and enhanced Monitoring functionality. Now supports grouping projects and improved visualization with better charts and graphics. Projects : Redesigned the Settings\u2192Users page to a Projects page, allowing project admins to add new users to projects. Also supports creating/selecting groups for monitoring functionality. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets for Chroma storage type. Workaround : Create a new datasource and reindex, or use Pgvector storage type when creating a datasource. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Prompt Saving Error : Fixed issues with saving prompts if the Name field contains leading spaces from copy/paste actions. GitLab Toolkit - Set Active Branch Tool : Resolved an issue where the 'Set Active Branch' tool was not functioning properly. Users can now successfully set the active branch in GitLab without encountering errors. Typo in Error Message When Selecting 'Update File' from GitLab Tool : Resolved an issue where a typo in the error message appeared when selecting the 'Update file' option from the GitLab tool. Agents Disappear on Scroll and Incorrect Message Displayed : Fixed an issue where agents disappeared from the page when scrolling, and an incorrect message was displayed. A page refresh was required to bring the agents back. User Search Crash in Settings : Resolved an issue where attempting to search for a user via the Teammates 'search box' in Settings\u2192Projects\u2192Users caused the UI to crash. The search functionality now operates smoothly without causing disruptions. Date Selection Crash in Monitoring Settings : Fixed a problem where selecting an incorrect date in the date fields on the Settings\u2192Monitoring page caused the UI to crash. Proper error handling and date validation have been implemented to ensure stability and prevent crashes.","title":"RN 1.3.0"},{"location":"release-notes/rn_current/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/rn_current/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/rn_current/#information","text":"Release Version : 1.3.0 Released on : 16-Sep-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/rn_current/#new-features","text":"New Navigation Flow : Completely redesigned navigation flow within ELITEA HUB. Access prompts, datasources, agents, and collections through dedicated menus. A new Project Selection dropdown list has been added next to your avatar for easy switching between public and private projects. The 'My Libraries' menu has been completely removed. Light Theme : A new light theme has been added for users who prefer bright and vivid colors. Quickly switch between dark and light themes from the Settings menu. Preloaded LLM Models : Deploy, select, and use locally loaded LLM models to speed up output generation and allow simultaneous calls to LLM models. Secrets : Introducing a secure vault for setting up passwords, tokens, and other authentication options within ELITEA HUB. Configure secrets once and use them across various components like Agent's toolkits. Notifications : New notification functionality to alert users about various events such as prompt publishing status within the ELITEA Hub. ELITEA Extensions : Updated versions of Alita Chat and Alita Chat Code for VSCode and IntelliJ IDEs. These versions support prompt versioning and variables, allowing selection of versions and variable values. Enhanced design for Alita Code in VSCode IDE and improved settings management for Alita Code plugin in IntelliJ IDE. Option to download pre-generated settings for Alita Code from ELITEA Hub \u2192 Configurations page. Pgvector Storage : Added Pgvector storage type for datasources, enhancing indexing, saving, and querying of data. New Agent Types : Introduced new agent types including OpenAI, Llama, and Autogen. Enhanced performance and stability of ReAct and Alita agent types. Bitbucket Toolkit for Agents : Allow your Agent to interact directly with Bitbucket repositories, enhancing version control and development processes. TesTrail Toolkit for Agents : Allow your Agent to interact directly with TestRail test management tool. New tools for Confluence Toolkit : Added Create page , Create pages , Delete page , Update page by id , Update page bt title , Update labels , Update pages , Site search , Search by title , Get page tree and Read page by id tools. Export Datasource : New functionality to export datasource instructions, conversation starters, welcome messages, and settings. Note : Datasets within the datasource will not be exported for security reasons. Welcome Message : Added a welcome message feature for prompts, datasources, and agents, providing additional context. Currently, the welcome message is sent to LLM along with other instructions. Future updates will allow users to configure the delivery of welcome messages. Conversation Starter : Added a feature for prompts and datasources to configure and initiate conversations with predefined questions, queries, or information.","title":"New Features"},{"location":"release-notes/rn_current/#changed-features","text":"Chat Functionality : Completely redesigned and improved Chat functionality. Enhanced ability to search and add various participants easily. Fixes implemented for synchronization and speed issues. Now supports agent and prompt versions, as well as prompts with variables. Monitoring : Completely redesigned and enhanced Monitoring functionality. Now supports grouping projects and improved visualization with better charts and graphics. Projects : Redesigned the Settings\u2192Users page to a Projects page, allowing project admins to add new users to projects. Also supports creating/selecting groups for monitoring functionality.","title":"Changed Features"},{"location":"release-notes/rn_current/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets for Chroma storage type. Workaround : Create a new datasource and reindex, or use Pgvector storage type when creating a datasource. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/rn_current/#fixed-issues","text":"Prompt Saving Error : Fixed issues with saving prompts if the Name field contains leading spaces from copy/paste actions. GitLab Toolkit - Set Active Branch Tool : Resolved an issue where the 'Set Active Branch' tool was not functioning properly. Users can now successfully set the active branch in GitLab without encountering errors. Typo in Error Message When Selecting 'Update File' from GitLab Tool : Resolved an issue where a typo in the error message appeared when selecting the 'Update file' option from the GitLab tool. Agents Disappear on Scroll and Incorrect Message Displayed : Fixed an issue where agents disappeared from the page when scrolling, and an incorrect message was displayed. A page refresh was required to bring the agents back. User Search Crash in Settings : Resolved an issue where attempting to search for a user via the Teammates 'search box' in Settings\u2192Projects\u2192Users caused the UI to crash. The search functionality now operates smoothly without causing disruptions. Date Selection Crash in Monitoring Settings : Fixed a problem where selecting an incorrect date in the date fields on the Settings\u2192Monitoring page caused the UI to crash. Proper error handling and date validation have been implemented to ensure stability and prevent crashes.","title":"Fixed Issues"},{"location":"release-notes/archived/rn1/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts. Information Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts. Known Issues N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements. Fixed Issues N/A - This being the first version, there are no previously fixed issues to report.","title":"RN 1.0.0"},{"location":"release-notes/archived/rn1/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/archived/rn1/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. This initial version introduces a suite of features aimed at enhancing productivity and creativity in working with prompts.","title":"Introduction"},{"location":"release-notes/archived/rn1/#information","text":"Release Version : 1.0.0 Released on : 23-Apr-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/archived/rn1/#new-features","text":"Create, Modify, and Save Prompts : Users can now create, modify, and save their prompts in a dedicated space, streamlining the prompt management process. Import Prompts : Seamlessly import prompts from Epam AI Dial, the previous version of Alita, ensuring continuity and ease of transition. Version Control : Maintain various versions of prompts in one place, with the capability to effortlessly switch between them. Execution Options : Execute prompts using Chat or Completion options, allowing users to gather and save the output (results) efficiently. Publish and Share Prompts : Publish your prompts and share them with your project and network, fostering collaboration and knowledge sharing. Engage with Published Prompts : Use published prompts and collections, with options to like them and mark them as favorites, enhancing community engagement. Organize with Collections and Tags : Group your prompts into Collections and categorize them with Tags for better organization and accessibility. Advanced Search Functionality : Enhanced search functionality to quickly find your prompts or public prompts and collections with various parameters. Tag-based Filtering : Filter prompts and collections using tags, making it easier to find relevant content. Datasource Configuration : Set up various datasources and configure them to enhance your results and the possibilities in using Generative AI. Embedding Creation : Users can create Embeddings, adding a layer of sophistication to prompt management. Similarity Search and Deduplication : Perform similarity searches and deduplicate content, ensuring the uniqueness and relevance of prompts.","title":"New Features"},{"location":"release-notes/archived/rn1/#known-issues","text":"N/A - As this is the initial release, there are currently no known issues. Feedback from users will be invaluable in identifying and addressing future improvements.","title":"Known Issues"},{"location":"release-notes/archived/rn1/#fixed-issues","text":"N/A - This being the first version, there are no previously fixed issues to report.","title":"Fixed Issues"},{"location":"release-notes/archived/rn2/","text":"Alita Release Notes Introduction Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide New Features IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention. Known Issues Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Fixed Issues GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"RN 1.0.1"},{"location":"release-notes/archived/rn2/#alita-release-notes","text":"","title":"Alita Release Notes"},{"location":"release-notes/archived/rn2/#introduction","text":"Alita is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn2/#information","text":"Release Version : 1.0.1 Released on : 27-May-2024 Access : Alita Platform . Note : You need to enable Epam VPN to access Alita. User Guide : Alita - User Guide","title":"Information"},{"location":"release-notes/archived/rn2/#new-features","text":"IDE Extensions : Added support for Alita Code and Alita Code Chat extensions for both Visual Studio Code and IntelliJ IDEA, enhancing coding efficiency directly from your favorite development environments. QTest Integration : Introduced QTest as a new source type under Datasource\u2192Dataset, allowing for seamless integration and management of testing data. Project Switcher : Implemented a new tool for swiftly navigating between different projects, improving workflow fluidity. Enhanced Search Functionality : Improved search capabilities, enabling more precise and faster retrieval of information across the platform. Dataset Status Indicators : Enhanced user interface for dataset status: Done : No indicator displayed. Preparing/In Progress : Displays a circular progress indicator using the material default component. Error : Shows a warning icon alongside a closeable warning alert to inform users of issues that need attention.","title":"New Features"},{"location":"release-notes/archived/rn2/#known-issues","text":"Database Corruption During Indexing : If a user searches in one dataset while another is indexing, there is a risk of database corruption, leading to irreproducible bugs. Workaround : It is recommended to create a new datasource and reindex the data within it. Delayed File Finder in Alita HUB : Users may experience delays when opening the file finder in Alita HUB. Prompt Saving Error : There is an issue where prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces.","title":"Known Issues"},{"location":"release-notes/archived/rn2/#fixed-issues","text":"GUI Freezing During Indexing : Resolved an issue where the frontend would freeze when indexing large files in a dataset. Token Expiry Display : Fixed a bug where expired tokens were not marked as Expired in the Configuration tab. Modal Design Issue : Corrected the stretched and improperly displayed design of the Add to collections modal, ensuring it now renders correctly.","title":"Fixed Issues"},{"location":"release-notes/archived/rn3/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns. Changed Features Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding. Known Issues Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication. Fixed Issues Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"RN 1.1.0"},{"location":"release-notes/archived/rn3/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/archived/rn3/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn3/#information","text":"Release Version : 1.1.0 Released on : 31-May-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/archived/rn3/#new-features","text":"Agents Framework : Introducing a powerful new feature, Agents, which integrates prompts, datasources, and external toolkits into a unified mechanism. This allows for seamless decision-making and action-taking processes, such as searching on Google or creating Jira tickets directly through the ELITEA platform. Toolkits Available for Agents : Prompt Toolkit : Leverage pre-configured prompts from your ELITEA project to ensure consistent and accurate interactions. Datasource Toolkit : Access structured data from pre-configured datasources, enhancing the Agent's ability to process and analyze information. OpenAPI Toolkit : Integrate with OpenAPI-compliant APIs to expand the Agent's external functionalities and interactions. Browser Toolkit : Equip your Agent with search engine capabilities, enabling access to a vast array of online information. Confluence Toolkit : Integrate content from Confluence to enrich the Agent's knowledge base and improve response accuracy. GitHub Toolkit : Allow your Agent to interact directly with GitHub repositories, enhancing version control and development processes. GitLab Toolkit : Enable direct interaction with GitLab repositories, providing specific project data to support informed decisions. Jira Toolkit : Manage Jira issues and projects directly from ELITEA, streamlining project management and enhancing productivity. Agent Toolkit : Incorporate other pre-configured agents, enabling complex, layered interactions and processes within your projects. Monitoring Enhancements : Enhanced monitoring capabilities allow users to track usage statistics with selectable metrics and timeframes, providing deeper insights into application performance and usage patterns.","title":"New Features"},{"location":"release-notes/archived/rn3/#changed-features","text":"Brand Transition : Alita has been rebranded to ELITEA . This change reflects our commitment to evolving and enhancing the platform's capabilities, aligning with our vision to provide a more elite and refined experience for our users. All references to Alita in the platform, documentation, and related materials have been updated to reflect this new branding.","title":"Changed Features"},{"location":"release-notes/archived/rn3/#known-issues","text":"Database Corruption During Indexing : There is a risk of database corruption if a user searches in one dataset while another is indexing. Workaround : Create a new datasource and reindex the data within it to avoid this issue. Prompt Saving Error : Prompts cannot be saved if the Name field is filled using a copy/paste action that includes leading spaces. Datasources - GIT source Authentication Issue : Authentication using SSH for Git source type in Datasource fails. Workaround : Use the HTTPS option with Username and Password for successful authentication. Agent: Confluence tool - Token Authentication type : Authentication using Token for Confluence tool in Agents fails. Workaround : Use the API key option for successful authentication.","title":"Known Issues"},{"location":"release-notes/archived/rn3/#fixed-issues","text":"Deduplication Enhancements : Implemented several fixes and improvements to the deduplication functionality, enhancing data integrity and operational efficiency. Delayed File Finder in ELITEA HUB : Users may experience delays when accessing the file finder in ELITEA HUB.","title":"Fixed Issues"},{"location":"release-notes/archived/rn4/","text":"ELITEA Release Notes Introduction ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before. Information Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide New Features Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions. Changed Features Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative. Known Issues Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password. Fixed Issues Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"RN 1.2.0"},{"location":"release-notes/archived/rn4/#elitea-release-notes","text":"","title":"ELITEA Release Notes"},{"location":"release-notes/archived/rn4/#introduction","text":"ELITEA is an innovative web application that revolutionizes how you interact with prompts. Designed as a dynamic workspace, it empowers users to create, organize, and collaborate on prompts like never before.","title":"Introduction"},{"location":"release-notes/archived/rn4/#information","text":"Release Version : 1.2.0 Released on : 21-June-2024 Access : ELITEA Platform . Note : You need to enable Epam VPN to access ELITEA. User Guide : ELITEA - User Guide","title":"Information"},{"location":"release-notes/archived/rn4/#new-features","text":"Chat Functionality : Introducing a comprehensive Chat feature that integrates all ELITEA functionalities into a single, cohesive environment for optimal output and collaboration: Public and Private Conversations : Engage openly with project members or conduct private discussions visible only to selected users. Participants : Enrich conversations by adding diverse participants such as users, prompts, data sources, agents, and language models. Interactions : Seamlessly interact with participants, copy responses, and utilize generated content effectively. Conversation Management : Organize your chats by saving, pinning, altering privacy settings, deleting, clearing, or exporting conversation contexts. Playback Feature : Navigate through conversation history with playback controls, allowing you to review without active model engagement. Artifact Toolkit for Agents : A new toolkit that enables agents to save their generated outputs directly as files, enhancing data management and retrieval. Jira Toolkit Enhancements : Introduce a tool to adjust the status of Jira issues directly, streamlining project management tasks. Browser Toolkit Extensions : Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Alita Agent Type : A new agent type that combines the strengths of OpenAI's and Langchain's ReAct approaches for complex, open-ended scenarios. This agent maintains chat history, improving its performance in prolonged interactions.","title":"New Features"},{"location":"release-notes/archived/rn4/#changed-features","text":"Confluence Toolkit Adjustments : Removed the Create Page and Page Exists tools to streamline functionalities. Browser Toolkit Changes : Removed the Duckduckgo search tool. Agent Type Updates : Declared the Raw agent type as obsolete, now reserved for legacy agents only. Datasource Authentication : Temporarily disabled SSH authentication for GIT sources, recommending HTTPS with Username and Password as an alternative.","title":"Changed Features"},{"location":"release-notes/archived/rn4/#known-issues","text":"Confluence Source Filtering : Issues with filtering by Space key and Page IDs. Workaround : Use the filtering by label option. Database Corruption During Indexing : Risk of database corruption if simultaneous actions occur in different datasets. Workaround : Create a new datasource and reindex. Prompt Saving Error : Issues saving prompts if the Name field contains leading spaces from copy/paste actions. GIT Source Authentication : SSH authentication for GIT sources fails. Workaround : Use HTTPS with Username and Password.","title":"Known Issues"},{"location":"release-notes/archived/rn4/#fixed-issues","text":"Confluence Tool Authentication : Resolved an issue with Token authentication; users should now use the API key method. GitLab Toolkit : Implemented several fixes to enhance functionality. Browser Toolkit : Added exception handling to operate without a Google CSE ID, ensuring broader accessibility and functionality.","title":"Fixed Issues"},{"location":"user-guide/chat/","text":"Conversations ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models. Creating a Conversation Click the + Conversation button located at the top right corner or + icon next to CONVERSATIONS . Provide the Name . By default, it is set to \"New Conversation\". After creating Conversation add partiicpants to the conversation by clicking the PARTICIPANTS + button. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list. Private and Public Conversations Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private. Participants Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project or public ones which can be added to the conversation to execute them and get responses. Datasources : Already created datasources within the project or public ones which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project or public ones which can be added to the conversation to execute them and get responses. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants. How to Add a Participant To add a participant to a conversation: Click the Add participants button if you just created a conversation or + icon next to PARTICIPANTS . A pop-up window appears. Type the letters of the name or description of the available participant in the Search field. You can also filter and select required participant by type or tags. As soon as you see the participant that you need from the proposed list, click the Chat Now button on the participant card. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section. Note : You can also add several participants at once (by clicking in the cards) and then click the Add Participants button. How to Use a Participant Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"Select from the list or mention participant you wish to engage with.\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again. How to Configure/Modify Participants You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. If the agent has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. Actions for Conversation The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Note : Not applicable now. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Chat"},{"location":"user-guide/chat/#conversations","text":"ELITEA Chat is an ultimate feature, allowing you to combine all ELITEA features in one place and achieve the best output and results. In the ELITEA framework, a conversation is a dialogue among various participants such as selected language models, prompts, datasources, agents, and human users. The chat uses natural language to interact with a human and receive/give feedback. Within one conversation, you can refer to previous questions and answers. However, different conversations don\u2019t share context. All your conversations are stored on the ELITEA server, and you can access them from any device you use. All your conversations are accessible from the Chat menu. Conversations support the following functionality: Public and Private Conversations : Share your conversation with other users from your project, involve them in the same conversation, or keep it private and visible only to you. Participants : Add various participants to the conversation, including other users in public conversations, prompts, data sources, agents, and language models, making them part of the conversation. Interactions : Interact with added participants, copy generated responses, and more. Managing Conversations : Save conversations, pin the most important ones at the top of the screen, make private conversations public, delete conversations, clean the content of the conversation, and export the context of the conversation. Playback : During playback, you can move backward and forward through the playback process or stop the conversation by simulating the current conversation without any engagement with models.","title":"Conversations"},{"location":"user-guide/chat/#creating-a-conversation","text":"Click the + Conversation button located at the top right corner or + icon next to CONVERSATIONS . Provide the Name . By default, it is set to \"New Conversation\". After creating Conversation add partiicpants to the conversation by clicking the PARTICIPANTS + button. Start the conversation by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. Your newly created conversation will subsequently appear on the Conversation's list.","title":"Creating a Conversation"},{"location":"user-guide/chat/#private-and-public-conversations","text":"Private conversations are only visible to the user who created them. You can add all available participants to your project and use this conversation. You can also make private conversations public later. Note : By default, all conversations created in a Private project will be Private as you can't invite/share such conversations with other users. Public conversations are visible to all users of the same project. Those users can also interact in the public conversations, add/remove their participants, delete conversations, copy messages, etc. Note : Users can't convert public conversations back to private.","title":"Private and Public Conversations"},{"location":"user-guide/chat/#participants","text":"Participants are additional \"tools\" that can be added to the conversation to enhance it. The following types of participants are available: Models : LLM models which can be added to the conversation to interact with Gen AI and get responses from the selected model. Prompts : Already created prompts within the project or public ones which can be added to the conversation to execute them and get responses. Datasources : Already created datasources within the project or public ones which can be added to the conversation to execute them and get responses. Agents : Already created agents within the project or public ones which can be added to the conversation to execute them and get responses. Note : Another category of participant is the user, which can't be added, but in the case of public conversations, users within the project can follow the conversation, interact with it, and thus become participants.","title":"Participants"},{"location":"user-guide/chat/#how-to-add-a-participant","text":"To add a participant to a conversation: Click the Add participants button if you just created a conversation or + icon next to PARTICIPANTS . A pop-up window appears. Type the letters of the name or description of the available participant in the Search field. You can also filter and select required participant by type or tags. As soon as you see the participant that you need from the proposed list, click the Chat Now button on the participant card. The participant will be immediately added to your conversation and become visible in the PARTICIPANTS section. Note : You can also add several participants at once (by clicking in the cards) and then click the Add Participants button.","title":"How to Add a Participant"},{"location":"user-guide/chat/#how-to-use-a-participant","text":"Check that the participant is selected and added to the conversation. If you see in the Conversation's main section \"Select from the list or mention participant you wish to engage with.\", then you need to include the participant that you want to use. To do it: You can either click on the required participant option from the PARTICIPANTS section. Or you can call the required participant from the \"Type your message\" input box by typing / - prompt, # - data source, @ - agent, > - model. Then select it from the dropdown list. After adding the active participant to the conversation, you can use it by typing simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to execute the participant. To remove the participant from the conversation's active participant list, click the X icon. Note: This will not remove the participant from the Conversation entirely. You can call it again.","title":"How to Use a Participant"},{"location":"user-guide/chat/#how-to-configuremodify-participants","text":"You can easily configure participants that you have added to the conversation. For Models : Navigate to the model. Click on the Settings icon. You can configure the following settings for the model: Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Prompts : Navigate to the prompt. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the prompt:Temperature, Top P (0-1), Top K, and Maximum Length. If the prompt has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Datasources : Navigate to the datasource. Click on the Settings icon. You can configure the following settings for the datasource: Embedding Settings : Initial Lookup Result (1-50), Pages Per Document (1-30), Expected Search Result (1-40). Temperature, Top P (0-1), Top K, and Maximum Length. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon. For Agents : Navigate to the agent. Click on the Settings icon. Select the version of the prompt. By default the \"latest\" will be selected. You can configure the following settings for the agent: Temperature, Top P (0-1), Top K, and Maximum Length. If the agent has variable(s), you can modify them as well. To apply changes, click the < SETTINGS button. You can also restore back to default settings by clicking the Restore icon.","title":"How to Configure/Modify Participants"},{"location":"user-guide/chat/#actions-for-conversation","text":"The following actions are available for created conversations from CONVERSATIONS sidebar: Delete : To delete a single conversation, on the left panel, in the conversation contextual menu, select Delete and confirm your action. Edit : To rename a conversation, on the left panel, in the conversation contextual menu, select Edit and confirm your action. Export : To export a single conversation, on the left panel, in the conversation contextual menu, point to Export. Note : Not applicable now. Make Public : To make a private conversation public, on the left panel, in the conversation contextual menu, click the Make Public icon. Note: You will not be able to convert it back to Private. Playback : The Playback mode can be used to simulate the current conversation without any engagement with models. This mode accurately reproduces the conversation like a recording. It's well designed for demo purposes. Pin : To pin a single conversation, on the left panel, in the conversation contextual menu, select Pin . Your conversation will be pinned at the top of your conversation's list. Note : You can unpin the conversation by clicking the Unpin action.","title":"Actions for Conversation"},{"location":"user-guide/collections/","text":"Collections Private project - Collections menu The Collections menu within Private project serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've crafted. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections The Collection serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects. How to Create a Collection Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection. Exploring Collections Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection How to Modify a Collection To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published. How to Filter Prompts within a Collection Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes. How to Publish a Collection To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain already published prompts before publication. How to Delete a Collection To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections. How to Export a Collection Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization. Collections Menu The Collections menu is a curated space of grouped prompts shared and published within the community. Layout of the Collections Menu Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community. Engaging with Collections Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage: Liking Collections Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: To like a collection, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the collection. Other Actions for Collections Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Collections"},{"location":"user-guide/collections/#collections","text":"","title":"Collections"},{"location":"user-guide/collections/#private-project-collections-menu","text":"The Collections menu within Private project serves as a dedicated inventory for all your collections, irrespective of their current status. Consider it your personal repository for saving and organizing the collections you've crafted. These features ensure your collections are not only stored securely but also organized in a manner that simplifies management, review, and retrieval, tailoring the user experience to your needs and preferences. The Purpose and Usefulness of Collections The Collection serve as a means to group prompts by theme, project, or any other meaningful categorization that enhances accessibility and usefulness for the users. Collections are immensely valuable for several reasons: Thematic Organization : They allow for the grouping of prompts by specific themes or projects, making it easy for users to find a set of related prompts. Efficiency : By organizing prompts into collections, we save time by providing consolidated resources that can be easily accessed and applied. Sharing Best Practices : Collections can be shared across teams, promoting best practices and unified testing approaches across different projects.","title":"Private project - Collections menu"},{"location":"user-guide/collections/#how-to-create-a-collection","text":"Creating a collection allows you to organize and categorize your prompts for better accessibility and management. Follow these steps to create a new collection: Click the + Collection button located at the top right corner of the page. You will be prompted to fill in the Name and Description fields. It's important to provide clear and concise information here, as this helps others understand the purpose and content of your collection. Click Save to create the collection.","title":"How to Create a Collection"},{"location":"user-guide/collections/#exploring-collections","text":"Exploring collections is straightforward and insightful: Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the selected collection, providing a comprehensive view of its contents. Within a collection, you can: View and Open available prompts Modify Collection (Name and Description) Filter Collection by tags Publish Collection Delete Collection Export Collection","title":"Exploring Collections"},{"location":"user-guide/collections/#how-to-modify-a-collection","text":"To modify an existing collection: Click the Edit icon. Update the Name and/or Description of the collection as needed. Click Save to apply the changes. Note : Modifications are restricted for collections that have already been published.","title":"How to Modify a Collection"},{"location":"user-guide/collections/#how-to-filter-prompts-within-a-collection","text":"Easily find specific prompts within a collection by selecting applicable tags from the Tags section. This enables efficient organization and retrieval based on subjects or themes.","title":"How to Filter Prompts within a Collection"},{"location":"user-guide/collections/#how-to-publish-a-collection","text":"To publish a collection: Ensure the collection is complete and relevant by reviewing its contents. Click the Publish collection icon to submit your collection for review, similar to the individual prompt publishing process. The collection will be evaluated according to guidelines for quality and relevance. Once approved, your collection will be published and made available under the Collection menu for community use. Note : A Collection must contain already published prompts before publication.","title":"How to Publish a Collection"},{"location":"user-guide/collections/#how-to-delete-a-collection","text":"To delete a collection: Click the Delete icon. Note that deleting a collection does not remove the prompts within it from your library. Note : Deletion is not possible for published collections.","title":"How to Delete a Collection"},{"location":"user-guide/collections/#how-to-export-a-collection","text":"Exporting a collection allows for its use on different platforms, offering formats tailored to each: [Alita format] - a JSON format designed for the ELITEA platform, including detailed information like prompt versioning and model configurations. [DIAL format] - a JSON format intended for the Epam AI Dial platform, incorporating platform-specific structuring. Exporting the Collection: Click the Export prompt icon to begin. Select your preferred format (Alita or DIAL) for the export. An export file will be generated and automatically downloaded to your device, enabling cross-platform utilization.","title":"How to Export a Collection"},{"location":"user-guide/collections/#collections-menu","text":"The Collections menu is a curated space of grouped prompts shared and published within the community.","title":"Collections Menu"},{"location":"user-guide/collections/#layout-of-the-collections-menu","text":"Organized into three distinct pages, the Collections menu introduces a structured way to explore and discover grouped prompts: Latest : Showcases the most recently published collections, offering insight into the newest themes and ideas being explored by the community. My Likes : Features the collections you have liked, creating a personalized library of favored content that can be revisited at any time. Trending : Displays collections that have gathered the most likes, serving as an excellent resource for finding highly-regarded and popular collections esteemed by the community.","title":"Layout of the Collections Menu"},{"location":"user-guide/collections/#engaging-with-collections","text":"Participation and interaction within the community are pivotal in highlighting and appreciating valuable collections. Below are ways you can actively engage:","title":"Engaging with Collections"},{"location":"user-guide/collections/#liking-collections","text":"Each collection, upon curation, becomes a vital resource. To show support and appreciation for a collection, you can use the Like functionality: To like a collection, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the collection.","title":"Liking Collections"},{"location":"user-guide/collections/#other-actions-for-collections","text":"Exploring Published Collections : Simply click on the collection card or the name of a collection. This action reveals the prompts contained within the opened collection, providing a comprehensive view of its contents. You will be able to work with published prompts within the collection. Detailed instructions for this process are available in the Other Actions for Published Prompts section. Exporting Collections : Collections can be exported for sharing or external use. Detailed instructions for this process are available in the How to Export a Collection section.","title":"Other Actions for Collections"},{"location":"user-guide/datasources/","text":"Datasources Private project - Datasources menu Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information. Creating a Datasource To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation. Exploring Datasources Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage. Connecting a Dataset to the Datasource The initial step involves linking your dataset to the desired datasource: Press the + icon to start adding a new dataset. Enter a name for your dataset. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded. Source type - File ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported file types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Table This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning. Source type - GIT For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles. Source type - Confluence For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. The Secret and Password options are available. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. The Secret and Password options are available. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance. Source type - QTest Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - Utilize a confidential key configured in the Secrets feature within ELITEA HUB for enhanced security during API requests. This secret can be selected from the secrets you have set up previously. Password - an option for API access, that verifies authorized requesters through a password. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. DQL for QTest - this setting allows you to query and filter data before indexing it. Utilize DQL (Data Query Language) to define specific criteria that refine the data fetched from QTest, ensuring that only relevant data is processed and indexed. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\"). TRANSFORMERS Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing. SUMMARIZATION Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization model - select from available LLMs based on your document\u2019s complexity. Document summarization - enables summarization of the entire document. Chunk summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis. CONTEXT Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions. WELCOME MESSAGE The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the datasource. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this datasource for asking questions about FT Armenia\" \"Don't forget to double-check the generated responses\" CONVERSATION STARTERS The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the datasource. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the datasource. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the datasource. Examples of Conversation Starters : \"How to create a prompt?\" \"I am on bench, and want to know what activities can be done\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the datasource more efficient and standardized. Working with Your Dataset After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do: Chat The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation. To use the Chat and query info : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an Chat model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Search The Search feature allows you to quickly locate specific information within your indexed dataset. How to Conduct a Search : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Deduplicate The Deduplication is a handy feature for identifying duplicate information. How to Run Deduplication : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : More items will be excluded , as they will not be considered similar enough. This can be useful if you want to ensure that only highly unique content remains. Lower values : More items will be retained , as they will be considered similar enough. This can be useful if you want to keep more variations of the content. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Click the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Show differences : An option allowing to quickly show/hide differences. Download result : Allows you to save the deduplication results directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Public project - Datasources menu The Datasources menu within Public project showcases a collection of published and shared datasources within the community. Layout of the Datasources Menu The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community. Engaging with Published Datasources Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation: Liking Published Datasources Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource. Other Actions for Published Datasources Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Datasources"},{"location":"user-guide/datasources/#datasources","text":"","title":"Datasources"},{"location":"user-guide/datasources/#private-project-datasources-menu","text":"Datasources play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. They enable the extension of LLMs by integrating user-specific or project-specific data, which is not initially part of the model\u2019s training set, thereby enhancing the LLM's context with tailored information.","title":"Private project - Datasources menu"},{"location":"user-guide/datasources/#creating-a-datasource","text":"To set up a new datasource and augment your model's capabilities: Click the + Datasource button located at the top right corner. Fill out the Name and Description fields. Choose an Embedding model from the dropdown list provided. Select the desired Storage type from another dropdown menu. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Click Save to finalize the creation.","title":"Creating a Datasource"},{"location":"user-guide/datasources/#exploring-datasources","text":"Discovering the intricacies of a datasource is both simple and insightful: Click on the card or the name of a datasource to unveil its configurations, providing a detailed overview of its setup and usage.","title":"Exploring Datasources"},{"location":"user-guide/datasources/#connecting-a-dataset-to-the-datasource","text":"The initial step involves linking your dataset to the desired datasource: Press the + icon to start adding a new dataset. Enter a name for your dataset. From the dropdown list, select the source type of your dataset. Available options include: File : Any supported file type for upload. Table : Supported file types with a table structure, such as CSV or XLSX. GIT : Any accessible Git repository. Confluence : Any Confluence page accessible to you. QTest : Any QTest project accessible to you. Depending on the selected source type, various configurations may be necessary to access the dataset source, primarily involving authentication and authorization parameters. This step is exempt for File and Table options since the files will be directly uploaded.","title":"Connecting a Dataset to the Datasource"},{"location":"user-guide/datasources/#source-type-file","text":"ELITEA supports a variety of file types and offers flexible settings to handle your documents effectively. Below is an easy-to-understand breakdown of the options, settings, and parameters available for configuration. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported file types: PDF, DOCX, TXT, JSON. Advanced Settings - under this section, additional features enable further customization of how your file is processed. Split Pages - when enabled, each page of your document is treated as a separate entity. This is particularly useful when dealing with PDF documents, enabling more granular control over the analysis or processing of individual pages. Parse Tables by Rows Selecting this option ensures that any tables within your document are parsed row by row, maintaining the structure and context. This setting is valuable when dealing with documents that contain tabular information, ensuring the data remains organized and comprehensible. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - File"},{"location":"user-guide/datasources/#source-type-table","text":"This functionality is crucial for users who work with structured data in formats such as spreadsheets or structured text files. The aim is to make the process straightforward for users without requiring deep technical knowledge. Here, we outline the options, settings, and parameters available for your table data sources. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. Choose File Option - select the file you wish to process. ELITEA supports a range of commonly used file types, ensuring compatibility and ease of use. Supported File Types: CSV, JSON, XLSX. Columns - specify which column(s) within your table you want to focus on. These columns should contain the data you wish to analyze or use for generating embeddings. You can select single or multiple columns depending on your requirement. This flexibility allows you to tailor the analysis to the specific data points that are most valuable to your objectives. To select multiple columns, separate each column name with a comma (\",\"). JSON Documents - enable this option if your table data is structured as JSON documents, particularly relevant when dealing with JSON files. This tells the system to parse the file as a collection of JSON entries, allowing for a more nuanced understanding and utilization of nested data structures within the file. Raw Content - when enabled, this setting ensures that your selected data is treated as raw content, bypassing any default preprocessing or formatting. This is particularly useful when you want the data to be ingested in its purest form, without any alterations that might affect its original structure or meaning.","title":"Source type - Table"},{"location":"user-guide/datasources/#source-type-git","text":"For users who rely on Git repositories to manage their code, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these repositories. Here, we outline the options, settings, and parameters available for your GIT source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Git Repo. To connect to your Git repository, you'll need to provide the URL. ELITEA supports two types of Git repository links: SSH - for a secure and password-less connection. If you choose this option, an SSH key pair is required, with the public key added to your Git account and the private key entered in the subsequent SSH Key field. For SSH : input the SSH Key in the designated field. HTTPS - a widely used method that might require username and password authentication based on the repository's access settings. For HTTPS : if prompted, enter the username and password to authenticate. Important Note : To ensure a successful connection, you must clone your Git repository and provide the cloned Git link . Simply copying the Git repository address from your browser's address bar is not sufficient. Cloning the repository ensures that you're using a valid, accessible link that ELITEA can connect to without issues. Branch - here, specify the branch within your Git repository you wish to access. By default, the ' main ' branch is selected, but you may adjust this to any branch name that suits your current focus or project needs. Advanced Settings - under this tab, we offer options to further customize how data is retrieved from your Git repository. Multithreading - enabling multithreading can significantly speed up the process of fetching data from your Git repo, especially beneficial for large repositories or when network latency is a concern. This option allows the system to perform multiple operations in parallel, reducing overall extraction time. Default Document Loader - choose the mechanism by which your document is loaded into the system. Each loader handles your file differently, catering to specific needs. TextLoader : - optimized for plain text documents, ensuring swift and efficient loading. PythonLoader : - best suited for technical or coded documents, offering more sophisticated parsing capabilities. Extension Whitelist - specify file extensions that are explicitly allowed. This security measure ensures only designated file types are processed, safeguarding against unwanted or potentially harmful files. List the extensions separated by commas (e.g., .pdf , .docx , .txt ), overriding the default supported types if necessary. Extension Blacklist - conversely, list file extensions you wish to exclude from processing. Any file type (e.g., .exe , .bin , .png ) mentioned here will be automatically rejected, further enhancing security and control over the documents your system handles.","title":"Source type - GIT"},{"location":"user-guide/datasources/#source-type-confluence","text":"For users who rely on Confluence pages to manage their information, documents, or other types of projects, this source type allows to streamline the process of linking and extracting data from these knowledge pages. Here, we outline the options, settings, and parameters available for your Confluence source type. Name - specify a unique name for your source configuration. This helps in easily identifying and managing multiple sources. URL - link to Confluence. To connect to your Confluence KB, you'll need to provide the URL. No need to provide the full link as the page (e.g. https://www.kb.epam.com/ is enough) handling must be done with the help of Filters option. Regarding authentication, you have two options to securely connect to Confluence: API Key : If you choose the API Key option, you'll need to generate an API Key from your Confluence account and input it in the provided API Key field. The Secret and Password options are available. Token : Similarly, if the Token option suits you better, you'll have to create an authentication Token from your Confluence user settings and enter it in the Token field. The Secret and Password options are available. Note : These authentication methods ensure secure access to your Confluence content, maintaining the integrity and confidentiality of your data. Username - input the username associated with your Confluence account. This is the same username you use to log in to your Confluence site. Hosting Option - choose the appropriate hosting type for your Confluence setup: Cloud - if your Confluence is hosted on Atlassian\u2019s cloud. Server - if your Confluence is hosted on your own servers or enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Note :This distinction is crucial for establishing the correct connection and accessing your data appropriately. Filter - use the filter option to refine which Confluence pages you wish to fetch. You can filter by: Space Key - to fetch pages from specific Confluence spaces. Page IDs - to target specific pages. Labels - to retrieve pages tagged with specific labels. Important Note : To establish a successful connection to Confluence from ELITEA, you must select one of these filters and provide the corresponding value for it. This step is crucial as it defines the scope of content that ELITEA will access and import from Confluence, aligning the integration process with your project's specific requirements. Advanced Settings - these settings offer additional controls over how your Confluence content is fetched and presented: Include Attachment - check this if you want to include page attachments in your data fetch. Useful for cases where documents or images are integral to your content. Content Format - select the format in which you wish to view or receive the content. Options include: View - the page content as displayed in Confluence. Storage - the raw storage format (HTML/XML) used by Confluence. Anonymous - content as it appears to users not logged in. Editor - content in an editable format. Pages Limit Per Request - define how many pages you want to fetch in a single request, with a default setting of 50. This helps manage data volume and response times. Max Total Pages - set the maximum number of pages the system should fetch, defaulting to 1000. Useful for limiting data scope and ensuring performance.","title":"Source type - Confluence"},{"location":"user-guide/datasources/#source-type-qtest","text":"Integrating QTest with ELITEA enhances your test management by connecting directly to QTest Test Case Management System (TCMS). This integration allows you to select test cases for duplication checks, search functionalities, and leverage manual test cases for future automation with Generative AI. Below, we detail the configuration options, settings, and parameters available for the QTest source type. URL - the link to your QTest. Note : You must provide the link to your QTest in the following format https://<host of your installation of QTest>/api/<api version used> QTest Project ID - the specific project ID within QTest you wish to connect to. Enter the project ID to direct ELITEA to the correct QTest project. API Key - ELITEA supports two types of authentication methods for QTest API Keys to ensure secure access: Secret - Utilize a confidential key configured in the Secrets feature within ELITEA HUB for enhanced security during API requests. This secret can be selected from the secrets you have set up previously. Password - an option for API access, that verifies authorized requesters through a password. Test Cases per Page - configures the number of test cases displayed per page within the QTest for selection. DQL for QTest - this setting allows you to query and filter data before indexing it. Utilize DQL (Data Query Language) to define specific criteria that refine the data fetched from QTest, ensuring that only relevant data is processed and indexed. Columns - specify the columns within your test cases that you wish to focus on for analysis or embedding generation. Select single or multiple columns to tailor the analysis to your project's specific needs. To select multiple columns, separate each column name with a comma (\",\").","title":"Source type - QTest"},{"location":"user-guide/datasources/#transformers","text":"Transformers enhance your documents by extracting significant keywords, summarizing content, and improving searchability. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Extract Keywords - options include: For Document - analyses the entire document for keyword extraction. For Chunks - processes document sections independently for more granular insights. Keyword Extractor - the only available option is KeyBert , designed for efficient keyword extraction. Keyword Strategy - choices range from Max Sum , to Max MMR High , and Max MMR Low , each offering different focuses on relevance and diversity. Maximum Keyword Count - defines the limit on the number of keywords to be extracted. Split By - determines how the document is sectioned for analysis, with options like Chunks, Lines, Paragraphs, Sentences, or Nothing.","title":"TRANSFORMERS"},{"location":"user-guide/datasources/#summarization","text":"Summarization utilizes LLMs to condense documents into their core messages. Due to the high computational demand, use of this feature incurs additional costs. Please note if you don't clearly understand the purpose of the parameters and options available here than leave them as is. Don't make any changes. Summarization model - select from available LLMs based on your document\u2019s complexity. Document summarization - enables summarization of the entire document. Chunk summarization - applies summarization to specific sections or chunks of the document. Finally, click Create to index the dataset for use. Note that processing time can take up to 10 minutes, depending on the source type and size. Note : Multiple datasets can be utilized within the same datasource, enhancing versatility and depth of analysis.","title":"SUMMARIZATION"},{"location":"user-guide/datasources/#context","text":"Context input field is a designated area for providing instructions (prompt'), that facilitates the utilization of information from configured datasets via LLMs. This prompt guides the LLM on how to interpret and analyze the dataset, ensuring that the generated output aligns with the user's specific objectives. Note : By providing detailed and clear instructions in the Context field, users effectively guide the processing and analysis of their datasets, leveraging the robust capabilities of LLMs for tailored insights and actions.","title":"CONTEXT"},{"location":"user-guide/datasources/#welcome-message","text":"The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the datasource. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this datasource for asking questions about FT Armenia\" \"Don't forget to double-check the generated responses\"","title":"WELCOME MESSAGE"},{"location":"user-guide/datasources/#conversation-starters","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the datasource. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the datasource. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the datasource. Examples of Conversation Starters : \"How to create a prompt?\" \"I am on bench, and want to know what activities can be done\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the datasource more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"user-guide/datasources/#working-with-your-dataset","text":"After you've successfully created your dataset(s), a variety of features become available for you to explore and utilize. These features are designed to help you interact with your dataset in a more intuitive and productive manner. Here's a brief overview of what you can do:","title":"Working with Your Dataset"},{"location":"user-guide/datasources/#chat","text":"The Chat feature is tailored for conversational AI models, enabling you to engage in dialogues or interactions akin to conversing with a human. Whether you're asking a question, making a statement, or giving a command, this feature is designed to generate responses that mimic human conversation. To use the Chat and query info : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Choose an Chat model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.) suited to your conversation needs. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K (1-40) - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Type your text in the chat box and click the Send icon to initiate the dialogue. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Chat"},{"location":"user-guide/datasources/#search","text":"The Search feature allows you to quickly locate specific information within your indexed dataset. How to Conduct a Search : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Initial Lookup Result (1 \u2013 50) - specifies the number of initial results retrieved from the indexed dataset(s) for further processing. Higher values : More initial results are retrieved, which can increase the chances of finding relevant information but may slow down processing. Lower values : Fewer initial results are retrieved, which can speed up processing but might miss some relevant information. Pages Per Document (1 \u2013 30) - defines the number of pages to be considered per document during the retrieval or processing phase. Higher values : More pages per document are considered, which can provide more comprehensive information but may slow down processing. Lower values : Fewer pages per document are considered, which can speed up processing but might miss some important details. Expected Search Results (1 \u2013 40) - sets the anticipated number of search results to be returned, guiding the system's retrieval scope. Higher values : More search results are returned, which can provide a broader range of information but may include less relevant results. Lower values : Fewer search results are returned, which can provide more focused and relevant information but might miss some useful results. String content - determines whether the system should include or consider specific text data in its processing or generation. Type your query into the input field and hit the Send icon. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Search"},{"location":"user-guide/datasources/#deduplicate","text":"The Deduplication is a handy feature for identifying duplicate information. How to Run Deduplication : Select the Embedding model from the dropdown list. Note : It must be the same one which is used for creating the datasource. Configure the following settings: Cut-off Score (0.1-1.0) - determines the threshold for identifying duplicate content based on similarity scores. Higher values : More items will be excluded , as they will not be considered similar enough. This can be useful if you want to ensure that only highly unique content remains. Lower values : More items will be retained , as they will be considered similar enough. This can be useful if you want to keep more variations of the content. Optionally, you can configure Advanced Settings for more tailord outputs by clicking the Settings icon. Note : Please exercise caution with these settings. If unsure about their functions, it's advisable to leave them at their default values. The following settings are available: Show Additional Metadata - a checkbox option that determines whether to display extra information about the content. Selected : Additional metadata will be shown, providing more context and details about the content. Not Selected : Additional metadata will not be shown, resulting in a cleaner and simpler display of the content. Exclude Fields - a comma-separated list of field names that should be excluded from the deduplication process. Specified fields : The fields listed will be ignored during deduplication, which means differences in these fields will not affect whether content is considered a duplicate. This can be useful if certain fields (like timestamps or IDs) are not relevant to the deduplication criteria. No fields specified : All fields will be considered during deduplication, which means any differences in any field can affect whether content is considered a duplicate. Click the Run button to start the process. Note: Remember, deduplication efforts will hinge upon the parameters you've set for the dataset. By using these features, you\u2019re equipped to enhance your dataset, making it a more efficient and effective tool for your AI applications. Proceed with adjustments only if you're confident in your understanding of their implications. Post-Output Actions: View Selection : A tool for quickly switching between Code view and List view views. Show differences : An option allowing to quickly show/hide differences. Download result : Allows you to save the deduplication results directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"Deduplicate"},{"location":"user-guide/datasources/#public-project-datasources-menu","text":"The Datasources menu within Public project showcases a collection of published and shared datasources within the community.","title":"Public project - Datasources menu"},{"location":"user-guide/datasources/#layout-of-the-datasources-menu","text":"The Datasources menu is organized into three distinct pages, each designed to offer a unique perspective on the available datasources: Latest : Displays all recently published datasources, providing a fresh look at the newest contributions to the community. My Likes : Highlights the datasources that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the datasources with the highest number of likes, serving as a valuable resource for discovering top-rated datasources that hold significant value and popularity within the community.","title":"Layout of the Datasources Menu"},{"location":"user-guide/datasources/#engaging-with-published-datasources","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable datasources. The following actions enable active participation:","title":"Engaging with Published Datasources"},{"location":"user-guide/datasources/#liking-published-datasources","text":"Upon publication, a datasource becomes a crucial resource for the community. To support and acknowledge a datasource, use the Like functionality: To like a datasource, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the datasource.","title":"Liking Published Datasources"},{"location":"user-guide/datasources/#other-actions-for-published-datasources","text":"Using Published Datasources : View and run datasources by clicking on the datasource card or name. Refer to the Exploring Datasources section for guidance on using datasource. Note : Modifications to a published datasource cannot be saved for future use.","title":"Other Actions for Published Datasources"},{"location":"user-guide/intro/","text":"Introduction Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with Generative AI. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts, datasources and agents like never before. Key Features: Prompt Management : Effortlessly create, modify, and manage prompts. Keep track of different versions to ensure you always have access to your best work. Datasources : Play a pivotal role in enhancing the functionalities of ELITEA by integrating user-specific or project-specific data. This not only broadens the LLM's context but also enriches it with tailored information, making your interactions more relevant and insightful. Agents : Customize and create virtual assistants within ELITEA to handle specific tasks or sets of tasks. These agents integrate prompts, datasources, and external toolkits into a cohesive mechanism, enabling actions such as online searches or creating Jira tickets based on decisions made by LLMs. Chat : Combine all ELITEA features in one place with ELITEA Chat, an ultimate feature that allows for dynamic interaction and optimal results. Engage in conversations that utilize natural language to interact with human users and seamlessly integrate feedback from various participants like language models, datasources, and agents. Extensions : Transform your coding workflow with Alita Code and Alita Code Chat the ultimate AI-powered IDE extensions. Integrated seamlessly with VS Code and IntelliJ, these extensions offers intelligent suggestions, automates routine tasks, and provides unmatched adaptability to elevate your coding experience. Collection Integration : Organize your prompts, datasources and agents into Collections for better workflow management or to concentrate on specific themes or projects. Execution with Precision : Tailor the execution of prompts using various models and parameters to meet your specific needs, ensuring a customized experience. Advanced Creation Tools : Craft complex prompts, datasources and agents with precision using tools like variables, system prompts, Assistant Messages, and advanced tools. Powerful Search : Employ a robust search functionality to easily locate prompts, datasources and agents by tags, names, or descriptions. Community Engagement : Engage with the community by creating, modifying, and publishing prompts, datasources and agents. Enhance collaboration through sharing and liking content. ELITEA is designed to be a versatile and powerful tool, enhancing how you interact with AI technologies and manage data-driven projects. Whether you're coding, creating content, or managing complex data sets, ELITEA provides the tools you need to succeed. Let's embark on this journey to unlock the full potential of your ideas. Our user guide will walk you through every feature, ensuring you maximize your ELITEA experience. Accessing ELITEA HUB To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA. ELITEA - Main Interface The ELITEA HUB's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating new items (conversation, prompt, datasource, agent and collection, importing prompt), Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Chat, Prompts, Datasources, Agents and Collections. Search : A Search box available to find prompts, datasources and agents by their names and descriptions. Note : The Search functionality operates within the selected menu and is not universal across the entire application. View Switcher : A tool for quickly switching between Card list and Table views. Quick button : A button that allows for the rapid creation of a new conversation, prompt, datasource, agent or collection. The default of this button ( +Conversation , +Prompt , +Datasource , +Agent or +Collection ) changes based on the selected menu. Notifications : Notification's bell allowing user to get notified about various events such as prompt publishing status within the ELITEA Hub. Project Switcher : A tool for quickly switching among projects. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure various project and profile specific settings. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts, datasources and agents with the community. General Navigation and Management Across the Application This section provides an overview of the common functionalities and actions available across various menus and pages within the application. The aim is to ensure a consistent and efficient user experience by maintaining uniformity in navigation and management features across both Private and Public projects. Private Project Navigation : In a Private project, you have exclusive access to your personalized content across the following menus: Chat menu: Access all your private and public conversations, allowing for seamless communication and collaboration. Prompts menu: View and manage all the prompts you have created, enabling easy modification and reuse. Datasources menu: Contains all the datasources you have developed. Agents menu: Access all your created agents, each designed to perform specific tasks or sets of tasks. Collections menu: Manage your collections of prompts, datasources, and agents, organized for specific projects or themes. Public Project Navigation : In a Public project, you can engage with the community and explore content created by other users through the following sections: Prompts menu: Navigate through the Latest prompts, explore prompts you've liked (My Likes), and discover Trending prompts within the community. Datasources menu: Access the Latest datasources, view datasources you've liked (My Likes), and explore Trending datasources shared by the community. Agents menu: Discover the Latest agents, check out agents you've liked (My Likes), and find Trending agents that are popular in the community. Collections menu: Explore the Latest collections, view collections you've liked (My Likes), and discover Trending collections that are gaining attention. While the context may vary depending on the specific page you're viewing, the core principles of action and functionality remain consistent. This unified approach ensures that whether you are navigating a private or public project, the experience is intuitive and user-friendly, facilitating effective management and exploration of content within the application. Common Viewing Options Card list view : Offers a compact, card-format snapshot of items like prompts, datasources, agents and collections, making it easy to visually scan through published materials. Table view : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis. Search and Filtering Functionality Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes. Sorting Options (Detailed View Only) Name & Description : Alphabetically organize published items by their names, providing an effortless method to find specific titles. Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. Likes : Order the items by the number of likes they have received. This functionality is applicable only for menus within Public project. Authors : Sort the items by the author's name. This functionality is applicable only for menus within Public project. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment. Discover - Menus ELITEA application consists of the following main menus: Chat Prompts Datasources Agents Collections Navigation : To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu. Settings The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. The Settings consists of several tabs and settings each dedicated to specific functionalities: Profile : Customize your user profile within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Code Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Projects : Manage users within project. This tab is only available for the user within admin permissions within the project. Theme : Switch between Dark and Light theme for the whole application. Log out : Securely log out from the ELITEA Hub. Navigation : To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section. Profile In the Profile , you\u2019re presented with options to personalize your account within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported. Monitoring The Monitoring feature in ELITEA is designed to provide a comprehensive overview of the application's usage and performance. This feature is essential for administrators and users who want to gain insights into various aspects of the application, from user engagement to the effectiveness of configured artifacts like prompts, datasources, and agents. By leveraging the detailed charts and statistics available within the Monitoring feature, you can make informed decisions to optimize the performance and user experience of your ELITEA application. This section will guide you through the various components of the Monitoring feature, including configuration options, key metrics, adoption and usage statistics, sentiment analysis, accuracy metrics, prompt topics, and topics summary. Each of these components offers valuable insights that can help you understand how the application is being used and how it can be improved. Configuration Options At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Projects : A dropdown lits allowing you to select the project. Note : For your Private project, you can only see your private project data. If you have an admin role in another projects, you can select other projects to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations. Key Metrics Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the ELITEA application. Tokens In : The number of tokens consumed by the ELITEA application. Tokens Out : The number of tokens generated by the ELITEA application. Gb Used : The amount of data processed by the ELITEA application. Prompts : The total number of prompts created. Datasources : The total number of datasources created. Agents : The total number of agents created. Conversations : The total number of conversations created. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period. Adoption and Usage Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy. Sentiments The Sentiments section provides a visual representation of the emotional tone of both user inputs and the outputs generated by LLMs. Understanding sentiment is crucial for tailoring responses to better meet user needs and improve overall interaction quality. Sentiment Analysis Overview Sentiment analysis categorizes text into three primary emotional states: Positive : Indicates a favorable or happy emotional tone. Negative : Indicates an unfavorable or unhappy emotional tone. Neutral : Indicates a neutral or indifferent emotional tone. ELITEA performs sentiment analysis on user inputs to gauge the user's emotional state. This capability is particularly important for providing high-quality customer service, as the LLM can adjust its response tone and content based on the user's emotions. Visual Representation The Sentiments section includes two pie charts that offer a clear visual representation of sentiment distribution: Human Input : This pie chart shows the sentiment distribution of user inputs. It helps you understand how users are feeling when they interact with the LLMs. LLM Output : This pie chart displays the sentiment distribution of LLM's outputs. It helps you ensure that the responses generated by the LLM are appropriate and aligned with user emotions. Practical Applications Understanding sentiment can significantly enhance the user experience in several ways: Customer Service : By analyzing the sentiment of user inputs, LLMs can adjust its responses to be more empathetic and supportive, thereby improving customer satisfaction. User Engagement : Monitoring sentiment trends over time can help you identify patterns in user behavior and adjust your strategies accordingly. Content Moderation : Sentiment analysis can be used to flag potentially harmful or inappropriate content, ensuring a safer and more positive interaction environment. Accuracy The Accuracy section provides detailed insights into the performance and reliability of the ELITEA application. This section includes various metrics and visualizations that help you understand how well the system is responding to user inputs and how effective your configured artifacts (prompts, datasources, agents, conversations) are. Relevance The Relevance metric is divided into two key lines: Input vs Context : This line measures the relevance of the user's input (question or query) against the context of the artifact (prompt, datasource, agent or conversation). In the ELITEA, \"context\" refers to the configured instructions for the artifact. A higher relevance score indicates that the user's input closely matches the context, making it easier for the LLM to provide accurate responses. Output vs Input : This line measures the relevance of the generated output by the LLM against the user's input. A higher relevance score here indicates that the output is closely aligned with the user's query, ensuring that the response is appropriate and useful. Note : The maximum value for relevance is 6. The higher the score, the better the relevance, indicating a more accurate and contextually appropriate interaction. Reliability The Reliability Score answers the question of whether there is enough context to respond accurately to the user's questions or queries. This metric helps you gauge the confidence level of the LLM's responses. Note : The maximum reliability score is 10. A higher score indicates that there is sufficient context to provide a correct and reliable response to the user's query. Prompt Quality vs Usage The Prompt Quality vs Usage is a 2x2 matrix that helps you evaluate the effectiveness and utilization of your artifacts (prompts, agents, datasources or conversations): Low Quality, Low Usage : Artifacts in this box have low quality scores and are rarely used. These artifacts may need to be re-evaluated or improved. High Quality, Low Usage : Artifacts in this box have high quality scores but are not frequently used. Efforts should be made to promote these high-quality artifacts to increase their usage. High Quality, High Usage : Artifacts in this box have high quality scores and are frequently used. These are your most effective artifacts and should be maintained. Low Quality, High Usage : Artifacts in this box have low quality scores but are frequently used. These artifacts should be improved in quality or their usage should be reduced in favor of higher-quality alternatives. Matrix legend : Quality Score : The maximum quality score is 4. A higher score indicates better quality. Calls : This metric shows how many times an artifact has been used. Depending on the context (matrix box), a higher number of calls can be either positive or negative. By analyzing these metrics, you can make informed decisions to improve the accuracy and reliability of your Alita AI application, ensuring a better user experience. Prompt Topics The Prompt Topics section provides an automatic classification of the available artifacts (prompts, datasources, and agents) within the Alita AI application. This section helps you understand the distribution and focus areas of your artifacts, enabling you to identify trends and gaps in your content. Chart Components The Prompt Topics section displays a clustered column chart that categorizes your artifacts by topic. This visual representation allows you to quickly see how many prompts, datasources, or agents are associated with each topic. The clustered column chart includes the following components: Items : Indicates the number of artifacts associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of your artifacts. Practical Applications Understanding the distribution of your artifacts across different topics can provide several benefits: Content Gaps : Identify topics with fewer artifacts, indicating potential areas where additional content may be needed. Content Focus : Recognize topics with a high number of artifacts, helping you understand the primary focus areas of your users. Resource Allocation : Allocate resources more effectively by focusing on topics that require more attention or improvement. By leveraging the insights provided by the Prompt Topics section, you can ensure that your application covers a comprehensive range of topics, enhancing the overall user experience and effectiveness of the application. Topics Summary The Topics Summary section provides an automatic classification of user inputs, categorizing the topics that users have queried or questioned about. This section helps you understand user interests and the most frequently discussed topics within ELITEA. Chart Components The Topics Summary section displays a clustered column chart that categorizes user inputs by topic. This visual representation allows you to quickly see how many times users have queried information for each topic within a selected timeframe. The clustered column chart includes the following components: Items : Indicates the number of user queries associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of user queries. Practical Applications Understanding the distribution of user queries across different topics can provide several benefits: User Interests : Identify the topics that users are most interested in, allowing you to tailor your content and responses to better meet their needs. Content Gaps : Recognize topics with fewer user queries, indicating potential areas where additional content or promotion may be needed. Trend Analysis : Monitor how user interests evolve over time, helping you stay ahead of emerging trends and adjust your strategies accordingly. By leveraging the insights provided by the Topics Summary section, you can ensure that ELITEA is aligned with user interests, enhancing the overall user experience and effectiveness of the application. The Monitoring feature in ELITEA offers a robust set of tools and metrics to help you understand the performance and usage of your application. By utilizing the various charts and statistics available, you can gain valuable insights into user engagement, sentiment, accuracy, and the distribution of topics within your project. These insights are crucial for making data-driven decisions that can enhance the overall user experience and effectiveness of your ELITEA application. Whether you are looking to improve customer's experience through sentiment analysis, optimize the relevance and reliability of LLM responses, or identify content gaps and user interests, the Monitoring feature provides the necessary data to guide your efforts. By regularly reviewing and analyzing these metrics, you can ensure that your project remains aligned with user needs and continues to perform at its best. By leveraging the comprehensive monitoring capabilities of ELITEA, you can create a more responsive, efficient, and user-friendly application, ultimately leading to higher user satisfaction and better overall performance. Configuration The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Code Chat. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential. To create a token: Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings and the Download Jetbrains Settings icons will appear next to the created token. This allows you to download the configuration files to integrate and configure the ELITEA HUB project with Alita Code extensions on VSCode and IntelliJ respectively. For more information about how to setup it, please refer to the Alita Code Documentation . Deployments The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations. Creating a New Deployment for EPAM AI Dial To set up a new deployment for EPAM AI Dial within your system, follow these detailed steps: Obtain API Key : Important : Before proceeding, you must obtain a separate API Key from the EPAM DIAL team. This key is essential for authenticating and enabling communication with the AI Dial services. API Key Retrieval : Once you have received the API Key and any additional required information via email, return to this page to input these details. Initiate Deployment Creation : Click the + icon to start creating a new deployment. Select Deployment Type : From the list of available deployment types, select AI Dial . Configure Deployment Details : In the configuration window, fill in the following information: Name : Enter a descriptive name for the deployment. This name will be displayed alongside LLM models configured with this deployment. API Base : For EPAM AI Dial, use https://ai-proxy.lab.epam.com as the API Base. Secret API Key : Paste the API Key that you received from the AI Dial team. API Version : Enter the API version information provided by the AI Dial team. Add Models to Deployment : Click the + icon to add one or more models associated with this deployment. For each model, provide the model's name, maximum input tokens, and capabilities. Important : Ensure that you enter the correct model name as used in EPAM AI DIAL. For detailed information on model specifications and configurations, refer to the EPAM AI Dial documentation . Click Save to complete the creation of the deployment. By following these steps, you can successfully create and configure a new deployment for EPAM AI Dial, enabling you to leverage advanced capabilities within your projects. Projects The Projects menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Note : It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Groups The Groups feature in ELITEA is designed to facilitate efficient management and monitoring of multiple projects by admins or managers. This feature allows you to consolidate several projects under a single group, making it easier to oversee and coordinate activities across these projects. If you are an admin of two or more projects, you can leverage the Groups feature to organize and monitor your projects collectively: Create a New Group : Click the Pencil icon to initiate the creation of a new group. You will be prompted to name the group and select the projects you wish to include. Add Projects to Existing Group : If you already have established groups, you can add additional projects to these groups. This grouping functionality not only simplifies the administrative workload but also enhances the visibility and control over multiple projects, enabling more effective management and monitoring. Teammates The Teammates feature in ELITEA is specifically crafted to streamline the process of collaborating within projects by allowing you to invite new users (teammates) and assign them appropriate roles. These roles include system, admin, editor, and viewer, each providing different levels of access and control within the project. Note : Only users with an admin role are empowered to invite new members. This ensures that the invitation and role assignment process is managed by users with appropriate authority and understanding of the project\u2019s needs. Inviting New Teammates : Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Teammates , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Teammates : The Teammates table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name. Secrets The Secrets feature in ELITEA serves as a secure vault designed to store and manage sensitive information such as passwords, tokens, API keys, and other authentication details. This centralized system allows you to configure secrets once and utilize them across various components, such as Agent's toolkits within ELITEA HUB. Creating a Secret : To add a new secret to the vault, follow these steps: Click the + icon to initiate the creation of a new secret. Enter a descriptive name for the secret to help you identify its use. In the Value field, input the token, password, API key, or any other authentication details. Once configured, this secret can now be selected and used within various components of ELITEA HUB. Managing Secrets : The management of secrets is straightforward and secure, facilitated by the Secrets table which displays all your configured secrets: View Secret : Click the Eye icon to reveal the value of a configured secret. This allows you to quickly check the details without modifying them. Copy Secret : Easily copy the secret value to your clipboard (by clicking the hidden value) for use in configurations or integrations. Hide Secret : Hide the secret from the interface to maintain security when not actively managing the secret. Modify Secret : Update the value of the secret if the existing credentials change or need to be corrected. Delete Secret : Remove a secret permanently from the vault if it is no longer needed or if security concerns necessitate its deletion. This feature enhances the security and efficiency of managing sensitive information within ELITEA, ensuring that authentication details are handled in a secure, centralized manner.","title":"Get Started"},{"location":"user-guide/intro/#introduction","text":"Welcome to the ELITEA platform, an innovative web application that revolutionizes how you interact with Generative AI. ELITEA is not just a repository but a dynamic workspace designed to empower you to create, organize, and collaborate on prompts, datasources and agents like never before. Key Features: Prompt Management : Effortlessly create, modify, and manage prompts. Keep track of different versions to ensure you always have access to your best work. Datasources : Play a pivotal role in enhancing the functionalities of ELITEA by integrating user-specific or project-specific data. This not only broadens the LLM's context but also enriches it with tailored information, making your interactions more relevant and insightful. Agents : Customize and create virtual assistants within ELITEA to handle specific tasks or sets of tasks. These agents integrate prompts, datasources, and external toolkits into a cohesive mechanism, enabling actions such as online searches or creating Jira tickets based on decisions made by LLMs. Chat : Combine all ELITEA features in one place with ELITEA Chat, an ultimate feature that allows for dynamic interaction and optimal results. Engage in conversations that utilize natural language to interact with human users and seamlessly integrate feedback from various participants like language models, datasources, and agents. Extensions : Transform your coding workflow with Alita Code and Alita Code Chat the ultimate AI-powered IDE extensions. Integrated seamlessly with VS Code and IntelliJ, these extensions offers intelligent suggestions, automates routine tasks, and provides unmatched adaptability to elevate your coding experience. Collection Integration : Organize your prompts, datasources and agents into Collections for better workflow management or to concentrate on specific themes or projects. Execution with Precision : Tailor the execution of prompts using various models and parameters to meet your specific needs, ensuring a customized experience. Advanced Creation Tools : Craft complex prompts, datasources and agents with precision using tools like variables, system prompts, Assistant Messages, and advanced tools. Powerful Search : Employ a robust search functionality to easily locate prompts, datasources and agents by tags, names, or descriptions. Community Engagement : Engage with the community by creating, modifying, and publishing prompts, datasources and agents. Enhance collaboration through sharing and liking content. ELITEA is designed to be a versatile and powerful tool, enhancing how you interact with AI technologies and manage data-driven projects. Whether you're coding, creating content, or managing complex data sets, ELITEA provides the tools you need to succeed. Let's embark on this journey to unlock the full potential of your ideas. Our user guide will walk you through every feature, ensuring you maximize your ELITEA experience.","title":"Introduction"},{"location":"user-guide/intro/#accessing-elitea-hub","text":"To access and navigate through ELITEA HUB, follow these steps: Open Your Browser : Launch your preferred web browser. Enter URL : Type https://alita.lab.epam.com into the address bar and press Enter. Login : Use your EPAM account credentials to log in. Note : Registration is not required. Initial Navigation : Upon successful login, you will be directed to the Chat menu. Note : If this is your first time logging into ELITEA, please allow up to 5 minutes for the private project initialization to complete before you start creating prompts. Switch Projects : After the Private project is initialized, you can switch from the Public project to your Private project using the Project dropdown list, located at the top right next to your avatar. Explore ELITEA : Click on the ELITEA icon on the top left side to navigate among the available menus. Here, you can create and manage prompts, datasources, agents, and collections. By following these steps, you will be able to effectively utilize the features and functionalities offered by ELITEA HUB. Note : You need to enable Epam VPN to access ELITEA.","title":"Accessing ELITEA HUB"},{"location":"user-guide/intro/#elitea-main-interface","text":"The ELITEA HUB's main interface encompasses several sections, including the Discover Menu, Search feature, Quick Navigation tabs, Settings, a Quick button for creating new items (conversation, prompt, datasource, agent and collection, importing prompt), Tags, and Trending Authors. Sections: Discover Menu : A sidebar menu allowing users to switch among different menus such as Chat, Prompts, Datasources, Agents and Collections. Search : A Search box available to find prompts, datasources and agents by their names and descriptions. Note : The Search functionality operates within the selected menu and is not universal across the entire application. View Switcher : A tool for quickly switching between Card list and Table views. Quick button : A button that allows for the rapid creation of a new conversation, prompt, datasource, agent or collection. The default of this button ( +Conversation , +Prompt , +Datasource , +Agent or +Collection ) changes based on the selected menu. Notifications : Notification's bell allowing user to get notified about various events such as prompt publishing status within the ELITEA Hub. Project Switcher : A tool for quickly switching among projects. Settings : Accessible by clicking on your user avatar/picture. Here, you can configure various project and profile specific settings. Tags : This section displays the tags (categories) associated with the content being viewed. The tags vary depending on the selected menu. Trending Authors : Shows the authors who have recently contributed or shared the most trending prompts, datasources and agents with the community.","title":"ELITEA - Main Interface"},{"location":"user-guide/intro/#general-navigation-and-management-across-the-application","text":"This section provides an overview of the common functionalities and actions available across various menus and pages within the application. The aim is to ensure a consistent and efficient user experience by maintaining uniformity in navigation and management features across both Private and Public projects. Private Project Navigation : In a Private project, you have exclusive access to your personalized content across the following menus: Chat menu: Access all your private and public conversations, allowing for seamless communication and collaboration. Prompts menu: View and manage all the prompts you have created, enabling easy modification and reuse. Datasources menu: Contains all the datasources you have developed. Agents menu: Access all your created agents, each designed to perform specific tasks or sets of tasks. Collections menu: Manage your collections of prompts, datasources, and agents, organized for specific projects or themes. Public Project Navigation : In a Public project, you can engage with the community and explore content created by other users through the following sections: Prompts menu: Navigate through the Latest prompts, explore prompts you've liked (My Likes), and discover Trending prompts within the community. Datasources menu: Access the Latest datasources, view datasources you've liked (My Likes), and explore Trending datasources shared by the community. Agents menu: Discover the Latest agents, check out agents you've liked (My Likes), and find Trending agents that are popular in the community. Collections menu: Explore the Latest collections, view collections you've liked (My Likes), and discover Trending collections that are gaining attention. While the context may vary depending on the specific page you're viewing, the core principles of action and functionality remain consistent. This unified approach ensures that whether you are navigating a private or public project, the experience is intuitive and user-friendly, facilitating effective management and exploration of content within the application.","title":"General Navigation and Management Across the Application"},{"location":"user-guide/intro/#common-viewing-options","text":"Card list view : Offers a compact, card-format snapshot of items like prompts, datasources, agents and collections, making it easy to visually scan through published materials. Table view : Provides an in-depth look at individual items, presenting extensive details for a comprehensive analysis.","title":"Common Viewing Options"},{"location":"user-guide/intro/#search-and-filtering-functionality","text":"Search : Seamlessly locate specific items by their name or description using the search feature, which operates within the menu you are currently exploring. This tool is invaluable for quickly finding relevant content. Filtering : Streamline your search by filtering items using specific tags. This feature is especially useful for discovering content related to particular subjects or themes.","title":"Search and Filtering Functionality"},{"location":"user-guide/intro/#sorting-options-detailed-view-only","text":"Name & Description : Alphabetically organize published items by their names, providing an effortless method to find specific titles. Create : Sort items by their creation date to monitor the chronological development of content or pinpoint the newest additions. Likes : Order the items by the number of likes they have received. This functionality is applicable only for menus within Public project. Authors : Sort the items by the author's name. This functionality is applicable only for menus within Public project. These standardized functionalities across different menus and pages are designed to simplify navigation and enhance the content management process within the application, promoting a coherent and user-friendly environment.","title":"Sorting Options (Detailed View Only)"},{"location":"user-guide/intro/#discover-menus","text":"ELITEA application consists of the following main menus: Chat Prompts Datasources Agents Collections Navigation : To naviagte among the menus, click the ELITEA icon on the top left. The Sidebar menu is opened. Click on the menu name to navigate to the desired menu.","title":"Discover - Menus"},{"location":"user-guide/intro/#settings","text":"The Settings is designed to offer you a centralized space to manage vital aspects of your account and configurations. This centralized space is accessible by clicking on your avatar located at the top right corner of the page. The Settings consists of several tabs and settings each dedicated to specific functionalities: Profile : Customize your user profile within ELITEA. Monitoring : Keep track of usage statistics by selecting different metrics and timeframes. Configuration : Manage essential technical settings crucial for the smooth operation of ELITEA's features like Alita Code or Alita Code Chat. Deployments : Handle the management and launching of AI models or services linked to your ELITEA project. Projects : Manage users within project. This tab is only available for the user within admin permissions within the project. Theme : Switch between Dark and Light theme for the whole application. Log out : Securely log out from the ELITEA Hub. Navigation : To navigate through the Settings menus, follow these steps: Click on the Your Avatar icon located at the top right corner of the page to open the Sidebar menu. Select the desired tab by clicking on its name to navigate to that specific section.","title":"Settings"},{"location":"user-guide/intro/#profile","text":"In the Profile , you\u2019re presented with options to personalize your account within ELITEA. About me - fill in or update your personal details to ensure your ELITEA profile remains current. Note : Markdown is supported.","title":"Profile"},{"location":"user-guide/intro/#monitoring","text":"The Monitoring feature in ELITEA is designed to provide a comprehensive overview of the application's usage and performance. This feature is essential for administrators and users who want to gain insights into various aspects of the application, from user engagement to the effectiveness of configured artifacts like prompts, datasources, and agents. By leveraging the detailed charts and statistics available within the Monitoring feature, you can make informed decisions to optimize the performance and user experience of your ELITEA application. This section will guide you through the various components of the Monitoring feature, including configuration options, key metrics, adoption and usage statistics, sentiment analysis, accuracy metrics, prompt topics, and topics summary. Each of these components offers valuable insights that can help you understand how the application is being used and how it can be improved.","title":"Monitoring"},{"location":"user-guide/intro/#configuration-options","text":"At the top of the Monitoring page, you have several options and settings to configure the charts and metrics you wish to monitor: Projects : A dropdown lits allowing you to select the project. Note : For your Private project, you can only see your private project data. If you have an admin role in another projects, you can select other projects to monitor. From and To Date Fields : These fields are used to select the time period for which you want to see the data. Type : A dropdown list allowing you to select among Prompt , Datasource , Agent , and Conversation to focus your monitoring on specific elements. Name : A dropdown list to select specific items by name, such as created prompts, datasources, agents, or conversations. Users : A dropdown list to select which users' data you want to monitor. Note : For your private project, you can only see your own user data. If you have an admin role in another project, you can select other users to monitor. To apply any changes or selections, click the Apply button. Use the Refresh button to update the monitoring data based on the latest activities and configurations.","title":"Configuration Options"},{"location":"user-guide/intro/#key-metrics","text":"Below the configuration options, you'll find an overview of key metrics that give you a snapshot of the current state of the system: Users : The total number of users interacting with the ELITEA application. Tokens In : The number of tokens consumed by the ELITEA application. Tokens Out : The number of tokens generated by the ELITEA application. Gb Used : The amount of data processed by the ELITEA application. Prompts : The total number of prompts created. Datasources : The total number of datasources created. Agents : The total number of agents created. Conversations : The total number of conversations created. These metrics are accompanied by a date range selector, allowing you to filter the data for a specific period.","title":"Key Metrics"},{"location":"user-guide/intro/#adoption-and-usage","text":"Below the key metrics, you'll find the Adoption and Usage section, which includes: Active Users : A bar chart displaying the number of active users over time. Token Usage : A line chart showing the tokens consumed (In) and generated (Out) over time. These charts provide insights into user engagement and the application's token economy.","title":"Adoption and Usage"},{"location":"user-guide/intro/#sentiments","text":"The Sentiments section provides a visual representation of the emotional tone of both user inputs and the outputs generated by LLMs. Understanding sentiment is crucial for tailoring responses to better meet user needs and improve overall interaction quality.","title":"Sentiments"},{"location":"user-guide/intro/#sentiment-analysis-overview","text":"Sentiment analysis categorizes text into three primary emotional states: Positive : Indicates a favorable or happy emotional tone. Negative : Indicates an unfavorable or unhappy emotional tone. Neutral : Indicates a neutral or indifferent emotional tone. ELITEA performs sentiment analysis on user inputs to gauge the user's emotional state. This capability is particularly important for providing high-quality customer service, as the LLM can adjust its response tone and content based on the user's emotions.","title":"Sentiment Analysis Overview"},{"location":"user-guide/intro/#visual-representation","text":"The Sentiments section includes two pie charts that offer a clear visual representation of sentiment distribution: Human Input : This pie chart shows the sentiment distribution of user inputs. It helps you understand how users are feeling when they interact with the LLMs. LLM Output : This pie chart displays the sentiment distribution of LLM's outputs. It helps you ensure that the responses generated by the LLM are appropriate and aligned with user emotions.","title":"Visual Representation"},{"location":"user-guide/intro/#practical-applications","text":"Understanding sentiment can significantly enhance the user experience in several ways: Customer Service : By analyzing the sentiment of user inputs, LLMs can adjust its responses to be more empathetic and supportive, thereby improving customer satisfaction. User Engagement : Monitoring sentiment trends over time can help you identify patterns in user behavior and adjust your strategies accordingly. Content Moderation : Sentiment analysis can be used to flag potentially harmful or inappropriate content, ensuring a safer and more positive interaction environment.","title":"Practical Applications"},{"location":"user-guide/intro/#accuracy","text":"The Accuracy section provides detailed insights into the performance and reliability of the ELITEA application. This section includes various metrics and visualizations that help you understand how well the system is responding to user inputs and how effective your configured artifacts (prompts, datasources, agents, conversations) are.","title":"Accuracy"},{"location":"user-guide/intro/#relevance","text":"The Relevance metric is divided into two key lines: Input vs Context : This line measures the relevance of the user's input (question or query) against the context of the artifact (prompt, datasource, agent or conversation). In the ELITEA, \"context\" refers to the configured instructions for the artifact. A higher relevance score indicates that the user's input closely matches the context, making it easier for the LLM to provide accurate responses. Output vs Input : This line measures the relevance of the generated output by the LLM against the user's input. A higher relevance score here indicates that the output is closely aligned with the user's query, ensuring that the response is appropriate and useful. Note : The maximum value for relevance is 6. The higher the score, the better the relevance, indicating a more accurate and contextually appropriate interaction.","title":"Relevance"},{"location":"user-guide/intro/#reliability","text":"The Reliability Score answers the question of whether there is enough context to respond accurately to the user's questions or queries. This metric helps you gauge the confidence level of the LLM's responses. Note : The maximum reliability score is 10. A higher score indicates that there is sufficient context to provide a correct and reliable response to the user's query.","title":"Reliability"},{"location":"user-guide/intro/#prompt-quality-vs-usage","text":"The Prompt Quality vs Usage is a 2x2 matrix that helps you evaluate the effectiveness and utilization of your artifacts (prompts, agents, datasources or conversations): Low Quality, Low Usage : Artifacts in this box have low quality scores and are rarely used. These artifacts may need to be re-evaluated or improved. High Quality, Low Usage : Artifacts in this box have high quality scores but are not frequently used. Efforts should be made to promote these high-quality artifacts to increase their usage. High Quality, High Usage : Artifacts in this box have high quality scores and are frequently used. These are your most effective artifacts and should be maintained. Low Quality, High Usage : Artifacts in this box have low quality scores but are frequently used. These artifacts should be improved in quality or their usage should be reduced in favor of higher-quality alternatives. Matrix legend : Quality Score : The maximum quality score is 4. A higher score indicates better quality. Calls : This metric shows how many times an artifact has been used. Depending on the context (matrix box), a higher number of calls can be either positive or negative. By analyzing these metrics, you can make informed decisions to improve the accuracy and reliability of your Alita AI application, ensuring a better user experience.","title":"Prompt Quality vs Usage"},{"location":"user-guide/intro/#prompt-topics","text":"The Prompt Topics section provides an automatic classification of the available artifacts (prompts, datasources, and agents) within the Alita AI application. This section helps you understand the distribution and focus areas of your artifacts, enabling you to identify trends and gaps in your content.","title":"Prompt Topics"},{"location":"user-guide/intro/#chart-components","text":"The Prompt Topics section displays a clustered column chart that categorizes your artifacts by topic. This visual representation allows you to quickly see how many prompts, datasources, or agents are associated with each topic. The clustered column chart includes the following components: Items : Indicates the number of artifacts associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of your artifacts.","title":"Chart Components"},{"location":"user-guide/intro/#practical-applications_1","text":"Understanding the distribution of your artifacts across different topics can provide several benefits: Content Gaps : Identify topics with fewer artifacts, indicating potential areas where additional content may be needed. Content Focus : Recognize topics with a high number of artifacts, helping you understand the primary focus areas of your users. Resource Allocation : Allocate resources more effectively by focusing on topics that require more attention or improvement. By leveraging the insights provided by the Prompt Topics section, you can ensure that your application covers a comprehensive range of topics, enhancing the overall user experience and effectiveness of the application.","title":"Practical Applications"},{"location":"user-guide/intro/#topics-summary","text":"The Topics Summary section provides an automatic classification of user inputs, categorizing the topics that users have queried or questioned about. This section helps you understand user interests and the most frequently discussed topics within ELITEA.","title":"Topics Summary"},{"location":"user-guide/intro/#chart-components_1","text":"The Topics Summary section displays a clustered column chart that categorizes user inputs by topic. This visual representation allows you to quickly see how many times users have queried information for each topic within a selected timeframe. The clustered column chart includes the following components: Items : Indicates the number of user queries associated with each topic. Topic Name : Displays the name of each topic, helping you identify the subject matter of user queries.","title":"Chart Components"},{"location":"user-guide/intro/#practical-applications_2","text":"Understanding the distribution of user queries across different topics can provide several benefits: User Interests : Identify the topics that users are most interested in, allowing you to tailor your content and responses to better meet their needs. Content Gaps : Recognize topics with fewer user queries, indicating potential areas where additional content or promotion may be needed. Trend Analysis : Monitor how user interests evolve over time, helping you stay ahead of emerging trends and adjust your strategies accordingly. By leveraging the insights provided by the Topics Summary section, you can ensure that ELITEA is aligned with user interests, enhancing the overall user experience and effectiveness of the application. The Monitoring feature in ELITEA offers a robust set of tools and metrics to help you understand the performance and usage of your application. By utilizing the various charts and statistics available, you can gain valuable insights into user engagement, sentiment, accuracy, and the distribution of topics within your project. These insights are crucial for making data-driven decisions that can enhance the overall user experience and effectiveness of your ELITEA application. Whether you are looking to improve customer's experience through sentiment analysis, optimize the relevance and reliability of LLM responses, or identify content gaps and user interests, the Monitoring feature provides the necessary data to guide your efforts. By regularly reviewing and analyzing these metrics, you can ensure that your project remains aligned with user needs and continues to perform at its best. By leveraging the comprehensive monitoring capabilities of ELITEA, you can create a more responsive, efficient, and user-friendly application, ultimately leading to higher user satisfaction and better overall performance.","title":"Practical Applications"},{"location":"user-guide/intro/#configuration","text":"The Configuration page serves as the nucleus for managing essential technical settings that enable the smooth operation of ELITEA's features, such as Alita Code or Alita Code Chat. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. URL - this is the base web address through which you interact with ELITEA\u2019s services. It's a crucial link for all your API calls or web requests. Project ID & Integration UID - unique identifiers for your project and integration instances. These are required when setting up or customizing ELITEA\u2019s services to work within your specific project environment. Integration Options - allows to select and display available LLMs and Embeddings integrated with your deployments. Model Name - displays the correct name of selected integration option Personal Tokens - access tokens are your key to secure communication with ELITEA's backend. Here, you can generate tokens that authorize your applications or scripts to perform operations on behalf of your account. Treat these tokens with care and keep them confidential. To create a token: Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings and the Download Jetbrains Settings icons will appear next to the created token. This allows you to download the configuration files to integrate and configure the ELITEA HUB project with Alita Code extensions on VSCode and IntelliJ respectively. For more information about how to setup it, please refer to the Alita Code Documentation .","title":"Configuration"},{"location":"user-guide/intro/#deployments","text":"The Deployments page is all about managing and launching AI models or services that you\u2019ve connected to your ELITEA project. Note : The available settings and configurations may vary depending on the project selected. It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project. Available Deployments - view a list of current AI deployments, such as AI Dial or Hugging Face, that have been linked to your project. This snapshot gives you quick access to manage these integrations. Creating New Deployments - while the possibility exists to set up new deployments, it\u2019s a process that requires coordination with the ELITEA team. This is to ensure seamless integration and avoid potential conflicts with existing configurations.","title":"Deployments"},{"location":"user-guide/intro/#creating-a-new-deployment-for-epam-ai-dial","text":"To set up a new deployment for EPAM AI Dial within your system, follow these detailed steps: Obtain API Key : Important : Before proceeding, you must obtain a separate API Key from the EPAM DIAL team. This key is essential for authenticating and enabling communication with the AI Dial services. API Key Retrieval : Once you have received the API Key and any additional required information via email, return to this page to input these details. Initiate Deployment Creation : Click the + icon to start creating a new deployment. Select Deployment Type : From the list of available deployment types, select AI Dial . Configure Deployment Details : In the configuration window, fill in the following information: Name : Enter a descriptive name for the deployment. This name will be displayed alongside LLM models configured with this deployment. API Base : For EPAM AI Dial, use https://ai-proxy.lab.epam.com as the API Base. Secret API Key : Paste the API Key that you received from the AI Dial team. API Version : Enter the API version information provided by the AI Dial team. Add Models to Deployment : Click the + icon to add one or more models associated with this deployment. For each model, provide the model's name, maximum input tokens, and capabilities. Important : Ensure that you enter the correct model name as used in EPAM AI DIAL. For detailed information on model specifications and configurations, refer to the EPAM AI Dial documentation . Click Save to complete the creation of the deployment. By following these steps, you can successfully create and configure a new deployment for EPAM AI Dial, enabling you to leverage advanced capabilities within your projects.","title":"Creating a New Deployment for EPAM AI Dial"},{"location":"user-guide/intro/#projects","text":"The Projects menu is specifically designed for administrators and becomes accessible when you hold administrative privileges in any project other than your private project within ELITEA. Note : It's important to select the appropriate project from the project dropdown menu to access specific configurations relevant to that project.","title":"Projects"},{"location":"user-guide/intro/#groups","text":"The Groups feature in ELITEA is designed to facilitate efficient management and monitoring of multiple projects by admins or managers. This feature allows you to consolidate several projects under a single group, making it easier to oversee and coordinate activities across these projects. If you are an admin of two or more projects, you can leverage the Groups feature to organize and monitor your projects collectively: Create a New Group : Click the Pencil icon to initiate the creation of a new group. You will be prompted to name the group and select the projects you wish to include. Add Projects to Existing Group : If you already have established groups, you can add additional projects to these groups. This grouping functionality not only simplifies the administrative workload but also enhances the visibility and control over multiple projects, enabling more effective management and monitoring.","title":"Groups"},{"location":"user-guide/intro/#teammates","text":"The Teammates feature in ELITEA is specifically crafted to streamline the process of collaborating within projects by allowing you to invite new users (teammates) and assign them appropriate roles. These roles include system, admin, editor, and viewer, each providing different levels of access and control within the project. Note : Only users with an admin role are empowered to invite new members. This ensures that the invitation and role assignment process is managed by users with appropriate authority and understanding of the project\u2019s needs. Inviting New Teammates : Enter the prospective member's email address in the Email Address input field. Select their role from the Role dropdown menu. Click the Invite button. An invitation will be sent, and upon their first login, their details will be added to the Teammates , activating their account. Notes Multiple users can be invited simultaneously by separating email addresses with a comma. For Epam projects, use the invitee's Epam email. For customer projects, the customer's Active Directory is utilized for invitations. Managing Teammates : The Teammates table displays all members, their roles, and their last login information. Admins can modify a user's role or revoke access by clicking the respective Edit or Delete icons next to a user's name.","title":"Teammates"},{"location":"user-guide/intro/#secrets","text":"The Secrets feature in ELITEA serves as a secure vault designed to store and manage sensitive information such as passwords, tokens, API keys, and other authentication details. This centralized system allows you to configure secrets once and utilize them across various components, such as Agent's toolkits within ELITEA HUB. Creating a Secret : To add a new secret to the vault, follow these steps: Click the + icon to initiate the creation of a new secret. Enter a descriptive name for the secret to help you identify its use. In the Value field, input the token, password, API key, or any other authentication details. Once configured, this secret can now be selected and used within various components of ELITEA HUB. Managing Secrets : The management of secrets is straightforward and secure, facilitated by the Secrets table which displays all your configured secrets: View Secret : Click the Eye icon to reveal the value of a configured secret. This allows you to quickly check the details without modifying them. Copy Secret : Easily copy the secret value to your clipboard (by clicking the hidden value) for use in configurations or integrations. Hide Secret : Hide the secret from the interface to maintain security when not actively managing the secret. Modify Secret : Update the value of the secret if the existing credentials change or need to be corrected. Delete Secret : Remove a secret permanently from the vault if it is no longer needed or if security concerns necessitate its deletion. This feature enhances the security and efficiency of managing sensitive information within ELITEA, ensuring that authentication details are handled in a secure, centralized manner.","title":"Secrets"},{"location":"user-guide/agents/agents-examples/","text":"Agents Examples and Materials Agents - Helpful Materials To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents. Video Tutorials Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation Agent Frameworks General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. ReAct Agent Type For the ReAct agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes. Practical Examples Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Agents Examples and Materials"},{"location":"user-guide/agents/agents-examples/#agents-examples-and-materials","text":"","title":"Agents Examples and Materials"},{"location":"user-guide/agents/agents-examples/#agents-helpful-materials","text":"To assist you in maximizing the capabilities of Agents within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Agents.","title":"Agents - Helpful Materials"},{"location":"user-guide/agents/agents-examples/#video-tutorials","text":"Explore our curated video tutorials that provide step-by-step instructions and insights on various aspects of working with Agents: Alita AQA Agent for QAvaJS autromation EBSCO Automated test generation","title":"Video Tutorials"},{"location":"user-guide/agents/agents-examples/#agent-frameworks","text":"General Guidelines for Both Agent Types When working with either the React or Raw agent types, it is imperative to adhere to the following general guidelines: Toolkit Interaction : Ensure to address the appropriate toolkits (e.g., JIRA, GitHub) and address the specific tools available within these toolkits (e.g., Create issue, Add comments). Execution Constraints : Always provide clear instructions or constraints to ensure that each toolkit is executed only once to avoid loops. This is crucial for maintaining efficient and error-free operations. ReAct Agent Type For the ReAct agent type, follow these detailed instructions to effectively integrate and utilize various toolkits and tools: Example: Test Case Generation ### Objective: You are an expert Software Testing engineer. Your task is to connect to a Git repository using the GitHub toolkit, read files related to \"Alita Documentation\" to find information about datasources, analyze this information, create three test cases covering datasource creation functionality, and save the generated test cases in a newly created Jira ticket using the Jira toolkit. ### Instructions: 1. Connect to GitHub Repository: - Use the GitHub toolkit to connect to the specified Git repository. - Ensure you have the necessary permissions to read files from the repository. 2. Read Files: - Use the \"Read file\" tool to read files related to \"Alita Documentation\" from the repository. - Focus on finding information about datasources. 3. Analyze Information: - As an expert Software Testing engineer, analyze the information about datasources. - Identify key functionalities and requirements for datasource creation. 4. Create Test Cases: - Based on your analysis, create three test cases covering datasource creation functionality. - Ensure the test cases are detailed, clear, and follow industry best practices. 5. Save Test Cases in Jira: - Use the Jira toolkit to create a new Jira Task. - Use the following project: ETSTCC - The created Issue type must be Task. - Ensure the Jira Task has the next available issue ID. - Save the generated test cases in the Description field. - Use the following Label: AI_Generated. - Generate a corresponding Summary and apply it to the Summary field of the Task. - Use only standard fields in Jira, do not use neither custom fileds or fields from plugins, they are not available. ### Constraints: - Execute each toolkit only once. - Do not get into a loop. - Provide the best possible output based on the available information. ### Example Test Case Format: Test Case ID: TC001 Title: Verify datasource creation with valid inputs Description: Ensure that a datasource can be created successfully when valid inputs are provided. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Enter valid inputs in all required fields. 3. Click on the \"Create\" button. Expected Result: The datasource is created successfully, and a confirmation message is displayed. Test Case ID: TC002 Title: Verify error message for missing required fields Description: Ensure that an appropriate error message is displayed when required fields are left blank during datasource creation. Preconditions: User is logged in and has access to the datasource creation page. Steps: 1. Navigate to the datasource creation page. 2. Leave one or more required fields blank. 3. Click on the \"Create\" button. Expected Result: An error message is displayed indicating that required fields must be filled. ### Execution: - Follow the instructions step-by-step. - Ensure each toolkit is executed only once. - Provide the best possible output based on the available information. Raw Agent Type For the Raw agent type, adhere to these specific guidelines to ensure the agent operates correctly: Preserve Existing Variables : Do not remove any pre-existing variables in the configuration as they are crucial for the agent's functionality. Avoid Assigning Values to Variables : Leave variables unassigned; they will be automatically populated during execution. Include the following essential sections in your configuration: ### Tools: {{tools}} - Say to user: tool: \"complete_task\", args: \"final_answer\" - complete message to be communicated to the user, shoudl contain as much details as possible ### Scratchpad {{agent_scratchpad}} ### Chat History {{chat_history}} ### User Input: {{input}} ### Response format { \"thoughts\": { \"text\": \"message to a user follow the style of your persona\", \"plan\": \"short bulleted, list that conveys long-term plan\", \"criticism\": \"constructive self-criticism\", }, \"tool\": { \"name\": \"tool name\", \"args\": { \"arg name\": \"value\" } } } You must answer with only JSON and it could be parsed by Python json.loads By following these guidelines and including the necessary code snippet, you ensure that the Raw Agent functions correctly and integrates seamlessly with the intended processes.","title":"Agent Frameworks"},{"location":"user-guide/agents/agents-examples/#practical-examples","text":"Gain hands-on experience with our detailed examples that illustrate the practical application of Agents in real-world scenarios:","title":"Practical Examples"},{"location":"user-guide/agents/agents/","text":"Agents Private project - Agents menu ELITEA Agents play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. ELITEA Agents is a feature that allows you to create and manage virtual assistants or \"agents\" within the ELITEA interface. These agents are designed to help you accomplish specific tasks or automate certain workflows by leveraging the natural language processing capabilities of GPT models supported by ELITEA. The purpose of Agents in ELITEA is to provide a more efficient way of interacting with the AI models for various use cases. Instead of engaging in open-ended conversations, you can define specific goals, tasks, or workflows for an agent to handle. This can be particularly useful in scenarios where you need to perform repetitive or complex tasks that involve multiple steps or require gathering and processing information from various sources. What are ELITEA Agents? ELITEA Agents are virtual assistants or bots that you can create and customize within the ELITEA interface. Each agent is designed to handle a specific task or set of tasks based on the instructions and capabilities you define for it. Agents bring prompts, datasources and external to LLM toolkits into one mechanism allowing to use integrate decisions made by LLMs and actions required to be taken, like search in Google or creating a Jira Tickets, etc. Agents are capable to work with more external toolkits. How do Agents work? When you create an agent, you provide it with a set of instructions, toolkits or a goal that you want it to accomplish. These instructions can be as simple or complex as needed, and they can include steps, conditions, and actions that the agent should take. The agent then uses the natural language processing capabilities of selected GPT model to understand and execute the instructions you've provided. Integration with External toolkits, Services, and APIs One of the powerful features of ELITEA Agents is their ability to integrate with a wide range of external toolkits, services, and APIs. This integration enables agents to access and interact with different platforms, empowering them to perform more complex and specialized tasks. Below are some examples of integrations that can be set up with ELITEA Agents: Project Management toolkits : ELITEA Agents can be integrated with toolkits like JIRA or Trello to help manage projects, track issues, and collaborate with team members efficiently. Test Management toolkits : Integration with toolkits such as TestRail or qTest can enable agents to assist with test case management, execution, and reporting, enhancing the software testing lifecycle. Documentation and Knowledge Base toolkits : Agents can connect to platforms like Confluence to help create, update, and manage documentation and knowledge bases, ensuring that information is always current and accessible. Version Control Systems : Integration with Git repositories like GitHub or GitLab can allow agents to assist with code management, pull requests, and code reviews, streamlining the development process. APIs and Web Services : ELITEA Agents can interact with various APIs and web services, such as Open APIs to retrieve and process data as needed, providing timely and relevant information. Web Browsers : Agents can be configured to automate tasks within web browsers, such as web scraping, web searching, or automating web-based workflows, which can significantly reduce manual effort. Internal toolkits and Systems : ELITEA Agents can also be integrated with internal ELITEA toolkits (prompts, datasources and agents). By leveraging these integrations, ELITEA Agents can become powerful virtual assistants that help automate and streamline a wide range of tasks across different platforms and toolkits. The specific integrations available may vary based on the capabilities of the ELITEA platform and the APIs or toolkits you want to connect with. It's important to note that setting up these integrations may require additional configuration and authentication steps, such as providing API keys, access tokens, or configuring webhooks or other communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, enabling ELITEA Agents to function effectively within your existing technological ecosystem. Note : For more information, please check Alita Tools and Alita SDK git repos. Creating an Agent To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type . Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter . Click Save . Your newly created agent will subsequently appear on the Agents page for your project. How to Create Instructions The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Instructions Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit). How to Select an Agent Type Choosing the appropriate Agent type is crucial as it dictates the level of detail and the nature of instructions required for the agent to operate effectively. Below is an overview of the available Agent types and their intended use cases: ReAct Description : This Agent type is ideal for straightforward, linear scenarios that require minimal context. Simply specify your requirements, including what actions the agent should perform, and add the necessary toolkits. Utilize fields such as Actor, Goals, Instructions, and Constraints to clearly describe the desired behavior. Best For : Simple tasks with clear, direct instructions. Alita Description : Alita agents are a hybrid of OpenAI's and Langchain's ReAct approaches, making them suitable for more complex, open-ended scenarios. Unlike the React type, Alita agents can maintain chat history, which enhances their ability to handle extended interactions. Best For : Complex scenarios that require ongoing interactions and the ability to retain context over time. Not recommended for simple, linear tasks. Dial Description : Dial agents are based on Epam AI DIAL technology and are designed to interact with models and functions or tools, specifically restricted to OpenAI models. Best For : Scenarios that require interaction with OpenAI models and can benefit from DIAL's capabilities. CodeMie Description : Coming soon. Integrated Agent Runtime for CodeMie agents. OpenAI Description : OpenAI agent types are designed to leverage the cutting-edge capabilities of GPT models. These agents excel in generating human-like text and handling a wide range of conversational tasks. They can be easily integrated with OpenAI's API, allowing for seamless interaction and response generation based on the model's extensive training data. Best For : Tasks that require high-quality natural language understanding and generation, such as customer support, content creation, and complex query resolution. Ideal for scenarios where engaging, contextually aware interactions are crucial. Autogen Description : Autogen agents specialize in automated content generation and data extraction tasks. These agents use advanced algorithms to parse and interpret data, then generate structured outputs such as reports, summaries, and detailed analyses. Autogen agents are highly customizable and can be tailored to specific industry needs. Best For : Automated report generation, data analysis tasks, and scenarios where structured data output is required. Ideal for sectors like finance, healthcare, and research where precision and reliability in data handling are paramount. Llama Description : Llama agents are built on top of the Llama model, known for its efficiency and adaptability across various languages and tasks. These agents are particularly effective in multilingual environments and can handle diverse datasets with ease. Llama agents are optimized for speed and accuracy, making them suitable for real-time applications. Best For : Multilingual applications, real-time interaction scenarios, and tasks that require processing large volumes of data efficiently. They are also well-suited for educational and informational services where quick, accurate responses are needed. Raw Description : Obsolete. Used for oldschool agents. Going to be depricated soon. Each of these agent types is tailored to leverage specific strengths of their underlying models and frameworks. Choosing the appropriate agent type based on the task requirements and desired outcomes ensures optimal performance and efficiency. Note : For more information how to select corresponding Agent type and create better instructions for agents please check Agent Frameworks document. How to select and configure Toolkits Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under TOOLS section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit alrady created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available: Agent toolkit The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration. Datasource toolkit The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration. Prompt toolkit The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt. Browser toolkit The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration. Confluence toolkit The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Create page : Enable this to allow the agent to create a new page in Confluence. Create pages : Enable this to allow the agent to create multiple pages in Confluence. Get page tree : Enable this to retrieve the hierarchical structure of pages in Confluence. Delete page : Enable this to allow the agent to delete a page. Update page by id : Enable this to allow the agent to update existing page by page id. Update page by title : Enable this to allow the agent to update page by title. Update labels : Enable this to allow the agent to update page labels. Update pages : Enable this to allow the agent to update multiple pages in Confluence. Site search : Enable this to search pages in Confluence. Search by title : Enable this to allow the agent to search existing page by page id. Read page by id : Enable this to allow the agent to read and show the content of the existing page by page id. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration. Jira toolkit The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. List comments : To allow showing available comments of the Jira issue. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Get specific field info : To allow getting info from the specific Jira field. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration. GitHub toolkit The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration. Gitlab toolkit Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Token : Provide the configured token for authentication. You have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration. Bitbucket toolkit The Bitbucket toolkit integrates into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from Bitbucket, facilitating better version control and development process integration. To configure Bitbucket toolkit : Click the + icon under Tools section. Select the Bitbucket tool from the dropdown list. The New Bitbucket tool configuration section is opened. Name : Assign a distinctive name to your Bitbucket toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Url : Enter the URL to your Bitbucket repository. Username : Input the Username associated with your Bitbucket account to complete the authentication process. Repository : Enter the name of the Bitbucket repository you wish to integrate (e.g. ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Password : Select this option if you are using your Bitbucket account password for authentication you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Bitbucket repository: Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Click the arrow icon next to the New Bitbucket tool to complete the setup and move back to the main menu of Agent configuration. Testrail toolkit The Testrail toolkit enables a direct integration with Testrauk, allowing users to manage test cases directly from the ELITEA platform. To configure TestTrail toolkit : Click the + icon under Tools section. Select the TestRail tool from the dropdown list. The New Testrail tool configuration section is opened. Name : Provide a unique name to identify your Testrail toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Testrail. Email : Enter the email used for authentication. Password : Enter the password for authentication. Tools - the following tools are avaialble for selection: Get case : To enable selecting test case. Get cases : To enable selecting test cases. Add case : To enable adding new case into Testrail. Click the arrow icon next to the New testrail tool to complete the setup and move back to the main menu of Agent configuration. Open API toolkit The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration. Custom toolkit The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration. Artifact toolkit The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration. WELCOME MESSAGE The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this agent for generating manual test cases\" \"Don't forget to double-check the generated test cases\" CONVERSATION STARTERS The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized. How to Execute Agent To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Managing Agent Versions: Save, Create Versions, and Manage To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them. How to Save an Agent: To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent. How to Create New Versions: For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements. Agents Menu The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents. Layout of the Agents Menu The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community. Engaging with Published Agents Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation: Liking Published Agents Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent. Other Actions for Published Agents Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use.","title":"Agents"},{"location":"user-guide/agents/agents/#agents","text":"","title":"Agents"},{"location":"user-guide/agents/agents/#private-project-agents-menu","text":"ELITEA Agents play a pivotal role in broadening and enriching the functionalities of ELITEA and AI technologies. ELITEA Agents is a feature that allows you to create and manage virtual assistants or \"agents\" within the ELITEA interface. These agents are designed to help you accomplish specific tasks or automate certain workflows by leveraging the natural language processing capabilities of GPT models supported by ELITEA. The purpose of Agents in ELITEA is to provide a more efficient way of interacting with the AI models for various use cases. Instead of engaging in open-ended conversations, you can define specific goals, tasks, or workflows for an agent to handle. This can be particularly useful in scenarios where you need to perform repetitive or complex tasks that involve multiple steps or require gathering and processing information from various sources.","title":"Private project - Agents menu"},{"location":"user-guide/agents/agents/#what-are-elitea-agents","text":"ELITEA Agents are virtual assistants or bots that you can create and customize within the ELITEA interface. Each agent is designed to handle a specific task or set of tasks based on the instructions and capabilities you define for it. Agents bring prompts, datasources and external to LLM toolkits into one mechanism allowing to use integrate decisions made by LLMs and actions required to be taken, like search in Google or creating a Jira Tickets, etc. Agents are capable to work with more external toolkits.","title":"What are ELITEA Agents?"},{"location":"user-guide/agents/agents/#how-do-agents-work","text":"When you create an agent, you provide it with a set of instructions, toolkits or a goal that you want it to accomplish. These instructions can be as simple or complex as needed, and they can include steps, conditions, and actions that the agent should take. The agent then uses the natural language processing capabilities of selected GPT model to understand and execute the instructions you've provided.","title":"How do Agents work?"},{"location":"user-guide/agents/agents/#integration-with-external-toolkits-services-and-apis","text":"One of the powerful features of ELITEA Agents is their ability to integrate with a wide range of external toolkits, services, and APIs. This integration enables agents to access and interact with different platforms, empowering them to perform more complex and specialized tasks. Below are some examples of integrations that can be set up with ELITEA Agents: Project Management toolkits : ELITEA Agents can be integrated with toolkits like JIRA or Trello to help manage projects, track issues, and collaborate with team members efficiently. Test Management toolkits : Integration with toolkits such as TestRail or qTest can enable agents to assist with test case management, execution, and reporting, enhancing the software testing lifecycle. Documentation and Knowledge Base toolkits : Agents can connect to platforms like Confluence to help create, update, and manage documentation and knowledge bases, ensuring that information is always current and accessible. Version Control Systems : Integration with Git repositories like GitHub or GitLab can allow agents to assist with code management, pull requests, and code reviews, streamlining the development process. APIs and Web Services : ELITEA Agents can interact with various APIs and web services, such as Open APIs to retrieve and process data as needed, providing timely and relevant information. Web Browsers : Agents can be configured to automate tasks within web browsers, such as web scraping, web searching, or automating web-based workflows, which can significantly reduce manual effort. Internal toolkits and Systems : ELITEA Agents can also be integrated with internal ELITEA toolkits (prompts, datasources and agents). By leveraging these integrations, ELITEA Agents can become powerful virtual assistants that help automate and streamline a wide range of tasks across different platforms and toolkits. The specific integrations available may vary based on the capabilities of the ELITEA platform and the APIs or toolkits you want to connect with. It's important to note that setting up these integrations may require additional configuration and authentication steps, such as providing API keys, access tokens, or configuring webhooks or other communication channels between ELITEA and the external toolkits or services. These steps ensure secure and seamless integration, enabling ELITEA Agents to function effectively within your existing technological ecosystem. Note : For more information, please check Alita Tools and Alita SDK git repos.","title":"Integration with External toolkits, Services, and APIs"},{"location":"user-guide/agents/agents/#creating-an-agent","text":"To set up a new agent: Click the + Agent button located at the top right corner. Fill out the Name and Description fields. Optionally, add tags by typing a tag name or selecting from pre-existing tags in the Tags input box. Select the Agent type . Provide instructions for selected Agent type in the Instructions field. Add and setup selected toolkits that agent must use. Optionally, add and configure Conversation Starter . Click Save . Your newly created agent will subsequently appear on the Agents page for your project.","title":"Creating an Agent"},{"location":"user-guide/agents/agents/#how-to-create-instructions","text":"The Instructions field in Agent is a crucial component where users input the necessary background information or instructions that guide the LLM in executing agent and generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests.","title":"How to Create Instructions"},{"location":"user-guide/agents/agents/#how-to-input-instructions","text":"Identify Key Information : Before entering data into the Instructions field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Instructions field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the agent's focus and efficiency. Using toolkits : For enhancing agent's capabilities, you can integrate toolkits and provide instructions how to use them and in which order. The name of toolkit can be denoted by \"\", (e.g. \"Access_JIRA\" toolkit).","title":"How to Input Instructions"},{"location":"user-guide/agents/agents/#how-to-select-an-agent-type","text":"Choosing the appropriate Agent type is crucial as it dictates the level of detail and the nature of instructions required for the agent to operate effectively. Below is an overview of the available Agent types and their intended use cases: ReAct Description : This Agent type is ideal for straightforward, linear scenarios that require minimal context. Simply specify your requirements, including what actions the agent should perform, and add the necessary toolkits. Utilize fields such as Actor, Goals, Instructions, and Constraints to clearly describe the desired behavior. Best For : Simple tasks with clear, direct instructions. Alita Description : Alita agents are a hybrid of OpenAI's and Langchain's ReAct approaches, making them suitable for more complex, open-ended scenarios. Unlike the React type, Alita agents can maintain chat history, which enhances their ability to handle extended interactions. Best For : Complex scenarios that require ongoing interactions and the ability to retain context over time. Not recommended for simple, linear tasks. Dial Description : Dial agents are based on Epam AI DIAL technology and are designed to interact with models and functions or tools, specifically restricted to OpenAI models. Best For : Scenarios that require interaction with OpenAI models and can benefit from DIAL's capabilities. CodeMie Description : Coming soon. Integrated Agent Runtime for CodeMie agents. OpenAI Description : OpenAI agent types are designed to leverage the cutting-edge capabilities of GPT models. These agents excel in generating human-like text and handling a wide range of conversational tasks. They can be easily integrated with OpenAI's API, allowing for seamless interaction and response generation based on the model's extensive training data. Best For : Tasks that require high-quality natural language understanding and generation, such as customer support, content creation, and complex query resolution. Ideal for scenarios where engaging, contextually aware interactions are crucial. Autogen Description : Autogen agents specialize in automated content generation and data extraction tasks. These agents use advanced algorithms to parse and interpret data, then generate structured outputs such as reports, summaries, and detailed analyses. Autogen agents are highly customizable and can be tailored to specific industry needs. Best For : Automated report generation, data analysis tasks, and scenarios where structured data output is required. Ideal for sectors like finance, healthcare, and research where precision and reliability in data handling are paramount. Llama Description : Llama agents are built on top of the Llama model, known for its efficiency and adaptability across various languages and tasks. These agents are particularly effective in multilingual environments and can handle diverse datasets with ease. Llama agents are optimized for speed and accuracy, making them suitable for real-time applications. Best For : Multilingual applications, real-time interaction scenarios, and tasks that require processing large volumes of data efficiently. They are also well-suited for educational and informational services where quick, accurate responses are needed. Raw Description : Obsolete. Used for oldschool agents. Going to be depricated soon. Each of these agent types is tailored to leverage specific strengths of their underlying models and frameworks. Choosing the appropriate agent type based on the task requirements and desired outcomes ensures optimal performance and efficiency. Note : For more information how to select corresponding Agent type and create better instructions for agents please check Agent Frameworks document.","title":"How to Select an Agent Type"},{"location":"user-guide/agents/agents/#how-to-select-and-configure-toolkits","text":"Toolkits are integrations with external or ELITEA's internal services, toolkits and APIs which allows to enhance Agents to use various resources and do the tasks. To add a new toolkit : Click the + icon under TOOLS section. Select the desired tool from the dropdown list. The New tool configuration section is opened. Configure it accordingly to provide agent access to this tool. Click the arrow icon next to the New tool to complete the setup and move back to the main menu of Agent configuration. To edit alrady created toolkit : Click the name of the already created Tool . The New [tool_name] tool configuration section is opened. Modify the configuration of the tool accordingly Click the arrow icon next to the New [tool_name] tool to complete the changes and move back to the main menu of Agent configuration. The following internal Tools are available:","title":"How to select and configure Toolkits"},{"location":"user-guide/agents/agents/#agent-toolkit","text":"The Agent toolkit provides a meta-level functionality by allowing your Agent to incorporate other pre-configured agents within your ELITEA project. This recursive capability enriches the Agent's functionality, enabling complex, layered interactions and processes. To configure Agent toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Agent tool configuration section is opened. Name : Provide informative name for the agent (toolkit). Description : provide informative description for the agent (toolkit). Agent : Select the agent from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the agent for the first time, the name and description of the selected agent will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : Select the available version of the selected agent from the dropdown list. Click the arrow icon next to the New Agent tool to complete the setup and move back to the main menu of Agent configuration.","title":"Agent toolkit"},{"location":"user-guide/agents/agents/#datasource-toolkit","text":"The Datasource toolkit empowers your Agent by providing access to pre-configured datasources within your ELITEA project. This toolkit facilitates the integration of structured data into the Agent's operations, enhancing its ability to process and analyze information efficiently. To configure Datasource toolkit : Click the + icon under Tools section. Select the Datasource tool from the dropdown list. The New datasource tool configuration section is opened. Name : Provide informative name for the datasource (toolkit). Description : Provide informative description for the datasource (toolkit). Datasource : Select the datasource from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the datasource for the first time, the name and description of the selected datasource will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Action : Select the required action type that will be used by agent (either Search or Chat ). This will allow Agent to use information from selected datasource either by searching it or by chating with it. Click the arrow icon next to the New datasource tool to complete the setup and move back to the main menu of Agent configuration.","title":"Datasource toolkit"},{"location":"user-guide/agents/agents/#prompt-toolkit","text":"The Prompt toolkit allows your Agent to utilize pre-configured prompts from your ELITEA project. This integration enables the Agent to leverage existing prompt configurations to streamline interactions and responses, ensuring consistency and accuracy in its engagements. To configure Prompt toolkit : Click the + icon under Tools section. Select the Prompt tool from the dropdown list. The New Prompt tool configuration section is opened. Name : Provide informative name for the prompt (toolkit). Description : Provide informative description for the prompt (toolkit). Datasource : Select the prompt from the dropdown list that you want to use as a toolkit for the agent. Note : If you select the prompt for the first time, the name and description of the selected prompt will be pulled and displayed as the name/description for the toolkit. Later you can modify them if needed. Version : select the available version of the selected prompt from the dropdown list. Click the arrow icon next to the New Prompt tool to complete the setup and move back to the main menu of Agent configuration. IMPORTANT: Currently, Agents don't support prompts with variables. Variable for agent is input parameter, if you have \u201cdefault\u201d you need to bake it into the prompt.","title":"Prompt toolkit"},{"location":"user-guide/agents/agents/#browser-toolkit","text":"The Browser toolkit significantly enhances the capabilities of your Agent by integrating robust search engine functionalities directly into its operations. This toolkit enables the Agent to access and search the web, thereby enriching the LLM with a vast array of information available online. This integration allows for a more informed and responsive Agent, capable of leveraging up-to-date web data in its tasks. To configure Browser toolkit : Click the + icon under Tools section. From the dropdown list, select the Browser tool to open the configuration settings. The New Browser tool configuration section is opened. Name : Assign a descriptive name to the browser toolkit for easy identification within Agent's instructions. Description : Provide a brief description of the browser toolkit's purpose and how it integrates with your workflow. API key : Input the API key for the CSE that you have configured for the selected search engine. Note : This is required for Google tool only. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. CSE ID : Input the Custom Search Engine ID configured for your selected search engine. Note : This is required for Google tool only. Tools : Choose which search engines to integrate by selecting from the available options: Wiki : Include Wikipedia search capabilities. Single URL Crawler : This tool is designed to crawl data from a specific web page within the Agent's context, making it ideal for targeted data extraction tasks. Multi URL Crawler : Use this tool to crawl data from multiple specified web pages within the Agent's context. It is suitable for broader data gathering operations across various sources. Get HTML Content : This tool allows you to retrieve the HTML content of a specified web page within the Agent's context, providing direct access to the page's structural data. Google : Integrate Google for comprehensive search functionalities. For creating CSE ID and API key for Google, please check the Programmable Search Engine page. Click the arrow icon next to the New Browser tool to complete the setup and move back to the main menu of Agent configuration.","title":"Browser toolkit"},{"location":"user-guide/agents/agents/#confluence-toolkit","text":"The Confluence toolkit seamlessly integrates Confluence, a widely-used platform for team collaboration and content management, into your Agent's toolkit. This tool enhances the Agent's knowledge base with user-specific or project-specific data from Confluence, enriching its context and response accuracy. To configure Confluence toolkit : Click the + icon under the Tools section. Select the Confluence tool from the dropdown list. The New Confluence tool configuration section is opened. Name : Provide an informative name for the Confluence toolkit. Description : Provide a detailed description of the Confluence toolkit's purpose. URL : Enter the URL to your Confluence instance (e.g., https://www.kb.epam.com/ ). The URL should be the base link as detailed handling is managed via the instructions. Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Confluence account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Hosting Option : Select the appropriate hosting type for your Confluence setup: Cloud : If your Confluence is hosted on Atlassian\u2019s cloud. Server : If your Confluence is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Confluence, ensure you select the Server option to establish the correct configuration. Tools : Enable the specific tools you need for your integration: Get pages with the label : Check this to retrieve pages associated with a specific label. Search pages : Check this to enable searching for pages within Confluence. Create page : Enable this to allow the agent to create a new page in Confluence. Create pages : Enable this to allow the agent to create multiple pages in Confluence. Get page tree : Enable this to retrieve the hierarchical structure of pages in Confluence. Delete page : Enable this to allow the agent to delete a page. Update page by id : Enable this to allow the agent to update existing page by page id. Update page by title : Enable this to allow the agent to update page by title. Update labels : Enable this to allow the agent to update page labels. Update pages : Enable this to allow the agent to update multiple pages in Confluence. Site search : Enable this to search pages in Confluence. Search by title : Enable this to allow the agent to search existing page by page id. Read page by id : Enable this to allow the agent to read and show the content of the existing page by page id. Advanced Settings : Configure additional settings to control data fetching and presentation: Pages limit per request : Set the maximum number of pages to retrieve per request (e.g., 5 ). Max total pages : Define the maximum number of pages to retrieve in total (e.g., 10 ). Number of retries : Specify how many times the tool should retry after a failure (e.g., 2 ). Min retry, sec : Set the minimum number of seconds to wait before retrying (e.g., 10 ). Max retry, sec : Set the maximum number of seconds to wait before retrying (e.g., 60 ). Click the arrow icon next to the New Confluence tool to complete the setup and return to the main menu of Agent configuration.","title":"Confluence toolkit"},{"location":"user-guide/agents/agents/#jira-toolkit","text":"The Jira toolkit enables a direct integration with Jira, allowing users to manage issues and projects directly from the ELITEA platform. This tool streamlines project management tasks by enabling real-time interactions and updates through the Agent, enhancing productivity and project tracking. To configure Jira toolkit : Click the + icon under Tools section. Select the Jira tool from the dropdown list. The New Jira tool configuration section is opened. Name : Provide a unique name to identify your Jira toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Jira instance (e.g., https://www.jira.epam.com/jira/ ). Authentication Options : Choose your preferred method for secure connection: API Key : Select this option if you are using an API key for authentication. You have two choices for providing the necessary credentials: Password : Enter your API key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your Jira account to complete the authentication process. Token : Select this option if you are using a token for authentication. Similar to the API key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Hosting Option : Select the appropriate hosting type for your Jira setup: Cloud : If your Jira is hosted on Atlassian\u2019s cloud. Server : If your Jira is hosted on your own servers or an enterprise environment. Important Note : When connecting to Epam's Jira, ensure you select the Server option to establish the correct configuration. Tools - the following tools are avaialble for selection: Search using JQL : To enable searching for Jira issues using Jira Query Language. Create issue : To allow the creation of new issues within Jira. Update issue : To enable updating existing Jira issues. List comments : To allow showing available comments of the Jira issue. Add comments : To allow adding comments to Jira issues. List projects : To enable listing all Jira projects. Set issue status : To set the status of Jira issues. Get specific field info : To allow getting info from the specific Jira field. Advanced Settings : Adjust the advanced settings to fine-tune the toolkit's operation: Verify SSL : Check this to enable SSL verification for secure connections to your Jira instance. Click the arrow icon next to the New Jira tool to complete the setup and move back to the main menu of Agent configuration.","title":"Jira toolkit"},{"location":"user-guide/agents/agents/#github-toolkit","text":"The GitHub toolkit integrates GitHub into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from GitHub, facilitating better version control and development process integration. To configure GitHub toolkit : Click the + icon under Tools section. Select the GitHub tool from the dropdown list. The New GitHub tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Repository : Enter the name of the GitHub repository you wish to integrate (e.g. ProjectAlita/projectalita.github.io ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Private Key : Select this option if you are using an Private key for authentication. App ID : Enter the App ID associated with your GitHub integration. Private Key : Enter the configured Private key. You have two choices for providing the necessary credentials: Password : Enter your Private key value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Token : Select this option if you are using a token for authentication. Similar to the Private key, you have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Password : Select this option if you are using your GitHub account password for authentication. Password : Enter the password associated with your GitHub account. Similar to previous options, you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Username : Additionally, you will need to input the Username associated with your GitHub account to complete the authentication process. Tools : Enable the tools that you require for interacting with your GitHub repository: Get issues : Enables retrieval of issues from the repository. Get issue : Allows fetching details of a specific issue. Comment on issue : Permits adding comments to issues. List open pull requests (PRs) : Lists all open pull requests. Get pull request : Retrieves details of a specific pull request. List pull request files : Lists the files changed in a pull request. Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. Update file : Permits updating existing files. Delete file : Allows for the deletion of files. List files in branch : Lists all files in a specific branch. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Get files from directory : Retrieves all files within a specified directory. Click the arrow icon next to the New GitHub tool to complete the setup and move back to the main menu of Agent configuration.","title":"GitHub toolkit"},{"location":"user-guide/agents/agents/#gitlab-toolkit","text":"Similar to the GitHub toolkit, the Gitlab toolkit integrates your Agent with Gitlab, enabling direct interaction with repositories and project data. This toolkit enriches the Agent's operational context with specific data from Gitlab, supporting more informed decisions and interactions in software development projects. To configure Gitlab toolkit: Click the + icon under Tools section. Select the Gitlab tool from the dropdown list. The New Gitlab tool configuration section is opened. Name : Assign a distinctive name to your GitHub toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. URL : Enter the URL to your GitLab repository (e.g., https://gitbud.epam.com/ ). Repository : Enter the name of the Gitlab repository you wish to integrate (e.g., Levon_Dadayan/alitatest ) Main branch : Specify the main branch of your repository, typically main . Token : Provide the configured token for authentication. You have two choices for providing the necessary credentials: Password : Enter the your token value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Gitlab repository: Create branch : Allows you to create new branches in the repository. Create pull request : Enables the creation of merge requests in GitLab. Create file : Permits the creation of new files within the repository. Delete file : Provides the option to delete files from the repository. Set active branch : Lets you specify a branch as the active one for operations. List branches in repo : Lists all branches within the specified repository. Get PR changes : Retrieves changes associated with a particular merge request. Create PR change comment : Allows you to comment on changes in a merge request. Click the arrow icon next to the New Gitlab tool to complete the setup and move back to the main menu of Agent configuration.","title":"Gitlab toolkit"},{"location":"user-guide/agents/agents/#bitbucket-toolkit","text":"The Bitbucket toolkit integrates into your Agent, allowing it to access and interact with repositories directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from Bitbucket, facilitating better version control and development process integration. To configure Bitbucket toolkit : Click the + icon under Tools section. Select the Bitbucket tool from the dropdown list. The New Bitbucket tool configuration section is opened. Name : Assign a distinctive name to your Bitbucket toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Url : Enter the URL to your Bitbucket repository. Username : Input the Username associated with your Bitbucket account to complete the authentication process. Repository : Enter the name of the Bitbucket repository you wish to integrate (e.g. ) Main branch : Specify the main branch of your repository, typically main . Authentication Options : Choose your preferred method for secure connection: Password : Select this option if you are using your Bitbucket account password for authentication you have two choices for providing the necessary credentials: Password : Enter your password value directly into the provided field. Secret : Select a pre-configured secret from the dropdown list. This secret should have been set up previously in Secrets page for secure storage and retrieval. Tools : Enable the tools that you require for interacting with your Bitbucket repository: Create pull request : Enables the creation of new pull requests. Create file : Allows for creating new files in the repository. Read file : Enables reading the contents of files. List branches in repo : Lists all branches in the repository. Set active branch : Sets a specific branch as the active one. Create branch : Enables the creation of new branches. Click the arrow icon next to the New Bitbucket tool to complete the setup and move back to the main menu of Agent configuration.","title":"Bitbucket toolkit"},{"location":"user-guide/agents/agents/#testrail-toolkit","text":"The Testrail toolkit enables a direct integration with Testrauk, allowing users to manage test cases directly from the ELITEA platform. To configure TestTrail toolkit : Click the + icon under Tools section. Select the TestRail tool from the dropdown list. The New Testrail tool configuration section is opened. Name : Provide a unique name to identify your Testrail toolkit within ELITEA. Description : Offer a concise description of what the integration is intended for. URL : Enter the URL to your Testrail. Email : Enter the email used for authentication. Password : Enter the password for authentication. Tools - the following tools are avaialble for selection: Get case : To enable selecting test case. Get cases : To enable selecting test cases. Add case : To enable adding new case into Testrail. Click the arrow icon next to the New testrail tool to complete the setup and move back to the main menu of Agent configuration.","title":"Testrail toolkit"},{"location":"user-guide/agents/agents/#open-api-toolkit","text":"The Open API toolkit extends your Agent's capabilities by integrating OpenAPI-compliant APIs. This toolkit allows for a broad range of external functionalities to be incorporated into the Agent, enabling it to interact with and utilize diverse external services and data sources. To configure Open API toolkit : Click the + icon under Tools section. Select the Open API tool from the dropdown list. The New Open API tool configuration section is opened. Name : Enter a unique name for your Open API toolkit integration. This name will be used to identify the toolkit within your agent's instructions. Upload your OpenAPI schema by following one of these methods: Enter Schema : You can directly paste your OpenAPI schema into the text area provided. Drag & Drop : Drag your OpenAPI schema file and drop it into the designated area. Choose File : Click on the choose file link to browse and select your OpenAPI schema file from your local system. Reviewing Actions: Once the schema is uploaded, the ACTIONS section will populate with the endpoints defined in your OpenAPI schema. Review the actions to ensure they have been correctly interpreted from your schema. Each action will display: Name : The name of the action as defined in the schema. Description : A brief description of what the action does. Method : The HTTP method used for the action (e.g., GET, POST, PUT, DELETE). Path : The endpoint path for the action. Setting Authentication: Configure the authentication method required for your OpenAPI: Authentication : Choose the appropriate authentication method for your API from the dropdown menu. Options may include None, API Key, Token, OAuth, etc., depending on your API's requirements. Click the arrow icon next to the New Open API tool to complete the setup and move back to the main menu of Agent configuration.","title":"Open API toolkit"},{"location":"user-guide/agents/agents/#custom-toolkit","text":"The Custom toolkit provides a flexible solution for users to create bespoke integrations tailored to their specific needs. This toolkit allows for the development of unique functionalities that are not covered by standard toolkit, offering limitless possibilities to enhance the Agent's capabilities. To configure Custom toolkit : Click the + icon under Tools section. Select the Custom toolkit from the dropdown list. The New Custom tool configuration section is opened. You will see a JSON template in the interface, which you can edit to define your custom toolkit: { \"name\": \"Custom tool\", \"description\": \"\", \"settings\": [], \"type\": \"custom\" } name : Provide a unique name for your custom toolkit that will be used to identify it within ELITEA. description : Enter a brief description of what your custom toolkit does or its purpose. settings : Define an array of settings for your custom toolkit. These settings can include various parameters that your toolkit will use. type : This should be set to \"custom\" to indicate that it is a custom tool. Writing the JSON Configuration: Edit the JSON template to match the specifications of your custom toolkit. Ensure that you input valid JSON syntax. Referencing ELITEA Tools Documentation: For detailed instructions on creating custom toolkits and understanding the available options, refer to the ELITEA Tools GitHub repository: Alita Tools GitHub Repository . This repository contains documentation and examples that can help you build your custom tool. Once you have configured your custom toolkit, review the JSON configuration for accuracy. Click the arrow icon next to the New Custom tool to complete the setup and move back to the main menu of Agent configuration.","title":"Custom toolkit"},{"location":"user-guide/agents/agents/#artifact-toolkit","text":"The Artifact toolkit integrates your project's dedicated database in ELITEA into your Agent, allowing it to access and interact with your project's buckets directly. This toolkit enhances the Agent's capabilities by providing it with user-specific or project-specific data from bucket, as well as saving the agent's generated output into bucket. To configure Artifact toolkit : Click the + icon under Tools section. Select the Artifact tool from the dropdown list. The New artifact tool configuration section is opened. Name : Assign a distinctive name to your Artifact toolkit integration. Description : Give a concise description that outlines the integration's intended purpose. Bucket : Specify the bucket name that you want to access or create. Tools : Enable the tools that you require for interacting with your Artifact: List Files : Lists all files in a specific bucket. Create File : Allows for creating new file in the bucket. Read File : Enables reading the contents of files from the bucket. Delete File : Allows for the deletion of files from the bucket. Append Data : Permits updating the context of existing file in the bucket. Click the arrow icon next to the New artifact tool to complete the setup and move back to the main menu of Agent configuration.","title":"Artifact toolkit"},{"location":"user-guide/agents/agents/#welcome-message","text":"The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the agent. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the datasource. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this agent for generating manual test cases\" \"Don't forget to double-check the generated test cases\"","title":"WELCOME MESSAGE"},{"location":"user-guide/agents/agents/#conversation-starters","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the agent. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the agent. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the agent. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the agent more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"user-guide/agents/agents/#how-to-execute-agent","text":"To execute the agent and get the output you have to: Configure the Agent : Initialize by providing the necessary instructions, and defining tools (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Temperature (0.1-1.0) - adjusts the level of creativity or unpredictability in responses. Higher values : Responses are more creative and varied, but may be less consistent and more unpredictable. Lower values : Responses are more consistent and predictable, but may be less creative and varied. Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity and consistency. Higher values : A wider range of words is considered, leading to more creative and diverse responses. Lower values : A narrower range of words is considered, leading to more consistent and predictable responses. Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Higher values : More words are considered, leading to more diverse and potentially creative responses. Lower values : Fewer words are considered, leading to more predictable and focused responses. Maximum Length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Higher values : Responses can be longer and more detailed. Lower values : Responses are shorter and more concise. Initiate Interaction : Once all instructions for the agent are set in the Instructions and/or Tools sections, you can start the execution by typing your text (be it a question or a command) into the chat box or initate it by selecting the Conversation Starter message (if you have configured it). Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to Clipboard icon to copy the generated text for use elsewhere. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history.","title":"How to Execute Agent"},{"location":"user-guide/agents/agents/#managing-agent-versions-save-create-versions-and-manage","text":"To optimally manage your agent, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your agent, create versions, and manage them.","title":"Managing Agent Versions: Save, Create Versions, and Manage"},{"location":"user-guide/agents/agents/#how-to-save-an-agent","text":"To save your work on an agent for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your agent and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your agent.","title":"How to Save an Agent:"},{"location":"user-guide/agents/agents/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your agent: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the agent, several options become available to you: Delete : Remove this version of the agent if it\u2019s no longer needed. Execute : Run this specific version of the agent to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the agent. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your agents, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"user-guide/agents/agents/#agents-menu","text":"The Agents menu showcases a collection of published and shared agents within the community. By default, upon logging in, the user is directed to the Latest page of the Agents menu, which presents newly published agents.","title":"Agents Menu"},{"location":"user-guide/agents/agents/#layout-of-the-agents-menu","text":"The Agents menu is organized into three distinct pages, each designed to offer a unique perspective on the available agents: Latest : Displays all recently published agents, providing a fresh look at the newest contributions to the community. My Likes : Highlights the agents that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the agents with the highest number of likes, serving as a valuable resource for discovering top-rated agents that hold significant value and popularity within the community.","title":"Layout of the Agents Menu"},{"location":"user-guide/agents/agents/#engaging-with-published-agents","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable agents. The following actions enable active participation:","title":"Engaging with Published Agents"},{"location":"user-guide/agents/agents/#liking-published-agents","text":"Upon publication, an agent becomes a crucial resource for the community. To support and acknowledge an agent, use the Like functionality: To like an agent, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the agent.","title":"Liking Published Agents"},{"location":"user-guide/agents/agents/#other-actions-for-published-agents","text":"Using Published Agent : View and run agent by clicking on the agent card or name. Refer to the How to Execute Agent section for guidance on using agent. Note : Modifications to a published agent cannot be saved for future use.","title":"Other Actions for Published Agents"},{"location":"user-guide/extensions/alita-chat/","text":"Alita Code Chat Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB. Pre-requisite Alita Code Chat operates in conjunction with Alita Code for both VS Code and IntelliJ. To utilize Alita Code Chat, you must first install Alita Code from their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace. Important : Ensure that Alita Code is not only installed but also properly configured with ELITEA HUB to function correctly. For detailed installation and configuration instructions, please refer to the Alita Code documentation . This step is crucial for enabling the full capabilities of Alita Code Chat within your development environment. Features list: Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned. Alita Code Chat for VS code Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code. Installation Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code. Alita Code Chat Usage With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and agents to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Prompts To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Datasources To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the prompt that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the AlitaCodeChat. Start conversation in the form of a question, statement, or command that simulates human-like interaction . AlitaCodeChat for IntelliJ AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode. Installation Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Alita Chat for IntelliJ offers two distinct modes to cater to different user preferences and integration styles. Each mode is designed to provide a seamless user experience while aligning with specific design philosophies: Native Mode : This mode is tailored to blend seamlessly with the IntelliJ environment. It adheres to the native design and style guidelines of IntelliJ, ensuring that the interface feels familiar and integrated for users who prefer consistency with their development environment. React Mode : Designed to echo the aesthetics and usability of ELITEA, this mode brings the distinctive look and feel of ELITEA's design language into IntelliJ. It's ideal for users who enjoy the ELITEA interface and wish to have a similar user experience within the IntelliJ platform. Both modes are crafted to provide a robust and intuitive chat interface, allowing users to choose according to their design preference and familiarity. Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem. AlitaCodeChat Usage Prompts To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew. Datasources To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew. Agents To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the agent that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew. Chat Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction . Additional Interaction Features Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Alita Code Chat"},{"location":"user-guide/extensions/alita-chat/#alita-code-chat","text":"Alita Code Chat for VSCode and IntelliJ is an auxiliary GUI for Alita Code, you can utilize the functionality of Alita Code and you can also chat with ELITEA HUB.","title":"Alita Code Chat"},{"location":"user-guide/extensions/alita-chat/#pre-requisite","text":"Alita Code Chat operates in conjunction with Alita Code for both VS Code and IntelliJ. To utilize Alita Code Chat, you must first install Alita Code from their respective marketplaces: VS Code : Install Alita Code from the VS Code Marketplace. IntelliJ : Install AlitaCode from the JetBrains Marketplace. Important : Ensure that Alita Code is not only installed but also properly configured with ELITEA HUB to function correctly. For detailed installation and configuration instructions, please refer to the Alita Code documentation . This step is crucial for enabling the full capabilities of Alita Code Chat within your development environment.","title":"Pre-requisite"},{"location":"user-guide/extensions/alita-chat/#features-list","text":"Chat with ELITEA directly. It will use the model settings set by Alita Code extension. Type trigger chat to add participants to chat: / for prompt, # for datasources and @ for agents. Note : Alita Code Chat doesn't support Chat History, in case of restarting VS Code or IntelliJ, the Chat History will be cleaned.","title":"Features list:"},{"location":"user-guide/extensions/alita-chat/#alita-code-chat-for-vs-code","text":"Alita Code Chat is a visual studio extension to work as chatting companion using Alita Code.","title":"Alita Code Chat for VS code"},{"location":"user-guide/extensions/alita-chat/#installation","text":"Getting started with Alita Code Chat is straightforward: Navigate to the Extensions section in VS Code. Search for Alita Code Chat in the Marketplace and click Install . Note : After successful installation Alita Code Chat shortcut will be added to left menu of VS Code.","title":"Installation"},{"location":"user-guide/extensions/alita-chat/#alita-code-chat-usage","text":"With Alita Code Chat set up, you can now: Prompts - call and use prompts configured in ELITEA HUB. Datasources - call and use datasources configured in ELITEA HUB. Agents - call and use agents configured in ELITEA HUB. Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Important: To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and agents to enable their proper functionality within the ELITEA ecosystem. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Alita Code Chat Usage"},{"location":"user-guide/extensions/alita-chat/#prompts","text":"To call and use Prompts from ELITEA HUB: Open the Alita Code Chat. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.","title":"Prompts"},{"location":"user-guide/extensions/alita-chat/#datasources","text":"To call and use Datasources from ELITEA HUB: Open the Alita Code Chat. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"user-guide/extensions/alita-chat/#agents","text":"To call and use Agents from ELITEA HUB: Open the Alita Code Chat. Type @ in the chat box. Select the prompt that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"user-guide/extensions/alita-chat/#chat","text":"Open the AlitaCodeChat. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"user-guide/extensions/alita-chat/#alitacodechat-for-intellij","text":"AlitaCodeChat is an IntelliJ plugin to work as chatting companion using AlitaCode.","title":"AlitaCodeChat for IntelliJ"},{"location":"user-guide/extensions/alita-chat/#installation_1","text":"Getting started with AlitaCodeChat is straightforward: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCodeChat in the Marketplace and click Install . Alita Chat for IntelliJ offers two distinct modes to cater to different user preferences and integration styles. Each mode is designed to provide a seamless user experience while aligning with specific design philosophies: Native Mode : This mode is tailored to blend seamlessly with the IntelliJ environment. It adheres to the native design and style guidelines of IntelliJ, ensuring that the interface feels familiar and integrated for users who prefer consistency with their development environment. React Mode : Designed to echo the aesthetics and usability of ELITEA, this mode brings the distinctive look and feel of ELITEA's design language into IntelliJ. It's ideal for users who enjoy the ELITEA interface and wish to have a similar user experience within the IntelliJ platform. Both modes are crafted to provide a robust and intuitive chat interface, allowing users to choose according to their design preference and familiarity. Note : After successful installation AlitaCodeChat shortcut will be added to right menu of IntelliJ. To ensure seamless integration and functionality, the Alita Code and AlitaCodeChat plugins must be installed with matching versions. Please verify that both plugins are updated to the same version to avoid compatibility issues. To successfully call and utilize prompts, datasources, or agents from ELITEA HUB, it is essential that these items are tagged with code in ELITEA HUB. This tag ensures that the resources are correctly categorized and accessible. Ensure that the code tag is applied to relevant prompts, datasources, and applications to enable their proper functionality within the ELITEA ecosystem.","title":"Installation"},{"location":"user-guide/extensions/alita-chat/#alitacodechat-usage","text":"","title":"AlitaCodeChat Usage"},{"location":"user-guide/extensions/alita-chat/#prompts_1","text":"To call and use Prompts from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type / in the chat box. Select the prompt that you want to run. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the prompt accurately. You can adjust or update variable values at any time by clicking the Settings icon. Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. If you need to start a fresh conversation or prompt, simply click the X icon to clear the current setup and begin anew.","title":"Prompts"},{"location":"user-guide/extensions/alita-chat/#datasources_1","text":"To call and use Datasources from ELITEA HUB: Open the AlitaCodeChat. Select the React or Native tab. Type # in the chat box. Select the datasource that you want to run. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or datasource, simply click the X icon to clear the current setup and begin anew.","title":"Datasources"},{"location":"user-guide/extensions/alita-chat/#agents_1","text":"To call and use Agents from ELITEA HUB: Open the AlitaCodeChat. Select the React tab. Type @ in the chat box. Select the agent that you want to run. Version Selection : Agents may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected agent version includes variables, a dialog will appear allowing you to input or modify the values. Prepopulated values might be present, or you may need to provide your own. Ensure that all required variables are correctly filled to execute the agent accurately. You can adjust or update variable values at any time by clicking the Settings icon. Start conversation in the form of a question, statement, or command that simulates human-like interaction . If you need to start a fresh conversation or application, simply click the X icon to clear the current setup and begin anew.","title":"Agents"},{"location":"user-guide/extensions/alita-chat/#chat_1","text":"Open the AlitaCodeChat. Select either the Native or React tab. Start conversation in the form of a question, statement, or command that simulates human-like interaction .","title":"Chat"},{"location":"user-guide/extensions/alita-chat/#additional-interaction-features","text":"Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Reload Alita Code Settings : This option allows to reload and update Alita Code settings. Stop generating : To stop generation of output. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Additional Interaction Features"},{"location":"user-guide/extensions/alita-code/","text":"Alita Code Get Started with Alita Code Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code amd InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience. Why Choose Alita Code? Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts. Key Features Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts and datasources powered by ELITEA Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation Alita Code for VS Code Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with Alita Code is straightforward and involves a few simple steps: Open VS Code and navigate to the Extensions section. In the Marketplace, search for Alita Code and click Install . Configuration on ELITEA HUB To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings icon will appear next to the created token. Click this icon to download the settings.json file, which contains all necessary configuration information for integration with VS Code. Note : The settings.json file includes essential information such as Project ID, ELITEA HUB's URL, LLM model, Integration UID, and the generated token. Important : Alternatively, you can manually copy and paste all required parameters into the Alita Code extension's settings in VS Code. Configuration on VS Code Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in VS Code. Navigate to the .vscode folder and open the settings.json file. If this folder does not exist, create it and add a settings.json file. Open the settings.json file downloaded from ELITEA HUB. Copy all information from this file into the .vscode/settings.json file in your project. Note : Be careful not to overwrite other configurations. If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Alita Code \u2192 Extension Settings \u2192 Workspace tab. Go to Extensions \u2192 Alita Code \u2192 Extension Settings . Open the Workspace tab and verify that all parameters are correctly populated from the settings.json file. Note : Manual adjustments can be made if necessary. Types of Settings in Alita Code Alita Code offers two types of settings to cater to different needs: User Settings : These are global settings that apply to all sessions across any workspace, providing a consistent environment across your projects. Workspace Settings : These are specific to a particular workspace, allowing for tailored configurations such as different project IDs or models, which is essential for managing separate environments or specific tasks. The following settings are available in both tabs (which can either be prepopulated or manually configured): Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alitacode: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting VS Code may be necessary for changes to take effect. Configuring Alita Code To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. Alita Code Usage Getting Started with Extension Commands Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together. Synchronize External Prompts Sync prompts and datasources created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita: Sync External Prompts from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB. Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Extend Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions. Predict (Execute) Prompt To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your Alita Code: Default View Mode settings . This could be appended, replaced, split, or prepended based on your configuration. Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB . AlitaCode for IntelliJ Idea AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend. Installation Getting started with Alita Code is straightforward and involves a few simple steps: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install . Configuration on ELITEA HUB To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download Jetbrains Settings icon will appear next to the created token. Click this icon to download the alita.xml file, which contains all necessary configuration information (except generated token) for integration with IntelliJ. Configuration on IntelliJ Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in IntelliJ. Navigate to the .idea folder and open the alita.xml file. If this folder does not exist, create it and add a alita.xml file. Open the alita.xml file downloaded from ELITEA HUB. Copy all information from this file into the .idea/alita.xml file in your project. Note : If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Settings \u2192 Tools \u2192 Alita tab. Go to Settings \u2192 Tools \u2192 Alita . Open it and verify that all parameters are correctly populated from the alita.xml file. Copy and paste generated token to the LLM Auth Token field. Check and apply configuration: Click the Reload icon next to the Integration Name dropdown list. Select the ai_dial as integration and click OK button. To complete the setup click the OK button. Settings in Alita Code Alita Code includes the following settings: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita option. LLM Auth Token : Provide your Bearer token for the LLM service provider. Provide Settings Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration Name : To use Epam AI Dial models, select ai_dial option. Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Check the Use custom model checkbox. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. Advanced Settings : Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response Timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting IntelliJ may be necessary for changes to take effect. Configuration To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files. AlitaCode Usage Getting Started with Extension Commands Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Synchronize External Prompts Sync prompts and datasources created in the ELITEA HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB. Create a Prompt Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. Alita Code will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples. Edit Prompt Context Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes. Predict (Execute) Prompt To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Alita Code"},{"location":"user-guide/extensions/alita-code/#alita-code","text":"","title":"Alita Code"},{"location":"user-guide/extensions/alita-code/#get-started-with-alita-code","text":"Welcome to the Alita Code your comprehensive resource for harnessing the power of the ultimate AI-powered IDE extension that's set to transform your coding workflow. Alita Code integrates seamlessly with VS Code amd InteliiJ, offering intelligent suggestions, automating routine tasks, and providing a level of adaptability that's unmatched, all designed to elevate your coding experience.","title":"Get Started with Alita Code"},{"location":"user-guide/extensions/alita-code/#why-choose-alita-code","text":"Alita Code is not just another IDE extension. It's a revolutionary tool designed to: Boost Productivity - with AI-powered suggestions, Alita Code analyzes your code in real-time, offering insights to enhance code quality, readability, and performance. Automate Testing and Documentation - simplify the creation of unit tests, integration tests, and automated tests. Alita Code also enriches your code with automatic commenting, making it more accessible and maintainable. Customizable Assistance - tailor Alita Code's assistance to your project's specific needs with customizable prompts, both internal and powered by Alita Backend's llms for external prompts.","title":"Why Choose Alita Code?"},{"location":"user-guide/extensions/alita-code/#key-features","text":"Alita Code comes packed with features designed to streamline your development process: AI-powered code suggestions for smarter coding Automated generation of unit tests, integration tests, and automated tests Automatic code commenting for better maintainability Customizable internal prompts for tailored assistance Project-specific external prompts and datasources powered by ELITEA Backend Code explanation and optimization recommendations Seamless native IDE integration Regular updates and enhancements Comprehensive documentation and dedicated support Collaboration-friendly design for team projects Secure and privacy-conscious implementation","title":"Key Features"},{"location":"user-guide/extensions/alita-code/#alita-code-for-vs-code","text":"Alita Code is a visual studio extension to handle prompt-engineering based code generation using ELITEA as a backend.","title":"Alita Code for VS Code"},{"location":"user-guide/extensions/alita-code/#installation","text":"Getting started with Alita Code is straightforward and involves a few simple steps: Open VS Code and navigate to the Extensions section. In the Marketplace, search for Alita Code and click Install .","title":"Installation"},{"location":"user-guide/extensions/alita-code/#configuration-on-elitea-hub","text":"To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download VS Code Settings icon will appear next to the created token. Click this icon to download the settings.json file, which contains all necessary configuration information for integration with VS Code. Note : The settings.json file includes essential information such as Project ID, ELITEA HUB's URL, LLM model, Integration UID, and the generated token. Important : Alternatively, you can manually copy and paste all required parameters into the Alita Code extension's settings in VS Code.","title":"Configuration on ELITEA HUB"},{"location":"user-guide/extensions/alita-code/#configuration-on-vs-code","text":"Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in VS Code. Navigate to the .vscode folder and open the settings.json file. If this folder does not exist, create it and add a settings.json file. Open the settings.json file downloaded from ELITEA HUB. Copy all information from this file into the .vscode/settings.json file in your project. Note : Be careful not to overwrite other configurations. If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Alita Code \u2192 Extension Settings \u2192 Workspace tab. Go to Extensions \u2192 Alita Code \u2192 Extension Settings . Open the Workspace tab and verify that all parameters are correctly populated from the settings.json file. Note : Manual adjustments can be made if necessary.","title":"Configuration on VS Code"},{"location":"user-guide/extensions/alita-code/#types-of-settings-in-alita-code","text":"Alita Code offers two types of settings to cater to different needs: User Settings : These are global settings that apply to all sessions across any workspace, providing a consistent environment across your projects. Workspace Settings : These are specific to a particular workspace, allowing for tailored configurations such as different project IDs or models, which is essential for managing separate environments or specific tasks. The following settings are available in both tabs (which can either be prepopulated or manually configured): Alitacode: Provider Server URL : Enter the URL of your LLM service provider. For connecting to ELITEA HUB, use https://alita.lab.epam.com . Alitacode: Auth Token : Provide your API Key or Bearer token for authentication with the LLM service provider. For ELITEA HUB, input the generated Token. Alitacode: Model Name : Select the desired LLM model from the dropdown list provided. Alitacode: Custom Model Name : If the required model is not listed, enter a custom model name for local prompts. Alitacode: Custom Model Tokens : Specify the maximum tokens for local prompts, with a default setting of 4096 tokens. Alitacode: Project ID : Input the Project ID for the ELITEA backend. This setting is ignored when using OpenAI. Alitacode: Integration Uid : Enter the Integration UID from the ELITEA backend. For ELITEA HUB, use the Integration UID provided by Alita lab. This setting is ignored for OpenAI. Alitacode: Max Tokens : Set the maximum number of tokens for the selected model. Alitacode: Temperature : Adjust the temperature setting for the selected model to control the randomness of the output. Alitacode: Default View Mode : Choose how the prediction results are displayed: append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. prepend -when you run Alita predict the results will be displayed before the text or part that you have selected. Alitacode: Top P : Set the Top P value for the selected model. Alitacode: Top K : Set the Top K value for the selected model. Alitacode: Verify Ssl : Toggle this setting to verify the LLM service provider's SSL certificate. For ELITEA HUB, keep this checkbox not selected. Alitacode: Enable : Toggle to enable or disable the Alita Code extension as needed. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting VS Code may be necessary for changes to take effect.","title":"Types of Settings in Alita Code"},{"location":"user-guide/extensions/alita-code/#configuring-alita-code","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuring Alita Code"},{"location":"user-guide/extensions/alita-code/#alita-code-usage","text":"","title":"Alita Code Usage"},{"location":"user-guide/extensions/alita-code/#getting-started-with-extension-commands","text":"Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend. Alita Code is designed to be your coding companion, offering a blend of AI-powered efficiency and customizable support. Whether you're looking to enhance your productivity, streamline your testing process, or simply make your code more understandable, Alita Code is here to help. Let's embark on this journey to revolutionize your coding experience together.","title":"Getting Started with Extension Commands"},{"location":"user-guide/extensions/alita-code/#synchronize-external-prompts","text":"Sync prompts and datasources created in the Alita HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita menu option. Sync Prompts Option : Select Alita: Sync External Prompts from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB.","title":"Synchronize External Prompts"},{"location":"user-guide/extensions/alita-code/#create-a-prompt","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita item. Create Prompt Option : Hover over Alita in the menu, and on the second level menu, select Create Prompt . Name Your Prompt : Enter a name for your prompt-template, such as \"Generate unit-tests\". Describe Your Prompt : Press Enter and provide a description for your prompt. Provide Prompt Content : Press Enter again and input the content of your prompt. This can be modified later in the .promptLib folder. Finalize Creation : Hit Enter to finalize. Alita will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"user-guide/extensions/alita-code/#extend-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita item. Extend Context Option : Hover over Alita and select \"Extend Context\" from the submenu. Choose a Prompt : Pick the prompt you wish to extend the context for from the dropdown list. Extend Context : The selected text will be automatically added to the prompt's context, enriching its understanding for future suggestions.","title":"Extend Prompt Context"},{"location":"user-guide/extensions/alita-code/#predict-execute-prompt","text":"To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita menu item. Predict Option : Hover over Alita and choose Alita Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your Alita Code: Default View Mode settings . This could be appended, replaced, split, or prepended based on your configuration. Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"user-guide/extensions/alita-code/#alitacode-for-intellij-idea","text":"AlitaCode is a IntelliJ plugin to handle prompt-engineering based code generation using ELITEA as a backend.","title":"AlitaCode for IntelliJ Idea"},{"location":"user-guide/extensions/alita-code/#installation_1","text":"Getting started with Alita Code is straightforward and involves a few simple steps: Navigate to the Settings \u2192 Plugins section in IntelliJ. Search for AlitaCode in the Marketplace and click Install .","title":"Installation"},{"location":"user-guide/extensions/alita-code/#configuration-on-elitea-hub_1","text":"To configure the necessary parameters for the Alita Code extension, follow these steps: Go to Settings \u2192 Configuration on the ELITEA HUB. Click the + icon to create a new token. Enter a name and set an expiration date for the token. Click Generate to create the token. Immediately copy and securely store the generated token; it will not be visible again once you close the pop-up window. From the Integration Option dropdown list, select the desired LLM model (e.g., gpt-4, gpt-4o, gpt-4-0125-preview, etc.). Once the LLM model is selected, the Download Jetbrains Settings icon will appear next to the created token. Click this icon to download the alita.xml file, which contains all necessary configuration information (except generated token) for integration with IntelliJ.","title":"Configuration on ELITEA HUB"},{"location":"user-guide/extensions/alita-code/#configuration-on-intellij","text":"Once Alita Code is installed, setting it up to work with your project in ELITEA HUB involves: Open your project in IntelliJ. Navigate to the .idea folder and open the alita.xml file. If this folder does not exist, create it and add a alita.xml file. Open the alita.xml file downloaded from ELITEA HUB. Copy all information from this file into the .idea/alita.xml file in your project. Note : If previous Alita Code configurations exist, remove them before adding new information. Save the file. The integration settings will now be applied under Settings \u2192 Tools \u2192 Alita tab. Go to Settings \u2192 Tools \u2192 Alita . Open it and verify that all parameters are correctly populated from the alita.xml file. Copy and paste generated token to the LLM Auth Token field. Check and apply configuration: Click the Reload icon next to the Integration Name dropdown list. Select the ai_dial as integration and click OK button. To complete the setup click the OK button.","title":"Configuration on IntelliJ"},{"location":"user-guide/extensions/alita-code/#settings-in-alita-code","text":"Alita Code includes the following settings: LLM Provider : Select the LLM Provider. To connect with ELITEA Hub, select Alita option. LLM Auth Token : Provide your Bearer token for the LLM service provider. Provide Settings Project ID : Enter the Project Id for ELITEA Backend, ignored for OpenAI. LLM Server URL : Enter the URL to your LLM service provider. (e.g. https://alita.lab.epam.com/ ) Integration Name : To use Epam AI Dial models, select ai_dial option. Integration UID : Enter the AI integration Id from ELITEA Backend, ignored for OpenAI. LLM Model Name : Choose the LLM model from the dropdown list. Custom Model Name : Enter a custom model name if the desired model is not listed. Check the Use custom model checkbox. Display Type : Select the default display mode for the predictions. append - when you run Alita Predict the results will be displayed after the text or part that you have selected. split - when you run Alita Predict the results will be displayed in a separate place (view). replace - when you run Alita Predict the results will be displayed instead of the text or part that you have selected. Advanced Settings : Custom Encoding Type : Select the encoding type, default cl100k_base . Custom Model Size : Set the max tokens for custom model, default is 4096 . LLM Response Timeout : Set the response timeout, default is 90 seconds. Max Tokens : Set the max tokens for the selected model. Temperature : Adjust the temperature for the selected model. Top K : Set the Top K value for the selected model. Top P : Set the Top P value for the selected model. These settings ensure that Alita Code is properly configured to interact with the ELITEA HUB, allowing for seamless integration and efficient use of LLM models within your projects. Note : Restarting IntelliJ may be necessary for changes to take effect.","title":"Settings in Alita Code"},{"location":"user-guide/extensions/alita-code/#configuration","text":"To initialize Alita Code in your project: Open any file and right-click to select Alita \u2192 Alita:Init . This creates a .promptLib folder with default prompts and prompts.json files.","title":"Configuration"},{"location":"user-guide/extensions/alita-code/#alitacode-usage","text":"","title":"AlitaCode Usage"},{"location":"user-guide/extensions/alita-code/#getting-started-with-extension-commands_1","text":"Jumpstart your Alita Code experience with these essential commands: Alita: Init : Initialize Alita Code in your workspace by creating a .promptLib folder at the root. Note : After successful initalization the Alita: Init command becomes unavailable. Alita: Create Prompt : Craft a new prompt within the .promptLib folder. Alita: Extend Context : Enhance the context of an existing prompt in the .promptLib folder. Alita: Predict : Choose from a list of prompts and generate predictions based on your selection. Alita: Sync External Prompts : Synchronize your external prompts and datasources with ELITEA Backend.","title":"Getting Started with Extension Commands"},{"location":"user-guide/extensions/alita-code/#synchronize-external-prompts_1","text":"Sync prompts and datasources created in the ELITEA HUB with your Alita Code setup for seamless integration: Open prompts.json : Locate and open the prompts.json file. Access Alita Menu : Right-click in the editor to see the Alita Actions item. Sync Prompts Option : Select the Alita: Sync External Prompts option from the submenu. Synchronization : The prompts and datasources will be synced and added to the prompts.json file. Usage : These prompts and datasources are now ready to be used with Alita: Predict command. Note : To sync and use prompts and datasources from ELITEA HUB, tag the prompt with code in ELITEA HUB.","title":"Synchronize External Prompts"},{"location":"user-guide/extensions/alita-code/#create-a-prompt_1","text":"Creating a custom prompt in Alita Code allows you to tailor Gen AI suggestions to your specific tasks. Here's how to create one: Open a File : Start by opening any file from your project, or create a new one. Access Alita Menu : Right-click in the editor view to bring up the context menu, where you'll find the Alita Actions item. Create Prompt Option : Hover over Alita Actions in the menu, and on the second level menu, select Alita: Create Prompt . The Create Prompt window is opened: Name : Assign a descriptive name that clearly reflects the aim of the prompt. Description : Summarize the purpose of the prompt, detailing what it intends to achieve. Context : Well crafted prompt corresponding to well-acceppted Frameworks for creating prompts (e.g. CREATE, CRISPE, Elavis Saravia, etc.). In case the prompt's context contains Variables , then provide the names and values of the variables in the Variables section. Click the Use the project integration settings in the context file checkbox to configure Model, Top-P, Top-K, Tempreature and MaX Tokens settings. Click the Ok button to create a prompt. This can be modified later in the .promptLib folder. Alita Code will add a reference to the new prompt in prompts.json and create a corresponding .yaml file in the .promptLib folder, which can be edited to extend content and add examples.","title":"Create a Prompt"},{"location":"user-guide/extensions/alita-code/#edit-prompt-context","text":"Enhance the context of an existing prompt with selected text from your code, improving the relevance of AI suggestions: Open and Select : Open any file from your project and select a portion of the text. Access Alita Menu : Right-click to open the context menu and find the Alita Actions item. Edit Context Option : Hover over Alita Actions and select Alita: Edit Context from the submenu. Choose a Prompt : Select the prompt you wish to modify for from the list and click the Edit button. Edit Context The selected prompt's yaml file will be opened where you can make the changes.","title":"Edit Prompt Context"},{"location":"user-guide/extensions/alita-code/#predict-execute-prompt_1","text":"To predict (execute) a prompt or a datasource directly from VS Code to generate Gen AI-driven code suggestions: Open a File and Select Text : Open any project file and select the text you want to analyze or for which you need suggestions. Access Alita Menu : Right-click in the editor view to see the Alita Actions item. Predict Option : Hover over Alita Actions and choose Alita: Predict from the submenu. Select a Prompt or Datasource: Choose the desired prompt or datasource from the dropdown list. Version Selection : Prompts may have multiple versions. Ensure you select the appropriate version from the dropdown list as different versions may vary in functionality and variables. Variable Management : If the selected prompt version includes variables, you will either see prepopulated values or you can provide your own values. Ensure that all required variables are correctly filled to execute the prompt accurately. View Predictions : After execution, the generated response will be displayed in your editor according to the method specified in your AlitaCode: Display Type . Note : You can use default prompts, those you've created, or external prompts and datasources synced from ELITEA HUB .","title":"Predict (Execute) Prompt"},{"location":"user-guide/prompts/prompts-examples/","text":"Prompts Examples and Materials Prompts - Helpful Materials To assist you in maximizing the capabilities of Prompts within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Prompts. Prompting Frameworks To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing: CREATE Framework The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. **Character**: Act as a senior software tester with expertise in regression testing. **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. **Examples**: Include scenarios like: **Preconditions**: CRM software has been updated to the latest version. **Steps to reproduce**: User logs in and accesses the customer data module. **Expected results**: User should see updated customer data without any data loss. **Adjustment**: Focus on critical modules like customer data management and transaction processing. **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality. Elavis Saravia Framework This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. **Instruction**: Generate test cases for user interface consistency across different devices. **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. **Input Data**: User accesses the application from different devices. **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type. CRISPE Framework The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. **Capacity and Role**: Serve as an automated testing tool expert. **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. **Personality**: Maintain a technical and precise tone throughout the test scripts. **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.","title":"Prompts Examples and Materials"},{"location":"user-guide/prompts/prompts-examples/#prompts-examples-and-materials","text":"","title":"Prompts Examples and Materials"},{"location":"user-guide/prompts/prompts-examples/#prompts-helpful-materials","text":"To assist you in maximizing the capabilities of Prompts within the ELITEA platform, we have compiled a selection of helpful materials. These resources are designed to guide you through the processes of creating, setting up, configuring, and effectively using Prompts.","title":"Prompts - Helpful Materials"},{"location":"user-guide/prompts/prompts-examples/#prompting-frameworks","text":"To further refine the instructions and ensure high-quality responses from LLMs, you can utilize structured prompting frameworks. These frameworks help in crafting precise and effective prompts by breaking down the requirements into specific components. Below are examples of how to apply these frameworks in the context of software testing:","title":"Prompting Frameworks"},{"location":"user-guide/prompts/prompts-examples/#create-framework","text":"The CREATE framework helps in constructing detailed and focused prompts by defining the Character, Request, Examples, Adjustment, Type of Output, and Extras. **Character**: Act as a senior software tester with expertise in regression testing. **Request**: Develop a detailed regression testing strategy for an upcoming version release of our CRM software. **Examples**: Include scenarios like: **Preconditions**: CRM software has been updated to the latest version. **Steps to reproduce**: User logs in and accesses the customer data module. **Expected results**: User should see updated customer data without any data loss. **Adjustment**: Focus on critical modules like customer data management and transaction processing. **Type of Output**: Format the strategy as a formal document with sections for objectives, scope, test scenarios, and resources. **Extras**: After formulating the strategy, provide a rationale for the choice of specific test scenarios and their expected impact on the software quality.","title":"CREATE Framework"},{"location":"user-guide/prompts/prompts-examples/#elavis-saravia-framework","text":"This framework simplifies the prompt creation process into four main elements: Instruction, Context, Input Data, and Output Indicator. **Instruction**: Generate test cases for user interface consistency across different devices. **Context**: The application is a cross-platform tool accessible on desktops, tablets, and smartphones. **Input Data**: User accesses the application from different devices. **Output Indicator**: The output should be a list of test cases, each describing the test steps, the expected results, and the device type.","title":"Elavis Saravia Framework"},{"location":"user-guide/prompts/prompts-examples/#crispe-framework","text":"The CRISPE framework provides a comprehensive approach by incorporating Capacity and Role, Insight, Statement, Personality, and Experiment. **Capacity and Role**: Serve as an automated testing tool expert. **Insight**: The software to be tested is an e-commerce platform with high transaction volumes and user concurrency. **Statement**: Create automated test scripts that simulate multiple user transactions simultaneously. **Personality**: Maintain a technical and precise tone throughout the test scripts. **Experiment**: Offer three variations of the test script focusing on different aspects of the transaction process (e.g., payment processing, cart updates, and user login). By integrating these frameworks into the Context section of your prompts, you can guide LLMs to produce more targeted and effective outputs. Each framework helps in structuring your request to the Gen AI, ensuring that all necessary details are included to generate the desired results.","title":"CRISPE Framework"},{"location":"user-guide/prompts/prompts/","text":"Prompts Private project - Prompts menu The Prompts menu within Private project serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted. How to Create a New Prompt In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button on the top right. Fill in the Name , Description , and Context fields. Click Save . Note : Name and Description are non-editable fields and can't be modified after saving the prompt. Tags In ELITEA, Tags serve as an efficient organizational tool that allows you to categorize and manage your collection of prompts, datasources and agents. By assigning relevant tags to each prompt, you create an intuitive labeling system that facilitates quick access and retrieval. Later on, you can filter prompts by these tags, simplifying the process of finding the precise prompt you need among a vast collection, which is especially useful for users with an extensive library of different prompt types and topics. To add a tag to the prompt : Type a tag name or select from pre-existing tags from Tags input box. Press comma or Enter to create/select tag. Click Save to save the prompt with selected tags. Note : User has the flexibility to assign one or more tags to each prompt, enabling a multi-dimensional labeling system. CONTEXT The Context field in ELITEA is a crucial component where users input the necessary background information or instructions that guide the LLM in generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Context : Identify Key Information : Before entering data into the Context field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Context field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the model's focus and efficiency. Using Variables : For dynamic content generation, you can incorporate variables directly into the Context. Variables are denoted by double curly braces, e.g., {{variable_name}}. After defining a variable in the Context, you must specify its value in the Variables section to let the model replace the placeholder with the actual data during processing. Note : For more information how to create better instructions for prompts please check Prompting Frameworks document. Editability and Version Control You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate. WELCOME MESSAGE The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the prompt. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this prompt for generating test cases\" \"Don't forget to review the generated test cases before usage\" CONVERSATION STARTERS The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the prompt. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the prompt. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the prompt. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the prompt more efficient and standardized. MESSAGES The MESSAGES section is a crucial component that allows users to structure the flow of interaction within a prompt. System Message : Sets the interaction's context and guidelines for the Gen AI, not visible to the user but crucial for defining the Gen AI's behavior. Assistant Message : The Gen AI's responses to user inputs, crafted within the context and constraints set by the system message. User Message : Inputs from the user, serving as prompts for the Gen AI to generate responses, thereby driving the conversation forward. In conversational models, these message types work together within prompts to create a structured and meaningful dialogue. The system message defines the framework, the user message initiates and guides the flow of the conversation, and the assistant message provides the content of the interaction, all contributing to a coherent and purposeful exchange. The System Message is a part of the prompt that provides instructions or context directly from the system's perspective. It sets the stage for the interaction, establishing rules, scenarios, or the setting for the Geb AI model to operate within. This is not generated in response to the user but is predefined by the designer of the prompt to guide the interaction. **Example:** **System Message**: \"You are an AI trained to assist in creating detailed and accurate test cases. Focus on clarity and precision, and ensure all responses adhere to software testing standards.\" This message informs the AI of its role in assisting with test case creation, setting expectations for the type of responses it should generate. The Assistant Message is the AI's response generated based on the user's input and the context provided by the system message. This message aims to fulfill the user's request for information, assistance, or interaction within the guidelines set by the system message. **Example:** **User Message**: \"Generate a test case for a login feature with email and password fields.\" **Assistant Message**: \"Test Case: Login Feature **Objective**: Verify that the user can log in using a valid email and password. **Steps**: 1. Navigate to the login page. 2. Enter a valid email in the email field. 3. Enter the corresponding password in the password field. 4. Click the login button. **Expected Result**: The user is redirected to the homepage after successful login. **Test Data**: Use registered email: user@example.com and password: SecurePass123.\" The assistant's message provides a structured test case based on the user's request, adhering to the guidelines set by the system message. The User Message is the input or query from the individual interacting with the Gen AI model. These messages are the user's side of the conversation, prompting the Gen AI to generate responses based on the context of the interaction as defined by the system message and the capabilities of the Gen AI. **Example:** **User Message**: \"Can you add a test for password validation error handling?\" This message prompts the assistant to expand on the existing test cases by adding specific scenarios related to error handling. To enhance the interactivity of a prompt, user can add multiple messages of any type by clicking the + icon, selecting the desired message type, and providing the relevant content. Additionally, user have the ability to delete, copy, and reorder messages to best fit the flow of the conversation, easily arranging them by dragging and dropping the message boxes as needed for optimal organization and presentation. VARIABLES The variables within prompts add a layer of dynamic customization, allowing you to tailor prompts to specific needs or contexts. Variables are denoted by double curly brackets (e.g., {{variable_name}}) and should be defined in the prompt's Context input box. Once a variable is entered into the CONTEXT, it automatically populates the VARIABLES section, where you can assign a value to that variable. This feature empowers users to create flexible and reusable prompts that can be easily adapted by changing the values of the variables as needed, without altering the entire prompt structure. Note : User has the flexibility to define one or more variables in each prompt. Variables can also be defined in Messages . How to Execute Prompt To execute the prompt and get the output you have 2 options: Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Completion - is supplied to generative AI models, such as text or code generators, with the intent of the model continuing or completing the given input. The AI uses the context provided in the prompt to produce a coherent and contextually relevant extension or completion of the text. Executing a Prompt Using the Chat Option: Configure the Prompt : Initialize by providing the necessary context, identifying the prompt with a name, and defining variable values (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Initiate Interaction : Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure. Executing a Prompt Using the Completion Option: Configure the Prompt : Start by providing the necessary context, naming the prompt, and setting variable values (if needed). Select the AI Model : Choose from the available AI models (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this to modulate the AI's creative or unpredictable outputs. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Choose the Completion option. Initiate Execution : Click the Run button. Managing Prompt Versions: Save, Create Versions, and Manage To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them. How to Save a Prompt: To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt. How to Create New Versions: For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements. How to Publish a Prompt To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button. Moderator Review Process Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data. Possible Outcomes of the Review After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration. Tracking the Status of Prompts Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication. How to Add Prompt into Collection To add prompts to your collection, follow these steps: Once you've created a collection , you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection . Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection. How to Export a Prompt Exporting prompts allows you to utilize them across different platforms by choosing between two specific formats: [Alita format] - this JSON format is optimized for the ELITEA platform, incorporating ELITEA-centric details such as prompt versioning, variables with their possible values, tags, and model configurations. [DIAL format] - also in JSON format, it's tailored for integration with the Epam AI Dial platform, including only information and structuring relevant to DIAL. Exporting Your Prompt: Initiate the process by clicking the Export prompt icon. Choose your preferred format (Alita or DIAL) for export. The export process will generate a file, which will then be automatically downloaded to your device. This functionalitsy facilitates the transfer and application of your prompts across different platforms by generating easily importable JSON files. How to Import a Prompt To use the prompts created in other platforms, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document. Public project - Prompts menu The Prompts menu within Public project showcases a collection of published and shared prompts within the community. Layout of the Prompts Menu The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community. Engaging with Published Prompts Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation: Liking Published Prompts Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt. Other Actions for Published Prompts Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt.s Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Prompts"},{"location":"user-guide/prompts/prompts/#prompts","text":"","title":"Prompts"},{"location":"user-guide/prompts/prompts/#private-project-prompts-menu","text":"The Prompts menu within Private project serves as a dedicated inventory for all your prompts, irrespective of their current status. Consider it your personal repository for saving and organizing the prompts you've crafted.","title":"Private project - Prompts menu"},{"location":"user-guide/prompts/prompts/#how-to-create-a-new-prompt","text":"In the context of AI and machine learning, a prompt is an instruction, question, or statement that is given to an AI model to elicit a response or output. It serves as the initial input for systems like conversational agents or generative models. Click the + Prompt button on the top right. Fill in the Name , Description , and Context fields. Click Save . Note : Name and Description are non-editable fields and can't be modified after saving the prompt.","title":"How to Create a New Prompt"},{"location":"user-guide/prompts/prompts/#tags","text":"In ELITEA, Tags serve as an efficient organizational tool that allows you to categorize and manage your collection of prompts, datasources and agents. By assigning relevant tags to each prompt, you create an intuitive labeling system that facilitates quick access and retrieval. Later on, you can filter prompts by these tags, simplifying the process of finding the precise prompt you need among a vast collection, which is especially useful for users with an extensive library of different prompt types and topics. To add a tag to the prompt : Type a tag name or select from pre-existing tags from Tags input box. Press comma or Enter to create/select tag. Click Save to save the prompt with selected tags. Note : User has the flexibility to assign one or more tags to each prompt, enabling a multi-dimensional labeling system.","title":"Tags"},{"location":"user-guide/prompts/prompts/#context","text":"The Context field in ELITEA is a crucial component where users input the necessary background information or instructions that guide the LLM in generating accurate and relevant responses. This section serves as the foundational knowledge base for the model to understand and process your specific requests. How to Input Context : Identify Key Information : Before entering data into the Context field, identify the essential details or instructions that the model needs to know to fulfill your request effectively. This could include the topic, specific terms, relevant background information, or the scope of the task. Enter the Details : In the Context field, clearly and concisely input the identified information. Ensure that the information is directly relevant to the task to maintain the model's focus and efficiency. Using Variables : For dynamic content generation, you can incorporate variables directly into the Context. Variables are denoted by double curly braces, e.g., {{variable_name}}. After defining a variable in the Context, you must specify its value in the Variables section to let the model replace the placeholder with the actual data during processing. Note : For more information how to create better instructions for prompts please check Prompting Frameworks document.","title":"CONTEXT"},{"location":"user-guide/prompts/prompts/#editability-and-version-control","text":"You can edit the Context field at any time to update or refine the instructions: Editing Existing Context : Simply make changes directly in the Context field and save them. This updates the prompt to reflect the latest information. Creating New Versions : If you want to keep the original version, you can save your changes as a new version. This is useful for comparing different versions or keeping a history of changes. Note : For more information check the Managing Prompt Versions: Save, Create Versions, and Manage . These features allow you to adapt and improve the instructions as needed, ensuring the responses remain relevant and accurate.","title":"Editability and Version Control"},{"location":"user-guide/prompts/prompts/#welcome-message","text":"The Welcome Message feature allows you to provide additional context for prompts, datasources, and agents. Currently, the Welcome Message is sent to LLM along with other instructions. How to Add the Welcome Message : Add the Welcome Message : Type the welcome message text in the input field. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured welcome message available to user in the Chat section. Using the Welcome Message : Go to the Chat section of the prompt. Here, you will see the configured Welcome Message . It will provide additional notification, instruction to the user. Examples of Welcome Message : \"Use this prompt for generating test cases\" \"Don't forget to review the generated test cases before usage\"","title":"WELCOME MESSAGE"},{"location":"user-guide/prompts/prompts/#conversation-starters","text":"The Conversation Starter feature enables you to configure and add predefined text that can be used to initiate a conversation when executing an agent. This feature is particularly useful for setting a consistent starting point for interactions facilitated by the prompt. How to Add a Conversation Starter : Access the Configuration Panel : Navigate to the Conversation Starter section. Add a Conversation Starter : Click the + icon to open the text input field where you can type the text you wish to use as a conversation starter. Save the Configuration : After entering the desired text, ensure to save the changes to the prompt. This action makes the configured conversation starter available for use. Using a Conversation Starter : Initiate a Conversation : Go to the Chat section of the prompt. Here, you will find the saved conversation starters listed. Click on the desired starter to automatically populate the chat input and execute the prompt. Examples of Conversation Starters : \"Generate test cases for provided Acceptance Criteria.\" \"Generate automatic test cases for selected [Test_Case_ID].\" By setting up conversation starters, you streamline the process of initiating specific tasks or queries, making your interactions with the prompt more efficient and standardized.","title":"CONVERSATION STARTERS"},{"location":"user-guide/prompts/prompts/#messages","text":"The MESSAGES section is a crucial component that allows users to structure the flow of interaction within a prompt. System Message : Sets the interaction's context and guidelines for the Gen AI, not visible to the user but crucial for defining the Gen AI's behavior. Assistant Message : The Gen AI's responses to user inputs, crafted within the context and constraints set by the system message. User Message : Inputs from the user, serving as prompts for the Gen AI to generate responses, thereby driving the conversation forward. In conversational models, these message types work together within prompts to create a structured and meaningful dialogue. The system message defines the framework, the user message initiates and guides the flow of the conversation, and the assistant message provides the content of the interaction, all contributing to a coherent and purposeful exchange. The System Message is a part of the prompt that provides instructions or context directly from the system's perspective. It sets the stage for the interaction, establishing rules, scenarios, or the setting for the Geb AI model to operate within. This is not generated in response to the user but is predefined by the designer of the prompt to guide the interaction. **Example:** **System Message**: \"You are an AI trained to assist in creating detailed and accurate test cases. Focus on clarity and precision, and ensure all responses adhere to software testing standards.\" This message informs the AI of its role in assisting with test case creation, setting expectations for the type of responses it should generate. The Assistant Message is the AI's response generated based on the user's input and the context provided by the system message. This message aims to fulfill the user's request for information, assistance, or interaction within the guidelines set by the system message. **Example:** **User Message**: \"Generate a test case for a login feature with email and password fields.\" **Assistant Message**: \"Test Case: Login Feature **Objective**: Verify that the user can log in using a valid email and password. **Steps**: 1. Navigate to the login page. 2. Enter a valid email in the email field. 3. Enter the corresponding password in the password field. 4. Click the login button. **Expected Result**: The user is redirected to the homepage after successful login. **Test Data**: Use registered email: user@example.com and password: SecurePass123.\" The assistant's message provides a structured test case based on the user's request, adhering to the guidelines set by the system message. The User Message is the input or query from the individual interacting with the Gen AI model. These messages are the user's side of the conversation, prompting the Gen AI to generate responses based on the context of the interaction as defined by the system message and the capabilities of the Gen AI. **Example:** **User Message**: \"Can you add a test for password validation error handling?\" This message prompts the assistant to expand on the existing test cases by adding specific scenarios related to error handling. To enhance the interactivity of a prompt, user can add multiple messages of any type by clicking the + icon, selecting the desired message type, and providing the relevant content. Additionally, user have the ability to delete, copy, and reorder messages to best fit the flow of the conversation, easily arranging them by dragging and dropping the message boxes as needed for optimal organization and presentation.","title":"MESSAGES"},{"location":"user-guide/prompts/prompts/#variables","text":"The variables within prompts add a layer of dynamic customization, allowing you to tailor prompts to specific needs or contexts. Variables are denoted by double curly brackets (e.g., {{variable_name}}) and should be defined in the prompt's Context input box. Once a variable is entered into the CONTEXT, it automatically populates the VARIABLES section, where you can assign a value to that variable. This feature empowers users to create flexible and reusable prompts that can be easily adapted by changing the values of the variables as needed, without altering the entire prompt structure. Note : User has the flexibility to define one or more variables in each prompt. Variables can also be defined in Messages .","title":"VARIABLES"},{"location":"user-guide/prompts/prompts/#how-to-execute-prompt","text":"To execute the prompt and get the output you have 2 options: Chat - is a specific type of input designed for conversational AI models, which aims to initiate or guide a dialogue. This can be in the form of a question, statement, or command that simulates human-like interaction, prompting the AI to produce a conversational response for engagement. Completion - is supplied to generative AI models, such as text or code generators, with the intent of the model continuing or completing the given input. The AI uses the context provided in the prompt to produce a coherent and contextually relevant extension or completion of the text.","title":"How to Execute Prompt"},{"location":"user-guide/prompts/prompts/#executing-a-prompt-using-the-chat-option","text":"Configure the Prompt : Initialize by providing the necessary context, identifying the prompt with a name, and defining variable values (if applicable). Select the AI Model : Choose the appropriate AI model (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this parameter to control the level of creativity or unpredictability in responses. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Initiate Interaction : Once all instructions for the prompt are set in the Context and/or Messages sections, you can start the execution by typing your text (be it a question or a command) into the chat box. Use simple commands like \"Go\", \"Start Generating\", \"Execute\", or \"Run it\" and click the Send icon to begin. These commands signal the Gen AI to process the information and generate the desired output based on the configured settings. Additional Interaction Features: Auto scroll to bottom : This option can be toggled on or off to automatically scroll to the bottom of the output as it is being generated. This feature is helpful during long outputs to keep the most recent content visible. Full Screen Mode : Increase the size of the output window for better visibility and focus. This mode can be activated to expand the output interface to the full screen. Post-Output Actions: Continue the Dialogue : To keep the conversation going, simply type your next question or command in the chat box and click the Send icon. Copy the Output : Click the Copy to clipboard icon to copy the generated text for use elsewhere. Append to Assistant Message : Use the Copy to Messages icon to add the output directly to the Assistant Message section for reference or further use. Regenerate Response : If the output isn't satisfactory, click the Regenerate icon to prompt the Gen AI to produce a new response. Delete Output : To remove the current output from the chat, click the Delete icon. Purge Chat History : For a fresh start or to clear sensitive data, click the Clean icon to erase the chat history. Specialized Download Options for Tabular outputs. When the Gen AI generates output in a tabular format, additional options become available to manage and utilize this structured data: Download as xlsx : Allows you to save the tabular output directly in an Excel spreadsheet format, facilitating easy data manipulation and analysis. Copy as markdown : Enables copying the tabular output in markdown format, suitable for use in markdown-supported environments like GitHub or blogging platforms. Copy as html : Permits copying the tabular output in HTML format, ideal for integration into web pages or emails, preserving the formatting and structure.","title":"Executing a Prompt Using the Chat Option:"},{"location":"user-guide/prompts/prompts/#executing-a-prompt-using-the-completion-option","text":"Configure the Prompt : Start by providing the necessary context, naming the prompt, and setting variable values (if needed). Select the AI Model : Choose from the available AI models (e.g., gpt-4-0125-preview, gpt-35-turbo, etc.). Set the Temperature Parameter : Adjust this to modulate the AI's creative or unpredictable outputs. Advanced Parameters (Optional): For finer control over response generation, you may adjust these optional settings: Top P (0-1) - determines the cumulative probability threshold for selecting words, balancing between creativity (higher values) and consistency (lower values). Top K - limits the choice of words to the K most probable, affecting the response's diversity and predictability. Maximum length - sets the cap on the response length, helping tailor responses to be as concise or detailed as desired. Choose the Completion option. Initiate Execution : Click the Run button.","title":"Executing a Prompt Using the Completion Option:"},{"location":"user-guide/prompts/prompts/#managing-prompt-versions-save-create-versions-and-manage","text":"To optimally manage your prompts, understanding how to save and create versions is crucial. Follow these guidelines to efficiently save your prompt, create versions, and manage them.","title":"Managing Prompt Versions: Save, Create Versions, and Manage"},{"location":"user-guide/prompts/prompts/#how-to-save-a-prompt","text":"To save your work on a prompt for the first time, simply click the Save button. This action creates what's known as the \" latest \" version of your prompt. You can continue to modify your prompt and save the changes to the \" latest \" version at any time by clicking the Save button again. If you wish to discard any changes made, you have the option to click the Discard button before saving. Remember : The \" latest \" version represents the initial version you create. You can keep updating this version with your changes by saving them, without the need to create additional versions for your prompt.","title":"How to Save a Prompt:"},{"location":"user-guide/prompts/prompts/#how-to-create-new-versions","text":"For instances where you need to create and manage different iterations of your prompt: Initiate a New Version : Start by clicking the Save As Version button. Name Your Version : When saving your work, provide a version name that clearly identifies the iteration or changes made. Click Save to confirm your entry. Best Practices for Version Naming : Length : Keep the version name concise, not exceeding 48 characters. This ensures readability and compatibility across various systems. Characters : Avoid using special characters such as spaces (\" \"), underscores (\"_\"), and others that might cause parsing or recognition issues in certain environments. Clarity : Choose names that clearly and succinctly describe the version's purpose or the changes it introduces, facilitating easier tracking and management of different versions. Upon creating a new version of the prompt, several options become available to you: Publish : Make this particular version of the prompt available for use. Delete : Remove this version of the prompt if it\u2019s no longer needed. Execute : Run this specific version of the prompt to see how it performs. Navigate Versions : Use the Version dropdown list to switch between and select different versions of the prompt. This allows for easy comparison and management of various iterations. By following these steps, you can effectively manage the lifecycle and iterations of your prompts, ensuring that each version is appropriately saved, published, and utilized as per your requirements.","title":"How to Create New Versions:"},{"location":"user-guide/prompts/prompts/#how-to-publish-a-prompt","text":"To make your prompt available to the wider Epam Network and Communities, follow these steps for publication: Publishing Initiation : With your prompt crafted and saved, initiate the process by clicking the Publish button. Version Naming : Assign an informative version name (e.g., Gen-1.0) in the pop-up window. This name should encapsulate the essence or objective of the prompt, facilitating version management and future iterations. Review Submission : Finalize your submission by clicking Publish , forwarding your prompt for the moderation review process. This stage is vital to guarantee the prompts shared within the Epam community meet a standard of quality and relevance. For publishing a specific version, firstly select the desired version and opt to publish. The chosen version's name appears in the \" Publish version \" pop-up window. It can be published as is or renamed before the final publication step. Note : After publishing, the prompt can be retracted by selecting the Unpublish button.","title":"How to Publish a Prompt"},{"location":"user-guide/prompts/prompts/#moderator-review-process","text":"Submission to publication triggers a meticulous assessment by the moderators, tasked with ensuring prompt standards for quality, efficiency, and security are upheld. Evaluative Steps Undertaken by Moderators : Initial Assessment : An initial examination confirms the prompt's completeness and adherence to the submission guidelines. Content Review : Evaluates the prompt\u2019s relevance, clarity, compatibility with best practices, and information security. Practical Evaluation : Assesses the prompt's operational feasibility, including variables, system commands, and projected outcomes. Compliance Check : Final verification against community norms and security protocols, ensuring the protection of sensitive data.","title":"Moderator Review Process"},{"location":"user-guide/prompts/prompts/#possible-outcomes-of-the-review","text":"After the review process, a prompt can be categorized into one of the following statuses: Approved : If the prompt meets all specified criteria, it is accepted and added to the Public project under the Prompts section, making it accessible to the community. Rejected : If the prompt does not meet the necessary standards, it is not approved for publication. Constructive feedback is provided to the creator, enabling them to make the required adjustments and submit a revised version for future consideration.","title":"Possible Outcomes of the Review"},{"location":"user-guide/prompts/prompts/#tracking-the-status-of-prompts","text":"Prompts undergo several statuses through the review phase: All : An overview of all submissions regardless of their review stage. Draft : Saved yet unsubmitted prompts. Published : Moderation-approved prompts, now accessible in the Public project. On Moderation : Prompts currently under review. Approval : This status indicates that the prompt is awaiting the author's approval before a new version can be published. Note : This feature is currently under development and is not available at the moment. Rejected : Prompts evaluated and declined for publication.","title":"Tracking the Status of Prompts"},{"location":"user-guide/prompts/prompts/#how-to-add-prompt-into-collection","text":"To add prompts to your collection, follow these steps: Once you've created a collection , you can start adding relevant prompts. Navigate to the prompt you wish to add and select an option to Add to Collection . Select the Collection you wish to add your prompt to from the pop-up window. You can add multiple prompts to a collection as long as they share the thematic relevance or purpose you've defined for your collection.","title":"How to Add Prompt into Collection"},{"location":"user-guide/prompts/prompts/#how-to-export-a-prompt","text":"Exporting prompts allows you to utilize them across different platforms by choosing between two specific formats: [Alita format] - this JSON format is optimized for the ELITEA platform, incorporating ELITEA-centric details such as prompt versioning, variables with their possible values, tags, and model configurations. [DIAL format] - also in JSON format, it's tailored for integration with the Epam AI Dial platform, including only information and structuring relevant to DIAL.","title":"How to Export a Prompt"},{"location":"user-guide/prompts/prompts/#exporting-your-prompt","text":"Initiate the process by clicking the Export prompt icon. Choose your preferred format (Alita or DIAL) for export. The export process will generate a file, which will then be automatically downloaded to your device. This functionalitsy facilitates the transfer and application of your prompts across different platforms by generating easily importable JSON files.","title":"Exporting Your Prompt:"},{"location":"user-guide/prompts/prompts/#how-to-import-a-prompt","text":"To use the prompts created in other platforms, follow these simple steps. Initiate Import : Select the Import option within ELITEA. Choose File : Browse and select the exported JSON prompt file. Complete Process : The prompt will be added under the Prompts section in ELITEA. Use Prompt : You can now access and utilize the imported prompt. Note : ELITEA supports Jinja template. Make sure the content and variables in your prompt adhere to this format, especially avoiding spaces in variable names. For more information please check ELITEA and Epam AI Dial document.","title":"How to Import a Prompt"},{"location":"user-guide/prompts/prompts/#public-project-prompts-menu","text":"The Prompts menu within Public project showcases a collection of published and shared prompts within the community.","title":"Public project - Prompts menu"},{"location":"user-guide/prompts/prompts/#layout-of-the-prompts-menu","text":"The Prompts menu is organized into three distinct pages, each designed to offer a unique perspective on the available prompts: Latest : Displays all recently published prompts, providing a fresh look at the newest contributions to the community. My Likes : Highlights the prompts that you have liked. This personalized page allows you to revisit favorites effortlessly. Trending : Showcases the prompts with the highest number of likes, serving as a valuable resource for discovering top-rated prompts that hold significant value and popularity within the community.","title":"Layout of the Prompts Menu"},{"location":"user-guide/prompts/prompts/#engaging-with-published-prompts","text":"Interaction within the community is highly encouraged to recognize and appreciate valuable prompts. The following actions enable active participation:","title":"Engaging with Published Prompts"},{"location":"user-guide/prompts/prompts/#liking-published-prompts","text":"Upon publication, a prompt becomes a crucial resource for the community. To support and acknowledge a prompt, use the Like functionality: To like a prompt, click on the Heart icon associated with it. If you wish to withdraw your like, simply click the Heart icon again to Unlike the prompt.","title":"Liking Published Prompts"},{"location":"user-guide/prompts/prompts/#other-actions-for-published-prompts","text":"Executing Published Prompts : View and run published prompts by clicking on the prompt card or name. Refer to the How to Execute Prompt section for guidance on running a prompt.s Note : Modifications to a published prompt cannot be saved for future use. Adding Published Prompts to Collections : Enhance your collections by including published prompts. Visit the How to Add Prompt into Collection section for instructions on incorporation. Exporting Published Prompts : For external use or backup, published prompts can be exported. Details on this process are found in the How to Export a Prompt section.","title":"Other Actions for Published Prompts"}]}